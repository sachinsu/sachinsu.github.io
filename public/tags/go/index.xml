<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Go on Learnings in IT</title>
    <link>https://sachinsu.github.io/tags/go/</link>
    <description>Recent content in Go on Learnings in IT</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Dec 2021 01:00:00 +0530</lastBuildDate><atom:link href="https://sachinsu.github.io/tags/go/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Can SQLite be considered for Server Applications?</title>
      <link>https://sachinsu.github.io/posts/is_sqlite_production_ready/</link>
      <pubDate>Thu, 30 Dec 2021 01:00:00 +0530</pubDate>
      
      <guid>https://sachinsu.github.io/posts/is_sqlite_production_ready/</guid>
      <description>Introduction While embarking on building any new server application, one of the key requirement is whether it needs durable, persistent storage of data (and in most cases, it does). This is followed by evaluating suitable data store. Likely evaluation criteria is Application&amp;rsquo;s Requirement (Tolerance for eventual consistency, High Availability etc.), Team&amp;rsquo;s familiarity, Costs, Tech. support availability and so on. In case of choices in relational databases, typical go to options are MySQL, PostgreSQL or even proprietary databases like Oracle , SQL Server.</description>
    </item>
    
    <item>
      <title>ELT approach for Data Pipelines</title>
      <link>https://sachinsu.github.io/posts/elt/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0530</pubDate>
      
      <guid>https://sachinsu.github.io/posts/elt/</guid>
      <description>Introduction While gathering data for Analytics, one often has to source data from multiple sources. Traditionally, the approach has been to do ETL (Extract-Transform-load) where,
 Extract - typically involves retrieving data from source. This could also be via streaming Transform - Apply transformation to the extracted data. Load - Loading the data in Operation Data store (ODS) or data warehouse Refer here for more details on ETL. ETL has been made easy by tools like Talend, SSIS and so on.</description>
    </item>
    
    <item>
      <title>Using Temporal.io to build Long running Workflows</title>
      <link>https://sachinsu.github.io/posts/temporalworkflow/</link>
      <pubDate>Mon, 07 Dec 2020 08:25:04 +0530</pubDate>
      
      <guid>https://sachinsu.github.io/posts/temporalworkflow/</guid>
      <description>Background In a typical business Application, there are often requirements for,
 Batch processing - Often long running Tasks like data import/export, End of day processing etc. These tasks are often scheduled to be executed at pre-defined interval or on occurance of an Event. Asychronous processing - Tasks, often part of business process / workflow, that can be performed asychronously or offloaded.  Such requirements are often fulfilled with custom approaches like batch processing frameworks, ETL Tools or using Queues or specific database features.</description>
    </item>
    
    <item>
      <title>Getting Started with OpenTelemetry</title>
      <link>https://sachinsu.github.io/posts/opentelemetry/</link>
      <pubDate>Sat, 07 Nov 2020 08:25:04 +0530</pubDate>
      
      <guid>https://sachinsu.github.io/posts/opentelemetry/</guid>
      <description>Background How many times have we landed up in a meeting staring at random slowness or such production issues in a distributed Application ? only to experience helplessness with limited (or often times no) visibility available about the runtime behavior of the Application. It often ends up in manually correlating whatever diagnostic data available from Application and combining it with trace/logs that are available from O/S, databases etc. and trying to figure out &amp;ldquo;Root cause&amp;rdquo; of the issue.</description>
    </item>
    
    <item>
      <title>Ninja - Using lightweight build system for Go projects </title>
      <link>https://sachinsu.github.io/posts/ninjabuildsystem/</link>
      <pubDate>Tue, 27 Oct 2020 10:25:04 +0530</pubDate>
      
      <guid>https://sachinsu.github.io/posts/ninjabuildsystem/</guid>
      <description>Background I primarily work on Windows for development purposes. Whenever its about writing code in Golang, invariably one comes across usage of Make. A quick check on popular Go projects on Github will show Makefile being used to automate tasks like linting, build, testing and deployment.
Being on Windows, i have been looking for alternative build tool that is easy to setup (i.e. doesn&amp;rsquo;t require mingw and such environments) and use compared to Make (which is primarily targetted at Unix and Unix like Operating Systems).</description>
    </item>
    
    <item>
      <title>Tool to mass DM followers on Twitter in Go</title>
      <link>https://sachinsu.github.io/posts/massdmgolang/</link>
      <pubDate>Sat, 25 Jul 2020 10:25:04 +0530</pubDate>
      
      <guid>https://sachinsu.github.io/posts/massdmgolang/</guid>
      <description>Background I recently came across bounty by Balaji Srinivasan to send Direct Message to all twitter followers. Currently, i do not intend to participate in bounty and this is mere exercise.
This is an attempt to write CLI tool in Golang in response to it.
For detailed requirements, refer here
Approach In Brief,
  CLI should,
 accept arguments like Twitter API Key,Auth token, DM Message Download all followers (with profile details) Rank them by Criteria (e.</description>
    </item>
    
  </channel>
</rss>
