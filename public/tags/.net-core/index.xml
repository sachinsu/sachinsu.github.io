<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>.Net Core on Learnings in IT</title><link>http://localhost:1313/tags/.net-core/</link><description>Recent content in .Net Core on Learnings in IT</description><generator>Hugo</generator><language>en</language><lastBuildDate>Sat, 11 May 2024 10:25:04 +0530</lastBuildDate><atom:link href="http://localhost:1313/tags/.net-core/index.xml" rel="self" type="application/rss+xml"/><item><title>Using local LLM with Ollama and Semantic Kernel</title><link>http://localhost:1313/posts/ollamasemantickernel/</link><pubDate>Sat, 11 May 2024 10:25:04 +0530</pubDate><guid>http://localhost:1313/posts/ollamasemantickernel/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>Artificial Intelligence, especially Large language models (LLMs) are all in high demand. Since OpenAI released ChatGPT, interest has gone up multi-fold. Since 2023, Powerful LLMs can be run on local machines. Local Large Language Models offer advantages in terms of data privacy and security and can be enriched using enterprise-specific data using Retrieval augmentation generation (RAG).Several tools exist that make it relatively easy to obtain, run and manage such models locally on our machines. Few examples are &lt;a href=https://ollama.com/
 
 target=_blank rel="noopener noreferrer"
>Ollama&lt;/a>, &lt;a href=https://github.com/hwchase17/langchain
 
 target=_blank rel="noopener noreferrer"
>Langchain&lt;/a>, &lt;a href=localai.io
 
 
>LocalAI&lt;/a>.&lt;/p></description></item><item><title>Getting Started with OpenTelemetry</title><link>http://localhost:1313/posts/opentelemetry/</link><pubDate>Sat, 07 Nov 2020 08:25:04 +0530</pubDate><guid>http://localhost:1313/posts/opentelemetry/</guid><description>&lt;h2 id="background">Background&lt;/h2>
&lt;p>How many times have we landed up in a meeting staring at random slowness or such production issues in a distributed Application ? only to experience helplessness with limited (or often times no) visibility available about the runtime behavior of the Application. It often ends up in manually correlating whatever diagnostic data available from Application and combining it with trace/logs that are available from O/S, databases etc. and trying to figure out &amp;ldquo;Root cause&amp;rdquo; of the issue.&lt;/p></description></item><item><title>Using Channels for High performance Producer consumer implementation</title><link>http://localhost:1313/posts/channelsforproducerconsumer/</link><pubDate>Wed, 12 Feb 2020 10:25:04 +0530</pubDate><guid>http://localhost:1313/posts/channelsforproducerconsumer/</guid><description>&lt;h2 id="background">Background&lt;/h2>
&lt;p>Recently, i got involved in assignment where in an application was facing issues with throughput. Expectation is to support more than 500 transactions per second while load testing results were indicating system was experiencing high latency beyond 100+ transactions per second.&lt;/p>
&lt;p>This application is developed in .NET Framework + .NET Core and primarily uses Relational Database for persistence and has point to point integration (mainly over HTTP) with internal &amp;amp; external application(s).&lt;/p></description></item></channel></rss>