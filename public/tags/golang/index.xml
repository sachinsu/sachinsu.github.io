<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Golang on Learnings in IT</title>
    <link>http://localhost:1313/tags/golang/</link>
    <description>Recent content in Golang on Learnings in IT</description>
    <generator>Hugo -- 0.149.0</generator>
    <language>en</language>
    <lastBuildDate>Sat, 11 May 2024 10:25:04 +0530</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/golang/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using local LLM with Ollama and Semantic Kernel</title>
      <link>http://localhost:1313/posts/ollamasemantickernel/</link>
      <pubDate>Sat, 11 May 2024 10:25:04 +0530</pubDate>
      <guid>http://localhost:1313/posts/ollamasemantickernel/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Artificial Intelligence, especially Large language models (LLMs) are all in high demand. Since OpenAI released ChatGPT, interest has gone up multi-fold. Since 2023, Powerful LLMs can be run on local machines. Local Large Language Models  offer advantages in terms of data privacy and security and can be enriched using enterprise-specific data using Retrieval augmentation generation (RAG).Several tools exist that make it relatively easy to obtain, run and manage such models locally on our machines. Few examples are &lt;a href=https://ollama.com/
    
    target=_blank rel=&#34;noopener noreferrer&#34;
&gt;Ollama&lt;/a&gt;, &lt;a href=https://github.com/hwchase17/langchain
    
    target=_blank rel=&#34;noopener noreferrer&#34;
&gt;Langchain&lt;/a&gt;,  &lt;a href=localai.io
    
    
&gt;LocalAI&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Resiliency Testing with Toxiproxy</title>
      <link>http://localhost:1313/posts/resiliencytoxiproxy/</link>
      <pubDate>Sat, 09 Jan 2021 10:25:04 +0530</pubDate>
      <guid>http://localhost:1313/posts/resiliencytoxiproxy/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;In a typical workflow of software development, Developer implements a Unit/component, tests it and pushes  the changes to source control repository. It then goes through Continuous integration, automated testing, provisioning and deployment. Given High availability requirements expected (or should i say assumed) nowadays,  As much as functional correctness of the Unit, it is also important to test how a Unit/Component handles failures, delays etc. in distributed environment.  Often, such behavior is observed in production itself, unless project team is following practices of &lt;a href=https://netflixtechblog.com/tagged/chaos-engineering
    
    target=_blank rel=&#34;noopener noreferrer&#34;
&gt;Chaos engineering&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Temporal.io to build Long running Workflows</title>
      <link>http://localhost:1313/posts/temporalworkflow/</link>
      <pubDate>Mon, 07 Dec 2020 08:25:04 +0530</pubDate>
      <guid>http://localhost:1313/posts/temporalworkflow/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;In a typical business Application, there are often requirements for,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Batch processing - Often long running Tasks like data import/export, End of day processing etc. These tasks are often scheduled to be executed at pre-defined interval or on occurance of an Event.&lt;/li&gt;
&lt;li&gt;Asychronous processing - Tasks, often part of business process / workflow, that can be performed asychronously or offloaded.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Such requirements are often fulfilled with custom approaches like batch processing frameworks, ETL Tools or using Queues or specific database features.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Getting Started with OpenTelemetry</title>
      <link>http://localhost:1313/posts/opentelemetry/</link>
      <pubDate>Sat, 07 Nov 2020 08:25:04 +0530</pubDate>
      <guid>http://localhost:1313/posts/opentelemetry/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;How many times have we landed up in a meeting staring at random slowness or such production issues in a distributed Application ? only to experience helplessness with limited (or often times no) visibility available about the runtime behavior of the Application. It often ends up in manually correlating whatever diagnostic data available from Application and combining it with  trace/logs that are available from O/S, databases etc. and trying to figure out &amp;ldquo;Root cause&amp;rdquo; of the issue.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ninja - Using lightweight build system for Go projects </title>
      <link>http://localhost:1313/posts/ninjabuildsystem/</link>
      <pubDate>Tue, 27 Oct 2020 10:25:04 +0530</pubDate>
      <guid>http://localhost:1313/posts/ninjabuildsystem/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;I primarily work on Windows for development purposes. Whenever its about writing code in Golang, invariably one comes across usage of Make. A quick check on popular Go projects on Github will show Makefile being used to automate tasks like linting, build, testing and deployment.&lt;/p&gt;
&lt;p&gt;Being on Windows, i have been looking for alternative build tool that is easy to setup (i.e. doesn&amp;rsquo;t require mingw and such environments) and use compared to Make (which is primarily targetted at Unix and Unix like Operating Systems).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Is WebAssembly future of Web Development</title>
      <link>http://localhost:1313/posts/webassembly/</link>
      <pubDate>Tue, 02 Jun 2020 10:25:04 +0530</pubDate>
      <guid>http://localhost:1313/posts/webassembly/</guid>
      <description>&lt;p&gt;Over the last many years, de-facto language of the Web (specifically front-end) has been Javascript (and variants like Typescript, ECMAScript versions and so on). The Web development has been revolving around HTML+CSS+Javascript trio. It all started with support for Javascript in browsers, followed by addition of XMLHTTP API, Rich DOM Manipulation Support in Javascript. To induce order and apply patterns to Javascript&amp;rsquo;s usage in browsers, numerous frameworks and libraries were introduced like &lt;a href=https://reactjs.org
    
    target=_blank rel=&#34;noopener noreferrer&#34;
&gt;React&lt;/a&gt; and &lt;a href=https://vuejs.org
    
    target=_blank rel=&#34;noopener noreferrer&#34;
&gt;Vue&lt;/a&gt; among others. To begin with, The target used to be browsers on Large Devices like Desktop &amp;amp; Laptops. However, soon all sorts of devices were targetted with advent of Responsive and Progressive CSS+Javascript libraries eg. &lt;a href=https://getbootstrap.com
    
    target=_blank rel=&#34;noopener noreferrer&#34;
&gt;Bootstrap&lt;/a&gt;. Offline Support soon came in ref: &lt;a href=https://electronjs.org
    
    target=_blank rel=&#34;noopener noreferrer&#34;
&gt;Electron&lt;/a&gt; and &lt;a href=https://web.dev/progressive-web-apps/
    
    target=_blank rel=&#34;noopener noreferrer&#34;
&gt;Progressive Web Applications&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
