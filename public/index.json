[{"content":"Introduction Architecture plays a pivotal role in the delivery of software in terms of achieving business goals set forth for the software like maintainability, availability, performance and many more. It helps introduce structured approach to development by means of having appropriate abstractions. Typical driving forces for a software are,\nFunctional requirements Quality attributes (performance, scalability, availability etc.) Agility (Need to respond fluently to changes) Constraints (Deployment platform) Principles (Automated testing, Automated deployment etc.) In this pursuit, there are alternate styles to structure software. Lets look at below ones which are dominant,\nMonolith - Traditional approach involving tiering or layering by means of separation of concerns like UI, business logic and Data into layers/tiers. Each layer is \u0026ldquo;horizontally\u0026rdquo; sliced (Packaged by Layer). Promotes rules like UI/Controller must talk to Service which should only talk to Repository/Data Access layer. Typical observation is that changes to any one of the layers usually results in changes across all layers. Any change typically involves re-deployment of entire or most parts of Application.\nMicroservices - an approach for developing a single application as a suite of small services, each running in it\u0026rsquo;s own processes and communicating with lightweight mechanisms like HTTP based APIs. Services are built around business capabilities and are independently deployable. Key objective is bare minimum of centralized management. Typically suitable for Large, complex software projects.\nAt a high level, Monolith approach has shown need for adaptation when it comes of agility expected from Software, while MicroServices provides agility , its often requires change in Organization\u0026rsquo;s approach and found to be suitable for large use cases where benefits outweigh related concerns like Eventual consistency, Operational Complexity and Distributed nature (Remote calls/(Fallacies of Distributed computing)[https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing]).\nGiven this, are their tailored approaches aimed at specific requirements ? Let\u0026rsquo;s look at them ,\nModular Monolith - Approach that tries to have golden mean between Monolith and Microservices by structuring the application into independent modules or components with well-defined boundaries with future possibilities of carving out microservices.\nVertical Slice Architecture (VSA)- Architecture is built around distinct requests, encapsulating and grouping all concerns from front-end to back-end.\nClean Architecture - Paradigm originally proposed by Robert Martin that isolates interfaces (user interfaces, databases, external systems, devices) from business logic.\nThis article aims to provide general context and aid in decision making about the above architecture styles. Please note Limitations of General Advice\nUnderstanding Each Architecture Individually: Modular Monolith Core Idea: is a way of organizing a software application into set of well defined, independent, extractable Modules.Modules have ‌specific functionality, which can be independently developed and tested, while the entire application is deployed as a single unit.\nKey Characteristics: Encapsulation, clear boundaries between modules, high cohesion within modules, low coupling between modules.\nBenefits: Easier to start, single deployment, can evolve towards microservices if needed, good for smaller to medium teams. Suitable to manage when significant domain-specific changes are expected.\nPotential Drawbacks/Concerns: Can become a \u0026ldquo;big ball of mud\u0026rdquo; if modularity isn\u0026rsquo;t strictly enforced, deployment unit size. These issues may be addressed using Fitness functions (e.g. Cyclomatic complexity, coupling) and static code analysis etc. Carries on with some monolith bottlenecks like fault tolerance, scalability, elasticity etc.\nModular Monolith Vertical Slice Architecture (VSA) Core Idea: This is in a way evolution of Modular Monolith where focus is on axes of expected change and modelling features end-to-end for it. For every individual request(s), all the code is co-located across layers. Organizing code around business capabilities or \u0026ldquo;verticals\u0026rdquo; (e.g., user management, order processing) rather than technical layers (UI, Business Logic, Data Access). A Module may have one or more features. Each feature is self-contained and can be developed/tested independently. Module boundaries are explicit. Aim is to Minimize coupling between slices and maximize within slice.\nKey Characteristics: Code organized by feature/capability, strong encapsulation within slices, minimal dependencies between slices, often involves defining clear boundaries.\nBenefits: High cohesion within slices, improved team autonomy, easier to understand and modify specific features, good for evolving complexity.\nPotential Drawbacks: Can lead to duplication if not managed carefully (e.g., common domain logic), requires a discipline of keeping slices truly independent.\nVertical Slice Architecture Vertical Slice Architecture Clean Architecture (or similar layered/hexagonal approaches): Core Idea: opinionated way to structure code and to separate the concerns of the application into layers. Core aim is to separate the business logic from infrastructure (i.e. data Access, external integrations etc.) and presentation layers. Originally popularized by Robert C Martin. Crux is to have business logic isolated from less stable external elements.\nKey Characteristics:\nDomain as the core, use of interfaces for external interactions. Aim is to achieve maintainability, testability, and extendability Ability to change infrastructure and presentation without affecting core business logic Ideal for complex, medium to large scale applications where maintainability and scalability are key objectives. Benefits: High testability, framework independence, maintainability, clear separation of concerns, easier to swap out external components.\nPotential Drawbacks: Can be perceived as overly complex for simple projects. Strict adhering to layering and use of interfaces often lead to lot of boilerplate code. Simple Applications may find it as overhead to implement.\nClean Architecture Comparative Analysis: Aspect Modular Monolith Vertical Slice Architecture Clean Architecture Application Size Suitable for small to medium Sized Applications. Easy to get started and is cost effective. Agnostic of Application size. But keep watch for refactoring opty. Larger initial codebase due to abstractions but clean separation helps irrespective of size Organization Modular approach per Domain functionalities By feature or use case, with each slice containing all relevant layers. by layers i.e. Presentation, Domain and Infrastructure Maintainability, Testability Individual slices/use cases can be tested Easier to maintain and test, as changes are localized to a single feature slice. Improved testability Flexibility Improved due to modularity but may require complete deployment High. Different features can use different technical implementations. High due to isolation of layers Scalability Useful when future scalability requirements are uncertain. Slices can be deployed independently Can be achieved by means of isolation of state management and ability to switch implementations Testability better than trad.Monolith High Each layer can be tested independently, Synergies and Overlaps: As one says there is no \u0026ldquo;one size fits all\u0026rdquo;, similarly there is no reason to constrain self to use a specific architectural style for Application and neither of the above styles are mutually exclusive. A Modular Monolith is where modules are structured but can use Vertical slice Architecture principles. A VSA based implementation can adopt clean Architecture principles with clean separation between domain logic and adapters (UI, Data stores, external integrations etc.) While VSA focuses on what to organize by, Clean Architecture focuses on how to organize within those boundaries.\nConclusion: The Architecture styles evolve as they are tested against real-time requirements in terms of flexibility, maintainability, scalability and so on. There is no one architecture style that fits many situation but each of the style provides path way to think and analyze fitment for the actual use case. As the First Law of Software Architecture states that everything in software is a trade-off, key is to evaluate these styles against requirements and arrive at tradeoffs and decide based on it.\nUseful References Modular Monolith 1 Modular Monolith 2 Modular Monolith 3 Vertical Slice Architecture 1 Clean Architecture from Robert Martin Clean Architecture 1 Clean Architecture 2 Clean Architecture 3 Cognitive load is all that matters Happy Coding !!\n","permalink":"http://localhost:1313/posts/comparearchitecturestyles/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eArchitecture plays a pivotal role in the delivery of software in terms of achieving business goals set forth for the software like maintainability, availability, performance and many more. It helps introduce structured approach to development by means of having appropriate abstractions. Typical driving forces for a software are,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFunctional requirements\u003c/li\u003e\n\u003cli\u003eQuality attributes (performance, scalability, availability etc.)\u003c/li\u003e\n\u003cli\u003eAgility (Need to respond fluently to changes)\u003c/li\u003e\n\u003cli\u003eConstraints (Deployment platform)\u003c/li\u003e\n\u003cli\u003ePrinciples (Automated testing, Automated deployment etc.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this pursuit, there are alternate styles to structure software. Lets look at below ones which are dominant,\u003c/p\u003e","title":"Clean Architecture, Modular Monolith and Vertical Slice Architecture "},{"content":"Introduction A Software Bill of Materials (SBOM) is a list of all the components, libraries, and modules that make up a software, providing transparency into its composition. It describes various packages and dependencies that go into creating a software artifact.\nWhy ? Software products are composed of many different components, some of which might come from third party sources. These third-party components and dependencies can have vulnerabilities, which attackers can exploit, leading to security incident or breaches. Key threats include attackers inserting malicious code, vulnerabilities in outdated components, and breaches by compromised suppliers. These issues can lead to data breaches, operational disruptions, and reputational damage. SBOM can help improve software security and protect against potential threats.\nEffective Incident Response - SBOM can assist in speeding up by providing detailed information on dependencies.\nVulnerabilities identification and patch management - Using SBOM, organizations can quickly spot and address known vulnerabilities in the software by patching them.\nCompliance - SBOM helps organizations to streamline adherence to security regulations, guidelines and best practices on software security by providing required transparency in software composition.\nMany Governments around that world are now recommending SBOM like,\nNIST CERT-IN Tools and Processes Lets look at ways to generate SBOM.\nThere are standards/specifications available to represent bills of material including SBOM. Important ones are,\nSPDX - An open standard capable of representing systems with software components in as SBOMs (Software Bill of Materials) and other AI, data and security references supporting a range of risk management use cases. CycloneDX - is a full-stack Bill of Materials (BOM) standard that provides advanced supply chain capabilities for cyber risk reduction. CycloneDX is an Ecma International standard published as ECMA-424. Various tools and libraries typically scan the container images, file systems and generate a Software Bill of Materials as per above specifications. Each tool supports parsing of files for various languages/platforms to extract details on dependencies.\nBelow are some of the open source tools available,\nCycloneDX has repository that contains various tools like, Cyclonedx-CLI - Cli for conversion, analysis, merging cyclonedx-dotnet - for .NET projects cyclonedx-gomod - for Go Modules cyclonedx-core-java - For Core Java Syft - Supports C/C++/Dotnet/Java/JavaScript and many more. Refer here.It can generate BOM in either SPDX or CycloneDX specification. Microsoft SBOM tool - Generates SPDX 2.2 compatible SBOM. The above tools are typically integrated in Build (CI/CD) pipeline for automated SBOM Generation.\nHigh level Adoption approach could be,\nInitiation Identify Critical Assets and Develop a Project Plan. Determine the SBOM format and minimum requirements. Identify security requirements,secure storage and tooling. Plan for Proof of Concept Progress Secure Installation and Operation Guidance Development. Preparation of SBOM Integrate SBOM in each phase of Secure Software Development Lifecycle. On going Analysis and review of existing SBOM periodically and any changes as needed Conclusion: Each of the above tool help generate SBOM for the platform in either the standard Specification format (SPDX/CycloneDX) or tool\u0026rsquo;s own proprietary format (e.g. syft has its own specification too.). Depending on the requirement, these tools can be effectively used for the projects.\nUseful References HBOM - Inventory hardware components for IoT, ICS, and other types of embedded and connected devices. OWASP AIBOM - AIBOM aims to provide transparency into how AI models are built, trained, and deployed. Happy Coding !!\n","permalink":"http://localhost:1313/posts/sbom/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA Software Bill of Materials (SBOM) is a list of all the components, libraries, and modules that make\nup a software, providing transparency into its composition. It describes various packages and dependencies that go into creating a software artifact.\u003c/p\u003e\n\u003ch3 id=\"why-\"\u003eWhy ?\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSoftware products are composed of many different components, some of which might come from\nthird party sources. These third-party components and dependencies can have vulnerabilities, which\nattackers can exploit, leading to security incident or breaches. Key threats include attackers inserting\nmalicious code, vulnerabilities in outdated components, and breaches by compromised suppliers. These issues can lead to data breaches, operational disruptions, and reputational damage. SBOM can help improve software security and protect against potential threats.\u003c/p\u003e","title":"What is Software Bill of Material (SBOM)"},{"content":"Introduction In the ever-evolving landscape of AI and machine learning, Google\u0026rsquo;s MCP Toolbox for Databases stands out. This open-source server enables developers to connect generative AI applications to enterprise databases, facilitating prompt-based querying and natural language processing (NLP). Whether you\u0026rsquo;re setting up your LLM on-premises using OLLAMA or leveraging providers like Gemini, Claude, or OpenAI, this toolbox offers a versatile and powerful solution. Lets explore it in detail.\nQuick Start Guide To get started with the Gen AI Toolbox for Databases, follow the official quick start guide. This guide provides detailed instructions on setting up your database and integrating it with the toolbox. While the guide focuses on using PostgreSQL, the principles can be applied to other supported databases as well.\nStep-by-Step Setup For a detailed walkthrough, refer here.\nSet Up Your Database: Ensure your database (PostgreSQL, in this case) is configured and running.\nInstall the Toolbox: Download and install the Gen AI Toolbox server.\nConfigure Your Connection: Set up the connection parameters to link your database with the toolbox.\nDeploy Your LLM: Choose your LLM provider (OLLAMA, Gemini, Claude, OpenAI) and configure it to work with the toolbox. I decided to try with Llama3.2 (Initially tried with Deepseek-r1 but it has some issues when used via Ollama w.r.t. tools usage) via Ollama.\nBelow are the additional steps,\nSet up additional libraries like,\nlangchain-ollama using pip install langchain-ollama\nollama using pip install ollama\nBelow are the changes to sample code.\nInclude package ref. at the top, from langchain_ollama import ChatOllama\nChange main functions code to use Ollama as,\ndef main(): # TODO(developer): replace this with another model if needed model = ChatOllama(model=\u0026#34;llama3.2:latest\u0026#34;) Ensure that\nOllama is running either as a Service or using ollama serve.\nRun toolbox, using ./toolbox --tools_file \u0026quot;tools.yml\u0026quot; . Note: Replace the name of configuration file as needed.\nMake any changes to yaml configuration for toolbox. This includes configuring Tools that are used by LLMs while inferencing. Each tool is mapped to specific Query and associated parameters.\nToolbox Configuration Run the code python \u0026lt;Name of file\u0026gt;.py\nIf all goes well, agent queries the database and one can confirm by the log generated by the toolbox and provides output.\nResponse to Prompt Key Use Cases The Gen AI Toolbox for Databases opens up a plethora of use cases, making it a valuable asset for enterprises:\n1. Prompt-Based Querying With the integration of LLMs, users can query databases using natural language prompts. This simplifies the process of data retrieval and analysis, making it accessible to non-technical users.\n2. Enhanced Data Insights By leveraging NLP, the toolbox can provide deeper insights into the data. It can identify patterns, trends, and anomalies that might be missed by traditional querying methods.\n3. Automated Reporting The toolbox can automate the generation of reports based on user queries. This not only saves time but also ensures that the reports are comprehensive and up-to-date.\n4. Real-Time Data Interaction Users can interact with the database in real-time, making it possible to get instant responses to their queries. This is particularly useful for applications that require up-to-the-minute data.\n5. Privacy and Security Users can only interact with the database via the queries specified in tools configuration for Toolbox. This is useful if database owner wants fine-grained control or restrict access to data. Use of local LLM for inference caters to cases where privacy is critical and expenses are sensitive topic and somewhat delayed response time is acceptable.\nConclusion Google\u0026rsquo;s Gen AI Toolbox for Databases is a game-changer in the realm of database management and AI integration. By enabling prompt-based querying and NLP, it democratizes access to data and enhances the capabilities of enterprise applications. Whether you\u0026rsquo;re working with on-premises setups or cloud providers, this toolbox offers a robust and flexible solution.\nFor more information, check out the official documentation and the GitHub repository.\nReferences: Google Cloud Blog\nGitHub Repository\nLangChain Announcement\nRunning Local LLMs\nMCP- What is it?\n","permalink":"http://localhost:1313/posts/genaidb/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn the ever-evolving landscape of AI and machine learning, Google\u0026rsquo;s \u003ca href=https://googleapis.github.io/genai-toolbox\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMCP Toolbox for Databases\u003c/a\u003e stands out. This open-source server enables developers to connect generative AI applications to enterprise databases, facilitating prompt-based querying and natural language processing (NLP). Whether you\u0026rsquo;re setting up your LLM on-premises using OLLAMA or leveraging providers like Gemini, Claude, or OpenAI, this toolbox offers a versatile and powerful solution. Lets explore it in detail.\u003c/p\u003e","title":"Exploring MCP Toolbox for Databases: A New Era of Database Querying"},{"content":"Summary Explore various approaches to handle out-of-order or delayed processing, addressing scenarios like bulk operations and long-running tasks. Learn about message queues, background workers, and other techniques to improve application responsiveness.\nIntroduction In the world of software development, we often encounter tasks that don\u0026rsquo;t need to or (should not) be completed immediately. Whether it\u0026rsquo;s sending mass emails, processing large datasets, or handling complex computations. Blocking the user\u0026rsquo;s main flow (Either on Web App or API) for these operations is rarely a good idea. That\u0026rsquo;s where out-of-order or delayed processing comes in.\nThis post will delve into different strategies for managing these asynchronous tasks, comparing their strengths and weaknesses, and providing practical examples.\nUse Cases Bulk Operations: Sending bulk emails, generating reports, or processing large files. Long-Running Tasks: Video transcoding, complex calculations, or data analysis. Non-Blocking User Interactions: Accepting user requests without waiting for completion, improving responsiveness Approaches Thread Pools (In-Process Concurrency)\nDescription: Using threads to execute tasks concurrently within the same application process. Pros: Simple to implement, low overhead for small tasks. Cons: Limited scalability, potential for resource contention, not suitable for distributed systems. Example (Go): package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func processTask(taskID int) { fmt.Printf(\u0026#34;Processing task %d\\n\u0026#34;, taskID) } func main() { tasks := []int{1, 2, 3, 4, 5} var wg sync.WaitGroup for _, task := range tasks { wg.Add(1) go func(id int) { defer wg.Done() processTask(id) }(task) } wg.Wait() } Example (C#): using System; using System.Threading.Tasks; public class Program { public static async Task ProcessTask(int taskID) { // Console.WriteLine($\u0026#34;Processing task {taskID}\u0026#34;); await Task.Delay(taskID); } public static async Task Main(string[] args) { int[] tasks = { 1, 2, 3, 4, 5 }; var taskList = new Task[tasks.Length]; for (int i = 0; i \u0026lt; tasks.Length; i++) { int taskID = tasks[i]; taskList[i] = ProcessTask(taskID); } await Task.WhenAll(taskList); Console.WriteLine(\u0026#34;All tasks completed.\u0026#34;); } } Background Workers (Dedicated Processes or as a sidekick)\nDescription: Running dedicated processes or services to handle background tasks. Pros: Good isolation, scalability, suitable for long-running tasks. Cons: Increased complexity, requires process management. Examples: Machinery (Go), Quartz.net (.NET), Hangfire (.NET). Often used with message queues. Go: Implementing a background worker involves creating a separate executable, or using a library that facilitates background task execution like Machinery. C# , Out-of-process approach can be implemented using Windows Service or Systemd on Linux. Alternatively, dedicated processes can be run as scoped service and process task(s) sequentially. Refer to \u0026ldquo;Queued Background tasks\u0026rdquo; example here. Scheduled Tasks (Cron Jobs/Task Schedulers)\nDescription: Executing tasks at specific intervals or times. Pros: Simple scheduling, suitable for recurring tasks. Cons: Less flexible than message queues, not ideal for event-driven tasks. Go: Using cron libraries like Gocron or Windows Task Scheduler. C#: Using Windows Task Scheduler, or libraries like Quartz.NET/hangfire. Message Queues (Asynchronous Communication)\nDescription: Using a message broker (e.g., RabbitMQ, Kafka, Redis Pub/Sub) to decouple task producers and consumers. Pros: Scalable, fault-tolerant, supports distributed systems, excellent for decoupling. Cons: Requires additional infrastructure, increased complexity. Example (Conceptual): Producer: Sends a message (task details) to a queue. Consumer (Worker): Retrieves the message from the queue and processes the task. Considerations: Message durability, delivery guarantees, message serialization. Go (using RabbitMQ): (Requires RabbitMQ client library) // Example using amqp library. Add error handling. // ... C# (using RabbitMQ): (Requires RabbitMQ client library) // Example using RabbitMQ.Client library. Add error handling. // ... Asynchronous APIs (Callbacks/Promises/Async-Await)\nDescription: Allowing client applications to initiate tasks and receive results later without blocking. Pros: Improves client-side responsiveness, good for web applications. Cons: Requires careful handling of asynchronous operations, potential for callback hell (older callback based approaches).d q Go: Using Goroutines and channels for asynchronous communication. C#: refer to implementation of Asynchronous (long-running) Apis here. Typical flow is as follow,\nAsync Request/Reply pattern Outbox Pattern\nDescription: The Outbox Pattern provides a reliable way to publish events or messages when database transactions are involved. Instead of directly publishing messages to a message queue, events are stored in an outbox table within the same database. This helps with consistency issues as updates can be part of same transaction context. A separate process then reads these events from the outbox table and publishes them to the message queue. This pattern is typically used alongside other patterns mentioned above.\nBenefits:\nAtomicity: Ensures that events are published only if the database transaction succeeds. Reliability: Prevents message loss in case of application crashes or network issues. Decoupling: Decouples the application from the message queue. Implementation: 1. Outbox Table: Typical outbox table to store events:\n```sql CREATE TABLE outbox ( id SERIAL PRIMARY KEY, payload JSONB NOT NULL, destination VARCHAR(255) NOT NULL, processed BOOLEAN NOT NULL DEFAULT FALSE, created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW() ); ``` Publishing Events: When an event occurs, insert a row into the outbox table within the same database transaction as the business logic. Background Processor: Create a background process that reads events from the outbox table, publishes them to the message queue, and updates the processed column. Idempotency: ensure that the message consumer is idempotent, to handle possible duplicate messages. Example (C# with PostgreSQL):\n```csharp using Npgsql; using System.Text; using System.Text.Json; using System.Threading; using System.Threading.Tasks; public class OutboxProcessor { private readonly string _connectionString; private readonly IConnection _rabbitConnection; public OutboxProcessor(string connectionString, IConnection rabbitConnection) { _connectionString = connectionString; _rabbitConnection = rabbitConnection; } public async Task ProcessOutbox(CancellationToken cancellationToken) { while (!cancellationToken.IsCancellationRequested) { try { using (var connection = new NpgsqlConnection(_connectionString)) { await connection.OpenAsync(cancellationToken); using (var transaction = connection.BeginTransaction()) { using (var command = new NpgsqlCommand( \u0026quot;SELECT id, payload, destination FROM outbox WHERE processed = FALSE FOR UPDATE SKIP LOCKED LIMIT 1\u0026quot;, connection, transaction)) { using (var reader = await command.ExecuteReaderAsync(cancellationToken)) { if (await reader.ReadAsync(cancellationToken)) { int id = reader.GetInt32(0); string payload = reader.GetString(1); string destination = reader.GetString(2); PublishToRabbitMQ(destination, payload); using (var updateCommand = new NpgsqlCommand( \u0026quot;UPDATE outbox SET processed = TRUE WHERE id = @id\u0026quot;, connection, transaction)) { updateCommand.Parameters.AddWithValue(\u0026quot;id\u0026quot;, id); await updateCommand.ExecuteNonQueryAsync(cancellationToken); } } } } await transaction.CommitAsync(cancellationToken); } } } catch (Exception ex) { Console.WriteLine($\u0026quot;Error processing outbox: {ex.Message}\u0026quot;); } await Task.Delay(1000, cancellationToken); } } private void PublishToRabbitMQ(string destination, string payload) { using (var channel = _rabbitConnection.CreateModel()) { channel.BasicPublish(exchange: \u0026quot;\u0026quot;, routingKey: destination, basicProperties: null, body: Encoding.UTF8.GetBytes(payload)); } } } ``` Notice the use of `SELECT .... FOR UPDATE ..... SKIP LOCKED`. This is useful in case outbox table will be accessed/read concurrently by multiple processes. This ensures read operation will skip (and not wait) records that have `read lock`. This feature is available in most of RDBMS. Comparison Table Approach Scalability Complexity Fault Tolerance Use Cases Thread Pools Low Low Low Simple, in-process tasks Message Queues High High High Distributed systems, decoupling, asynchronous communication Background Workers High Medium Medium Long-running tasks, dedicated processing Scheduled Tasks Medium Low Low Recurring tasks, scheduled operations Asynchronous APIs Medium Medium Medium Web applications, non-blocking client interactions, improved responsiveness \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; Conclusion Choosing the right approach depends on the specific requirements of your application. Message queues and background workers offer excellent scalability and fault tolerance for complex, distributed systems. Thread pools and scheduled tasks are suitable for simpler scenarios. Asynchronous APIs are crucial for improving client-side responsiveness in web applications.\nBy understanding these techniques, you can effectively manage out-of-order and delayed processing, enhancing the performance and user experience of your applications.\nUseful links (#usefullinks) Happy Coding !!\n","permalink":"http://localhost:1313/posts/outoforder/","summary":"\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eExplore various approaches to handle out-of-order or delayed processing, addressing scenarios like bulk operations and long-running tasks. Learn about message queues, background workers, and other techniques to improve application responsiveness.\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn the world of software development, we often encounter tasks that don\u0026rsquo;t need to or (should not) be completed immediately. Whether it\u0026rsquo;s sending mass emails, processing large datasets, or handling complex computations. Blocking the user\u0026rsquo;s main flow (Either on Web App or API) for these operations is rarely a good idea. That\u0026rsquo;s where out-of-order or delayed processing comes in.\u003c/p\u003e","title":"Taming Time: Strategies for Out-of-Order and Delayed Processing"},{"content":"Background There was a requirement to perform series of tasks, involving generation of output files, such that the required throughput is achieved. These tasks involve database read operation, external API invocation and file i/o. Generally, benchmarking showed that executing them in sequential way was not helpful. What if asynchronous programming be used to perform this task.\nSo Lets Start.\nApproach Lets assume that this typical use case requires,\nfetching data from database for the purpose of merging placeholders in a Template and perform mail merge\nGenerate PDF file from mail-merged output of last step (say HTML to PDF)\nsend notification to users via third party API.\nThe requirement is to perform these steps in such a way that 50 or more notifications (with file) are sent per minute.\nFor the purpose of simplicity, lets assume that,\nDatabase read operation and HTML generation basis template, takes upto 2 seconds per iteration We will use Puppeteer Sharp library for PDF Generation External API Integration takes up to 2 seconds per call Since current approach of sequential execution is not helpful, lets try below (both the methods process 5 requests[i.e. generate 5 pdf files] per iteration),\nUsing Task asynchronous programming model - This uses Task library to start tasks in parallel and subsequently process them as each completes. Using Task Async. Library Using Dataflow - Task Parallel Library - This uses Dataflow Library to orchestrate each step in the process and use parallelism for performance. Using DataFlow Library Below is the Report from Benchmarkdotnet for both the approaches.\nBenchmark Results As one can see, using above techniques, It is straightforward to write asynchronous code that performs parallel execution and achieves better performance compared to sequential alternate approach.\nReferences:\nBenchmarkDotNet Introduction to Benchmarking C# Code with Benchmark .NET Happy Coding !!\n","permalink":"http://localhost:1313/posts/parallelprocessing/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eThere was a requirement to perform series of tasks, involving generation of output files, such that the required throughput is achieved. These tasks involve database read operation, external API invocation and file i/o. Generally, benchmarking showed that executing them in sequential way was not helpful.  What if asynchronous programming be used to perform this task.\u003c/p\u003e\n\u003cp\u003eSo Lets Start.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cp\u003eLets assume that this typical use case requires,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003efetching data from database for the purpose of merging placeholders in a Template and perform mail merge\u003c/p\u003e","title":"Using Asynchronous programming to manage parallel processing "},{"content":"Location Mumbai, Maharashtra, India\nProfessional Title Senior Technical Architect at Worldline India\nWhat do you do ? I write code. In my current role, I am responsible for Architecture for all the systems in Payments space covering Acquiring and Issuance of Cards, UPI (QR based payment system in India). I am involved in creating and maintaining the Architecture of various systems, integration between them, primarily focussing on non-functional (ilities) aspects.\nWhy ? I like building things and understanding patterns.\nWhat should we read? Poor Charlies Almanack by Charlie Munger\nURLS: Linkedin\nMy Blog\nI appreciate any ideas/suggestions you have on how I can improve this site.\n","permalink":"http://localhost:1313/now/","summary":"\u003ch2 id=\"location\"\u003eLocation\u003c/h2\u003e\n\u003cp\u003eMumbai, Maharashtra, India\u003c/p\u003e\n\u003ch2 id=\"professional-title\"\u003eProfessional Title\u003c/h2\u003e\n\u003cp\u003eSenior Technical Architect at Worldline India\u003c/p\u003e\n\u003ch2 id=\"what-do-you-do-\"\u003eWhat do you do ?\u003c/h2\u003e\n\u003cp\u003eI write code. In my current role, I am responsible for Architecture for all the systems in  Payments space covering Acquiring and Issuance of Cards, UPI (QR based payment system in India). I am involved in creating and maintaining the Architecture of various systems, integration between them, primarily focussing on non-functional (ilities) aspects.\u003c/p\u003e","title":"What am i doing *NOW*"},{"content":"Introduction Artificial Intelligence, especially Large language models (LLMs) are all in high demand. Since OpenAI released ChatGPT, interest has gone up multi-fold. Since 2023, Powerful LLMs can be run on local machines. Local Large Language Models offer advantages in terms of data privacy and security and can be enriched using enterprise-specific data using Retrieval augmentation generation (RAG).Several tools exist that make it relatively easy to obtain, run and manage such models locally on our machines. Few examples are Ollama, Langchain, LocalAI.\nSemantic Kernel is an SDK from Microsoft that integrates Large Language Models (LLMs) like OpenAI, Azure OpenAI, and Hugging Face with conventional programming languages like C#, Python, and Java. Semantic Kernel also has plugins that can be chained together to integrate with other tools like Ollama.\nThis post describes usage of Ollama to run model locally, communicate with it using REST API from Semantic kernel SDK.\nOllama To setup Ollama follow the installation and setup instructions from the Ollama website. Ollama runs as a service, exposing a REST API on a localhost port.Once installed, you can invoke ollama run to talk to this model; the model is downloaded, if not already and cached the first time it\u0026rsquo;s requested.\nFor the sake of this post, we can use Phi3 model, so run ollama run phi3. This will download phi3 model, if not already, and once done, it will present a prompt. Using this prompt, one can start chatting with the model.\nWhy SemanticKernel ? As such , Ollama can be integrated with from any application via REST API. Then why go for SemanticKernel SDK? It provides a simplified integration of AI capabilities into existing applications, lowering the barrier of entry for new developers and supporting the ability to fine-tune models. It supports multiple languages like C#, Python and Java.\nUsing Ollama Install Ollama by following instructions here.Ollama exposes set of REST APIs, check Documentation here. It provides range of functions like get response for Prompt, get Chat response. for Specific operations, it supports streaming and non-streaming response. First step is to download/pull using ollama run phi3. This will pull, if required, the model and set it up locally. In the end, it will show prompt where user can interact with model.\nNow Ollama API can be easily accessed. Below is the gateway class.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 ``` public class OllamaApiClient { private HttpClient _client = new(); public Configuration Config { get; } public interface IResponseStreamer\u0026lt;T\u0026gt; { void Stream(T stream); } public class ChatMessage { [JsonPropertyName(\u0026#34;role\u0026#34;)] public string Role { get; set;} [JsonPropertyName(\u0026#34;content\u0026#34;)] public string Content {get;set;} } public class ChatResponse { [JsonPropertyName(\u0026#34;model\u0026#34;)] public string Model { get; set; } [JsonPropertyName(\u0026#34;created_at\u0026#34;)] public string CreatedAt { get; set; } [JsonPropertyName(\u0026#34;response\u0026#34;)] public string Response { get; set; } [JsonPropertyName(\u0026#34;message\u0026#34;)] public ChatMessage? Message { get; set; } [JsonPropertyName(\u0026#34;messages\u0026#34;)] public List\u0026lt;ChatMessage\u0026gt; Messages { get; set; } [JsonPropertyName(\u0026#34;embedding\u0026#34;)] public List\u0026lt;Double\u0026gt; Embeddings { get; set; } [JsonPropertyName(\u0026#34;done\u0026#34;)] public bool Done { get; set; } } public class ChatRequest { [JsonPropertyName(\u0026#34;model\u0026#34;)] public string Model { get;set;} [JsonPropertyName(\u0026#34;prompt\u0026#34;)] [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)] public string Prompt {get; set;} [JsonPropertyName(\u0026#34;format\u0026#34;)] [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)] public string Format {get; set;} [JsonPropertyName(\u0026#34;messages\u0026#34;)] [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)] public IList\u0026lt;ChatMessage\u0026gt; Messages {get; set;} [JsonPropertyName(\u0026#34;stream\u0026#34;)] public bool Stream {get; set;} = false; } public class Configuration { public Uri Uri { get; set; } public string Model { get; set; } } public OllamaApiClient(string uriString, string defaultModel = \u0026#34;\u0026#34;) : this(new Uri(uriString), defaultModel) { } public OllamaApiClient(Uri uri, string defaultModel = \u0026#34;\u0026#34;) : this(new Configuration { Uri = uri, Model = defaultModel }) { } public OllamaApiClient(Configuration config) : this(new HttpClient() { BaseAddress = config.Uri }, config.Model) { Config = config; } public OllamaApiClient(HttpClient client, string defaultModel = \u0026#34;\u0026#34;) { _client = client ?? throw new ArgumentNullException(nameof(client)); _client.Timeout = TimeSpan.FromMinutes(10); (Config ??= new Configuration()).Model = defaultModel; } public async Task\u0026lt;ChatResponse\u0026gt; GetEmbeddingsAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; return await PostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/embeddings\u0026#34;,message,token); } public async Task\u0026lt;ChatResponse\u0026gt; GetResponseForChatAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; return await PostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/chat\u0026#34;,message,token); } public async Task\u0026lt;ChatResponse\u0026gt; GetResponseForPromptAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; return await PostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/generate\u0026#34;,message,token); } public async IAsyncEnumerable\u0026lt;ChatResponse\u0026gt; GetStreamForPromptAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; message.Stream = true; await foreach(ChatResponse resp in StreamPostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/generate\u0026#34;,message,token)) { yield return resp; } } public async IAsyncEnumerable\u0026lt;ChatResponse\u0026gt; GetStreamForChatAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; message.Stream = true; await foreach(ChatResponse resp in StreamPostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/chat\u0026#34;,message,token)) { yield return resp; } } private async Task\u0026lt;TResponse\u0026gt; GetAsync\u0026lt;TResponse\u0026gt;(string endpoint, CancellationToken cancellationToken) { var response = await _client.GetAsync(endpoint, cancellationToken); response.EnsureSuccessStatusCode(); var responseBody = await response.Content.ReadAsStringAsync(cancellationToken); return JsonSerializer.Deserialize\u0026lt;TResponse\u0026gt;(responseBody); } private async Task PostAsync\u0026lt;TRequest\u0026gt;(string endpoint, TRequest request, CancellationToken cancellationToken) { var content = new StringContent(JsonSerializer.Serialize(request), Encoding.UTF8, \u0026#34;application/json\u0026#34;); var response = await _client.PostAsync(endpoint, content, cancellationToken); response.EnsureSuccessStatusCode(); } private async IAsyncEnumerable\u0026lt;TResponse\u0026gt; StreamPostAsync\u0026lt;TRequest,TResponse\u0026gt;(string endpoint, TRequest request, CancellationToken cancellationToken) { var content = new StringContent(JsonSerializer.Serialize(request), Encoding.UTF8, \u0026#34;application/json\u0026#34;); var response = await _client.PostAsync(endpoint, content, cancellationToken); using Stream stream = await response.Content.ReadAsStreamAsync(); using StreamReader reader = new StreamReader(stream); while (!reader.EndOfStream) { var jsonString = await reader.ReadLineAsync(cancellationToken); TResponse result = JsonSerializer.Deserialize\u0026lt;TResponse\u0026gt;(jsonString); yield return result; } yield break; } private async Task\u0026lt;TResponse\u0026gt; PostAsync\u0026lt;TRequest, TResponse\u0026gt;(string endpoint, TRequest request, CancellationToken cancellationToken) { var content = new StringContent(JsonSerializer.Serialize(request), Encoding.UTF8, \u0026#34;application/json\u0026#34;); var response = await _client.PostAsync(endpoint, content, cancellationToken); response.EnsureSuccessStatusCode(); var responseBody = await response.Content.ReadAsStringAsync(cancellationToken); return JsonSerializer.Deserialize\u0026lt;TResponse\u0026gt;(responseBody); } } With this class in place, now it can be integrated with SemanticKernel.\nIntegrating with SemanticKernel Semantickernel SDK operates on a plug-in system, where developers can use pre-built plugins or create their own. These plugins consist of prompts that the AI model should respond to, as well as functions that can complete specialized tasks. Accordingly, it provides interfaces for (Chat completion)[https://learn.microsoft.com/en-us/dotnet/api/microsoft.semantickernel.chatcompletion.ichatcompletionservice?view=semantic-kernel-dotnet] and Text Generation tasks which can be use d to integrate with external implementation like Ollama.\nBelow are implementations of these interfaces that use Ollama API,\nText Generation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 public class TextGenerationService : ITextGenerationService { public string ModelApiEndPoint { get; set; } public string ModelName { get; set; } public IReadOnlyDictionary\u0026lt;string, object?\u0026gt; Attributes =\u0026gt; throw new NotImplementedException(); public async Task\u0026lt;IReadOnlyList\u0026lt;TextContent\u0026gt;\u0026gt; GetTextContentsAsync(string prompt, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, CancellationToken cancellationToken = default) { var client = new OllamaApiClient(ModelApiEndPoint, ModelName); OllamaApiClient.ChatRequest req = new OllamaApiClient.ChatRequest() { Model=ModelName, Prompt=prompt, }; OllamaApiClient.ChatResponse resp = await client.GetResponseForPromptAsync(req , cancellationToken); return new List\u0026lt;TextContent\u0026gt;() { new TextContent(resp.Response) }; } public async IAsyncEnumerable\u0026lt;StreamingTextContent\u0026gt; GetStreamingTextContentsAsync(string prompt, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, CancellationToken cancellationToken = default) { var ollama = new OllamaApiClient(ModelApiEndPoint, ModelName); OllamaApiClient.ChatRequest req = new OllamaApiClient.ChatRequest() { Prompt=prompt, Stream=true }; await foreach( OllamaApiClient.ChatResponse resp in ollama.GetStreamForPromptAsync(req, cancellationToken)) { yield return new StreamingTextContent( text: resp.Response) ; } } } Chat Completion 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 public class OllamaChatCompletionService : IChatCompletionService { public string ModelApiEndPoint { get; set; } public string ModelName { get; set; } public IReadOnlyDictionary\u0026lt;string, object?\u0026gt; Attributes =\u0026gt; throw new NotImplementedException(); public async Task\u0026lt;IReadOnlyList\u0026lt;ChatMessageContent\u0026gt;\u0026gt; GetChatMessageContentsAsync(ChatHistory chatHistory, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, CancellationToken cancellationToken = default) { var client = new OllamaApiClient(ModelApiEndPoint, ModelName); OllamaApiClient.ChatRequest req = new OllamaApiClient.ChatRequest() { Model=ModelName }; req.Messages = new List\u0026lt;OllamaApiClient.ChatMessage\u0026gt;(); // iterate though chatHistory Messages foreach (var history in chatHistory) { req.Messages.Add(new OllamaApiClient.ChatMessage{ Role=history.Role.ToString(), Content=history.Content }); } OllamaApiClient.ChatResponse resp = await client.GetResponseForChatAsync(req , cancellationToken); List\u0026lt;ChatMessageContent\u0026gt; content = new(); content.Add( new(role:resp.Message.Role.Equals(\u0026#34;system\u0026#34;,StringComparison.InvariantCultureIgnoreCase)?AuthorRole.System:AuthorRole.User,content:resp.Message.Content)); return content; } public async IAsyncEnumerable\u0026lt;StreamingChatMessageContent\u0026gt; GetStreamingChatMessageContentsAsync(ChatHistory chatHistory, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, CancellationToken cancellationToken = default) { var client = new OllamaApiClient(ModelApiEndPoint, ModelName); OllamaApiClient.ChatRequest req = new OllamaApiClient.ChatRequest() { Model=ModelName }; req.Messages = new List\u0026lt;OllamaApiClient.ChatMessage\u0026gt;(); // iterate though chatHistory Messages foreach (var history in chatHistory) { req.Messages.Add(new OllamaApiClient.ChatMessage{ Role=history.Role.ToString(), Content=history.Content }); } CancellationTokenSource source = new CancellationTokenSource(); CancellationToken token = source.Token; await foreach (OllamaApiClient.ChatResponse resp in client.GetStreamForChatAsync(req,token)) { yield return new(role:resp.Message.Role.Equals(\u0026#34;system\u0026#34;,StringComparison.InvariantCultureIgnoreCase)?AuthorRole.System:AuthorRole.User, content:resp.Message.Content ?? string.Empty); } } } Above implementation is for demonstration purposes only. I am sure further optimization is certainly possible.\nAfter this, it is time to use it as client of SemanticKernel SDK. Below is the test case for chat completion service,\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [Fact] public async void TestChatGenerationviaSK() { var ollamachat = ServiceProvider.GetChatCompletionService(); // semantic kernel builder var builder = Kernel.CreateBuilder(); builder.Services.AddKeyedSingleton\u0026lt;IChatCompletionService\u0026gt;(\u0026#34;ollamaChat\u0026#34;, ollamachat); // builder.Services.AddKeyedSingleton\u0026lt;ITextGenerationService\u0026gt;(\u0026#34;ollamaText\u0026#34;, ollamaText); var kernel = builder.Build(); // chat generation var chatGen = kernel.GetRequiredService\u0026lt;IChatCompletionService\u0026gt;(); ChatHistory chat = new(\u0026#34;You are an AI assistant that helps people find information.\u0026#34;); chat.AddUserMessage(\u0026#34;What is Sixth Sense?\u0026#34;); var answer = await chatGen.GetChatMessageContentAsync(chat); Assert.NotNull(answer); Assert.NotEmpty(answer.Content!); System.Diagnostics.Debug.WriteLine(answer.Content! } Full Source code of this post is available here.\nSummary Local AI combined with Retrieval Augmented Generation is powerful combination that any one get started with without need for subscriptions while conserving data privacy. Next step in this is to Use RAG for augmenting the results using enterprise/private data.\nHappy Coding !!\nHelpful Links Demystifying Retrieval Augmented Generation with .NET Gemma, ollama and Langchaingo ","permalink":"http://localhost:1313/posts/ollamasemantickernel/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eArtificial Intelligence, especially Large language models (LLMs) are all in high demand. Since OpenAI released ChatGPT, interest has gone up multi-fold. Since 2023, Powerful LLMs can be run on local machines. Local Large Language Models  offer advantages in terms of data privacy and security and can be enriched using enterprise-specific data using Retrieval augmentation generation (RAG).Several tools exist that make it relatively easy to obtain, run and manage such models locally on our machines. Few examples are \u003ca href=https://ollama.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOllama\u003c/a\u003e, \u003ca href=https://github.com/hwchase17/langchain\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLangchain\u003c/a\u003e,  \u003ca href=localai.io\n    \n    \n\u003eLocalAI\u003c/a\u003e.\u003c/p\u003e","title":"Using local LLM with Ollama and Semantic Kernel"},{"content":"Java Language Articles, E-books Getting Started with Java in 2023 Finding Java Thread Leaks With JDK Flight Recorder and a Bit Of SQL ","permalink":"http://localhost:1313/links/java/","summary":"\u003ch2 id=\"java-language\"\u003eJava Language\u003c/h2\u003e\n\u003ch3 id=\"articles-e-books\"\u003eArticles, E-books\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.morling.dev/blog/getting-started-with-java-development-2023/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGetting Started with Java in 2023\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.morling.dev/blog/finding-java-thread-leaks-with-jdk-flight-recorder-and-bit-of-sql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFinding Java Thread Leaks With JDK Flight Recorder and a Bit Of SQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages - Java"},{"content":"Background Ever encountered a scenario where REST API consumption works from tools like curl, Web Browser but not from Application. Lets dive in.\nThe requirement is as simple as consuming REST API from a Application over TLS.\nProblem Statement The REST API, to be consumed, is standard API interface which requires access over TLS. The client in this case is Windows 2016 server.\nDuring Development, Windows 10 is used to develop and test the code. Later, the same is tested on a Windows 2016 Server. It is at this stage, it fails with cryptic Error \u0026ldquo;The request was aborted: Could not create SSL/TLS secure channel\u0026rdquo;. But it works fine with other tools like curl, PostMan or even from a Web Browser.\nNetwork trace log from Application Causal Analysis Given that this error was related TLS/SSL and it is standard across platforms. What could be the reason for this behavior? With not much luck with Application level trace, its time to take help of Wireshark. If you are new to Wireshark then refer to this excellent write-up by Julia Evans.\nSo, i used wireshark during test from CURL as well as from the Application and below is what is shows,\nUsing CURL List of Ciphers Exchanged during \u0026#39;Client Hello\u0026#39; Cipher returned by Server during \u0026#39;Server Hello\u0026#39; With CURl, TLS handshare happens as intended and API works as expected.\nVia Application Below is list of ciphers exchanged and list is considerably short compared to earlier.\nList of Ciphers Exchanged during \u0026#39;Client Hello\u0026#39; Below is error logged\nTLS handshake Error To understand this behavior, Let\u0026rsquo;s do a quick primer.\nThere are many implementations of TLS/SSL (a.k.a. Security service providers) available across platforms. Notably,\nNetwork Security Services This is used by browsers like Firefox\nLibreSSL - Used by Chrome, curl (in ready-to-use build, refer here)\nRefer here for nice comparison of various implementations in summary format.\n`Microsoft Windows has its own Implementation called Windows SSPI (a.k.a. schannel SSPI). As per TLS/SSL Overview,\nSchannel is a Security Support Provider (SSP) that implements the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) Internet standard authentication protocols. Microsoft Windows and development platforms like .NET use this implementation by default. Via this provider it is possible for Administrators to enforce policies like restrict version of TLS, usage of ciphers and so on. Note that, as part of Security/Compliance requirements, It is often necessary to have these policies enforced and this is exactly what was done.\nBelow is Sample C# code using BouncyCastle (alternate library for cryptography)\nWrap up Hence, the resolution for this could be,\nMake sure that Server hosting the API complies with any of the ciphers allowed on the client. In case if this is not possible then , Cipher restrictions on the client will have to be modified (assuming its within the requirement for Compliance). Useful References, 1 - CURL using OpenSSL in default build\nHappy Troubleshooting !!\n","permalink":"http://localhost:1313/posts/tlshandsharefailure/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eEver encountered a scenario where REST API consumption works from tools like \u003ca href=https://github.com/jeroen/curl\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ecurl\u003c/a\u003e, Web Browser but not from Application. Lets dive in.\u003c/p\u003e\n\u003cp\u003eThe requirement is as simple as consuming REST API from a Application over TLS.\u003c/p\u003e\n\u003ch2 id=\"problem-statement\"\u003eProblem Statement\u003c/h2\u003e\n\u003cp\u003eThe REST API, to be consumed, is standard API interface which requires access over TLS. The client in this case is Windows 2016 server.\u003c/p\u003e\n\u003cp\u003eDuring Development, Windows 10 is used to develop and test the code. Later, the same is tested on a Windows 2016 Server. It is at this stage, it fails with cryptic Error \u0026ldquo;The request was aborted: Could not create SSL/TLS secure channel\u0026rdquo;. But it works fine with other tools like curl, PostMan or even from a Web Browser.\u003c/p\u003e","title":"Troubleshooting TLS handshake issue"},{"content":"Background A Client has E-commerce Application consisting of services aimed at specific domains of business functionality it serves. One of these services is responsible for accepting the order, authenticating it and forwarding it for further processing in terms of inventory checks, payment and so on. For Authentication, this service sends SMS to Customer\u0026rsquo;s Mobile number (and e-mail id) and customer is supposed to confirm this order placement by means of entering Code received in it. This code is valid for a short duration.\nThe requirement is to add a URL to this SMS which customer can use to view the order and confirm it on Mobile itself.\nFor above, there are constraints like,\nService is expected to trigger SMS, with required content like code, URL Etc., instantaneously. This is because time-bound action is expected from customer post receiving this SMS. SMS Message size restrictions to be taken into consideration while adding URL to it (since it already has other content in it). Implementation details Given the size restrictions on SMS, a URL need to be as short as possible. Hence, URL Shortener will have to be used which reduces length of overall URL. Additionally, very low latency is expected while preparing content of SMS and sending the same (by calling Telecom Service Provider\u0026rsquo;s API) hence external services like Bitly are most probably not useful. This is because the whole response time will then be tied to performance, up-time of this external service. Better alternative is to generate short / nano ID within Service itself. This will work assuming appropriate short domain (like t.me or youtu.be etc.) is available.\nBelow are the alternatives to generate short id within the Service,\nNanoid HashIds Base62 algorithm One can choose any of the above considering tolerance for Collision. With Nanoid, one can check extent to which length can be reduced while avoiding collision using this Calculator.\nThis approach helps with,\nEncapsulation - Keeping logic of short id generation, logging it in storage (ie. database), and responding to request for URL containing this short id within service itself. Keep external dependencies to minimum as much as possible so as to have better control over latency/throughput and easier monitoring. Useful References Why Nanoids by Planetscale Building highly reliable Web sites System Designer’s Interview - Insider’s Guide - Has Nice chapter on URL Shorteners Happy Coding !!\n","permalink":"http://localhost:1313/posts/shortidgeneration/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eA Client has E-commerce Application consisting of services aimed at specific domains of business functionality it serves. One of these services is responsible for accepting the order, authenticating it and forwarding it for further processing in terms of inventory checks, payment and so on. For  Authentication, this service sends \u003ca href=https://en.wikipedia.org/wiki/SMS\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSMS\u003c/a\u003e to Customer\u0026rsquo;s  Mobile number (and e-mail id) and customer is supposed to confirm this order placement by means of entering Code received in it. This code is valid for a short duration.\u003c/p\u003e","title":"URL Shortener in High Throughput Service"},{"content":"Background How Nuke Helps Summary Key Advantages of Nuke are,\nC# based DSL to compose build pipeline Build pipeline is part of solution (i.e. actual code) display a dependency graph logging support for lot of CI/CD helper tools Useful References, Nuke - Documentation Cake Fake Happy Code building !!\n","permalink":"http://localhost:1313/posts/nukebuildautomation/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003ch2 id=\"how-nuke-helps\"\u003eHow Nuke Helps\u003c/h2\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eKey Advantages of Nuke are,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eC# based DSL to compose build pipeline\u003c/li\u003e\n\u003cli\u003eBuild pipeline is part of solution (i.e. actual code)\u003c/li\u003e\n\u003cli\u003edisplay a dependency graph\u003c/li\u003e\n\u003cli\u003elogging\u003c/li\u003e\n\u003cli\u003esupport for lot of CI/CD helper tools\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"useful-references\"\u003eUseful References,\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.nuke.build/docs/getting-started/philosophy.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNuke - Documentation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/cake-build/cake\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCake\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fake.build/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFake\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHappy Code building !!\u003c/p\u003e\n\u003chr\u003e\n\u003cscript src=\"https://utteranc.es/client.js\" repo=\"sachinsu/sachinsu.github.io\" issue-term=\"title\" label=\"blogcomment\"\n    theme=\"github-light\" crossorigin=\"anonymous\" async\u003e\u003c/script\u003e","title":"Nuke as Build Automation tool for .NET projects"},{"content":"PostgreSQL General Articles Mistakes to avoid while using PostgreSQL Free Postgres database (or SQLite) from fly.io Using generate_series feature for reporting When Postgres blocks: 7 tips for dealing with locks PostgreSQL - Don’t do this Is PostgreSQL good enough? Online event processing by Martin Klepmann PostgreSQL rocks, except when it blocks: Understanding locks Connection handling best practice with PostgreSQL 10 Things I Hate About PostgreSQL PostgreSQL - Advanced Administration by Bruce Momjian Top Tools and Recommendations to Manage Postgres in an Enterprise: Administration, Performance, High Availability, and Migration Using PostgreSQL as Cache and Read Optimization tips Adyen’s Use of PostgreSQL PostgreSQL version Upgrade @ Gitlab Zombodb - PostgreSQL and ElasticSearch work together Using pg_timetable for job scheduling Using pg_cron to schedule background tasks Using pg_cron to roll up for Analytics PG Database Configuration Helper Full text search in PostgreSQL Postgres full text search capabilities Full text search (Crunchydata) PostgreSQL - Best practices(Azure) Designing high performance time series data table in (RDS) postgresql while using BRIN Index Informative blog on PostgreSQL Understanding GIN indexes PostgreSQL - Using SQL for Data Analysis Approach to Bulk Import in PostGreSQL Schema updates with zero downtime in PostgreSQL How to JSON in PostgreSQL Grouping, Rollups and Cubes Row level Security Just use postgres Performance tuning, configuration etc. pgassistant - insights into database behavior, identifies schema-related issues, and assists in correcting them Partitioning as Query Optimization Strategy Database Configuration Builder Configuration for Diagnosing Performance issues OrioleDB- Solving Wicked problems of PostgreSQL 5 Minutes in PostgreSQL - Videos PostgreSQL Tips Optimizing AutoVaccum in Postgresql 10 Things i hate about PostgreSQL Various index types and their usage Few gotchas for Application Developers Five tips for healthy PostgreSQL database Make PostgreSQL healthy and speedy Diagnose Linux related Disk \u0026amp;amp; RAM issues PostgreSQL database configuration tuning advicer Database configuration for Web Services Online explain analyzer \u0026amp;amp; Generally Good Blog on PostgreSQL Vertically scaling PostgreSQL How PostgreSQL Query Optimizer works A Performance Dashboard Simple script to analyse your PostgreSQL database configuration, and give tuning advice Tuning PostgreSQL for High Write Throughput Postgres is a great pub/sub \u0026amp;amp; job server PostgreSQL - Optimize Configuration Be careful with CTE in PostgreSQL Per core Connection limit guidance for EDB PostgreSQL - Claim unused Index size PgBadger - A fast PostgreSQL Log Analyzer Using CTE to perform binary search on table Top tools to manage PostgreSQL Performance Impact of idle Postgresql connections (usage of Pgbench) How to Manage Connections Efficiently in Postgres, or Any Database How to Audit PostgreSQL Database SQL Optimizations in PostgreSQL: IN vs EXISTS vs ANY/ALL vs JOIN PostgreSQL Scaling advice in 2021 Security Hardening for PostgreSQL Working with Postgres @ Zerodha Using PostgreSQL for Data warehouse Testing PG High availability with Patroni Comparison of PostgreSQL Monitoring tools Using Timeout feature of PostgreSQL Benchmarking bulk data ingestion in PostgreSQL All about indexes in PostgreSQL Use cases for Partitioning Asynchronous Commits for faster data loading Push style Notifications and Background Queue Processing using Listen/Notify and skiplocked Queues in PostgreSQL How postgresql stores data on disk Using Postgresql for job queueing and lessons learned Interesting Extensions/Products Using duckdb and postgres together Collection of Postgresql related tools PostgreSql based Message queue End-to-end machine learning solution Incrementally update Materialized Views in real-time using Materialize Artificial Intelligence with PostgreSQL Materialize - Incrementally-updated materialized views - in ANSI Standard SQL and in real time. pg_bulkload - pg_bulkload is a high speed data loading tool for PostgreSQL. pgcenter - Command-line admin tool for observing and troubleshooting Postgres. TOTP implementation in PLPGSQL Connection pooler - Odyssey Connection pooler - PGBouncer Setting up Multiple pgBouncer Instances Connection pooler and much more - Pgpool-II Change data capture in PostgreSQL Swarm64 DA -20x faster PostgreSQL query performance Greenplum - data warehouse, based on PostgreSQL Apache Age - graph database functionality for PostgreSQL Distributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres. Supabase -Listen to PG changes in real time without using Listen/Notify Job queues, Single reader and pub/sub Use cases for scaling out PostgreSQL - Citus Database lab Engine - Fast cloning of Database for dev/QA/staging PGSync - Sync data from one Postgres database to another Neon - Serverless Open source PostgreSQL Push PG Listen/Notify events over Websockets Generate ERD using D2 Diagrams Mathesar - Spreadsheet-like Web interface for PostgreSQL Migration to PostgreSQL Migration Guide from Oracle to PostgreSQL Lessons while migrating from Oracle to PostgreSQL Reshape - easy-to-use, zero-downtime schema migration tool Migra - diff tool for PostgreSQL Schema pgroll: PostgreSQL zero-downtime migrations made easy reshape: An easy-to-use, zero-downtime schema migration tool for Postgres High Availability Tools for Multi-Master Replication PostgreSQL Replication Distributed PostgreSQL Change Data Capture, Asynchronous change processing etc. Electric SQL - Mobile Local first sync layer with PostgreSQL PGQ - Queueing Solution PGQ - as used by Skype Bucardo - Asynchronous replication for PostgreSQL using Triggers Using Logical Decoding, Wal2json for CDC Webedia’s approach of using Customer processor (walparser) to read from Wal2JSON and CDC between PG and Elasticsearch Message queuing using native postgresql Queues in PostgreSQL Message queueing with native postgresql Using PGQ to invalidate caches pgstream- turns your database into an event stream Wal-listener CLI Postgres as Message Queue Data Privacy PgSodium - Interface to LibSodium from PostgreSQL including Server Key Management PostgreSQL Anonymizer - hides or replaces personally identifiable information (PII) Vector Embeddings Storing OpenAI embeddings in Postgres with pgvector Overview of pgVector Scalability and performance Scaling in PG Bulk import performance aspects Data Analysis Window functions for Data Analysis Data Synchronization, CDC Electric - Sync data from PostgreSQL Debezium - Stream changes from database ","permalink":"http://localhost:1313/links/postgresql/","summary":"\u003ch1 id=\"postgresql\"\u003ePostgreSQL\u003c/h1\u003e\n\u003ch2 id=\"general-articles\"\u003eGeneral Articles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://philbooth.me/blog/nine-ways-to-shoot-yourself-in-the-foot-with-postgresql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMistakes to avoid while using PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fly.io/blog/free-postgres/?utm_source\u0026#61;hackernewsletter\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_term\u0026#61;code\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFree Postgres database (or SQLite) from fly.io\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rob.conery.io/2018/08/01/simple-monthly-reports-in-postgresql-using-generate_series/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing generate_series feature for reporting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2018/02/22/seven-tips-for-dealing-with-postgres-locks/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhen Postgres blocks: 7 tips for dealing with locks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://wiki.postgresql.org/wiki/Don%27t_Do_This#Database_Encoding\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Don’t do this\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://renesd.blogspot.com/2017/02/is-postgresql-good-enough.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIs PostgreSQL good enough?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://queue.acm.org/detail.cfm?id\u0026#61;3321612\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOnline event processing by Martin Klepmann\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2018/02/15/when-postgresql-blocks/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL rocks, except when it blocks: Understanding locks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/connection-handling-best-practice-with-postgresql/ba-p/790883\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection handling best practice with PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@rbranson/10-things-i-hate-about-postgresql-20dbab8c2791\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 Things I Hate About PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://momjian.us/main/writings/pgsql/administration.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Advanced Administration by Bruce Momjian\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.enterprisedb.com/blog/top-tools-and-recommendations-manage-postgres-enterprise-administration-performance-high\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTop Tools and Recommendations to Manage Postgres in an Enterprise: Administration, Performance, High Availability, and Migration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://renesd.blogspot.com/2019/10/using-postgresql-as-cache.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing PostgreSQL as Cache and Read Optimization tips\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.adyen.com/blog/updating-a-50-terabyte-postgresql-database\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAdyen’s Use of PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://about.gitlab.com/blog/2020/09/11/gitlab-pg-upgrade/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL version Upgrade @ Gitlab\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.zombodb.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZombodb - PostgreSQL and ElasticSearch work together\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/products/pg_timetable/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing pg_timetable for job scheduling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/evolving-pg-cron-together-postgres-13-audit-log-background/ba-p/1829588\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing pg_cron to schedule background tasks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2017/12/27/real-time-analytics-dashboards-with-citus/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing pg_cron to roll up for Analytics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresqlco.nf/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePG Database Configuration Helper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://rachbelaid.com/postgres-full-text-search-is-good-enough/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFull text search in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://xata.io/blog/postgres-full-text-search-engine\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgres full text search capabilities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/postgres-full-text-search-a-search-engine-in-a-database\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFull text search (Crunchydata)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/postgresql/application-best-practices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Best practices(Azure)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/database/designing-high-performance-time-series-data-tables-on-amazon-rds-for-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesigning high performance time series data table in (RDS) postgresql while using BRIN Index\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://depesz.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInformative blog on PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pganalyze.com/blog/gin-index\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstanding GIN indexes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hakibenita.com/sql-for-data-analysis\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Using SQL for Data Analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/postgresql-bulk-loading-huge-amounts-of-data/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproach to Bulk Import in PostGreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fabianlindfors.se/blog/schema-migrations-in-postgres/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSchema updates with zero downtime in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ftisiot.net/postgresqljson/main/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to  JSON in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/postgresql-grouping-sets-rollup-cube/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGrouping, Rollups and Cubes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.tangramvision.com/blog/hands-on-with-postgresql-authorization-part-2-row-level-security\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRow level Security\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.amazingcto.com/postgres-for-everything/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJust use postgres\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"performance-tuning-configuration-etc\"\u003ePerformance tuning, configuration etc.\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/nexsol-technologies/pgassistant\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epgassistant - insights into database behavior, identifies schema-related issues, and assists in correcting them\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ashutoshpg.blogspot.com/2023/08/partitioning-as-query-optimization.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePartitioning as Query Optimization Strategy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgconfig.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase Configuration Builder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/blog/exposing-postgres-performance-secrets\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConfiguration for Diagnosing Performance issues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/AlexanderKorotkov/solving-postgresql-wicked-problems\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOrioleDB- Solving Wicked problems of PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/channel/UCDV_1Dz2Ixgl1nT_3DUZVFw/videos\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e5 Minutes in PostgreSQL - Videos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/postgres-tips\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL Tips\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2022/07/28/debugging-postgres-autovacuum-problems-13-tips/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOptimizing AutoVaccum in Postgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rbranson.medium.com/10-things-i-hate-about-postgresql-20dbab8c2791\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 Things i hate about PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/postgres-indexes-for-newbies?utm_source\u0026#61;hackernewsletter\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_term\u0026#61;data\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVarious index types and their usage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hagander.net/talks/PostgreSQL%20Gotchas%20for%20App%20Developers.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFew gotchas for Application Developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/five-tips-for-a-healthier-postgres-database-in-the-new-year\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFive tips for healthy PostgreSQL database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://info.crunchydata.com/blog/cleaning-up-your-postgres-database\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMake PostgreSQL healthy and speedy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.highgo.ca/2021/02/08/troubleshooting-performance-issues-due-to-disk-and-ram/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDiagnose Linux related Disk \u0026amp;amp; RAM issues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresqltuner.pl\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL database configuration tuning advicer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tightlycoupled.io/my-goto-postgres-configuration-for-web-services/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase configuration for Web Services\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://explain.depesz.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOnline explain analyzer \u0026amp;amp; Generally Good Blog on PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pgdash.io/blog/scaling-postgres.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVertically scaling PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/how-the-postgresql-query-optimizer-works/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow PostgreSQL Query Optimizer works\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ankane/pghero\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Performance Dashboard\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresqltuner.pl\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSimple script to analyse your PostgreSQL database configuration, and give tuning advice\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/GrantMcAlister/tuning-postgresql-for-high-write-throughput\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTuning PostgreSQL for High Write Throughput\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://webapp.io/blog/postgres-is-the-answer/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgres is a great pub/sub \u0026amp;amp; job server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresqlco.nf/en/doc/param/9275132/real-life-example-when-to-use-outer-cross-apply-in-sql/9275865#9275865\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Optimize Configuration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hakibenita.com/be-careful-with-cte-in-postgre-sql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBe careful with CTE in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://richyen.com/postgres/2021/09/03/less-is-more-max-connections.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePer core Connection limit guidance for EDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hakibenita.com/postgresql-unused-index-size\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Claim unused Index size\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/darold/pgbadger\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePgBadger - A fast PostgreSQL Log Analyzer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.endpoint.com/blog/2020/10/02/postgresql-binary-search-correlated-data-cte\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing CTE to perform binary search on table\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.enterprisedb.com/blog/top-tools-manage-postgres-enterprise-administration-performance-high-availability-and\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTop tools to manage PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/database/performance-impact-of-idle-postgresql-connections/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePerformance Impact of idle Postgresql connections (usage of Pgbench)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://brandur.org/postgres-connections\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to Manage Connections Efficiently in Postgres, or Any Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://severalnines.com/database-blog/how-to-audit-postgresql-database\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to Audit PostgreSQL Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2020/04/16/sql-optimizations-in-postgresql-in-vs-exists-vs-any-all-vs-join/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Optimizations in PostgreSQL: IN vs EXISTS vs ANY/ALL vs JOIN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/postgres-scaling-advice-for-2021/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL Scaling advice in 2021\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://goteleport.com/blog/securing-postgres-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSecurity Hardening for PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://zerodha.tech/blog/working-with-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWorking with Postgres @ Zerodha\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.narrator.ai/blog/using-postgresql-as-a-data-warehouse/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing PostgreSQL for Data warehouse\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2021/06/11/postgresql-ha-with-patroni-your-turn-to-test-failure-scenarios/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTesting PG High availability with Patroni\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sematext.com/blog/postgresql-monitoring/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComparison of PostgreSQL Monitoring tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/control-runaway-postgres-queries-with-statement-timeout\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Timeout feature of PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/database/speed-up-time-series-data-ingestion-by-partitioning-tables-on-amazon-rds-for-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenchmarking bulk data ingestion in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pganalyze.com/blog/postgres-create-index\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAll about indexes in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.anayrat.info/en/2021/09/01/partitioning-use-cases-with-postgresql/#storage-tiering\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse cases for Partitioning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2020/08/21/postgresql-synchronous_commit-options-and-synchronous-standby-replication/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsynchronous Commits for faster data loading\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.enterprisedb.com/blog/listening-postgres-how-listen-and-notify-syntax-promote-high-availability-application-layer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePush style Notifications and Background Queue Processing using Listen/Notify and skiplocked\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;WIRy1Ws47ic\u0026amp;list\u0026#61;PLlrxD0HtieHjSzUZYCMvqffEU5jykfPTd\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQueues in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://drew.silcock.dev/blog/how-postgres-stores-data-on-disk/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow postgresql stores data on disk\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.rudderstack.com/blog/scaling-postgres-queue/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Postgresql for job queueing and lessons learned\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"interesting-extensionsproducts\"\u003eInteresting Extensions/Products\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://motherduck.com/blog/postgres-duckdb-options\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing duckdb and postgres together\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of Postgresql related tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tembo-io/pgmq\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSql based Message queue\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresml.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEnd-to-end machine learning solution\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://materialize.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIncrementally update Materialized Views in real-time using Materialize\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://momjian.us/main/writings/pgsql/AI.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArtificial Intelligence with PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://materialize.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMaterialize - Incrementally-updated materialized views - in ANSI Standard SQL and in real time.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ossc-db/pg_bulkload\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epg_bulkload - pg_bulkload is a high speed data loading tool for PostgreSQL.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/lesovsky/pgcenter\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epgcenter - Command-line admin tool for observing and troubleshooting Postgres.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/pyramation/totp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTOTP implementation in PLPGSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/yandex/odyssey\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection pooler - Odyssey\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgbouncer.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection pooler - PGBouncer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.2ndquadrant.com/en/blog/running-multiple-pgbouncer-instances-with-systemd/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSetting up Multiple pgBouncer Instances\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgpool.net/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection pooler and much more - Pgpool-II\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/change-data-capture-in-postgres-how-to-use-logical-decoding-and/ba-p/1396421e\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChange data capture in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://swarm64.com/swarm64-da/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSwarm64 DA -20x faster PostgreSQL query performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/greenplum-db/gpdb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGreenplum - data warehouse, based on PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://age.apache.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApache Age - graph database functionality for PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/knadh/sql-jobber\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/supabase/realtime\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSupabase -Listen to PG changes in real time without using Listen/Notify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://spin.atomicobject.com/2021/02/04/redis-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJob queues, Single reader and pub/sub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/when-to-use-hyperscale-citus-to-scale-out-postgres/ba-p/1958269\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse cases for scaling out PostgreSQL - Citus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgres.ai/products/how-it-works\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase lab Engine - Fast cloning of Database for dev/QA/staging\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ankane/pgsync\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePGSync - Sync data from one Postgres database to another\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/neondatabase/neon\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNeon - Serverless Open source PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/CrunchyData/pg_eventserv\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePush PG Listen/Notify events over Websockets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/zekenie/d2-erd-from-postgres\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGenerate ERD using D2 Diagrams\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/centerofci/mathesar\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMathesar - Spreadsheet-like Web interface for PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"migration-to-postgresql\"\u003eMigration to PostgreSQL\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/new-oracle-to-postgres-migration-guide-for-azure/ba-p/2055303\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMigration Guide from Oracle to PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/building-an-oracle-to-postgresql-migrator-lessons-learned/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLessons while migrating from Oracle to PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/fabianlindfors/reshape\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReshape - easy-to-use, zero-downtime schema migration tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/djrobstep/migra\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMigra - diff tool for PostgreSQL Schema\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/xataio/pgroll\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epgroll: PostgreSQL zero-downtime migrations made easy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/fabianlindfors/reshape\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ereshape: An easy-to-use, zero-downtime schema migration tool for Postgres\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"high-availability\"\u003eHigh Availability\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://wiki.postgresql.org/wiki/Replication,_Clustering,_and_Connection_Pooling\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTools for Multi-Master Replication\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;jPp4XIY4XRw\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL Replication\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/blog/an-overview-of-distributed-postgresql-architectures\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"change-data-capture-asynchronous-change-processing-etc\"\u003eChange Data Capture, Asynchronous change processing etc.\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://electric-sql.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eElectric SQL - Mobile Local first sync layer with PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://wiki.postgresql.org/wiki/PGQ_Tutorial\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePGQ - Queueing Solution\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgcon.org/2009/schedule/attachments/91_pgq.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePGQ - as used by Skype\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://bucardo.org/Bucardo/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBucardo - Asynchronous replication for PostgreSQL using Triggers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/change-data-capture-in-postgres-how-to-use-logical-decoding-and/ba-p/1396421\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Logical Decoding, Wal2json for CDC\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.postgresql.eu/events/pgconfeu2019/sessions/session/2651/slides/237/Deploy%20your%20own%20replication%20system%20with%20Wal2json.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWebedia’s approach of using Customer processor (walparser) to read from Wal2JSON and  CDC between PG and Elasticsearch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/message-queuing-using-native-postgresql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMessage queuing using native postgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgcon.org/2016/schedule/attachments/414_queues-pgcon-2016.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQueues in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/message-queuing-using-native-postgresql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMessage queueing with native postgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hagander.net/talks/cache_invalidation_2014.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing PGQ to invalidate caches\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tmc/pqstream\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epgstream- turns your  database into an event stream\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ihippik/wal-listener\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWal-listener CLI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dagster.io/blog/skip-kafka-use-postgres-message-queue\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgres as Message Queue\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-privacy\"\u003eData Privacy\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/michelp/pgsodium\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePgSodium - Interface to LibSodium from PostgreSQL including Server Key Management\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.postgresql.org/about/news/postgresql-anonymizer-10-privacy-by-design-for-postgres-2452/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL Anonymizer -  hides or replaces personally identifiable information (PII)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"vector-embeddings\"\u003eVector Embeddings\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://supabase.com/blog/openai-embeddings-postgres-vector\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStoring OpenAI embeddings in Postgres with pgvector\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jkatz05.com/post/postgres/pgvector-overview-0.5.0/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOverview of pgVector\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"scalability-and-performance\"\u003eScalability and performance\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.postgresql.org/docs/current/populate.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling in PG\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.postgresql.org/docs/current/populate.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBulk import performance aspects\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-analysis\"\u003eData Analysis\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/blog/window-functions-for-data-analysis-with-postgres\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWindow functions for Data Analysis\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-synchronization-cdc\"\u003eData Synchronization, CDC\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://electric-sql.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eElectric - Sync data from PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://debezium.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDebezium - Stream changes from database\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"PostgreSQL"},{"content":"Introduction While embarking on building any new server application, one of the key requirement is whether it needs durable, persistent storage of data (and in most cases, it does). This is followed by evaluating suitable data store. Likely evaluation criteria is Application\u0026rsquo;s Requirement (Tolerance for eventual consistency, High Availability etc.), Team\u0026rsquo;s familiarity, Costs, Tech. support availability and so on. In case of choices in relational databases, typical go to options are MySQL, PostgreSQL or even proprietary databases like Oracle , SQL Server. Seldom one considers SQLite for this purpose.\nAt the outset, SQLite is well-known as file-based database used in specific use cases like software running on peripheral/low resource devices such as Mobiles, tablets or in browsers for intermediate storage.Recently, i came across session by Ben Johnson on using SQLite in production. In the Video, it is mentioned that SQLite can potentially be used for server applications having 100s of concurrent requests.\nIn SQLite, There can only be a single writer at a time. However, it supports concurrency by allowing multiple connections to be opened to database and it internally serializes the write requests. This limitation (of single writer) was addressed by means of implementing Write ahead log. In this, where transactions are first written to a separate file (called \u0026rsquo;log\u0026rsquo; file) and then moved to database on commit. When WAL Mode is used, it supports much better concurrent reads and writes to the database.\nLets check if SQLite can really be considered for non-trivial, server based applications.\nCode To have proof of concept (POC) to simulate typical real world use case, lets expose HTTP based API using Go as below,\nimport ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/rs/xid\u0026#34; _ \u0026#34;modernc.org/sqlite\u0026#34; ) const dbfilepath string = \u0026#34;./foo.db\u0026#34; const params string = \u0026#34;?_pragma=busy_timeout%3d5000\u0026amp;_pragma=journal_mode%3dwal\u0026#34; // Open opens the database connection. func Open(dsn string) (*sql.DB, error) { db, err := sql.Open(\u0026#34;SQLite\u0026#34;, dsn) if err != nil { log.Fatal(err) return nil, err } // setting this to higher number (i.e.\u0026gt; 1) not only causes constraint violation (probably because the way isolation works in SQLite over same and diff. connections) and but also degrades performances db.SetMaxOpenConns(runtime.NumCPU()) return db, nil } We will use ModernC SQLite library which is CGO free port of SQLite. However, there are other libraries listed here\nNext,we have HTTP handler which exposes POST end point and writes data to SQLite database,\nfunc main() { err := setUpDB() if err != nil { log.Println(\u0026#34;Error while setting up database\u0026#34;) return } db, err := Open(dbfilepath + params) if err != nil { log.Printf(\u0026#34;%q: %s\\n\u0026#34;, err, dbfilepath+params) return } defer db.Close() mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/Addfoo\u0026#34;, FooHandler(db)) log.Println(\u0026#34;Listening on :3000...\u0026#34;) err = http.ListenAndServe(\u0026#34;:3000\u0026#34;, mux) log.Fatal(err) } func genXid() string { guid := xid.New() return guid.String() } func FooHandler(db *sql.DB) func(http.ResponseWriter, *http.Request) { return func(w http.ResponseWriter, r *http.Request) { if r.URL.Path != \u0026#34;/Addfoo\u0026#34; { http.NotFound(w, r) return } switch r.Method { case http.MethodGet: // Handle the GET request... http.Error(w, \u0026#34;method not allowed\u0026#34;, http.StatusMethodNotAllowed) case http.MethodPost: // Handle the POST request... tx, err := db.Begin() if err != nil { log.Printf(\u0026#34;begin. Exec error=%s\\n\u0026#34;, err) return } defer tx.Commit() // intVal := randomSeed.Int63() uid := genXid() _, err = tx.Exec(fmt.Sprintf(\u0026#34;insert into Foo(id, Name) values(\u0026#39;%s\u0026#39;,\u0026#39;name-%s\u0026#39;)\u0026#34;, uid, uid)) if err != nil { log.Printf(\u0026#34;Error inserting record -\u0026gt; %s\\t%s\\n\u0026#34;, err.Error(), strings.HasSuffix(err.Error(), \u0026#34;(SQLite_BUSY)\u0026#34;)) http.Error(w, \u0026#34;Internal Error\u0026#34;, http.StatusInternalServerError) return } w.WriteHeader(http.StatusCreated) case http.MethodOptions: w.Header().Set(\u0026#34;Allow\u0026#34;, \u0026#34;GET, POST, OPTIONS\u0026#34;) w.WriteHeader(http.StatusNoContent) default: w.Header().Set(\u0026#34;Allow\u0026#34;, \u0026#34;GET, POST, OPTIONS\u0026#34;) http.Error(w, \u0026#34;method not allowed\u0026#34;, http.StatusMethodNotAllowed) } } } Above is simple HTTP handler function which is invoked on call to /Addfoo endpoint and adds a record to a table in database.\nNext is to check throughput provided by this HTTP API. We can use benchmarking tool for this purpose. It generates a load against API and records the response times, errors and so on and presents analysis based on it. One such tool is Bombardier and there are others like wrk, wrk2 and so on. I used Bombardier primarily because it is cross-platform (Golang based) and works on Windows, which i am using to conduct this POC.\nFirst, application is started as go run . which starts the HTTP server, ready to receive requests.\nNext is to use Bombardier to assess throughput of the API,\nWith limit of 100 requests per second, result shows, average latency of 2.23ms with no errors thrown Database has around 1252 records. bombardier.exe -m POST -l -r 100 http://localhost:3000/Addfoo Bombarding http://localhost:3000/Addfoo for 10s using 125 connection(s) [===========================================================================================================================================================] 10s Done! Statistics Avg Stdev Max Reqs/sec 99.96 32.72 254.39 Latency 2.23ms 4.39ms 119.61ms Latency Distribution 50% 1.72ms 75% 2.32ms 90% 3.12ms 95% 3.31ms 99% 4.44ms HTTP codes: 1xx - 0, 2xx - 1001, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 21.20KB/s With limit of 100 requests per second, result shows, average latency of 2.23ms with no errors thrown Database has around 1252 records. bombardier.exe -m POST -l -r 100 http://localhost:3000/Addfoo Bombarding http://localhost:3000/Addfoo for 10s using 125 connection(s) [===========================================================================================================================================================] 10s Done! Statistics Avg Stdev Max Reqs/sec 99.96 32.72 254.39 Latency 2.23ms 4.39ms 119.61ms Latency Distribution 50% 1.72ms 75% 2.32ms 90% 3.12ms 95% 3.31ms 99% 4.44ms HTTP codes: 1xx - 0, 2xx - 1001, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 21.20KB/s With limit of 1000 requests per second, Latency has gone up 15x Still no error reported and database has additional records. bombardier.exe -m POST -l -r 1000 http://localhost:3000/Addfoo Bombarding http://localhost:3000/Addfoo for 10s using 125 connection(s) [===========================================================================================================================================================] 10s Done! Statistics Avg Stdev Max Reqs/sec 964.73 314.04 2149.94 Latency 30.05ms 80.20ms 1.48s Latency Distribution 50% 4.02ms 75% 16.00ms 90% 74.75ms 95% 155.30ms 99% 434.48ms HTTP codes: 1xx - 0, 2xx - 9670, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 202.72KB/s With limit of 4000 requests per second, it looks like below, bombardier.exe -m POST -l -r 4000 http://localhost:3000/Addfoo Bombarding http://localhost:3000/Addfoo for 10s using 125 connection(s) [===========================================================================================================================================================] 10s Done! Statistics Avg Stdev Max Reqs/sec 1304.49 688.92 2199.91 Latency 95.00ms 174.73ms 2.40s Latency Distribution 50% 35.00ms 75% 95.11ms 90% 228.16ms 95% 382.68ms 99% 1.02s HTTP codes: 1xx - 0, 2xx - 13186, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 275.73KB/s Overall, above shows that,\nSQLite with WAL mode on and busy timeout set to 5 seconds can support high concurrency Above is very simplistic test, in real application it is likely going to be very different (i.e. most likely on the lower side of throughput) since there will be multiple connections reading and writing to not one but many tables concurrently. This is likely to impact throughput and latency. One of the factors on why better throughput is recorded could be because SQLite, being implemented as library, can be easily integrated with application and resides on same node/VM as application. This helps tremendously in avoiding network round trip and helps in much better performance. Refer to Martin Fowler\u0026rsquo;s First law Back to evaluating databases for a given use case and SQLite fits in ,\nCriteria Description SQLite ACID Guarantees Is Database expected to provide Strong Consistency guarantees? (this may not be required for every use case) Yes.Note that, there is no isolation between operations that occur within the same database connection. Data Durability Does Database maintain data in durable ,consistent way? Yes Reliability Does it provide reliable storage ? (Although storage reliability is not limited only to software and often depends on other factors like type of storage, associated hardware.) Yes Availability Is database highly available? SQLite being file based, availability is confined to the Node/VM on which it is running. It can be further enhanced using tools like, Litestream (which implements change data capture and syncs it with remote storage like AWS S3 or SFTP among others). rqlite is clustered database based on SQLite. network partition support Does database support partitioning of data? No. Being a file based data storage system, it is constrained on single node i.e. it can be scaled vertically. However, it can be setup in active + Stand-by backup mode using specific tools. Additionally, other databases (files on same node) can be attached to and accessed by application as one database. Tech. Support In case of FOSS software, is Community active in terms of releases/bug fixes as well as on discussion forums? Are their any providers who provide paid support? SQLite is mature database. Though, it is open source, it does not accept pull requests from anyone out side of core committers. Having said that, one has to check for availability of support in case things go north (corrupted database and so on.) Database features Support for Typical RDBMS features like Data types, User Management \u0026amp; Security, Stored procedures (but not triggers) etc. Refer here for detailed comparison of features across SQLite and populate RDBMSs. Hopefully, above provides good starting point in deciding database for your next application. As always, comments/suggestions are welcome.\nUseful References Limits in SQLite Consider SQLite SQLite has good support for JSON, read about it here SQLite as a document database, read about it here Interesting lists of extensions sqlite-utils - Collection of utilities including migration from MySQL/PostgreSQL Sqlite and Go by David Crawshaw Server side SQLite SQLite backup using Cron Happy Coding !!\n","permalink":"http://localhost:1313/posts/is_sqlite_production_ready/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWhile embarking on building any new server application, one of the key requirement is whether it needs durable, persistent storage of data (and in most cases, it does). This is followed by evaluating suitable data store. Likely evaluation criteria is Application\u0026rsquo;s Requirement (Tolerance for eventual consistency, High Availability etc.), Team\u0026rsquo;s familiarity, Costs, Tech. support availability and so on.\nIn case of choices in relational databases, typical go to options are MySQL, PostgreSQL or even proprietary databases like Oracle , SQL Server. Seldom one considers \u003ca href=https://SQLite.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQLite\u003c/a\u003e for this purpose.\u003c/p\u003e","title":"Can SQLite be considered for Server Applications?"},{"content":"Introduction We develop a piece of software with aim to fulfil specific business requirements in terms of resource usage, throughput, availability among others. Profiling and benchmarking are approaches that developer has in his/her arsenal to gain continuous feedback on whether a piece of code is behaving optimally and adhering to it\u0026rsquo;s objectives.\nLets look at what they mean,\nProfiling is defined as process aimed at understanding the behavior of a program. A profile result might be a table of time taken per function, as per this and this) Benchmarking measures the time for some whole operation. e.g. I/O operations per second under some workload. So the result is typically a single number, in either seconds or operations per second. Or a data set with results for different parameters, so you can graph it.. Refer this for more information. Also do check Benchmarking correctly is hard by Julia Evans. Typically, Profiling is supported by most of the environments (either via IDEs like Visual Studio or through language itself [Like Go] has buil-in provision for the same while Benchmarking is typically performed on dedicated testing infrastructure.\nIn this article, We will look at couple of tools in this space that can be easily integrated in developer\u0026rsquo;s workflow so as to get early feedback. Lets\u0026rsquo; go.\nProfiling Pyroscope is Open Source Application for profiling Application. It is a cross-language tool i.e. programs in variety of languages can be profiled using it. It works in client server model where in, - Client - Pyroscope executable runs the intended code (in languages like C#, Ruby) etc. (in case of Go, it is available as dependency) and collects instrumentation details to be sent to server. - Server - Runs as a separate process (on Linux [Works in WSL if using Windows] or Mac), collects the data from client processes and renders them as table and/or flame graph via Web UI.A flamegraph is a way to visualize resources used by a program, like CPU usage or memory allocations, and see which parts of your code were responsible.\nLets see how a function in C# can be instrumented using PyroScope.\nDevelop function to be profiled Lets have ASP.NET Core 5.0 based Web API as below, Simple Web API handler in C# Setup Pyroscope\nInstall Pyroscope Application by following instructions here for Windows. Note that, Pyroscope server component won\u0026rsquo;t run on Windows in which case either Windows Subsystem for Linux (WSL) or Docker can be used. In case of Linux, instructions provided here are sufficient for both client and server components.\nI have setup the application on Windows 10 while using WSL for Pyroscope Server.\nConfigure Pyroscope client and run the Application\nBuild the application using dotnet build\nConfigure below environment variables (below is powershell format or you can use SET ... commands on command prompt),\n``` $env:PYROSCOPE_SPY_NAME=\u0026quot;dotnetspy\u0026quot;; $env:PYROSCOPE_APPLICATION_NAME=\u0026quot;my.dotnet.app\u0026quot;; $env:PYROSCOPE_SERVER_ADDRESS=\u0026quot;http://localhost:4040\u0026quot;; ``` Update path to include pyroscope installation folder using $env:Path += \u0026quot;;C:\\Program Files\\Pyroscope\\Pyroscope Agent\\\u0026quot;\nRun the Application using pyroscope exec dotnet .\\bin\\Debug\\net5.0\\webapi.dll.\nRun Pyroscope Server\nStart Pyroscope server from WSL Linux prompt using, sudo pyroscope server. The output of this command should show Port on which server is running.\nEither use curl or hey tool to invoke the API. Below command shows how to generate load using hey, run .\\hey.exe -m GET -c 10 -q 2 http://localhost:5000/weatherforecast (Note: Modify the URL As appropriate) Observe the flame graph in Pyroscope Web UI.\nObserve the Table and/or flamegraph using Pyroscope Web interface. Below screenshot shows flamegraph for above code. Refer here and here for everything about flame graphs.\nTable and flamegraph for API Table and flamegraph for API Overall, Pyroscope provides easy way to observe Memory/CPU utilization as part of developer workflow on workstation itself. This is especially useful for development environments which do not provide profiling out of the box.\nBenchmarking Crank is tool used by Microsoft internally to benchmark applications. It is released as Nuget package and currently .NET based code or Docker Containers can be benchmarked using it. Lets see steps to benchmark .NET Application using Crank.\nWrite code, intended to be benchmarked. In this case, its very simple one as below,\nC# Code to be benchmarked Setup Crank\nFollow the instructions provided here to setup crank. Crank expects Configuration in YAML format which contains details like Job to be used. Crank has built-in jobs which are essentially wrappers around CLI load testing tools like bombardier and wrk and so on. Since i am using Windows to run crank, we will go with Bombardier which is cross platform. Below is how a basic configuration looks like,\nCrank YAML Configuration It allows for extensibility in terms of overriding the job configuration in terms of how load should be generated etc.\nRun Crank Agent - Next step is to run crank agent in a command prompt or powershell by simply running crank-agent\nRecord data for benchmarking using Crank CLI.\nNow run Crank from the application folder as crank --config crank.benchmarks.yml --scenario hello --profile local --application.options.displayOutput true\nThis command builds the code and launches job while recording the Utilization and other parameters and shows output like,\nApplication\u0026#39;s CPU Utilization Observations during executing load testing Overall, i found Crank helpful for following,\nit helps quickly test effect of any code changes by means of quickly benchmarking the application. The overall benchmarking might not be similar to end state ie. when the application will be deployed on target infrastructure. However, it still gives insights to developer about impact of code changes Crank can be easily used for local applications as well as for docker containers. It can either be used locally or in distributed manner. Useful References Pyroscope Crank Performance Anti-patterns Happy Profiling and Benchmarking !!\n","permalink":"http://localhost:1313/posts/profiling_n_benchmarking/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWe develop a piece of software with aim to fulfil specific business requirements in terms of resource usage, throughput, availability among others. Profiling and benchmarking are approaches that developer has in his/her arsenal to gain continuous feedback on whether a piece of code is behaving optimally and adhering to it\u0026rsquo;s objectives.\u003c/p\u003e\n\u003cp\u003eLets look at what they mean,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProfiling is defined as process \u003ccode\u003eaimed at  understanding the behavior of a program. A profile result might be a table of time taken per function,\u003c/code\u003e as per \u003ca href=https://stackoverflow.com/questions/34801622/difference-between-benchmarking-and-profiling\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ethis\u003c/a\u003e and \u003ca href=https://en.wikipedia.org/wiki/Profiling_%28computer_programming%29\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ethis\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eBenchmarking  \u003ccode\u003emeasures the time for some whole operation. e.g. I/O operations per second under some workload. So the result is typically a single number, in either seconds or operations per second. Or a data set with results for different parameters, so you can graph it.\u003c/code\u003e. Refer \u003ca href=https://en.wikipedia.org/wiki/Benchmark_%28computing%29\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ethis\u003c/a\u003e for more information. Also do check \u003ca href=https://jvns.ca/blog/2016/07/23/rigorous-benchmarking-in-reasonable-time/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenchmarking correctly is hard by Julia Evans\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTypically, Profiling is supported by most of the environments (either via IDEs like \u003ca href=https://docs.microsoft.com/en-us/visualstudio/profiling/profiling-feature-tour?view\u0026#61;vs-2022\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisual Studio\u003c/a\u003e or through language itself [Like \u003ca href=https://go.dev/blog/pprof\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo\u003c/a\u003e] has buil-in provision for the same while Benchmarking is typically performed on dedicated testing infrastructure.\u003c/p\u003e","title":"Profiling and benchmarking tools for Applications"},{"content":"Introduction I have been reading excellent Database Reliability Engineering book and below are my notes from it.\nKey Incentive(s) for Automation\nElimination of Toil - Toil is the kind of work tied to running a production service that tends to be manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly as a service grows. Important System Characteristics\nLatency, also known as response time, is a time-based measurement indicating how long it takes to receive a response from a request. It is best to measure this for end-to-end response from the customer rather than breaking it down component by component. This is customer-centric design and is crucial for any system that has customers, which is any system\nAvailability - This is generally expressed as a percentage of overall time the system is expected to be available. Availability is defined as the ability to return an expected response to the requesting client. Note that time is not considered here, which is why most SLOs include both response time and availability. After a certain latency point, the system can be considered unavailable even if the request is still completing. Availability is often denoted in percentages, such as 99.9% over a certain window. All samples within that window will be aggregated\nHigh availability - For any mission-critical data that you truly care about, you should avoid running with less than three live copies. That’s one primary and two-plus secondaries for leader-follower data stores like MySQL or MongoDB or a replication factor of three for distributed data stores like Cassandra or Hadoop. Because you never, ever want to find yourself in a situation in which you have a single copy of any data you care about, ever. This means that you need to be able to lose one instance while still maintaining redundancy, which is why three is a minimum number of copies, not two.\nInfrastructure engineering Virtualization * Hypervisor - A hypervisor or virtual machine monitor (VMM) can be software, firmware, or hardware. The hypervisor creates and runs VMs. A computer on which hypervisor runs one or more VMs is called a host machine, and each VM is called a guest machine. The hypervisor presents the guest operating systems with a virtual operating platform and manages the execution of the guest operating systems. Databases running within hypervisors show lower boundaries for concurrency than the same software on bare metal. When designing for these virtualized environments, the focus should be on a horizontally scaled approach, minimizing concurrency within nodes.\nStorage - Storage durability and performance are not what you would expect in the virtualized world. Between the page cache of your VM and the physical controller lies a virtual controller, the hypervisor, and the host’s page cache. This means increased latency for I/O. For writes, hypervisors do not honor calls in order to manage performance. This means that you cannot guarantee that your writes are flushed to disk when there is a crash.\nDatabase Servers\nPhysical servers - Recommended to have dedicated ones for database (and not shared) Why ? Much control with OS and more visibility May find redundant capacity on a dedicated hardware. Linux is not particularly optimized for database loads requiring low latency and high concurrency. The kernel is not predictable when it goes into reclaim mode, one of the best recommendations we can give is to simply ensure that you never fully use your physical memory by reserving it to avoid stalls and significant latency impacts. You can reserve this memory by not allocating it in configuration Storage\nCapacity - Single large disks are single points of failure, unless mirrored (RAID 1). RAID 0 will have its MTBF reduced by a factor of N, where N is the number of disks striped together.\nThroughput - When considering the needs, you must consider IOPS for the peak of a database’s workload rather than the average.\nLatency - Latency is the end-to-end client time of an I/O operation; in other words, the time elapsed between sending an I/O to storage and receiving an acknowledgement that the I/O read or write is complete.\nTransactional applications are sensitive to increased I/O latency and are good candidates for SSDs. You can maintain high IOPS while keeping latency down by maintaining a low queue length and a high number of IOPS available to the volume. Consistently driving more IOPS to a volume than it has available can cause increased I/O latency. Throughput-intensive applications like large MapReduce queries are less sensitive to increased I/O latency and are well-suited for HDD volumes. You can maintain high throughput to HDD-backed volumes by maintaining a high queue length when performing large, sequential I/O Availability - Plan for disk failures.\nDurability - When your database goes to commit data to physical disk with guarantees of durability, it issues an operating system call known as rather than relying on page cache flushing. An example of this is when a redo log or write-ahead log is being generated and must be truly written to disk to ensure recoverability of the database. Filesystem operations can also cause corruption and inconsistency during failure events, such as crashes. Journaling filesystems like XFS and EXT4 significantly reduce the possibility of such events, however.\nStorage Area Networks (SAN) vs. SSDs - Data snapshots and movement are some of the nicest features in modern infrastructures, where SSDs provide better IO than traditional SANs.\nRelational Database Internals\nIn Relational databases, data is stored in containers called blocks or pages that correspond to a specific number of bytes on disk. Different databases will use blocks or pages in their terminology. In this book, we use blocks to refer to both. Blocks are the finest level of granularity for storing records. Oracle Database stores data in data blocks. A page is a fixed size called a block, just like blocks on disks. Blocks are the smallest size that can be read or written to access data. This means that if a row is 1 K and the block size is 16 K, you will still incur a 16 K read operation. If a database block size is smaller than the filesystem block size, you will be wasting I/O for operations that require multiple pages. A block require some metadata to be stored, as well, usually in the form of a header and trailer or footer. This will include disk address information, information about the object the block belongs to, and information about the rows and activity that have occurred within that block.\nMost databases structure their data in a binary tree format, also known as B-tree. A B\u0002tree is a data structure that self-balances while keeping data sorted. The B-tree is optimized for the reading and writing of blocks of data, which is why B-trees are commonly found in databases and filesystems\nSummary of the attributes and benefits of B-trees: Excellent performance for range-based queries.\nNot the most ideal model for single-row lookups\nKeys exist in sorted order for efficient key lookups and range scans.\nStructure minimizes page reads for large datasets.\nBy not packing keys into each page, deletes and inserts are efficient, with only occasional splits and merges being needed.\nPerform much better if the entire structure can fit within memory.\nA crucial variable in configuring your databases for underlying storage is the database block size. We’ve discussed the importance of aligning database block sizes with the underlying disk block sizes, but that is not enough. If you are using Solid-State Drives (SSDs), for instance, you might find smaller block sizes provide much better performance while traversing B-trees. An SSD can experience a 30% to 40% latency penalty on larger blocks versus performance on Hard Disk Drives (HDDs). Because reads and writes are required in B-tree structures, this must be taken into account.\nNon-Relational Database Internals\nWhat is sorted-string tables (SST) storage engine? - It has a number of files, each with a set of sorted key–value pairs inside. Unlike in the block storage discussed earlier, there is no need for the metadata overhead at the block or row level. Keys and their values are opaque to the DBMS and stored as arbitrary binary large objects (BLOBs). Because they are stored in a sorted fashion, they can be read sequentially and treated as an index onthe key by which they are sorted.\nThere is an algorithm that combines in-memory tables, batch flushing, and periodic compaction in SST storage engines. This algorithm is referred to a log-structured merge (LSM) tree architecture\nA bloom filter is a data structure that you can use to evaluate whether a record key is present in a given set.\nDatabase Indexes\nHash indexes - A hash map is a collection of buckets that contain the results of a hash function applied to a key. That hash points to the location where the records can be found. A hash map is only viable for single-key lookups because a range scan would be prohibitively expensive. Bitmap Indexes - A bitmap index stores its data as bit arrays (bitmaps). When you traverse the index, it is done by performing bitwise logical operations on the bitmaps. In B-trees, the index performs the best on values that are not repeated often. This is also known as high cardinality. The bitmap index functions much better when there are a small number of values being indexed Replication\nTypes Synchronous - A transaction that is written to a log on the leader is shipped immediately over the network to the followers. The leader will not commit the transaction until the followers have confirmed that they have recorded the write. This ensures that every node in the cluster is at the same commit point. This means that reads will be consistent regardless of what node they come from, and any node can take over as a leader without risk of data loss if the current leader fails. On the other hand, network latency or degraded nodes can all cause write latency for the transaction on the leader.\nAsynchronous - A transaction is written to a log on the leader and then committed and flushed to disk. A separate process is responsible for shipping those logs to the followers, where they are applied as soon as possible. In asynchronous replication models, there is always some lag between what is committed on the leader and what is committed on the followers. Additionally, there is no guarantee that the commit point on one follower is the same as the others. In practice, the time gap between commit points might be too small to notice.\nSemi-synchronous - In this algorithm, only one node is required to confirm to the leader that they have recorded the write. This reduces the risk of latency impacts when one or more nodes are functioning in degraded states while guaranteeing that at least two nodes on the cluster are at the same commit point. In this mode, there is no longer a guarantee that all nodes in the cluster will return the same data if a read is issued on any reader.\nFormats used during Replication\nStatement based logs - the actual SQL or data write statement used to execute the write is recorded and shipped from the leader to followers. e.g. MySQL Write-ahead logs - A write-ahead log (WAL), also known as a redo log, contains a series of events, each event mapped to a transaction or write. In the log are all of the bytes required to apply a transaction to disk. In systems, such as PostgreSQL, that use this method, the same log is shipped directly to the followers for application to disk. Approaches\nRow based Replication - In row-based replication (also called logical), writes are written to replication logs on the leader as events indicating how individual table rows are changed. Columns with new data are indicated, columns with updated information show before/after images, and deletes of rows are indicated as well. Replicas use this data to directly modify the row rather than needing to execute the original statement.\nBlock level Replication - Block-level replication is synchronous and eliminates significant overhead in the replicated write. However, you cannot have a running database instance on the secon‐dary node. So, when a failover occurs, a database instance must be started. If the for‐mer master failed without a clean database shutdown, this instance will need to perform recovery just as if the instance had been restarted on the same node.\nMethods\nSingle Leader - (Simplest of replicated environments) All writes go to single leader and are replicated to other nodes. Advantages are that there will be no consistency conflicts. There are some variations like data getting replicated to only few followers which further replicate to remaining ones. By far the most common implementation of replication due to simplicity.\nMultiple Leaders - There are 2 approaches,\nThere are typically 2 leaders responsible for receiving writes and propagating them to replicas. each leader is located in different data centers/availability zones. Any node can take reads or writes at any time. More complex than Single Leader approach due to need for conflict resolution. Use cases,\nAvailability - In case of failover with Single Leader approach, impact may last from 30 seconds to minutes depending on how the system is designed. This is due to replication consistency checks, crash recovery and more such steps. This impact could be unacceptable. Locality - Application is requirement is such that it needs to cater to users in different regions with separate datacenters. This could be to for data protection purposes or to ensure low latency. Disaster Recovery - Highly critical application with need to have multiple data centers to ensure availability. Conflict resolution approaches,\nSharding - distribute range of primary keys across leaders Affinity - Specific users (by region, unique ID) are always redirected to specific leader Shard by Application layer ie. Application instance is deployed in each datacenter avoid need for active/active cross region replication Write anywhere- Any node can take read or write requests. Attributes typically associated with such systems are,\nEventual consistency - there is no guarantee that data is consistent across all nodes at any time, that data will eventually converge. Read \u0026amp; Write Quorum - It indicates minimum number of readers or writers necessary to guarantee consistency of data. Quorum of 2 in 3 node cluster means one node\u0026rsquo;s failure is tolerated. Formula: N is the number of nodes in a cluster.R is the number of read nodes available, and W is the number of write nodes. If R + W is greater than N, you have an effective quorum to guarantee at least one good read after a write. Sloppy quorums - Indicates situation when nodes are available but unable to meet quorum due to lack of data. Anti Entropy - Mechanism to keep data synchronized across nodes even in case of inactivity (i.e. no reads). Anti-entropy is critical for datastores that store a lot of cold, or infrequently accessed,data. Data governance is the management of the availability, integrity, and security of the data that an organization saves and uses. Intro‐duction of new data attributes is something that should be considered carefully and documented. The use of JSON for data storage allows new data attributes to be introduced too easily and even accidentally.\nImportant aspects in Infrastructure Architecture,\nRelaxed durability means data loss must be considered an inevitability. Instance instability means automation, failover, and recovery must be very reliable. Horizontal scale requires automation to manage significant numbers of servers. Applications must be able to tolerate latency instability. Infrastructure Management An immutable infrastructure is one that is not allowed to mutate, or change, after it has been deployed. If there are changes that must happen, they are done to the version controlled configuration definition, and the service is redeployed.In the interest of moderation and middle ground, there can be some mutations that are frequent, automated and predictable, and can be allowed in the environment. Manual changes are still prohibited, keeping a significant amount of the value of predictability and recoverability while minimizing operational overhead. , Packer allows you to create multiple images from the same configuration. This includes images for virtual machines on your workstation. Using a tool like Vagrant on your workstation allows you to download the latest images, build the VMs, and even run through a standard test suite to verify that everything works as expected.\nPacker is one such tool from Hashicorp that creates images. The interesting thing about Packer is that it can create images for different environments (such as Amazon EC2 or VMWare images) from the same configuration. Most configuration management utilities can create baked images as well. Service Discovery \u0026amp; Service catalog - Service discovery is an abstraction that maps specific designations and port numbers of your services and load balancers to semantic names. A service catalog can be very simple, storing service data to integrates services, or it can include numerous additional facilities, including health checks to ensure that data in the catalog provides working resources.\nIsolation of Network Traffic - Network traffic can be broken up in,\nInternode communications Application traffic Administrative traffic Backup and recovery traffic Isolation of traffic is one of the first steps to proper networking for your databases. You can do this via physical network interface cards (NICs), or by partitioning one NIC Data Security - Tracking every failed and successful SQL statement sent to database is critical for identifying SQL injection attacks. SQL syntax errors can be a leading indicator\nData Architecture\nFrontline Datastores - Historically, these systems have been referred to as OnLine Transactional Processing (OLTP) systems. They were characterized by a lot of quick transactions, and thus they were designed for very fast queries, data integrity in high concurrency, and scale based on the number of transactions they can handle concurrently. All data is expected to be real time with all of the necessary details to support the services using them. Each user or transaction is seeking a small subset of the data. This means query patterns tend to focus on finding and accessing a small, specific dataset within a large set. Effective indexing, isolation, and concurrency are critical for this, which is why it tends to be fulfilled by relational systems. Typical characteristics are, Low-latency writes and queries\nHigh availability\nLow Mean Time to Recover (MTTR)\nAbility to scale with application traffic\nEasy integration with application and operational services\nDatabase proxies - Sits between application and frontline datastores. It could be,\nLayer 4 (Networking transport layer) - Uses the information available at networking layer like destination IP Addresses to distribute the traffic. This type can not work with factors like load or replication lag while distributing traffic Layer 7 - Operates at higher level of networking transport layer. At this layer, proxy can include functionality like, Health checking and redirection to healthy servers Splitting of reads and writes to send reads to replicas Query rewriting to optimize queries that cannot be tuned in code Caching query results and returning them Redirecting traffic to replicas that are not lagged Generate metrics on queries Perform firewall filtering on query types or hosts Event and Messaging systems - Used for actions to be triggered after a transaction like,\nData must be put into downstream analytics and warehouses Orders must be fulfilled Fraud detection must review a transaction Data must be uploaded to caches or Content Delivery Networks (CDNs) Personalization options must be recalibrated and published Caches and Memory Store - Used to overcome slowness in Disk I/o. Approaches to putting data are,\nPutting data in cache after its been written to persistent data store Writing to cache and datastore at the same time (Fragile due to possibility of one of the store failing) Writing to cache first and then to datstore asynchronously (Write-through approach) Lambda Architecture - The Lambda architecture is designed to handle a significant volume of data that is processed rapidly to serve near-real-time requests, while also supporting long\u0002running computation. Lambda consists of three layers: batch processing, real-time processing, and a query layer.If data is written to a frontend datastore, you can use a distributed log such as Kafka to create a distributed and immutable log for the Lambda processing layers. Some data is written directly to log services rather than going through a datastore. The pro‐cessing layers ingest this data.\nKappa Architecture - Append only immutable log is used in this Architecture. Kappa architecture eliminates the batch processing system, with the expectation that the streaming system can handle all transformations and computations. One of the biggest values to Kappa is the reduction in complexity and operational expense of Lambda by eliminating the batch processing layer. It also aims to reduce the pain of migrations and reorganizations. When you want to reprocess data, you can start a reprocessing, test it, and switch over to it.\nApplication Architecture Patterns\nEvent sourcing pattern - Changes to entities are saved as sequence of state changes. When state changes, a new event is appended to the log. The datastore is called as event store. it maintains audit of life cycle of entity which helps in recreation or populating the tables in case of data loss. However, evolution of entity over period of time needs to be managed as it may invalidate previous events. It allows giving full historical access via API for auditing, reconstruction, and different transformations can provide significant benefits.\nCQRS - The driver for this is the idea that same data can be represented for consumption using multiple models or views. like Append only log for writes and read optimized data stores for queries.\nMonitoring and Observability Synthetic Monitoring - The case for synthetic monitoring is to provide coverage that is consistent and thorough. Users might come from different regions and be active at different times. This can cause blind spots if we are not monitoring all possible regions and code paths into our service. With synthetic monitoring, we are able to identify areas where availability or latency is proving to be unstable or degraded, and prepare or mitigate appropriately. Examples of such preparation/mitigation include adding extra capacity, performance tuning queries, or even moving traffic away from unstable region\nLatency SLO - Service Level Objective could be \u0026ldquo;Ninety-nine percent request latency over one minute must be between 25 and 100 ms\u0026rdquo;.\nWHY MTTR (Mean time to recover) Over MTBF (Mean time between failure)? When you create a system that rarely breaks, you create a system that is inherently fragile. Will your team be ready to do repairs when the system does fail? Will it even know what to do? Systems that have frequent failures that are controlled and mitigated such that their impact is negligible have teams that know what to do when things go sideways. Processes are well documented and honed, and automated remediation becomes actually useful rather than hiding in the dark corners of your system\nSome of the Important statistics (Metrics, Events, Logs\u0026hellip;.) to be observed from observability perspective are,\nMetrics\nLatency - How long are client calls to your service ? Availability - How many calls result in errors? Call Rates - How oftern are calls sent to service? Utilization - How critical resources are being utilized to ensure quality of service and capacity. Types of Metrics, Counters - These are cumulative metrics that represent how many times a specific occurrence of something has occurred. Gauges - These are metrics that change in any direction, and indicate a current value, such as temperature, jobs in queue, or active locks. Histograms - A number of events broken up into configured buckets to show distribution. Summaries - This is similar to histogram but focused on proving counts over sliding windows of time Events - An event is a discrete action that has occurred in the environment. A change to a config is an event. A code deployment is an event. A database master failover is an event. Each of these can be signals that are used to correlate symptoms to causes.\nAlerts \u0026amp; Notifications\nAlerts - An alert is an interrupt to a human that instructs him to drop what he’s doing and investigate a rules violation that caused the alert to be sent. This is an expensive operation and should be utilized only when SLOs are in imminent danger of violation.\nTickets/tasks - For work that must be done but there is o imminent disaster. The output of monitoring should be tickets/tasks for developers\nNotifications - Events like Code Deployment completed.\nAutomation - One example is Autoscaling basis outcome of monitoring.\nVisualization - GUI tool for visualizing outcome of monitoring.\nMinimum Viable monitoring set Databases Monitor if your databases are up or down (pull checks). Monitor overall latency/error metrics and end-to-end health checks (push checks).\nInstrument th application layer to measure latency/errors for every database call (push checks).\nGather as many metrics as possible about the system, storage, database, and app layers, regardless of whether you think they will be useful. Most operating systems, services, and databases will have plug-ins that are fairly comprehensive.\nCreate specific checks for known problems. For example, checks based on losing x percent of database nodes or a global lock percent that is too high\nHealth check at the application level that queries all frontend datastores\nQuery run against each partition in each datastore member, for each datastore\nImminent capacity issues\nDisk capacity Database connections Error log scraping\nDB restarts Corruption Database connection layer - A tracing system should be in place be able to break out time talking to a proxy and time from the proxy to the backend as well. You can capture this via tcpdump and Tshark/Wireshark for ad hoc sampling. This can be automated for occasional sampling.\nUtilization Connection upper bound and connection count (Tip: PostgreSQL uses one Unix process per connection. MySQL, Cassandra, and MongoDB use a thread per connection) Connection states (working, sleeping, aborted, and others) Kernel-level Open file utilization Kernel-level max processes utilization Memory utilization Thread pool metrics such as MySQL table cache or MongoDB thread pool utilization Network throughput utilization Measure Saturation using, TCP connection backlog Database-specific connection queuing, such as MySQL back_log Connection timeout errors Waiting on threads in the connection pools Memory swapping Database processes that are locked With utilization and saturation, you can determine whether capacity constraints and bottlenecks are affecting the latency of your database connection layer. Monitor Errors, Database logs will provide error codes when database-level failures occur. Sometimes you have configurations with various degrees of verbosity. Make sure you have logging verbose enough to identify connection errors, but do be careful about overhead, particularly if your logs are sharing storage and IO resources with your database. Application and proxy logs will also provide rich sources of errors. Host errors discussed in the previous section should also be utilized Internal Database Activity\nThroughput and latency metrics Reads Writes Inserts Updates Deletes Other Operations Commits Rollbacks DDL Statements Other admin. tasks Commits, redo, journaling Dirty buffers (MySQL) Checkpoint age (MySQL) Pending and completed compaction tasks (Cassandra) Tracked dirty bytes (MongoDB) (Un)Modified pages evicted (MongoDB) Memory structures A mutex (Mutually Exclusive Lock) is a locking mechanism used to synchronize access to a resource such as a cache entry. Only one task can acquire the mutex. This means that there is ownership associated with mutexes, and only the owner can release the lock (mutex). This protects from corruption. A semaphore restricts the number of simultaneous users of a shared resource up to a maximum number. Threads can request access to the resource (decrementing the semaphore) and can signal that they have finished using the resource (incrementing the semaphore). Application\nMeasuring and logging all requests and responses to pages or API endpoints. also external services, which includes databases, search indexes, 3rd party APIs and caches. Any jobs or independent workflows that should be monitored. Any independent, reusable code like a method or function that interacts with databases, caches, and other datastores should be instrumented. Monitor how many database calls are executed by each endpoint, page, or function/method When doing SQL tuning, a big challenge is mapping SQL running in the database to the specific place in the codebase from which it is being called. In many database engines, you can add comments for information. These comments will show up in the database query logs. This is a great place to insert the codebase location Logging - Logs should include stack traces Setting up an external check for each major product or service, as well as a health check on the monitoring service itself, is a good best practice Server (Metrics)\nCPU Memory Network interfaces Storage I/O Storage capacity Storage controllers Network controllers CPU interconnect Memory interconnect Storage interconnect Server (Logs) - should be sent to processors (e.g. Logstash, Loki)\nkernel, cron, authentication, mail, and general messages logs as well as process- or application-specific log to ingest, such as MySQL, or nginx Overall, this book is highly recommended for understanding the Observability landscape. Though focussed on databases, it covers lot of ground on other aspects involved in infrastructure.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/dbre/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eI have been reading excellent \u003ca href=https://www.oreilly.com/library/view/database-reliability-engineering/9781491925935/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase Reliability Engineering\u003c/a\u003e book and below are my notes from it.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eKey Incentive(s) for Automation\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eElimination of Toil - Toil is the kind of work tied to running a production service that tends to be manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly as a service grows.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eImportant System Characteristics\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eLatency\u003c/em\u003e, also known as response time, is a time-based measurement indicating how long it takes to receive a response from a request. It is best to measure this for end-to-end response from the customer rather than breaking it down component by component. This is customer-centric design and is crucial for any system that has customers, which is any system\u003c/p\u003e","title":"Database Reliability Engineering - My Notes"},{"content":"Introduction Suppose you have a distributed application running in production and it is based on Micro services/Service Oriented Architecture and have SLA of being \u0026ldquo;always on\u0026rdquo; (be available 24*7, barring deployments of course !!). In such cases, having proper monitoring of Application health in place is absolutely essential.\nWhat if Monitoring is an afterthought (i.e. application is already in production) ? and that there is little apetite for additional components like (Visualization tools, specialized storage for logs/metrics/traces) for monitoring?\nIs it even possible to have near real time Monitoring of Application\u0026rsquo;s behaviour using already-in-use technologies (like PostgreSQL) ?\nMonitoring and more generically, \u0026ldquo;Observability\u0026rdquo; has three pillars. They are Logs, Metrics and traces. Many of the existing applications are producing either (mostly logs or traces) but seldom all. Hence, it is necessary to use existing logs/traces as basis for Metrics generation.\nThere are on-going developments With standards like Opentelemetry in this field. Some have even suggested ( here \u0026amp; here) that traces (distributed) will eventually replace logging.\nApproach The high level architecture looks like below,\nHigh Level Architecture Considering as-is state of Application Architecture and given the constraints (mentioned earlier), this post covers approach that is based upon,\nPostgreSQL - Data store for Analytics and Reporting TimescaleDB - Timescale plugin for PostgreSQL FluentBit - Processing of Web Server logs \u0026amp; forwarding to database Grafana - Data Visualization and Monitoring platform. Lets see how to get this done step by step.\nData Collection and Storage TimescaleDB Timescale is a Postgresql Plugin for time-series data management.\nRationale\nThe reports and dashboards expected for near real time API monitoring are time intensive in nature. TimescaleDB is optimized for such time intensive reporting and suits well for this use case as it is a plugin over PostgreSQL, which is already being used for analytics/reporting. Installation of plugin is straightforward. Step by Step tutorial is very helpful.\nNext step is to create a database for the data to be used for Monitoring. Hyper table(s) in this database will contain Metrics data, collected from Application and web server (IIS).\nOne of the required dashboard/report was to monitor API request(s) in terms of success \u0026amp; failure (%), Response times (in buckets like 1-5 secs,5-10 secs and so on).\nFor each API request, application collects specific details and persists it in database. Currently below attributes are stored in database as part of each log entry,\nAttribute Description Time Timestamp of event Service Attribute indicating service name Operation Attribute indicating Operation of the service for which request was received Outcome Outcome of the API Invocation i.e. Success or Failure Timeout Timestamp of completion of API invocation The DDL command will look like,\ncreate table apilog (time timestamptz not null, service text not null, operation text, outcome text not null, timeout timestamptz ); After creating the table, it will have to be converted into Hypertable by using command,\nSELECT create_hypertable('apilog', 'time');\nNote: Timescale transparently manages storage for hyper table and PostgreSQL Developer can continue to use standard SQL/plpgsql with it.\nFor the sake of quick testing, One can add dummy data to this table using below SQL,\ninsert into apilog SELECT (current_timestamp - \u0026#39;0 day\u0026#39;::interval), (case when x = 1 then \u0026#39;finance\u0026#39; else \u0026#39;it\u0026#39; end),(case when x = 1 then \u0026#39;getPrices\u0026#39; else \u0026#39;getUptime\u0026#39; end), (case when x \u0026lt; 2 then \u0026#39;success\u0026#39; else \u0026#39;failure\u0026#39; end), (current_timestamp - \u0026#39;0 day\u0026#39;::interval) + trunc(random() * 20) * \u0026#39;1 second\u0026#39;::interval FROM generate_series(0, 5000, 5) AS t(x); Currently, Application generates log events in OLTP Database and data from this database is replicated to Reporting database. Since we have created new Hyper table to host this data,a simple approach of Trigger can be used to populate it from current table.\nIn real scenario, you may want to consider replicating the data directly to hyper table.\nFluentBit So far , we have collected Application logs in the database. There is one more source which is of importance in the context of Monitoring and that is infrastructure software. It could be Operating System, Web Servers and so on. They generate lot of logs and metrices that can be ingested and consumed in conjuction with Application log to get better picture. We will look at how Web server logs can be sourced in data source.\nThere are many monitoring tools (refer Useful links below for comparison) available with focus on IT and Network monitoring. Such tools readily include infrastructure software too. For the sake of this article, We can use Log collector tool for this purpose. As such there are many log collector tools available, we will use Fluentbit.At a very High level, It has concepts of,\nInput - Log sources Parsers - Plugins to parse \u0026amp; transform the logs Output - Log Destination like Prometheus, Kafka, PostgreSQL and so on. Some of the advantages of Fluentbit are,\nHigh log delivery performance with efficient resource utilization Robut and Lightweight approach Log enrichment at Node level itself than on the destination Simpler configuration format Setup FluentBit - Fluentbit provides binaries that are bundled with package managers in case of Linux and as installers for Windows.\nAs of writing of this post, Pre-built binaries do not include output plugin for PostgreSQL. So Fluentbit has to be built from source after modifying Cmakelist so,\nClone the github repository\nModify CMakeLists.txt file as below,\noption(FLB_OUT_PGSQL \u0026quot;Enable PostgreSQL output plugin\u0026quot; No)\nto\noption(FLB_OUT_PGSQL \u0026quot;Enable PostgreSQL output plugin\u0026quot; Yes)\nRefer to Compiling from Source for further details.\nConfiguration - Once fluentbit is installed, It needs to be configured to read Web server logs , parse them and push them to PostgreSQL.\nBelow is sample configuration to periodically read Web Server Logs (in w3c log format), parse and push them to PostgreSQL,\n[SERVICE] Flush 5 Daemon Off Log_Level debug Log_File d:\\monitoring\\fluentbit.log Parsers_File parsers.conf Parsers_File generated/parsers_generated.conf HTTP_Server On HTTP_Listen 0.0.0.0 HTTP_Port 2020 [INPUT] Name tail Tag format.iis Parser dips-w3c path d:\\temp\\iis.log DB d:\\temp\\raw.iis.db [OUTPUT] Name pgsql Match * Host 172.0.0.1 Port 5432 User fluentbit Password fluentbit Database timescalepoc Table iislogs Timestamp_Key time Configuration for Parser is as below,\n[PARSER] Name dips-w3c Format regex Regex ^(?\u0026lt;time\u0026gt;\\d{4}-\\d{2}-\\d{2} \\d{2}[\\:\\.]\\d{2}[\\:\\.]\\d{2}) (?\u0026lt;serverip\u0026gt;\\S+) (?\u0026lt;method\u0026gt;\\S+) (?\u0026lt;uristem\u0026gt;\\S+) (?\u0026lt;uriquery\u0026gt;\\S+) (?\u0026lt;serverport\u0026gt;\\S+) (?\u0026lt;username\u0026gt;\\S+) (?\u0026lt;clientip\u0026gt;\\S+) (?\u0026lt;userAgent\u0026gt;\\S+) (?\u0026lt;referrer\u0026gt;\\S+) (?\u0026lt;status\u0026gt;\\S+) (?\u0026lt;substatus\u0026gt;\\S+) (?\u0026lt;win32status\u0026gt;\\S+) (?\u0026lt;timetaken\u0026gt;\\S+) (?\u0026lt;useragent1\u0026gt;\\S+) (?\u0026lt;auth\u0026gt;\\S+) (?\u0026lt;contenttype\u0026gt;\\S+) Time_Key time Time_Format %F %T Time_Keep True types serverPort:integer httpStatus:integer httpSubStatus:integer win32Status:integer timetaken:integer This parser basically uses Regular Expression to parse each line in log file into key - value pairs with data points of interest.\nIn terms of output, Fluentbit\u0026rsquo;s Postgresql plugin provisions the table itself with a structure that stores entire JSON in field as part of row. Either this table can be used as is or use \u0026ldquo;Before insert\u0026rdquo; trigger as suggested by Fluentbit\u0026rsquo;s manual to parse the Json and populate separate table.\nFluentbit can be easily configured to run as daemon (on Linux) or Service (on windows).\nVisualization With data getting added to timescaledb Hyper table,Lets see how it can be visualized.\nTypically, there are 2 approaches to be considered for Visualization,\nCustom-built Web UI - This only makes sense if,\nThere is already a Reporting/Visualization Web UI in place and adding new dashboards/reports is not much pain Not much customization and/or slicing-dicing is expected. Limited Efforts available. Off the shelf Tools - This approach makes sense if,\nIt is expected that Monitoring dashboards should be flexible and provide ease of customization by business or power users.\nAdditional dashboards are expected or can be provisioned with minimal or no coding.\nThere are many paid and open source tools available. Notable OSS options are,\nGrafana - Tailor made for Monitoring and extensive analysis of Time series data. Apache Superset - open-source application for data exploration and data visualization able to handle data at petabyte scale. Lets see how Grafana can be used for visualization (Probably, i may evaluate superset some time and update this post.)\nGrafana Grafana has multiple offerings and one of them being Open source, Self-hosted Application. It has Go backend and is very easy to install. For Windows, Just follow the steps at Installation.\nOnce grafana is setup, one can quickly start it by running grafana-server. By default, it starts Web server at port 3000. With Grafana Web-based GUI up and running, lets perform below steps to get dashboard in place.\nConnectivity to PostgreSQL - One needs to add Data Source in Grafana which in this case is PostgreSQL Database. It can be added from sidebar on Grafana UI, by hovering over \u0026ldquo;Configuration\u0026rdquo; option. In below screenshot, it shows configuration. Grafana: Connect to PostgreSQL Add Dashboard - Once the Data source is setup, next step is to add a dashboard. Dashboard essentially is a visualization or a report. It has Query (in this case SQL Query) to fetch the data. Below screenshot shows configuration of simple query for Dashboard, Grafana: Query for Dashboard Grafana requires certain functions to be included (like $__time(..) and $__timeFilter(..)) in query so as to facilitate filtering/ordering by user through UI, like shown below,\nGrafana: View data and apply Filter Grafana provides extensive ways to transform on the data fetched by SQL Query. This feature is more aimed at business and power user who may want to perform additional analysis on it. Alternative is to provide desired SQL and get the visualization like Time series or Graph as shown below,\nGrafana: Complex SQL Query with minimal transformation Grafana: Time Series Visualization Note that there are many more features provided by Grafana (in terms of transformations, Visualization options, Access Control to UI itself and so on.\nKey points with this approach are,\nLeveraging tools/products currently in use. Greater Flexibility in Visualization over custom built tool containing canned reports/graphs Lesser learning curve than inducting new tools. This post barely touches surface of what each of the individual tools mentioned have on offer, one would do well to go through their documentation to derive most value out of it.\nUseful links (#usefullinks) Comparison of IT Monitoring tools Nice Introduction to Modern Observability Happy Coding !!\n","permalink":"http://localhost:1313/posts/nrtanalysispostgresql/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eSuppose you have a distributed application running in production and it is based on Micro services/Service Oriented Architecture and have SLA of being \u0026ldquo;always on\u0026rdquo; (be available 24*7, barring deployments of course !!). In such cases, having proper monitoring of Application health in place is absolutely essential.\u003c/p\u003e\n\u003cp\u003eWhat if Monitoring is an afterthought (i.e. application is already in production) ? and that there is little apetite for additional components like (Visualization tools, specialized storage for logs/metrics/traces) for monitoring?\u003c/p\u003e","title":"Near real time API Monitoring with Grafana and PostgreSQL"},{"content":"Course Overview Welcome to Pluralsight. My name is Julie Lerman, and this is Steve Smith. Together, we\u0026rsquo;d like to welcome you to our course, Domain‑Driven Design Fundamentals. Steve is a trainer and architect with NimblePros and spends a lot of time helping teams write better code, faster. And Julie is well known in the DDD community for helping reluctant teams embrace domain‑driven design. In this course, we give you a strong foundation for learning how to build applications and microservices using domain‑driven design. DDD has proven to be a very effective approach for managing complex requirements. The original version of this course has helped many thousands of learners leverage domain‑driven design, and they have shared amazing feedback. Now, we\u0026rsquo;ve updated the course and its sample application to reflect ideas and tools that have emerged since that first version. Some of the major topics that we\u0026rsquo;ll cover include what are the essential ideas of domain‑driven design? What are the main patterns used in domain models? We\u0026rsquo;ll also talk about how to break up concepts into smaller parts and how these smaller aggregates and contexts communicate with one another. By the end of this course, you\u0026rsquo;ll know how to break down customer requirements into a maintainable domain model and structure a solution using domain‑driven design. Before beginning the course, you should at least be familiar with software development, ideally using C#. From here, you should feel comfortable diving into DDD and design patterns with courses on the DDD learning path and the design patterns learning path. We hope you\u0026rsquo;ll join us on this journey to learn domain‑driven design with the Domain‑Driven Design Fundamentals course, at Pluralsight.\nIntroducing Domain-Driven Design Introduction and Overview Hi, this is Steve Smith ‑and this is Julie Lerman. Welcome to our course, Domain‑Driven Design Fundamentals. ‑We\u0026rsquo;re looking forward to sharing our experience with DDD and how it\u0026rsquo;s helped us and our clients. You\u0026rsquo;re welcome to reach out to us online. ‑You can find me online at thedatafarm.com or on Twitter @julielerman. ‑And I\u0026rsquo;m online at ardalis.com or on Twitter as @ardalis. ‑Eric Evans coined the term Domain‑Driven Design in his groundbreaking book with the same title published in 2004. Since then, other titles have followed, including great books expanding on the subject by Jimmy Nilsson and Vaughn Vernon and so many who are now also great experts at DDD. And there are also now a number of fantastic DDD conferences and even a well‑established virtual meetup. ‑There\u0026rsquo;s definitely continued and renewed interest in Domain‑Driven Design as both the demand for and complexity of software continues to grow. Domain‑Driven Design is commonly referred to as DDD and even has its own Twitter hashtag, dddesign. Although DDD has been around for so long, it continues to be a great approach to building software that we both enjoy employing and sharing with others. And as more minds have gotten involved in DDD, it continues to evolve.\nWhat to Expect from This Course and This Module Domain‑Driven Design is a huge topic. Our focus will be on the developer perspective and the technical and coding aspects of DDD more so than architectural concerns. We\u0026rsquo;ll start by talking about why we think you should even be watching this course. Next, we\u0026rsquo;ll jump right into an existing solution so you can get a concept of what the code and the architecture of an application written using DDD practices looks like. Then we\u0026rsquo;ll start digging into the big DDD concepts like modeling problems of the domain, what the various technical components of DDD are, and how you can use DDD to manage complex projects. Throughout the course, we\u0026rsquo;ll use the existing solution so you can see how some of this process works. ‑With this in hand, we\u0026rsquo;ll walk through extending the sample based on a new request from the client. Since this is a fundamentals course, we certainly don\u0026rsquo;t expect to turn you into an expert by the end of it; however, you should be well on your way to understanding the value behind Domain‑Driven Design and how some of the practices can be employed to improve your success with complex software projects. Right now, if you\u0026rsquo;re new to DDD, you don\u0026rsquo;t even know what you don\u0026rsquo;t know yet. However, once you\u0026rsquo;re done with this course, you\u0026rsquo;ll know more about DDD, but of course, you\u0026rsquo;ll also realize how much more there is to learn. That\u0026rsquo;s one of the great things about our industry. The more you know, the more you realize how much more there is you don\u0026rsquo;t know. ‑In this module, we\u0026rsquo;ll focus on the value of Domain‑Driven Design. You\u0026rsquo;ll learn what the term represents and what problems DDD can help you with in your software building process. ‑Not only will we share the benefits of DDD, but we will be sure to highlight some of the potential drawbacks. Finally, you\u0026rsquo;ll get a look at a small application that we\u0026rsquo;ll be using throughout the course as you learn DDD.\nUnderstanding the Value of Domain-Driven Design Domain‑Driven Design focuses on the problems of the business domain that you\u0026rsquo;re attempting to solve. Its a critical shift from decades of focusing on how to store your data and then letting that drive how the software is designed. But that workflow added a lot of unnecessary complexity to the task of building software. So why should you watch this course? Why should you care about learning Domain‑Driven Design. Steve and I have both been designing and developing software for a very long time. Without giving away our ages, we\u0026rsquo;ve got over 40 years of experience between the two of us, and we\u0026rsquo;ve both been very inspired by Domain‑Driven Design. In many ways, it aligns very naturally with ideas that we\u0026rsquo;ve each come to from our own experience. It also takes these ideas and lays them out in a way that\u0026rsquo;s not only illuminating, but it\u0026rsquo;s repeatable. When Eric Evans wrote his book, his goal was to understand what was behind the successes he had achieved with large‑scale, complex software projects and what were the patterns. That\u0026rsquo;s what he laid out in the book. ‑This is why we care about DDD, and we hope that you can gain from our experience, which is why we put together this course. DDD provides principles and patterns to help us tackle difficult software problems and even business problems. These are patterns that are being used successfully to solve very complex problems. The more we\u0026rsquo;ve learned about DDD, the more we found these ideas aligned with the approaches we\u0026rsquo;ve learned from our many combined years of experience. DDD provides us with a clean representation of the problem in code that we can readily understand and verify through tests. We developers live to code. When starting on a new project, we\u0026rsquo;re eager to jump in and start coding so that we can build some software. But you can\u0026rsquo;t build software unless you truly understand the client\u0026rsquo;s needs. DDD places as much emphasis on not only comprehending what your client wants, but working with them as full partners through a project. The ultimate goal isn\u0026rsquo;t to write code, not even to build software, but to solve problems. ‑You need to realize that nobody really wants your program. They want what it can give them. There\u0026rsquo;s a famous saying in sales. Buy a quarter‑inch drill, they want to buy quarter‑inch holes. Your client\u0026rsquo;s not interested in building software, but in being successful at their mission. Software provides a more efficient means to this end.\nGaining a High-Level Understanding of DDD Domain‑driven design is for solving complex problems. Evans put a lot of thought into the subtitle of his DDD book and came up with Tackling Complexity in the Heart of Software. But DDD itself is a complex topic. To start with, we think it\u0026rsquo;s helpful to look at it from a very high level. We call it the 10,000 foot view here in the US, but that\u0026rsquo;s probably 3,048 meters to the rest of you. ‑One of the critical pieces of DDD is to encourage better interaction with domain experts. These are the people who live and breed the business or process or whatever you are targeting with the software you\u0026rsquo;re planning to write. You may be thinking, but we already talked to them. Perhaps, but probably you\u0026rsquo;re using your terms, not theirs, and maybe talking in the language of tables in a database rather than domain concepts. Or you may presume that after some standard requirements gathering, you can infer enough about the problem at hand to design the solution on your own. After our own history in the business of developing software, we know that that rarely ends well. DDD guides us to engage with the domain experts at much greater length and through much more of the process than many software teams are used to doing. ‑When talking with Eric Evans about this, he told us that you really need to cultivate your ability to communicate with business people in order to free up their creative modeling. Another core theme in DDD is to focus on a single subdomain at a time. Say you\u0026rsquo;re asked to build software for a spaceship manufacturer. They describe their business tasks such as purchasing materials, engineering, managing employees, advertising their spaceships and share with you their dreams about mass producing spaceships when the market\u0026rsquo;s ready. Each one of these tasks are in themselves a complex subdomain filled with their own specific tasks, terminology, and challenges, and those subdomains may have only minimal interaction between them. Many applications just try to do too many things at once, then adding additional behavior gets more and more difficult and expensive. With DDD, you\u0026rsquo;ll divide and conquer. By separating the problem into separate subdomains, each problem can be tackled independently, making the problem much easier to solve. This lets us focus on the problem of employee management separately from the problem of sourcing materials for producing the spaceships. The term modeling is important in DDD and refers to how you decipher and design each subdomain. You\u0026rsquo;ll learn much more about this as you progress through the course. ‑The final theme in our high‑level perspective of DDD is writing the code to implement each subdomain. The principle of separation of concerns not only plays a critical role in identifying the subdomains, but within each subdomain, we use it as well. Many applications spread the domain logic between the persistence layer and the user interface, making it much more difficult to test and to keep all of the business logic consistent. DDD applies separation of concerns to help steer you clear of this problem by focusing on the domain and not on details like how to persist data into a database or how to connect to a service in the cloud. Those become implementation details that you can worry about separately. While implementing these subdomains, the focus is on the subdomain, the problems of the subdomain you are trying to solve with your software. You don\u0026rsquo;t get bogged down worrying about infrastructure concerns.\nExploring the Benefits and Potential Drawbacks of DDD Domain‑Driven Design is a big commitment. While Steve and I have both chosen to leverage pieces of DDD as we learn more about the wider scope, one thing we\u0026rsquo;re both confident about is that it\u0026rsquo;s providing a lot of benefits to our work. Because DDD guides us to focus on small, individual, nearly autonomous pieces of our domain, our process and the resulting software is more flexible. We can easily move or modify the small parts with little or no side effects. It even lets us be more flexible with our project resources as we\u0026rsquo;re building the software. ‑The resulting software also tends to be more closely mapped to the customer\u0026rsquo;s understanding of the problem. DDD gives you a clear and manageable path through a very complex problem. When you look at the code, you can see that it\u0026rsquo;s generally well organized and easily tested, and the business logic all lives in one place. Even if you don\u0026rsquo;t use full DDD for a project, there are many patterns and practices that you can use by themselves to benefit your application. So keep watching, even if you don\u0026rsquo;t think you\u0026rsquo;ll need all of it. ‑We often describe DDD as a way to take big, messy problems and transform them into small, contained, solvable problems. But DDD is not a path for every project. It\u0026rsquo;s real benefit is for complex domains. Even Eric Evans explicitly states that DDD isn\u0026rsquo;t suitable for problems when there\u0026rsquo;s substantial technical complexity, but little business domain complexity. Using DDD is most beneficial when the complexity of the domain makes it challenging for the domain experts to communicate their needs to the software developers. By investing your time and effort into modeling the domain and coming up with a set of terminology that\u0026rsquo;s understood for each subdomain, the process of understanding and solving the problem becomes much simpler and smoother. ‑But all this comes at a cost. You\u0026rsquo;ll spend a lot of time talking about the domain and the problems that need to be solved, and you\u0026rsquo;ll spend plenty of time sorting out what is truly domain logic and what is just infrastructure. The easy example there is data persistence, or for the sake of our spaceship manufacturer, maybe it\u0026rsquo;s how to communicate with an external service that helps to verify that potential buyers are properly vetted for space travel. ‑You\u0026rsquo;ll have a big learning curve as you learn new principles, patterns, and processes. There\u0026rsquo;s no question about that. DDD is a big topic and gaining expertise from end to end is a big commitment. This course doesn\u0026rsquo;t aim to make you an end‑to‑end expert in DDD, but to give you a big step forward that will allow you to not only comprehend the concepts, but you\u0026rsquo;ll gain a lot of new tools that you can use right away, whether or not you choose to dig further. And it\u0026rsquo;s worth restating that DDD is not always the correct path for your applications. And it\u0026rsquo;s helpful to keep in mind some of the scenarios where DDD is just going to be overkill. For example, if you have an application or a subdomain that\u0026rsquo;s just a data‑driven app and doesn\u0026rsquo;t need much more than a lot of CRUD logic, there\u0026rsquo;s really no need to use DDD. It would be a waste of time and effort. ‑And be clear about the difference between complexity in your business domain and technical complexity. DDD is designed to help with complex domains. If your domain is simple, even if you have a lot of technical challenges to overcome, DDD still may not be the right path. For example, if you are writing a tic‑tac‑toe game for a touch screen with a new complex API, the complexity lies in the touch interactions of the two players on the screen. The domain itself is well known and just comes down to Xs and Os. Getting others to follow the DDD approach can also be a drawback. There may be some politics involved in this decision. It really depends on your team and your organization. We hope that another takeaway from this course will be to help you understand the concrete benefits of DDD, which you can show to your coworkers to help convince them.\nInspecting a Mind Map of Domain-Driven Design In his DDD book, Evans included a really useful diagram of how many of the concepts and patterns of DDD are interrelated. Let\u0026rsquo;s take a look at that mind map. ‑Evans refers to this as a navigation map, and it lays out all of the pieces of Domain‑Driven Design and how they relate to one another. We want you to see it so that you have a concept of the big picture, even though in this course we\u0026rsquo;ll spend most of our time on a subset. We will be defining many of these terms later on in the course, so don\u0026rsquo;t panic. We\u0026rsquo;ve mentioned modeling the domain and subdomains a few times. Modeling is an intense examination of the problem space. Key to this is working together with the subject matter experts to identify the core domain and other subdomains that you\u0026rsquo;ll be tackling. Another important aspect of modeling is identifying what\u0026rsquo;s called bounded contexts. And within each of these bounded contexts, you focus on modeling a particular subdomain. As a result of modeling a bounded context, you\u0026rsquo;ll identify entities, value objects, aggregates, domain events, repositories, and more and how they interact with each other. ‑In the image, there\u0026rsquo;s more than just these subdomains, however. For example, there is a concept of an anti‑corruption layer, which allows subdomains to communicate with one another from behind their boundaries. The model also has notes for each element, such as free teams to go separate ways. This is something that can be accomplished once you\u0026rsquo;ve identified the boundaries of each subdomain. Or avoid overinvesting in generic subdomains. That could be something like a credit card verification service that you could choose to use rather than building yourself. As you begin focusing on specific subdomains, another very important DDD concept surfaces, driven by the need for clear, concise communication. It\u0026rsquo;s called the ubiquitous language. A simple definition of a ubiquitous language is to come up with terms that\u0026rsquo;ll be commonly used when discussing a particular subdomain. And they will most likely be terms that come from the problem space, not the software world, but they have to be agreed upon so that as discussions move forward, there is no confusion or misunderstanding created by the terminology used by various members of the team. ‑We invite you to pause this video to look over this map and read the notes associated with the various elements and contemplate what they might mean. We\u0026rsquo;ll revisit this throughout the course, and we hope that the map will make more and more sense as you work through the course.\nIntroducing Our Sample Application Now we want to switch over and show you a relatively small DDD‑based solution that we\u0026rsquo;ll be working on for the rest of the course. This app represents an appointment scheduling system for a veterinary clinic. It\u0026rsquo;s \u0026ldquo;small\u0026rdquo;, but since DDD requires a certain amount of complexity to warrant its use, it\u0026rsquo;s bigger than most demos you\u0026rsquo;ll see in other courses or presentations. For this course, we decided that we would use a veterinary clinic management system because it has a decent amount of complexity, and that means that we can apply some of the DDD principles, but it also gives us an excuse to show off pictures of our pets. ‑And our friends pets too. We\u0026rsquo;ve got a whole bunch of pet pictures from other Pluralsight authors in here, and they\u0026rsquo;re all so cute. ‑We\u0026rsquo;ve got Ben Franklin here from Michael Jenkins. We\u0026rsquo;ve got Patrick Neborg\u0026rsquo;s dog here, Sugar. Aren\u0026rsquo;t these guys cute? And, of course, Julie\u0026rsquo;s got Sampson. ‑Oh, my handsome boy. ‑And I\u0026rsquo;ve got Darwin, the silly poodle. He was just a puppy when we recorded the first version of this course, and he\u0026rsquo;s got a new friend, Rosie. Rosie is just a puppy. I guess every time I get a puppy we have to update this course. ‑So the idea behind this application is that if you\u0026rsquo;re working at the front desk of a vet clinic and someone walks in, maybe they want to schedule an appointment, or the phone rings with someone who wants to schedule an appointment for their pet, the first thing you\u0026rsquo;re going to do is look that client up, the person, in the system. ‑So the user starts by looking up the client, and from there, they can choose which of the clients, animals or patients, they\u0026rsquo;re going to schedule. So here\u0026rsquo;s Julie with Sampson. Here\u0026rsquo;s Kim with Roxy. Next, the user is just going to click on an open slot in the schedule, which opens up the create appointment window. ‑Oh, Roxy, you\u0026rsquo;re such a cutie. We can set up Roxy for a wellness exam with Dr. Smith. ‑Now notice before we save this appointment, it isn\u0026rsquo;t yet confirmed. We\u0026rsquo;ll get to that in a minute. So we save, and the appointment shows up. Now the complexity in this system comes into play when we have to do some checks for certain things. We want to make sure, for instance, that Roxy isn\u0026rsquo;t already scheduled in one of the other rooms at this exact time. We also want to send an email notification to Kim to let her know that Roxy has this appointment scheduled. We\u0026rsquo;ll add a link in the email the client can click to confirm. And in a real system, perhaps it would add it to their calendar of choice. The idea is to cut down on no‑show appointments for the clinic. ‑Of course, there are other features of this application. We\u0026rsquo;re focused on the schedule right now, but we do need to be able to manage client data and manage their pet data, the clinic\u0026rsquo;s patients, and things like that. Admins need to be able to manage doctors and rooms and appointment type since these all might change over time or from one clinic to another that uses the same software. But those are mostly CRUD tasks, which means we\u0026rsquo;re just talking about adding and removing records and maybe making some edits without a whole lot of complexity. We\u0026rsquo;ll talk about those tasks in a different compartment of the application than the schedule, which, of course, has a lot more complexity.\nExploring the Sample App\u0026rsquo;s High-level Structure So why don\u0026rsquo;t we take a look at the structure of our app? This is a distributed application built with ASP.NET Core on .NET 5. It\u0026rsquo;s running Blazor WebAssembly in the front end, which is talking to APIs running on ASP.NET Core. There are three different web apps that the system uses. Two are used internally by client staff, and then there\u0026rsquo;s the public‑facing website for the clinic, which is needed for the confirmation links that users will click. The two clinic apps, Front Desk and Clinic Management, each have their own database, and all three apps communicate with one another using messages transported by RabbitMQ. Like I said, it\u0026rsquo;s maybe a little more complicated than most demos. We want the sample app to be something you spend some time with and extend as part of your experience with this course, so please be sure to check it out and run it locally. It should just work if you have Docker installed. ‑Now let\u0026rsquo;s take a quick look at how the code is organized. The full solution is hosted on Steve\u0026rsquo;s GitHub account. Here\u0026rsquo;s the URL, but we\u0026rsquo;ll definitely also have that URL in the resources slides at the end of this module. PLURALSIGHT DDD FUNDAMENTALS is the name of the root of our GitHub repository. In here, you can see the three web apps, ClinicManagement, FrontDesk, and the public‑facing website, VetClinicPublic. ‑There\u0026rsquo;s also a folder for SharedKernel, which we\u0026rsquo;ll talk about a little bit later. The first app we\u0026rsquo;re going to focus on though is the FrontDesk app. ‑Our main focus for this course is going to be the front desk application and its scheduling functionality. Looking at the solution, you can see it\u0026rsquo;s broken up into seven projects, which seems like a lot, but three of them are just there to support Blazor The server‑side code, where our domain model resides, is just three projects. ‑The most important project is FrontDesk.Core. That\u0026rsquo;s where the domain model is defined. All of the app\u0026rsquo;s infrastructure needs, like how it talks to its database or RabbitMQ, are kept in the FrontDesk.Infrastructure project. In the front end, in this case, ASP.NET Core and its API endpoints, is in the FrontDesk.Api project. This is the front end from the server\u0026rsquo;s perspective. The system is using a clean architecture design which you may also hear referred to as onion architecture or ports and adapters. I cover this in my N‑Tier Applications in C# course, and I have a popular GitHub solution template you can use to set up a new project using this approach. ‑With clean architecture, the project dependencies all point towards the domain model in the core project, so both the API and infrastructure projects have a dependency on Core. Core should never depend on infrastructure concerns, but it can leverage NuGet packages that don\u0026rsquo;t couple it to infrastructure concerns. ‑In this case, it\u0026rsquo;s using a couple of utility packages, as well as the SharedKernel package that\u0026rsquo;s shared by other apps. We\u0026rsquo;ll talk more about SharedKernel later. The ClinicManagement app uses the same kind of structure and also has a Blazor front end because why not? It\u0026rsquo;s pretty much just CRUD, so we don\u0026rsquo;t focus too much on its domain model, but it is a distinct app with its own database, and we do need to build into our design a way to propagate changes from it to the FrontDesk app. ‑Finally, there\u0026rsquo;s the public web app. It\u0026rsquo;s just one project, and it\u0026rsquo;s pretty simple. This is responsible for sending emails, which this demonstration fakes using a tool called PaperCut, and it hosts the link that clients click to confirm appointments. The public web app also needs to communicate with the front desk, but it doesn\u0026rsquo;t have a database of its own, nor does it access any of the other app\u0026rsquo;s databases. ‑That\u0026rsquo;s it in a nutshell. We\u0026rsquo;ll demonstrate the confirmation emails and more complex use cases later in the course. But for now, that should give you an idea of how the ideas we\u0026rsquo;re sharing are put into practice.\nReview and Resources So, as we\u0026rsquo;ve talked about, creating applications is not about writing code, even though often that\u0026rsquo;s a really, really fun part for us developers, but it\u0026rsquo;s about solving problems. And the more complex the problems are, the more difficult the whole project becomes. So Domain‑Driven Design gives us some great patterns and practices for attacking these more complex problems, and they get us to really focus on interacting with the domain experts, breaking apart our domain, and working on things in smaller units and in a very organized fashion. And in the end, it gives us a much more efficient and effective path to success in creating our solutions. ‑Yeah, we talked about some of the benefits that Domain‑Driven Design provides, as well as some of the drawbacks. Specifically, your team just needs to know Domain‑Driven Design, and your domain experts need to be available to work with you on these systems. Domain‑Driven Design is a big topic. We looked at some of the different concepts that are involved in DDD, and we\u0026rsquo;re going to look at a lot more of them in depth through this course. But remember that this is just an introduction to Domain‑Driven Design, so some of these aspects that are a little more advanced, we\u0026rsquo;re not going to be able to cover with a great deal of depth. ‑In the next module, we\u0026rsquo;ll start exploring the process of discovering and modeling domains. Here are some links to resources that we mentioned this module and others that we find relevant. ‑This is Steve Smith ‑and this is Julie Lerman, and thanks for watching Domain‑Driven Design Fundamentals.\nModeling Problems in Software Introduction and Overview Hi. This is Steve Smith. ‑And this is Julie Lerman. Welcome back to our Domain‑Driven Design Fundamentals course. This module will focus on modeling problems in software, and you\u0026rsquo;re welcome to reach out to us online. You can find me online at thedatafarm.com or on Twitter @julielerman. ‑And I\u0026rsquo;m at ardalis.dot com or on Twitter as @ardalis. In this module, we\u0026rsquo;re going to take a look at how we decompose the model for the veterinary office domain. We\u0026rsquo;ll talk about the importance of domain experts in DDD. ‑We\u0026rsquo;ll drive this point home with a play in which we\u0026rsquo;ll consider a few different scenarios for how the project might have gone, which should provide you with examples of ways to involve the domain expert in the design of the system. ‑Next, we\u0026rsquo;ll talk about the domain model and some of the elements that typically are found in this part of the application. It\u0026rsquo;s important to separate the core domain model from related subdomains, and we\u0026rsquo;ll talk about how bounded contexts can help us accomplish this separation. ‑And then we\u0026rsquo;ll wrap things up by talking about ubiquitous language and how this seemingly small thing with a big name can have a large impact on your model, your design, and, of course, your application. So let\u0026rsquo;s get started.\nIntroducing Our Domain Steve and I both have a love for animals. In fact, Steve\u0026rsquo;s wife, Michelle, is a veterinarian. In thinking about a sample application we could use for this course, we wanted to use something complex enough to justify the use of DDD. The veterinary clinic management domain made a lot of sense, allowing us to leverage our own experience as pet owners, as well as having a domain expert available in the form of Michelle, or Dr. Smith as we\u0026rsquo;ll be referring to her in the course. ‑There are many different pieces involved in managing a typical veterinary clinic. The staff needs to be able to schedule appointments. They likely need to schedule their own working shifts as well. They need to be able to invoice for their services and collect payments and, in many cases, send out bills. They\u0026rsquo;ll also need to be able to store and retrieve medical records, as well as work with external labs and specialty clinics. Most veterinary practices also have products for sale and may need to track inventory, as well as sales. And there are often follow‑ups and reminders that may need to be sent by mail, phone, or perhaps email. There is certainly sufficient complexity in this domain to merit the use of domain‑driven design.\nPlanning Ahead to Learn About the Domain Of course, it\u0026rsquo;s a good idea to speak with a domain expert about the systems requirements before diving in and beginning to code a solution. Whether you\u0026rsquo;re tasked with building a full system or just adding a new feature, an overall understanding of the client\u0026rsquo;s business is a critical start. Of course, it\u0026rsquo;s just the beginning. It\u0026rsquo;s also important that you have a continuous conversation with the domain expert throughout the development of the system. The simple system we showed in the last module needs some updates. So we\u0026rsquo;re going to share some conversations we had with the domain expert to help validate our initial assumptions. ‑An important part of this conversation is going to be identifying the things that aren\u0026rsquo;t included in the scope of the project or feature. To that end, we\u0026rsquo;ll try to identify subdomains within the overall problem domain and then determine whether or not we need to concern ourselves with these subdomains at the moment. If not, we can consciously remove them from the scope with the customer\u0026rsquo;s approval and avoid confusion and possible missed expectations later. To get started though, we do want to know a little bit about the big picture.\nConversation with a Domain Expert: Exploring the Domain and Its Subdomains As Julie already mentioned, my wife, Michelle, is a veterinarian. In addition, she has a deep understanding of software development processes, having successfully managed software teams at NimblePros and Teller. She has graciously agreed to play the role of domain expert for our course. In real life, she knows quite a bit about software and technology, but for the purposes of this course, she\u0026rsquo;s playing the more traditional role of a veterinarian with little background in software development. Hi Dr. Smith. Thanks for your time today. Julie and I would like to learn more about what goes on in your veterinary clinic. Can you share some of the big picture processes involved in the day‑to‑day operation of a clinic? ‑So the biggest thing is probably scheduling patients and keeping track of them once they arrive. Clients will usually call ahead unless it\u0026rsquo;s an emergency, and then we need to get them entered into our system. Of course, surgical procedures need to be scheduled in advance. And when they\u0026rsquo;re here, we need to record information about the patient, our observations, notes, and diagnoses. ‑Wow, that\u0026rsquo;s quite a list. Probably not what you were dreaming about when you started vet school. So many of these are all secondary to the core reason for being a vet, keeping pets healthy. And, I think it sets you apart from other businesses that have to manage clients and schedule appointments. But, you can\u0026rsquo;t run a business without it. Is that all? ‑So when the appointment is over, they also have to pay. So most of the time that\u0026rsquo;s done immediately, but we do have some billing that\u0026rsquo;s done after the fact, and when they\u0026rsquo;re checking out, they may need to buy some things for their pets, toys or prescriptions, or maybe some prescription food as well, and we need to track all of that as well. For some of the lab work, we need to send that out and get the results back, and some prescriptions go out to outside pharmacies as well. So we need to manage all of those through the system. ‑Okay, so payments, billing, point of sale, labs, prescriptions, anything else? ‑I think that\u0026rsquo;s about it. Oh, we also use the system to note which staff members are working when, and right now our website isn\u0026rsquo;t integrated into the system at all, but we were thinking it would be great if clients could view information about their pets, maybe schedule appointments, look up prescriptions, and we can make updates to the site without having to go through our computer contractor. ‑Okay, great. So, we\u0026rsquo;ll add staff scheduling and content management to the list. I don\u0026rsquo;t want to assume you know what a content management system is. We also call it a CMS, you might have heard of that. It\u0026rsquo;s a type of software system that lets the owner, that\u0026rsquo;s you, be in charge of the information that\u0026rsquo;s displayed. A blog is a really good example of a CMS that can be managed by its owner. ‑I have a blog, so I understand exactly what you mean. Something like that would be really great for us to have so we can make updates right in‑house. But it\u0026rsquo;s kind of like a blog, especially something that\u0026rsquo;s more professional than my personal blog. ‑Cool. So I think that\u0026rsquo;s probably enough of a big picture view for us to consider at the moment. Now let\u0026rsquo;s try and think about which of these are connected to the others so we can determine which ones we need to worry about for our application\u0026rsquo;s needs. ‑We started with this fairly complicated view of the overall problem domain, but now we\u0026rsquo;ve segregated these into different areas and we know which ones we need to focus on right now and which ones we can treat as external collaborators. ‑Determining where we can safely draw the line between what problem our immediate application needs to solve and what is outside of its area is certainly helpful. It\u0026rsquo;s also important that this be well understood and communicated among everyone involved in the project.\nConversation with a Domain Expert: Exploring the Scheduling Subdomain Now that we have a better understanding of the domain and the other subdomains around the scheduling system, it\u0026rsquo;s time to focus more on understanding the scheduling subdomain. We had another meeting with Dr. Smith, and you can listen in. ‑Hi guys, welcome back to the clinic. How are things going with the computer system? ‑We\u0026rsquo;re making good progress, and now we\u0026rsquo;re ready to look at another more complex feature. ‑We know there\u0026rsquo;s a lot that goes on here, but today we want to focus on appointment scheduling because we realize we\u0026rsquo;re still a little confused about it. ‑Since we\u0026rsquo;ve both owned pets for a long time, we figure we probably have a rough idea of what\u0026rsquo;s needed, but it\u0026rsquo;ll be good to talk through it with you. Do your patients usually schedule their appointments over the phone? ‑Okay, so yeah our patients aren\u0026rsquo;t usually involved in the scheduling. Usually, it\u0026rsquo;s the clients that call in for appointments for their pets. And yeah, usually it\u0026rsquo;s on the phone or in person when they\u0026rsquo;re checking out after an office visit. Julie and I talked about that earlier. ‑Yeah, so Steve, the patients are the animals, and the clients are the people or the pet owners. ‑Right, right, of course, that\u0026rsquo;ll be important to get right. ‑Remember, we talked about that. So the client needs to make an appointment for their pet. They\u0026rsquo;ll talk to a staff member who will schedule the appointment. What kind of information do they need in order to do that? ‑So that really depends on the type of appointment. It could be an office visit, or it could be a surgery. Why don\u0026rsquo;t we talk about the office visits first. If it\u0026rsquo;s just for a wellness exam, that\u0026rsquo;s pretty standard. They just need to choose an available time slot with one of the doctors. Some of the visits can be scheduled with just a technician though, so if they need just their toenails trimmed, for example. ‑Or painted, like Samson. He gets his toenails painted. ‑Does he really? ‑No, I\u0026rsquo;m joking. I just want to, pink. ‑I\u0026rsquo;m sure he\u0026rsquo;d love that. Okay, so office visits might be an exam requiring the doctor or another kind of appointment that only requires a technician. ‑Right. We also have to worry about our rooms too. We only have five exam rooms available, and we try not to overbook. We don\u0026rsquo;t like for our clients to have to wait too long in the reception area, especially if we have a lot of cats and big dogs out there at the same time. It makes them all really nervous. ‑What about other staff? ‑So our technicians will float between the exam rooms and other areas of the clinic as needed, except, of course, for those scheduled technician visits. We do have a schedule for the staff, but it\u0026rsquo;s separate from how we schedule our appointments. ‑Okay, so what about the surgeries? ‑Well, if it\u0026rsquo;s a surgery, those are only scheduled on certain days, and they require that the operating room be available, as well as some recovery space in the kennel area. It also depends on what kind of surgery or procedure we\u0026rsquo;re going to be doing. Something simple like a dental cleaning takes less time and fewer people than a caesarean section for a bulldog. ‑Okay, so an appointment is either an office visit or a surgery. Office visits happen in the exam room; surgeries require the operating room and recovery space. Is that right? ‑Right. And depending on the reason for the visit or the surgery, different staff might need to be involved. ‑So we\u0026rsquo;ll probably want to have separate classes for appointments and surgeries. ‑Classes? No, we refer our clients to obedience and puppy preschool classes at other facilities. We don\u0026rsquo;t actually schedule any of those in the clinic themselves. ‑I\u0026rsquo;m sorry. That\u0026rsquo;s a software term. In software, we have different classifications of concepts in the program, which are called classes. I\u0026rsquo;m just getting ahead of myself here. Sorry. ‑Don\u0026rsquo;t worry. We\u0026rsquo;re not going to make you learn our software terms. Steve and I will try to have a little bit more self control with that. We do want to make sure we\u0026rsquo;re all speaking the same language when it comes to concepts in the application though. ‑Okay, so I have another quick question. Do we have to worry about multiple staff members scheduling appointments at the same time? ‑No, there should only ever be one person doing the scheduling at a time, although I could see if we grew in the future that could change. But I don\u0026rsquo;t think that\u0026rsquo;ll happen in the next couple of years. Okay, then we don\u0026rsquo;t have to worry about the rare occurrence of two people creating a conflict if they\u0026rsquo;re trying to schedule an appointment for different patients in the same room or with the same doctor. That\u0026rsquo;ll keep things a lot simpler. And we need to know before an appointment if certain resources are available, like rooms and doctors. And then if they are and we want to schedule the appointment, then we need to be able to book the doctor, the room, and any other resources. Hey, is it okay if we refer to doctors as resources? ‑Sure, that makes sense. You know, I think it makes sense to use the term resources to refer to the doctors, the rooms, and the technicians since those are all things that can affect whether or not an appointment can be scheduled. But remember, sometimes it\u0026rsquo;ll be just a vet tech in a room, and other times it might be the doctor in the room, but sometimes you might need the doctor, the technician, and a room. ‑Wow, this is a lot more complicated than we\u0026rsquo;d realized, but it\u0026rsquo;s interesting. This is going to be cool to model in the application.\nReviewing Key Takeaways from Meeting with Domain Expert(s) Some of the things we learned in that initial high‑level discussion with the domain expert included the fact that patients and clients are not the same thing to a veterinarian. ‑Yeah, that\u0026rsquo;s pretty obvious in hindsight. But in most other medical professions, it is the patients who make appointments and pay the bills. It\u0026rsquo;s good we were able to get on the same page with the customer on that early on in the process. ‑I think it helped Dr. Smith put some of the processes she uses into explicit terms that we could program against also. A lot of times just describing the process to someone who is unfamiliar with it can really help improve the understanding of it. It\u0026rsquo;s like that idea that when you have to teach something to someone else, it makes you learn it a lot better. Listen to what Dr. Smith had to say at the end of our conversation about this. ‑Yeah, I never really thought about the details of how we do some of these things since it\u0026rsquo;s just something we do, and we don\u0026rsquo;t really think about it. Being more explicit about what the rules are that determine how we do are scheduling could help us avoid some of the occasional scheduling problems we\u0026rsquo;ve had. This is going to be great. ‑We also need to remember not to use too much programmer jargon, especially when there are programming terms that might have a different meaning in the customer\u0026rsquo;s domain. ‑I agree. It\u0026rsquo;s a little early for us to be worrying about how things might end up looking in the code anyway. At this stage, the main focus is on understanding the domain. We\u0026rsquo;ll get to building the software soon enough. But first, we want to make sure we know what problem it\u0026rsquo;s going to be solving. One of the most important things we can do as we explore the problem with the domain expert is to try and make their implicit knowledge about the process they use now explicit. Once we\u0026rsquo;re able to capture the process and its rules and exceptions with some detail, we can start to work on modeling a solution using this information. Building software is hard. One of my favorite sayings is as software developers, we fail in two ways. We build the thing wrong, or we build the wrong thing. By making sure we understand what the customer needs and, of course, working closely with the customer throughout the development process, we can dramatically reduce the likelihood of the second kind of failure, which is much harder to fix typically. ‑Hey, Steve. I like the way you quote yourself here, but it really is a great quote.\nTaking a First Pass at Modeling our Subdomain After talking to Dr. Smith about how appointments work, we\u0026rsquo;ve identified a few high‑level elements of our model. The central concept in this application seems to be the appointment itself. Typically, an appointment is scheduled by a client for a patient. Booking an appointment often requires an exam room and a doctor, but may involve other resources. Appointments might be for office visits or vaccinations, or they might be surgeries, which are a separate kind of thing entirely with their own rules which involved different kinds of procedures. Surgeries require different resources too, like operating rooms and recovery rooms. ‑That\u0026rsquo;s a pretty good high‑level view of the model we have so far for the appointment management part of our application. I think it\u0026rsquo;s worth noting that some of the concerns of this application are going to also play a part in other subdomains. For instance, I\u0026rsquo;m pretty sure we\u0026rsquo;re also going to be working with clients and patients in a lot of the different parts of this application. ‑Yeah, I think it\u0026rsquo;s time we introduce the idea of bounded contexts.\nUsing Bounded Contexts to Untangle Concepts that Appear to Be Shared As you develop your model, remember to identify its bounded context. That is, where is this model valid? If you don\u0026rsquo;t put boundaries around your model, eventually, pieces of it will be used where they don\u0026rsquo;t fit. Concepts that make sense in one part of the application may not make sense in another, even if they have the same name and sometimes even if they literally refer to the same thing. ‑For example, as we built out the appointment scheduling portion of this system, we needed to know some very basic information about clients. But in the context of appointment scheduling, these are very simple concepts with little behavior beyond their names. However, in the billing context, we\u0026rsquo;ll want to include contact and payment information for clients, but that\u0026rsquo;s information we don\u0026rsquo;t care about back in the appointment scheduling context. If we try to reuse the same exact client model in multiple places, it\u0026rsquo;s likely to cause inconsistent behavior in our system. ‑That\u0026rsquo;s right. For instance, we might decide to include some form of validation on clients to ensure we have enough information to bill them. If we\u0026rsquo;re not careful, that validation might inadvertently prevent us from being able to use clients to schedule appointments, which certainly isn\u0026rsquo;t the desired behavior. Maybe the billing system requires that clients have a valid credit card in order to save changes for them, but it wouldn\u0026rsquo;t make sense for a lack of a credit card to prevent us from saving an appointment for a client in the appointment scheduling system. In this example, we have two contexts, but the boundaries between them are blurred and overlapping. Eric Evans notes that models are only valid within specific contexts. Therefore, it\u0026rsquo;s best to explicitly define the context within which a model applies. We should be able to avoid compromising the model within this context, keeping it strictly consistent within these bounds and avoiding distractions or confusion from outside issues. ‑Once we explicitly define our bounded contexts, we can easily see whether or not we have elements of our model that are trying to span multiple contexts. In this example, we\u0026rsquo;d want to keep a simple view of a client in the appointment scheduling up and a richer version of the client with contact and billing information in the billing context. We would define these two views of a client in two separate classes, and they will most likely live in separate applications. In fact, Evans recommends that bounded contexts maintain their separation by giving each context its own team, codebase, and database schema. ‑While this is ideal, in many real‑world apps, we need to work on systems where this level of separation is not present, usually due to resource constraints or for political reasons within the organization. Remember though, if you have multiple contexts, you\u0026rsquo;ll want to keep them bounded. And one way to maintain this separation is to keep their data, code, and team members distinct from one another, although in real world, I\u0026rsquo;ve never seen something with that level of separation. ‑Yeah, but I think even if it\u0026rsquo;s not possible to literally do that with your company and your team, just having that concept in mind really helps in your brain have that idea of separation. ‑I agree. I know that just thinking about the fact that these things ought to be separated and trying to figure out a way to do it means that even if you can\u0026rsquo;t get to the ultimate level where everything is is completely separate, you can still introduce separations through things like namespaces, separate folders, separate projects, anything you can do to make it clear that these are different contexts that shouldn\u0026rsquo;t be sharing too much information. ‑You know, I think that\u0026rsquo;s also really important point about this course in general and DDD in general. For me, it\u0026rsquo;s really hard to think of all of these things we\u0026rsquo;re learning as hard and fast rules, like you have to do it this way or you\u0026rsquo;re not doing it right. I like to see all of this as really good guidance. So, you know, it helps me keep my eye on the prize, and when there\u0026rsquo;s places where I can\u0026rsquo;t truly achieve exactly what DDD kind of directs me to do, you know, I\u0026rsquo;m using my own experience, my own intelligence to make decisions about how to do things, and I\u0026rsquo;m letting DDD guide me in a lot of scenarios. ‑Sure. And some of these ideals, I think of like 100% test coverage. It\u0026rsquo;s almost impossible in most real‑world applications to achieve 100% test coverage. But just because that ideal is not something you can ever achieve doesn\u0026rsquo;t mean that you shouldn\u0026rsquo;t strive for more test coverage. ‑Yeah, yeah, totally, totally agree with that.\nConversation with Eric Evans on Subdomains and Bounded Contexts When learning about DDD, most of us have a hard time understanding how subdomains and bounded contexts are different. We asked Eric Evans about this and got some great insight. He explained that a subdomain is a view on the problem space, how you\u0026rsquo;ve chosen to break down the business or domain activity, whereas a bounded context represents the solution space, how the software and the development of that software has been organized. Quite often, these will match up perfectly, but not always. ‑Eric helped us understand this further with the example of a room that you want to cover with carpeting. The room is the problem space, so it\u0026rsquo;s like a subdomain. You could install a wall‑to‑wall carpet that matches the shape of the room perfectly. This would be like when the subdomain and the bounded context encompass the same thing. But other times you might just use some area rugs to cover the floor, and the area rugs solve the problem. They cover the part of the floor where you walk, and you don\u0026rsquo;t have to worry about cold feet in the winter. And that\u0026rsquo;s a scenario where the area rugs are like bounded contexts that don\u0026rsquo;t match the subdomain, but they solve the problem even though they\u0026rsquo;re not an exact match to the shape of the room.\nIntroducing Context Maps If your organization has multiple bounded contexts, and ideally these are separated, there can be confusion when the different teams are talking to one another. Again, DDD focuses at least as much on effective communication as it does on anything specifically related to the code we produce. Evans recommends using context maps to visualize and demonstrate to all teams where the boundaries between their context lie. ‑Think about a complex topographical map. It will frequently include a legend, like the one shown here, in order to explain what each of the lines and symbols on the map mean. However, this legend is only valid within the context of the map with which it appears. Trying to use this legend on another map would be confusing at best. ‑A good first step for an existing application is to create a map that shows how things are. Remember that the names of your contexts are also important as you\u0026rsquo;ll refer to them frequently when discussing different parts of the application. It may be that things are not as separate as they should be, and that\u0026rsquo;s worth noting. If you have separate teams responsible for different contexts that share resources, it\u0026rsquo;s important that each team understands which aspects of the application they can change on their own and which are shared dependencies they\u0026rsquo;ll need to coordinate with other teams to avoid breaking things. If we look at these two sets of concepts, we can see some obvious overlap. For one thing, Client appears in both contexts, but we know that for appointment scheduling we really only care about the client\u0026rsquo;s name, whereas in the billing system they\u0026rsquo;ll want additional information like address and payment details. However, although the details involved vary, we know that Mr. Jones, the client on the left, is the same actual person as Mr. Jones, the client on the right. However, we also have a concept of notifications on both sides, and in this case, they\u0026rsquo;re referring to different things. On the left, we\u0026rsquo;re talking about sending a notification when an appointment is booked as a reminder, and on the right, we\u0026rsquo;re talking about notifying the client that their payment was received or perhaps that it\u0026rsquo;s past due. ‑Especially in smaller organizations, it\u0026rsquo;s common to have one team responsible for several contexts of the same overall application. In such cases, it\u0026rsquo;s also common for the team to use a single codebase for the bounded context that they\u0026rsquo;re working with and store it in a single repository, such as GitHub. Usually, there will also be a shared database. As we\u0026rsquo;ve already noted, this is not ideal since it makes it much more difficult to maintain the boundaries between the separate contexts. ‑Part of creating a context map involves explicitly identifying its boundaries. If we try to draw the boundaries around these two bounded contexts, we can see there are now several resources that belong to each bounded context. This isn\u0026rsquo;t ideal if the two contexts really are meant to be kept separate. ‑In the ideal case for a large complex system, we would have bounded contexts like these, with their own teams, codebases, and database. For instance, on the left, we have an appointment scheduler application. It\u0026rsquo;s being worked on by Team Awesome, and they\u0026rsquo;re storing all of their code in their own repository called vet‑app‑sched. And, of course, this application has its own database. This team is free to change anything they want with their model or any other part of their system without worrying about breaking anything outside the boundaries for the team on the right, which is working on a billing system, and their team has decided to call themselves Team Ultimate, store their code in a repository called vet‑billing, and, of course, using their own database. By having this separation, this can greatly increase team velocity and reduce integration bugs. ‑Of course, you\u0026rsquo;re probably wondering how the two systems will interoperate. There are a number of patterns that can be applied to enable this kind of integration. We won\u0026rsquo;t be covering all of them in this course, but one question that frequently comes up is how to share cross‑cutting concerns like blogging and shared abstractions such as people names that are used by multiple bounded contexts. For this scenario, a common approach is to designate these shared concepts or resources as what we call a shared kernel. Team Awesome and Team Ultimate agreed to share the subset of the domain model. Since they\u0026rsquo;re sharing it, they also agree not to change it without coordinating with the other team first. Frequently, the shared kernel will either be a part of the customer\u0026rsquo;s core domain, or some set of generic subdomains, or even both, though it could be any part of the model that both teams require. Using a shared kernel is a tradeoff between code reuse and consistency and the overhead involved in integrating changes to the shared kernel across multiple teams and bounded contexts. It works best when the shared model is relatively stable.\nAddressing the Question of Separate Databases per Bounded Context The concept of having separate databases for each bounded context often throws people for a loop. But with the advent of microservices, which also, by definition, each have their own database, teams are beginning to get more accustomed to the idea. Here\u0026rsquo;s what Eric Evans said to us when we talked with him about the problems created by trying to share a database across teams. \u0026ldquo;If you\u0026rsquo;re in a company where you share your database and it gets updated by hundreds of different processes, it\u0026rsquo;s very hard to create the kind of models that we\u0026rsquo;re talking about and then write software that does anything interesting with those models.\u0026rdquo; Given that sharing a database across bounded contexts is really not a great idea, then we have another important question. ‑Another question that comes up often is how to sync data between the individual databases that are tied to each of the bounded contexts. Some different patterns you can use are publisher/subscriber, commonly referred to as pub/sub, and two‑way synchronization. Pub/sub is definitely simpler and preferable when you can manage it. You can use different implementations like message queues, database processes, batch jobs, or synchronous API calls. It\u0026rsquo;s really up to you how you want to design your synchronization between bounded contexts. The point is just that you don\u0026rsquo;t get the integration for free from using a shared database.\nSpecifying Bounded Contexts in our Application We talked with Eric again to get his perspective on defining context boundaries. Some of the key points he shared were that first, it\u0026rsquo;s important to understand that it\u0026rsquo;s never a simple task whether you\u0026rsquo;re new to it or not. And he\u0026rsquo;s seen stumbling blocks of all sorts. The most common is not having a clear enough context boundary, so the effort of applying DDD isn\u0026rsquo;t clearly separated from other tasks related to building software. ‑He also reminded us that the bounded context is such an essential ingredient that is probably the biggest stumbling block. And it\u0026rsquo;s not often one that an individual on a project can usually addressed by themselves. It kind of has to be dealt with at the team level or even the organizational level. In our application, we\u0026rsquo;ve organized the solution to make it clear where the boundaries are between our contexts. The main area that we are currently focused on is the appointment scheduling bounded context. ‑We\u0026rsquo;ve identified two other bounded contexts that are involved in the overall application or will be eventually. For instance, it\u0026rsquo;ll be important for users to be able to manage clients and their patients. The staff of the clinic also needs a way to manage their schedules so they know who\u0026rsquo;s working on different days. We\u0026rsquo;re referring to these two bounded contexts as client patient management and resource scheduling. ‑We also have a few parts of the application that are common to several bounded contexts. These are cross‑cutting concerns that we have consciously chosen to share. In DDD, we isolate such code into its own package referred to as a shared kernel, and it\u0026rsquo;s worth noting that a bounded context does not always mean a separate application, even though we\u0026rsquo;ve identified several different bounded contexts. ‑It\u0026rsquo;s also a great opportunity to consider packaging logic up into microservices. Do keep in mind, however, that there\u0026rsquo;s not always a 1:1 alignment between bounded contexts and microservices or applications. Also, let\u0026rsquo;s not forget that our application will definitely need a front end.\nUnderstanding the Ubiquitous Language of a Bounded Context We\u0026rsquo;ve mentioned already that an important part of DDD is an emphasis on effective communication among the stakeholders in the project. And remember, if you\u0026rsquo;re a programmer, count yourself as one of the stakeholders in whatever you\u0026rsquo;re working on since you certainly have a stake in its success. The language we use to describe the problem and how we choose to model it is key to the shared understanding we want to have with our domain experts in order to be successful. Having a single, shared, ubiquitous language helps avoid unnecessary confusion and translation within the team building the software and is one of the fundamental practices of Domain‑Driven Design. And when I talk about the team building the software, I don\u0026rsquo;t just mean the programmers. I mean the whole team, including the business people that are deriving what the software should do. The discovery of the Rosetta Stone allowed us to unlock several different languages by showing the same message in three different texts. We don\u0026rsquo;t want to have to have a Rosetta Stone or any other sort of tool to help us translate between what the business is talking about and what the programmers are talking about. We want to make sure that everyone is speaking the same language the whole time so that translation is unnecessary. ‑Think about if you\u0026rsquo;ve ever used an online translation tool to round trip a sentence. You can run into similar communication issues in your application if you\u0026rsquo;re constantly having to translate to and from the domain expert terms or the programmer\u0026rsquo;s terms. Here\u0026rsquo;s an example of a user story for a sample system about creating appointments. ‑We have a lot of developer friends in Nigeria, so I thought it would be fun to try out Igbo for our translation. We used a website to translate between English and Igbo a few times, and in the end, the user story has changed just enough to create confusion. Translation software is pretty good these days, and we were hoping for a more humorous result, but according to animal experts, it\u0026rsquo;s close, but not the same as a veterinary technician. ‑But the point here, of course, isn\u0026rsquo;t just relating to different international languages, but to the different languages spoken by business experts and programmers. ‑Incidentally, a great practice when you\u0026rsquo;re discussing your system requirements with customers is to always try and explain back to them what you think it is they want the system to do so they have an opportunity to correct your understanding of what they think they just told you. ‑Definitely. Remember, one of the key benefits of using a ubiquitous language is that all parties can understand it without having to perform any translation. This means when you show a test or some code to a domain expert, you don\u0026rsquo;t have to explain that in the system you call something an animal when the domain expert calls it a patient. ‑Evans cautions that a project faces serious problems when it\u0026rsquo;s language is fractured. When domain experts stick to using their jargon while the technical team members have their own language tuned to discussing the domain terms in the design, translation errors will manifest as software bugs. Neither the customers nor the developer\u0026rsquo;s language is sufficient for all parties to discuss the application effectively. What is needed is a shared common language that incorporates and uses terms defined in the domain model. The use of this language must be ubiquitous, and the more the language is used, the more will force deficiencies in the model into the open. ‑And by ubiquitous, we mean it must be used everywhere within the bounded context. The vocabulary of the language includes the names of model classes and prominent operations. The team should use these common terms in code, in diagrams, on the whiteboard, in design documents, and especially when discussing the system. ‑Yeah, pretty much ubiquitous means everywhere, all the time. Even in that one email you\u0026rsquo;re sending off to another developer, stick to using the terms that you\u0026rsquo;ve agreed makes sense for this bounded context.\nConversation with a Domain Expert: Working on our Ubiquitous Language You\u0026rsquo;ve heard some of our conversations that helped lead to a ubiquitous language for the scheduling app. There was another important one that happened early on between Michelle and me that we want to share with you now. ‑Pay attention to not only the clarification of the terms, but also to the fact that Julie and Michelle are equal partners in this conversation. Although Julie is trying to lead the conversation towards the goal of identifying the correct terms, she\u0026rsquo;s careful not to make assumptions about Michelle\u0026rsquo;s domain. ‑So Michelle, last time you and Steve and I got together to talk, Steve and I have been working on just kind of fleshing things out and planning things, and I realized that we had some confusion over some of the common terms, like things that, as real pet owners, we would kind of assume the terms are, but then when we\u0026rsquo;re thinking about business and software, we\u0026rsquo;re thinking of the terms a little differently. So I was wondering if we could just sort that out with you so that we\u0026rsquo;re all on the same page and using the same terms and using terms that none of us have to stop and think about what we\u0026rsquo;re talking about. We\u0026rsquo;ll always know what they mean. ‑Sure. ‑The first thing is we have these clients, those are the people who own the pet. So when thinking about the software and business, we think of them as clients, but kind of in the real world, and me, I have a pet, I go to the vet all the time. I think of myself as a pet owner. So what do you refer to those people who bring the pets, pay their bills, call and make the appointments, etc? ‑Most of the time, I mean those would be listed as as clients. ‑Okay, so you do call them clients. You don\u0026rsquo;t worry about calling them owners, and of course, it sounds kind of weird to say I own a dog, right? ‑He kind of owns you. ‑Yeah, that\u0026rsquo;s more like it. You\u0026rsquo;re the pro you know. So then what about that dog, like are they patients, are they pets, are they clients? What do you refer to the pets as? ‑So for the purpose of the medical record, we refer to them as the patient. ‑Okay. So it would be client and patient. ‑Exactly. And actually in veterinary medicine they talk a lot about this triad, the veterinary client/patient relationship, where all three are really important in that. ‑Okay. So those are actually terms that are commonly used in your industry. Industry, that sounds so weird, but with that. Cool. Alright, so the next one we were also going back and forth on was an appointment or an office visit. When somebody is scheduling a visit, scheduling to come in, how do you refer to that? ‑So there would be two big subsets of what they might be scheduling to come in for. They might schedule a surgery, which is an easy one to define. They\u0026rsquo;re going to come in, we\u0026rsquo;re going to do some sort of a procedure. Usually, there is going to be some anesthetic involved. That would be a surgery and that would be outside of our normal office hours. ‑Oh, okay. So what about when they just come in for regular stuff? ‑So when they come in for regular appointments, you could call those office visits or appointments, and there are a few different subsets of those. You may have an appointment that\u0026rsquo;s a wellness exam, and in that exam, we would be doing, of course, a physical examination and generally wellness treatments like vaccination, some blood work, generally your healthy pet who is coming in for a routine checkup. ‑So that\u0026rsquo;s an office visit and there is a couple other things that come under the umbrella of office visit, but if I, I\u0026rsquo;m also thinking about scheduling because that\u0026rsquo;s the thing we\u0026rsquo;re really going to be focused on is the scheduling portion of the app. So we\u0026rsquo;re always scheduling an appointment, an appointment for a surgery, an appointment for an office visit, whatever type of office visit that is, so is using the term appointment, does that make sense? Would you, if if I said appointment would you think that could be a surgery, that could be a checkup, that could be whatever. This thing to be scheduled is what I want to define. ‑Yeah, I mean I think you could call them all appointments, but I would differentiate between the surgery and something that\u0026rsquo;s done in the office, but then I would further differentiate in the office between a wellness exam, an exam for somebody that\u0026rsquo;s coming in with a problem, or an exam that doesn\u0026rsquo;t need to see a doctor, but could just be done by a technician like a toenail trim. ‑Oh good. Yeah, we always need those, clickety‑clack on the floors. Alright, so I think then we\u0026rsquo;ll use just the overall umbrella of we\u0026rsquo;ll schedule an appointment and then we\u0026rsquo;ll be more explicit about what type of an appointment that\u0026rsquo;s going to be. Would that feel okay to you? ‑Yeah, that makes sense to me. ‑Great. Excellent. Alright, so I\u0026rsquo;ll get back to Steve and then we\u0026rsquo;ve got another meeting set up I think in a few days to just hash out some more details after Steve and I\u0026rsquo;ve gotten some more of our ducks in a row. ‑Sounds great! ‑Excellent. Thanks Michelle. Bye bye. ‑Thank you. Bye. ‑Now we have a stake in the ground for our ubiquitous language. As we continue working with Michelle, not only will we learn more items for the bounded context, but there is also a chance that the ubiquitous language will evolve. Eric Evans guides us to pay attention to those changes because a change in the ubiquitous language is also likely to mean a change in the domain model. We have to update our design to accommodate what we\u0026rsquo;ve learned.\nReviewing Important Concepts from This Module We\u0026rsquo;ve covered quite a few concepts in this module. One of the most important ones is just understanding the problem domain and the overall thing that your software is working within. ‑‑And breaking things apart. I know that when I started out, I had a really hard time really understanding differences between the core domain, the subdomains, and the bounded context, especially the subdomains and the bounded context because at first glance, they looked like the same thing to me. ‑‑Sure, it\u0026rsquo;s really easy to have an application where you have some kind of a concept, like a customer that you know is used by every system that your organization uses. And it ends up becoming this like God object in your database and in your different applications where any given application might only care about a tiny subset of that concept. ‑‑Yeah. So, for me, I think the most important thing is really focusing on the bounded context. Getting down to that and understanding about the boundaries. One thing that helps me a lot is just stating within the context of this and then suddenly like, oh right, that\u0026rsquo;s what a context is. It\u0026rsquo;s not like some mysterious new term that Eric Evans invented. He just is leveraging what makes sense. Within the context of appointment scheduling, this is what a client looks like. Within the context of billing, this is what a client looks like. ‑‑Sure, I think that makes a lot of sense. And it\u0026rsquo;s valuable, even when you have an application, like a legacy application that wasn\u0026rsquo;t built with domain‑driven design. Let\u0026rsquo;s go ahead and look at some more terms here. For instance, we\u0026rsquo;ve got what you were just talking about, I think of as context mapping. And even in a legacy application, it can be valuable to kind of map out what are all the concepts in this application and where are the overlaps with different subdomains that maybe we haven\u0026rsquo;t even defined in this legacy application. ‑‑Yeah. Even if you\u0026rsquo;re not planning on making huge changes to it, it\u0026rsquo;s still really, really helpful to just kind of update your perspective on things. Sometimes it just leads to new understandings. ‑‑I think the shared kernel is a really important part of this, too, because in almost every real‑world organization I\u0026rsquo;ve worked with, there are different types of cross‑cutting concerns, and we talked about one of them being the authentication piece, and that\u0026rsquo;s definitely a really common one. But there are usually others too that you want to share. ‑‑Yeah, and, again, it\u0026rsquo;s another one of those things that sounds like it might be a big, scary, mysterious thing because you haven\u0026rsquo;t referred to it that way, but if you really just start out thinking of it as the common stuff, but then‑‑‑I think one of the important things, though, is even within the context of domain‑driven design, we have a ubiquitous language because if I say common, you might have a different idea of what I mean by common, but if I say shared kernel, we\u0026rsquo;ve got an agreed‑upon understanding of what we\u0026rsquo;re talking about there. So at first, I really kind of pushed back against using these terms because I felt like a lot of the DDD experts were just throwing them around all the time. And then I started really getting a better understanding of why it\u0026rsquo;s important to use those terms. It\u0026rsquo;s about‑‑‑it\u0026rsquo;s the ubiquitous language of domain‑driven design so everybody\u0026rsquo;s on the same page. ‑‑Yeah, I do agree that that\u0026rsquo;s an important part of learning about DDD and other areas of software development, like, for instance, design patterns. These things give us these terms that we can use that are very, very dense. If we talk about shared kernel, it would take me three or four sentences to describe what I meant by that. But in these two words, you know exactly what I mean, just like if I talk about using a strategy design pattern, that is much easier to convey than if I were to try and describe it with words and have to draw a UML diagrams to say what I mean. ‑‑And it\u0026rsquo;s the same, again, with the ubiquitous language because now I really have a better understanding of the fact that what it means is the language is ubiquitous throughout a particular bounded context. When we\u0026rsquo;re talking about a scheduling app, we\u0026rsquo;re going to use these terms all the way through, like you were saying before, we use it not just when we\u0026rsquo;re talking to the domain expert but in our class names, in our methods, it\u0026rsquo;s just ubiquitous throughout all of the pieces of the things that are involved in that bounded context from one end all the way to the other of it. ‑‑And I think as we\u0026rsquo;ll see when we look at the code again, some of the constructs in .NET, like namespaces, are really appropriate to ubiquitous language because when you prefix that same term in your code with a particular namespace, that tells all the other programmers that if I say SchedulingApp.notification, we know that that has a different meaning that if I\u0026rsquo;m talking about EmailReminder.notification. ‑‑Or SchedulingApp.client versus Billing.client. ‑‑Exactly.\nReview and Resources In this module, we learned about our domain, in this case, a veterinary practice. We talked about it at length with a real live domain expert and identified the core elements of our domain model. We identified a variety of subdomains and focused in on the key area that we would be addressing first with our application. ‑We spent some time designing the system based on our conversations with Michelle, identifying boundaries between different contexts, and noting how sometimes the same object with the same name might mean something different within a different context. ‑Finally, we talked about the importance of communication in general and in particular having a ubiquitous language. We know that Domain‑Driven Design can help us avoid many design errors and wasted time miscommunicating as we work on a complex project. ‑Steve and I are so grateful to Eric Evans for spending time with us while we were creating this course in order to share his luminous advice and insights. In the next module, we\u0026rsquo;ll drill into the domain model so you can have a good understanding of its critical elements. ‑This is Steve smith, ‑and this is Julie Lerman. Thanks again for watching Domain‑Driven Design Fundamentals.\nElements of a Domain Model Introduction and Overview Hello, this is Julie Lerman, ‑and this is Steve Smith. ‑In this module, we\u0026rsquo;re going to focus on the elements of a domain model which are in our bounded context. ‑You\u0026rsquo;ve seen these in the mind map. It\u0026rsquo;s patterns like entities and aggregates and more. ‑You can find me online at ardalis.com or on Twitter as @ardalis. ‑And you can find me online at thedatafarm.com or on Twitter at @julielerman. ‑In this module, we\u0026rsquo;ll focus on the technical aspects involved when modeling a bounded context. We use these terms while modeling, and these same terms refer to patterns we\u0026rsquo;ll use when we code. The concepts flow through the entire process, which is great. You don\u0026rsquo;t have to keep switching hats or mindsets. ‑We\u0026rsquo;ll start by grounding ourselves in the domain and understand why it\u0026rsquo;s important to stay focused there. DDD models are driven by behaviors, not classes and properties. This is another very cool shift in thinking for those of us who have always focused on objects. Then you\u0026rsquo;ll learn about some terms used to describe domain models, rich and anemic. You learn what the terms mean at a conceptual level and what the code that they\u0026rsquo;re describing looks like. ‑Entities are the key types in your system, but not every type in your system is an entity. ‑You\u0026rsquo;ll learn how entities fit into DDD, how to differentiate entities that have complex needs from simpler entities that might only need some basic CRUD logic, and you\u0026rsquo;ll be able to see how we\u0026rsquo;re implementing all of these concepts in our code.\nThe Importance of Understanding DDD Terms Domain‑Driven Design is filled with lots of specific terms. Much like the ubiquitous language that we use to make it easier to communicate while working within a bounded context, understanding and using the terms of DDD makes it easier to talk about the process. We\u0026rsquo;ll spend the bulk of this module focusing on some of the concepts behind modeling bounded contexts, concepts that are critical to this process, but, unfortunately, often misunderstood. ‑I\u0026rsquo;ve definitely had my challenges with some of the DDD concepts. Some of my issues were because the terms overlap with other technologies I use. For example, I do a lot of work with Microsoft\u0026rsquo;s ORM called Entity Framework. Entities are a key element in Entity Framework, and they\u0026rsquo;re also a key element in DDD. So I thought my understanding of entities from Entity Framework was enough to translate to DDD entities, but it really wasn\u0026rsquo;t, and my less than solid grasp on DDD entities caused problems when I was trying to model domains and implement the model and code. We also have the concept of a context in Entity Framework. While the real goal of that context is to provide interaction with the database, it also does provide a boundary around a model. But it\u0026rsquo;s very different than the concept of a bounded context, and that definitely confused me for a while. Another important element in a DDD model is value objects. These got me pretty confused at first, and my ego was saved by discovering that others have also been confused by value objects. But I\u0026rsquo;ve worked on my DDD education and sorted these problems out, so in this module, it\u0026rsquo;s really important to both Steve and I that you start off on the right foot with a proper understanding of entities, value objects, and some of the other DDD puzzle pieces so that Domain‑Driven Design can help you with your complex problems, not complicate them even more.\nFocusing on the Domain It\u0026rsquo;s important to remember that first D in DDD stands for Domain, and yeah, the other two Ds, Driven and Design. But we really want to focus on Domain here. ‑By now, you\u0026rsquo;ve probably heard us talk about this plenty, but both Julie and I find that we constantly have to remind ourselves to focus on the domain. We hear ourselves begin to talk about the user interaction with the app and have to ask, well, what part of the vet clinic domain is this user? Yeah, obviously we care about the user and how the actual application will work from their perspective, but that\u0026rsquo;s for another conversation, and we have to draw ourselves back to focusing on modeling the domain. ‑I have quite a long history with data access, and I catch myself worrying about how our domain model will translate to the database so that things definitely get persisted correctly. That\u0026rsquo;s when Steve needs to give me that look, you\u0026rsquo;re doing it again, Julie, and I have to bring my focus back to the domain of the vet clinic again. So while it may seem redundant to harp on domain, domain, domain, this diligent focus will help you avoid the complications and distractions that come from thinking outside of the domain or the subdomain that you\u0026rsquo;re focused on. ‑Here\u0026rsquo;s an important quote from Eric Evans\u0026rsquo; book about this focus on the domain. \u0026ldquo;The Domain Layer is responsible for representing concepts of the business, information about the business situation, and business rules. State that reflects the business situation is controlled and used here, even though the technical details of storing it are delegated to the infrastructure. This layer of the domain is the heart of business software.\u0026rdquo; ‑Just to reiterate, the domain model is the heart of the business software. This is the whole point behind Domain‑Driven Design. Focus on the domain, not the technical details of how the software will work. ‑In a typical database‑driven app, we\u0026rsquo;re used to focusing on properties or attributes of classes. Our apps sometimes become all about editing property values and the state of our objects. However, when we are modeling a domain, we need to focus on the behaviors of that domain, not simply about changing the state of objects. ‑Michelle didn\u0026rsquo;t talk to us about setting the name of a dog or editing the time of an appointment. She told us that she needs to schedule an appointment, and when she does that, she needs to book a room and create a schedule item on a doctor\u0026rsquo;s calendar as well. So scheduling appointment is a lot more than setting the attributes of the objects involved, the appointment time and identity of the pet we\u0026rsquo;re making the appointment for. We\u0026rsquo;re talking instead about how the system behaves. In response to scheduling an appointment, the system should also book a room and do something to the calendars of the doctor and any vet techs that might be involved.\nIdentifying Events Leads to Understanding Behaviors An important way to identify behaviors in your system is by focusing on events. Doing so gives you a great path to understanding the behaviors of your domain. Alberto Brandolini devised a great way to brainstorm with clients, which is referred to as event storming. It begins by having a somewhat chaotic brainstorming session with a good number of domain experts writing events on Post‑its and sticking them on a wall. The format of what they write is in the past tense. For example, an appointment was booked, a client contacted the office, or a dog was weighed in. I facilitated quite a few event storming workshops with clients, and I\u0026rsquo;m a big fan of using this process to help get a picture of the domain, discover bounded contexts, and even discover key problems that should be addressed. Another interesting methodology for modeling a system based on events is called Event Modeling. Adam Dymitruk came up with this workflow and has had great success using it to help teams collaborate on learning about the domain and designing the flow of software. I was fortunate to participate in a three‑day workshop with Adam to learn about Event Modeling. We won\u0026rsquo;t be teaching you about event storming or Event Modeling in this course, those are beyond the scope of our goals here, but we did want to be sure you were aware of them. You\u0026rsquo;ll find links for more information about event storming and Event Modeling at the end of this module.\nComparing Anemic and Rich Domain Models In order to understand the difference between design that\u0026rsquo;s focused on attributes versus design focused on behaviors, it will help to understand two commonly‑used terms in domain‑driven design, anemic domain models and rich domain models. An anemic domain model is a domain model that is focused on the state of its objects, which is the antithesis of DDD. While the term is somewhat negative indicating a deficiency, you don\u0026rsquo;t need to perceive it that way. There is nothing wrong with anemic classes when all you need to do is some CRUD logic, but if you are creating a domain model, you\u0026rsquo;ve already made the decision that your domain is too complex for simple CRUD. So anemia in a domain model is considered an anti‑pattern. ‑Martin Fowler writes about anemic domain models with such drama that you may never mistakenly use them in your domain model. He says the basic symptom of an anemic domain model is that at first blush it looks like the real thing. There are objects, many named after the nouns in the domain space, and these objects are connected with the rich relationships and structure that true domain models have. The catch comes when you look at the behavior and you realize that there is hardly any behavior on these objects making them little more than bags of getters and setters. Indeed, often these models come with design rules that say you are not to put any domain logic in the domain objects. Instead, there are a set of service objects would capture all the domain logic. These services live on top of the domain model and use the domain model for data. ‑What we aim for then is rich domain models, not anemic domain models when we are modelling our domain. Rich domain models will represent the behaviors and business logic of your domain. Classes that simply affect state are considered an anti‑pattern in a domain model, and therefore, get the nasty label of anemic, even though they are perfectly fine in a CRUD model. Martin Fowler doesn\u0026rsquo;t mince words when it comes to anemic domain models saying the fundamental horror of this anti‑pattern is that it\u0026rsquo;s so contrary to the basic idea of object‑oriented design, which is to combine data and process together. I have to say I agree and I\u0026rsquo;ve worked with many teams who have had to deal with the self‑inflicted pain of treating their domain entities like DTOs lacking any encapsulation or behavior. That can work for simple CRUD apps, but it\u0026rsquo;s often a disaster in a DDD model. ‑While Martin Fowler and other DDDers have strong words to say about anemic domain models, we\u0026rsquo;d like to share a gentler message, which is to strive for rich domain models and have an awareness of the strengths and weaknesses of those that are not so rich.\nUnderstanding Entities Even though a DDD app is driven by behavior, we still need objects. DDD expresses two types of objects, those which are defined by an identity and those which are defined by their values. We\u0026rsquo;ll focus first on the objects that are defined by their identity. These objects are called entities. ‑An entity is something we need to be able to track, locate, retrieve, and store, and we do that with an identity key. Its properties may change, so we can\u0026rsquo;t use its properties to identify the object. If you\u0026rsquo;ve done any type of data persistence in software, you\u0026rsquo;re probably pretty familiar with entities and their keys. When we are modeling a problem, we can talk about entities without having to think about how they are implemented in the resulting software. But when it is time to start coding, there are patterns to follow to ensure that these objects have the technical attributes of Domain‑Driven Design entities. ‑As you can see from this section of the DDD navigation map, entities are pretty integral to our software. So, before we can learn about these other elements, domain events, repositories, factories, and more, you should have a very good understanding of an entity. ‑The most important entity in our model is Appointment. This is what we will be creating, editing, and retrieving in the context of scheduling appointments. Appointment inherits from a base class we\u0026rsquo;ve created called Entity. We\u0026rsquo;ll look at that more in just a bit. Notice that all of the classes shown here are inheriting from the identity base class. However, although the other classes are entities, after our discussions with Michelle, we came to the conclusion that we would like to have a separate utility for managing client and patient information and to manage information about staff and staff scheduling. Thus, we don\u0026rsquo;t need very much information or behavior related to these collaborating entities within the bounded context of appointment scheduling.\nDifferentiating CRUD from Complex Problems that Benefit from DDD ‑Let\u0026rsquo;s take a closer look at that data that supports scheduling appointments in our system. ‑We determined that managing the client, patient, and staff information, which is external to this model, was well‑suited to just simple CRUD. We didn\u0026rsquo;t identify complex rules or behaviors for creating and editing that data. Thus, the concepts of doctors, rooms, clients, and patients are managed outside of the scheduling bounded context. ‑For comparison, look at the CRUD classes for Patient and Client in the other bounded context. They\u0026rsquo;re very simple. They don\u0026rsquo;t inherit from our entity base class, and most interestingly, their ID properties are integers. We\u0026rsquo;ll let the database assign the IDs when we create these classes. So these classes are not designed using domain‑driven design. Now let\u0026rsquo;s go back to the appointment scheduling context. The client, patient, doctor, and room classes here are completely different from the CRUD classes we just saw. However, they do have a subset of the same fields from those CRUD classes. All we need to know about these objects when we\u0026rsquo;re scheduling is their IDs, their names, and maybe a few other details. But here, they\u0026rsquo;re simply used as look‑up data, and they\u0026rsquo;reread‑only.\nSwitching Between Contexts in a UI Even though our domain is split up into a number of bounded context, the user interface can be designed in a way that moving from one context to another is seamless to the end users, they don\u0026rsquo;t need to know that these things are in separate bounded contexts. While maintaining client and patient data is a completely separate task from scheduling appointments, Michelle wanted to be sure that anyone working at the front desk is able to easily move between these tasks in the software without disrupting their workflow. So let\u0026rsquo;s say the person at the clinic who does the scheduling is on the phone with Kim and about to make an appointment for Roxy to come in, but then the other line rings, they put Kim on hold, and it\u0026rsquo;s me. And in the nicest way possible, I\u0026rsquo;ve called to just let her know they\u0026rsquo;ve got my last name spelled wrong. That happens all the time. People just want to put that h in there. Even though they\u0026rsquo;re in the middle of scheduling and scheduling has its own backend, its own bounded context, and is totally separate from client management, they can still drive the app right over to the Client Management area and very quickly fix my name and save that. Then they can just flip back to the schedule. Notice that Kim is still the active scheduling client that\u0026rsquo;s showing up in the left‑hand corner and the change to the spelling of my last name is already visible on the schedule. And so now that person can go ahead and finish up with Kim scheduling the very adorable Roxy for a wellness exam. To the user, there is no real difference between doing the scheduling and doing the client management, it\u0026rsquo;s just a nice smooth flow between the two, it doesn\u0026rsquo;t feel like, oh, now we have to open up a different application in order to do this other thing and doesn\u0026rsquo;t break everything they\u0026rsquo;re in the middle of, but for the purposes of designing our application, everything is bound within its own individual context. And when designing this context, we don\u0026rsquo;t have to worry about switching from one context to another. ‑So remember, we\u0026rsquo;re talking about what makes these all entities. An appointment object needs to be located and tracked and we need to be able to edit them easily. Using a unique identity allows us to persist and retrieve an appointment even if some of its values change. Appointment is definitely an entity in our system. We actually had to think a little more about client, patient, doctor, and room in this particular context. Our discussions highlighted the fact that when creating appointments, we only need access to some of the high‑level information about the client, patient, doctor, and room, but these objects won\u0026rsquo;t be edited. So we wanted these stripped down read‑only types that give us minimal amount of detail for each. We do still need to be able to uniquely identify them though, they do have some identity. If the client\u0026rsquo;s name changes, a change we would make in the client management system, that new name will need to be reflected when we look at the appointment scheduling for that client. There should only ever be one record to represent a particular client in this bounded context. So client and the other types that are reference types in this context are still entities. We triple checked our decision with another kind of domain expert, Vaughn Vernon, a DDD expert, and we were happy to get his thumbs up on this particular decision. So Julie, Michelle, and I also talked about how to name the types that are simply reference types in this particular bounded context. At first, we were worried that we might get confused by having different definitions of client, patient, doctor, and room. We wanted to call them client details or client view or something like that, but thanks to the ubiquitous language, the fact that we are in the scheduling context drives our comprehension of what a client means in this particular space. ‑A client in scheduling is still a client, so we use the same name, even though it\u0026rsquo;s a differently defined pipe than the client we work with in the Client/Patient Management app. ‑Right, and thanks to namespaces in our code, we\u0026rsquo;re able to keep it clear which ones are which in the code.\nUsing GUIDs or Ints for Identity Values So, all these types inherit from our base entity class. However, notice that those reference types use int for their base entity\u0026rsquo;s ID and not the GUID that\u0026rsquo;s used by appointment. That\u0026rsquo;s because all of the management of those other types happens to be done using CRUD, and with CRUD, it\u0026rsquo;s easy to just use database‑generated ints. Appointment is built using DDD principles, and you\u0026rsquo;ll see that it\u0026rsquo;s much easier to use GUIDs when building DDD entities and their related logic rather than relying on the database to provide the identity values. Not only is it easier, but it follows DDD principals more clearly, since we will build all of our domain logic around appointments without involving the database. We would have a hard time working with appointments in our model and in our unit tests as we develop the application if we always needed a database to assign their IDs. ‑So that\u0026rsquo;s not to say that you can\u0026rsquo;t use integer IDs If you\u0026rsquo;re going to use a DDD style of application; it just makes it a little harder. Wouldn\u0026rsquo;t you say, Julie? ‑Yeah, yeah, and I\u0026rsquo;ve definitely come up against that. With the stuff that I do with Entity Framework, I\u0026rsquo;ve made sure that I show patterns for continuing to use the database‑generated ints because I didn\u0026rsquo;t want to give people the impression that they had to throw away, like, for me like 25 years of this dependency. And like all of a sudden I have to go cold turkey and move over to GUIDs. ‑Sure, I mean, there\u0026rsquo;s trade‑offs in what you choose to use for your ID, but having an ID that we can generate in the client and just in our code has a lot of value. ‑Every time we\u0026rsquo;ve been working on some of our different unit tests and we needed as part of the test to instantiate something that was an int, we were like, ugh, now we have to find another way to get that in there because we were protecting it and it was a problem. As our own experience grew, we realized there\u0026rsquo;s another way to bridge this conflict by using both GUIDs and database‑generated ints in an entity. This way, while creating objects, you\u0026rsquo;ve got the control over key generation with the GUIDs, and they\u0026rsquo;re not depending on the database. However, once the data has been created in the database and int keys exist for it, then you can benefit from those when adding indexes and performing queries in the database.\nTalking with Eric Evans About the Responsibility of Entities We talked with Eric Evans to gain some additional insight into entities. Specifically, I asked him how entities align with the single responsibility principle. ‑‑If you\u0026rsquo;re not familiar with this object‑oriented programming principle, you can learn more about it in Steve\u0026rsquo;s SOLID course right here, on Pluralsight. ‑‑One of the questions that I\u0026rsquo;ve heard is, What is the single responsibility for an entity? Or to put it another way, does having an entity that has a lot of business logic in it violate the single responsibility principle? ‑‑Eric told us that entities are very central, and so it\u0026rsquo;s natural that they get heaped up with lots of functionality. ‑‑But there\u0026rsquo;s a downside to this. As you build out the system, there are more and more conflicting demands for these central entities, so they end up being huge. Evans said that the main responsibility is the identity and the lifecycle. ‑‑Eric also told us that single responsibility is a good principle to apply to entities, and it points you towards the sort of responsibility that an entity should retain. Anything that doesn\u0026rsquo;t fall into that category, we ought to put somewhere else.\nImplementing Entities in Code Let\u0026rsquo;s take a look at an entity in our veterinary appointment scheduling application, FrontDesk. We\u0026rsquo;re going to look at the Appointment class, which defines all the information that we need to schedule an appointment for a particular animal or patient. It associates the patient with the doctor, room, and appointment type, and also includes the start and end time for the appointment. Now, the Appointment class inherits from BaseEntity, which is a generic base class. In this case, it\u0026rsquo;s BaseEntity, as you can see here. The GUID is defining the type of our identity property, our ID. ‑Right. And we talked about that earlier when we were looking at the structure of the different entities in this model. We wanted Appointment to have a GUID because we\u0026rsquo;re creating new appointments on the fly. So, let\u0026rsquo;s take a look at that BaseEntity class. First of all, it\u0026rsquo;s an abstract class. So we can\u0026rsquo;t just create a BaseEntity object, we have to create something that is a BaseEntity, such as an appointment. And using generics, we\u0026rsquo;re saying that the BaseEntity is going to use whatever type we ask it to, and that type is for defining the ID. So for Appointment, we said BaseEntity is going to be using a GUID as its identity. I mentioned this earlier, why I would need GUID for appointment in this context because I need to be able to create new appointments in this context, and I\u0026rsquo;m not going to be waiting for the database to generate the ID for me. So using a GUID lets me create that ID right up front as I\u0026rsquo;m creating that new appointment. So I\u0026rsquo;m giving it its ID. The BaseEntity class also has a property to hold a list of domain events that will define explicitly for each of the types that inherit from this base entity. You\u0026rsquo;ll learn more about domain events further on in this course. ‑All right, so let\u0026rsquo;s take a look back at the rest of Appointment. Now, since Appointment has more behavior than just state, we don\u0026rsquo;t want to have it just be a bag of properties that our application can get and set however they would like. ‑Because that would be an anemic domain model. ‑Yes, because that would tend to lead us toward a more anemic domain model. ‑And we want a rich one. ‑Now, in particular, we\u0026rsquo;re also constraining how we create this appointment. We want to ensure we create appointments in a valid state, so that means passing in the minimum necessary elements an appointment needs to have. Sometimes we\u0026rsquo;ll want to update an appointment. Remember, these aren\u0026rsquo;t value objects. They\u0026rsquo;re not immutable, so we can change them. When we need to modify an appointment, we\u0026rsquo;re going to do that through methods. And so, for instance, if we decide we want to modify what room an appointment is scheduled in, we\u0026rsquo;re going to do that through a method rather than just a setter. We do this because there\u0026rsquo;s additional behavior we may want to do. In this case, we have some guards, again to ensure a valid value is being passed. ‑These guards are a set of reusable functions that you\u0026rsquo;ll find in the shared kernel of our solution. ‑And we also want to raise an appointmentUpdatedEvent, that we might handle and send a notification or perform some other action as a result of what happened. ‑And that also gives us the flexibility in the future to change what type of logic we want to trigger. ‑And that\u0026rsquo;s something we can\u0026rsquo;t do very easily If we just let anybody in the application set the value. ‑Right. ‑By providing a method to use to update room explicitly and otherwise making the setter private, we force all interaction with the model to use this method, which gives us just one place to model behavior that should be associated with this operation. It\u0026rsquo;s the same as with the constructor, we need to do our best to keep our domain model in a consistent state so the rest of the application can count on it being correct. ‑Right, because otherwise somebody could satisfy the requirement that they pass in the room ID, but they might pass it in as 0, which would be invalid. So, we\u0026rsquo;re further constraining that they don\u0026rsquo;t do that either. The appointment would be invalid if it had a room ID that didn\u0026rsquo;t correspond to an actual room entity. And in any case, the database wouldn\u0026rsquo;t let that fly since there\u0026rsquo;s a foreign key relationship between appointment and room. ‑Yes, but we want to make at least some effort to catch such problems in our code, rather than relying on the persistent store to inform us of a user error. Overall, using guard clauses, like the ones you\u0026rsquo;ve seen here, help us ensure our entities aren\u0026rsquo;t partially constructed and inconsistent. Once we\u0026rsquo;ve created an appointment, we need to record it as part of the clinic schedule, which involves some additional rich behavior. So, if we scroll down to the bottom, we have this method called Schedule. And this is where we\u0026rsquo;re going to do the additional work involved with actually saving an appointment and ensuring it fits in with other appointments that have already been scheduled. We\u0026rsquo;re not going to worry about the code at the moment, but the idea is that this method would query the database for other appointments that might be near this one and make sure there is an available slot in the schedule that this one fits into. Then it will save the appointment and raise an event, letting the rest of the app know that a new appointment has been scheduled. In the next module, we\u0026rsquo;ll investigate this design further and revise it a little bit. Now, let\u0026rsquo;s look at one more simple entity that this bounded context needs, the Doctor class. You can see that Doctor inherits from BaseEntity as well, but in this case it\u0026rsquo;s using an int for its key. The only other property it has is a string Name property. ‑This is a minimal implementation of the Doctor type that satisfies the scheduling bounded context. It\u0026rsquo;s essentially no more than a reference type. Doctor and the other similar types, Patient, Room, etc., are all organized into this folder called SyncedAggregates.\nSynchronizing Data Across Bounded Contexts Let\u0026rsquo;s dig a little more into how these reference types in the scheduling bounded context are getting their data from the Clinic Management app, especially if the two BCs aren\u0026rsquo;t sharing a database. If you recall from seeing the class descriptions of all of these classes, the AppointmentType, Client, Doctor, Patient, and Room, we had explicitly decided that these are reference entities where we\u0026rsquo;re actually doing their maintenance elsewhere so they\u0026rsquo;re not adding any unneeded complexity to the Front Desk application. ‑‑Right. And they\u0026rsquo;re just READONLY. So we\u0026rsquo;re never having to create or modify them. ‑‑And we\u0026rsquo;re using the ints that were created by the database when we persisted these with a CRUD context in a different application, but there are still entities here, just entities of type integer. The Clinic Management bounded context is responsible for updating these types. When changes are made, application events are published by Clinic Management, and this Front Desk bounded context subscribes to those events and updates its copies of the entities. ‑‑One of the questions we get all the time when we describe how bounded contexts have separate databases is, How do we synchronize changes between these two apps? This is one of the simplest and most common approaches. One app is responsible for updates, and the other apps just subscribe to the changes and are notified when they occur. ‑‑This is an example of eventual consistency. The two systems aren\u0026rsquo;t immediately kept in sync using a transaction or something similar, but through message queues, eventually the different bounded contexts are updated to the new state when a change is made.\nReview and Resources We\u0026rsquo;ve covered a lot of ground in this module and you\u0026rsquo;ve learned a lot of new terms, so we just want to review some of them with you before we move onto the next module. The first is a pair of terms that often go hand in hand, anemic domain models versus rich domain models. And remember the anemic domain models, while often looked down upon from the perspective of DDD, they\u0026rsquo;re perfectly fine for CRUD. These are models that look a lot more like a database schema than a class that has lots of methods and rich behavior in it. On the other side of that is a rich domain model, which is what we strive for in domain‑driven design, and that\u0026rsquo;s a model that really is focused on behavior, not just changing the values of properties. ‑Then we talked about entities and entities tend to be one of the core pieces of our domain model. The key thing that distinguishes an entity from other types in our model is that it has some kind of identity that we can use to track it over time and to bring it in and out of persistence. This module provided you with your first look at implementing a bounded context in code, an important part of tactical design. You learned about the difference between anemic models and rich models, and that while anemic models have their place, focusing on behavior with rich domain models is how DDD lets us solve complex problems. Entities are the classes in our domain models that are tracked by an identifier allowing us to build graphs and eventually persist and retrieve that data. ‑Sometimes we are working with entities whose behavior and rules are critical to the bounded context in which we\u0026rsquo;re working. Other entities may only provide supporting or reference data. You learned how to help identify the differences between them. Then you got to look at the appointment class in our scheduling app to see how we have applied rules and behaviors in that entity. You also looked at one of the reference entities and learned how we use message queues to ensure the reference and the data that is maintained in the clinic management app is made available to the scheduling bounded context, even though they do not share a database. ‑In the next module, we\u0026rsquo;ll focus on some more important elements of a domain model, value objects and domain services. We\u0026rsquo;ve referenced a lot of interesting and helpful resources in this module and here are two pages of links for you to follow up with if you want to dig in a little further, including Steve\u0026rsquo;s Pluralsight course on SOLID principles of object‑oriented design and information on event storming and event modeling. This is Julie Lerman ‑and this is Steve Smith, and thanks for watching our course, Domain‑Driven Design Fundamentals.\nUnderstanding Value Objects \u0026amp; Services in the Model Introduction and Overview Hello! I\u0026rsquo;m Julie Lerman. ‑And I\u0026rsquo;m Steve Smith. Welcome back to Domain‑Driven Design Fundamentals. In this module, we\u0026rsquo;ll continue exploring the elements of a domain model as we dig into value objects and domain services. ‑Value objects are a confusing concept. So we\u0026rsquo;ll begin by looking at where they fit into the mind map and introducing what makes an object a value object, and how they relate to entities in a model. ‑We\u0026rsquo;ll share some more guidance from Eric Evans and Vaughn Vernon, and then show how we\u0026rsquo;ve implemented value objects in our code. ‑Next, you\u0026rsquo;ll gain a high‑level understanding of domain services, and solidify that by exploring their features, and then some examples of domain services.\nGetting Acquainted with Value Objects When introducing entities, Steve and I talked about objects that were defined by a thread of continuity and identity, not defined by their values. So, what about objects that are defined by their values? These are called value objects, and they play an equally important role in a domain model, as entity objects do. ‑A value object has very specific characteristics. It is an object that is used to measure, quantify, or describe something in your domain. Rather than having an identity key, its identity is based on the composition of the values of all of its properties. Because the property values define a value object, it should be immutable. In other words, you shouldn\u0026rsquo;t be able to change any of the properties once you\u0026rsquo;ve created one of these objects. Instead, you would simply create another instance with the new values. If you need to compare two value objects to determine if they are equal, you should do so by comparing all of the values. Value objects may have methods and behavior, but they should never have side effects. Any methods on the value objects should only compute things; they shouldn\u0026rsquo;t change the state of the value object, since it\u0026rsquo;s immutable, or the system. If a new value is needed, a new value object should be returned. Don\u0026rsquo;t confuse the value object\u0026rsquo;s pattern with C# and .NET support for value types and reference types. Custom value types in C# are defined with structs, while reference types are defined as classes. In DDD, both entities and value objects are typically defined as classes. Classes have advantages over structs when it comes to encapsulation and support for inheritance‑based extension and reuse.\nRecognizing Commonly Used Value Objects To help you better understand the basics of value objects, let\u0026rsquo;s take a look at some value objects that you probably use all the time as a developer. The most commonly employed value object is a string. In .NET and many other languages, a string type is immutable, and you now know that immutability is one of the key attributes of a value object. A string is a collection of characters, and the combination of all those characters give that string meaning. For example, C‑A‑R in English, a car. If a string were mutable, we could change the R to T. Now the string is C‑A‑T, a cat, which has a very different meaning than a car. Or we could add a letter, maybe put an S in front of it, turning CAR to SCAR, also completely changing the meaning of car. But it\u0026rsquo;s not just the array of characters that gives a string its meaning, the order of them is also critical. Just think of the word dog, d‑o‑g. Shifting its letters around gives us something with a very different meaning. ‑So one of the things that .NET makes it really easy to do is to modify strings, like you can change the length of it or make one all upper case. But when you call, for example, ToUpper on a string, it doesn\u0026rsquo;t just change that string object, it gives you a new instance of a string that now has all uppercase characters. ‑Many developers say that monetary values in financial systems have been perfect candidates for value objects in their system. And Ward Cunningham provides us with a really helpful example, a company\u0026rsquo;s worth. If a company is worth 50 million dollars, that means something, 50 million dollars. It\u0026rsquo;s a very specific measurement. Fifty million on its own is not a measurement, it has no meaning without the unit, which in this case is dollars. But dollars alone doesn\u0026rsquo;t describe worth either. In fact, dollars doesn\u0026rsquo;t really help, does it, because is it US dollars or Canadian dollars, Australian dollars? It only makes sense when you put the two together as 50 million US dollars. There\u0026rsquo;s actually one more factor to take into account, is the point in time of this 50 million dollars because of the way financial systems work and the fluidity of monetary values. ‑We could still just have the two properties in this Company class, but by creating a value object you also protect and constrain the measurement. For instance, we might have a class called Company. It might have one decimal property that represents the worth amount and another string property that represents the worth unit. The problem with this approach is that it doesn\u0026rsquo;t tie these properties together in any way. These two properties appear to be independent of one another, but they\u0026rsquo;re obviously closely related. If an update is made just to the Worth Unit string, it could obviously have a tremendous impact on the company\u0026rsquo;s worth as a combination of these two concepts. Fifty million rupees has a very different worth than 50 million US dollars. To ensure nobody can set the unit without also specifying the amount, a separate value object can be introduced to represent the entire worth concept. This ensures the entire object must be updated as a whole. Since the worth type is immutable, the only way to make updates to the Worth property on the Company class is by replacing the whole instance with a new one, not just changing an isolated field. ‑A value object is not always for a measurement though. It can be another type of description. Eric Evans calls out dates as a great example for value objects. I\u0026rsquo;ve used this one often, DateTimeRange, and it was perfect for the vet appointment scheduling app. We usually set a start and an end time together and can\u0026rsquo;t really set one without the other. Also, we often need to pass the two values, start and end time, around from one method to another. So we\u0026rsquo;ve encapsulated them in a value object called DateTimeRange. The properties have private setters, which makes the object immutable since we can\u0026rsquo;t change them. We aren\u0026rsquo;t showing the full logic of the class here, but when we look at the value objects in our application you\u0026rsquo;ll see more of how we implement a value object in our software to ensure that it meets all of the attributes, not just immutability, but how we handle equality, comparison, and other logic.\nGetting More Insight from Eric Evans and Vaughn Vernon In his book, Implementing Domain‑Driven Design, Vaughn Vernon recommends that we should try to use value objects, instead of entities, wherever possible. He says, it may surprise you to learn that we should strive to model using value objects instead of entities wherever possible. Even when a domain concept must be modeled as an entity, the entity\u0026rsquo;s design should be biased towards serving as a value container rather than a child entity container. What this means is that you\u0026rsquo;ll find that your design will have a number of entities who have very little logic of their own or very few primitives as their properties, but instead will have a number of properties that each are themselves a value object. ‑So he\u0026rsquo;s not saying everything should be value objects, but that it\u0026rsquo;s probably our natural instinct to start by thinking of things as entities and then maybe once in a while go, oh, maybe that should be a value object. So what Vaughn is suggesting is really start by thinking every time should this be a value object and you will surprise yourself at how many times something that you originally might have thought of as an entity really does make a lot more sense as a value object. ‑Or sometimes when you\u0026rsquo;re looking at an entity, there might be a couple of properties that seem to always go together, you might be able to bundle these properties into a single value object. It\u0026rsquo;s interesting to note that identity values can be treated as value objects as well. In many systems, entities have a primitive type, usually int or GUID as their ID, but this means that it\u0026rsquo;s easy to substitute a client ID for a patient ID if developers are not careful. By creating actual value objects for client ID and patient ID, which can still be stored as ints or GUIDs, it can eliminate this kind of error from our design. ‑Here is an example of a Client class that\u0026rsquo;s inheriting from base entity, but specifying that the type will be ClientIdValueObject rather than a scalar type like int or GUID, that\u0026rsquo;s followed by a service class that has a CreateAppointmentFor method which takes a clientId and a patientId. If those IDs were both GUIDs, the runtime code would allow you to accidentally pass them in in the wrong order because the signature is only constraining that you pass in two GUIDs and that could create a big problem when you\u0026rsquo;re trying to build an appointment. But with the specialized value objects, you can tightly constrain the parameters to avoid this problem rather than adding a lot of extra logic elsewhere to protect you from making that mistake. For me, this highlights the beauty of DDD thinking. With this little bit of upfront work, you\u0026rsquo;re removing the complexity of solving the kind of problem that could be created by accidentally transposing the client id and patient id. In our conversations with Eric Evans, we asked him for his thoughts on putting logic into value objects. He told us that he thinks value objects are a really good place to put methods and logic because we can do our reasoning without side effects and especially the complications that identity brings along, all those things that make logic tricky. We can put functions on those value objects and then do the pure reasoning right there in the value object. ‑Eric also called out date libraries as a good example of a value object. They perform common functions on dates so we don\u0026rsquo;t have to keep coding them ourselves in our entities or services. For example, a date library could be used for calculating a person\u0026rsquo;s age from their birth date. As long as the library causes no side effects to the date in question, it can work well as a value object.\nImplementing Value Objects in Code Our primary demo involves scheduling appointments. Appointments have a start and an end time. These two things always go together, so they make sense to extract as a value object. Here\u0026rsquo;s a closer look at the DateTimeRange ValueObject we created for the course\u0026rsquo;s demo. We also have a DateTimeOffsetRange, which is identical, but includes support for time zones. Because DateTimeRange is a pretty low‑level concept that could be useful in a number of different applications, it\u0026rsquo;s implemented in the shared kernel package. The class inherits from a ValueObject base class that provides flexible equality checking behavior, so we don\u0026rsquo;t need to clutter our class with overloads for Equals, GetHashCode, et cetera. It was written by fellow author and DDD expert, Vladimir Khorikov. ‑Because this is a ValueObject, you can see that all of its properties are read only. Recent versions of C# and Entity Framework Core do allow us to avoid even having a setter in there when we want to define read‑only properties, and we also now have the use of records in C#. EF Core can comprehend read‑only properties that don\u0026rsquo;t have any setters at all, and it takes advantage of fields. But here we\u0026rsquo;ve written our value objects in a more generalized way that\u0026rsquo;s not taking advantage of any specific or specialized features. However, you can adapt these samples to benefit from those specific APIs and language versions that you\u0026rsquo;re working with. The important goal here, though, however you implement it, is that the state of the value object should not be changed once it\u0026rsquo;s been created and as part of the domain model. ‑Right. Value objects should get all of their state through their constructor, and any invariants that need to be checked should happen in a constructor as well. In this case, the date time range is guarding against having a start time that exceeds its end time. If it does, an exception will be thrown. The second constructor that takes a timespan calls the first one using constructor chaining, so in either case, the guard will always be enforced. Since the DateTimeRange is immutable and cannot be created in an invalid state, the rest of the domain model can count on it being valid. ‑Our DateTimeRange type does have some additional methods that let us create new DateTimeRange instances from existing ones, much like the DateTime type provides options to create new date times by adding time to an existing instance. In our type, for example, to change an appointment set to end at 10:30 instead of ending at 11:00, a new instance of DateTimeRange can be created using the newEnd method. Finally, the base ValueObject class requires overriding a GetEqualityComponents method. This is used when comparing two instances of the ValueObject, and it\u0026rsquo;s up to you to decide which properties should or shouldn\u0026rsquo;t be included. In the case of DateTimeRange, the start and end times are sufficient. If two DateTimeRange instances have the same start and end values, they should be considered equal. ‑Custom logic needed to determine whether one appointment overlaps with another is another area where the ValueObject can help. The whole appointment isn\u0026rsquo;t needed to determine if there is an overlap in appointments. Only the DateTimeRange is used in such a calculation. Thus, the Overlaps method, shown here, has been moved out of the Schedule and Appointment classes and into the ValueObject, where it is more reusable, and it reduces the complexity and responsibilities of the other domain types. ‑We asked Eric to share his thoughts on moving logic out of entities into value objects. He agreed that it\u0026rsquo;s a good idea. What he said was if there\u0026rsquo;s logic that\u0026rsquo;s really the classic software logic, I like to add that in value objects. You can really test value objects much easier than entities, and you can use them much more freely. So your entity becomes this critical piece of glue, an orchestrator among different value objects. But that doesn\u0026rsquo;t mean that you won\u0026rsquo;t have some logic in the entity. It\u0026rsquo;ll just be very concise. ‑Eric also said that it\u0026rsquo;s a nice way to work towards the ubiquitous language to the point where you look in the methods of the entity and you see higher‑level things. They read like use case level communication, rather than nitty gritty detail. My personal takeaway from this is to keep an eye on the properties of your entities, and specifically, their types. If you find that they\u0026rsquo;re all primitive types, like ints and strings, think about if any of those primitive things could be grouped together as value objects instead. Another value object that we can point out here is the AnimalType. This is just to give you an idea that our value objects can be extremely simple. In this case, AnimalType is just a combination of the species and the breed of a particular pet or patient that we\u0026rsquo;re dealing with at the vet clinic. And there\u0026rsquo;s not a whole lot of other behavior here. But it does provide us with a container by encapsulating these two related properties together as a single value object.\nUnderstanding Domain Services When an operation is important to the model but doesn\u0026rsquo;t necessarily belong on any one entity or value object, a service is often appropriate. But don\u0026rsquo;t be too quick to give up on finding a natural home for the operation on an existing entity or value object or you may end up with a very procedural anemic model. Frequently, domain services serve as orchestrators for operations that require several different collaborating entities or value objects. Evans notes that good domain services must first and foremost not be a natural part of an existing entity or value object. Again, we don\u0026rsquo;t want to shift all of our rich behavior from our entities and value objects to our services. Services should also have a defined interface that\u0026rsquo;s comprised of domain model elements. And finally, domain services should be stateless, though they may have side effects. What this means is we should always be able to simply create a new instance of a service to perform an operation, rather than having to rely on any previous history that might have occurred within a particular service instance. But of course, the result of calling a method on a service might result in changes to the state of the system itself. These rules apply specifically to domain services which belong in the core of our application. Your software will likely also use services to perform work related to infrastructure or as part of the front end of the application. ‑Here are some examples of the kinds of services we might find in different layers of a DDD application. The UI layer represents the front end of the system and should have as little business logic as possible. It is frequently combined with the application layer, which should be concerned with behavior necessary for the application, but unrelated to the customer\u0026rsquo;s problem domain. For example, the application may need to work with file formats or parse some XML, and it might have services for these purposes, but these are unrelated to the domain. In the core of the application where we store our core model and domain objects, we will define any domain services for operations that don\u0026rsquo;t belong somewhere else. These services will frequently involve operations on multiple domain elements or may be responsible for orchestrating some kind of workflow. For instance, processing an order might involve a series of steps and multiple domain elements as the system checks inventory, verifies customer information, maybe charges a credit card, and then sends messages to ship the order, notify the customer, and reduce inventory. Finally, we have infrastructure‑level services. These will usually implement interfaces that are defined in the core of the domain, such as I send email. But since they require access to external dependencies, like file systems, databases, or network resources, they live in the infrastructure layer of the system. With respect to our domain, you may find infrastructure not very interesting, ‑although the people who create the internal workings of those services might find them quite fascinating. We\u0026rsquo;ll look at implementing services in our application later on in the course.\nReview and Resources Let\u0026rsquo;s review some of the important terms you learned in this module. You heard us talk about immutability, which is a really critical attribute for value objects. And immutability just means once an object has been instantiated, you can\u0026rsquo;t change the value of any of its properties. ‑Another important term we learned about is the value object. A value object is an immutable class that is defined by the sum of the different properties that it has. We don\u0026rsquo;t need an identity for a particular value object. In fact, a value object doesn\u0026rsquo;t have any identity outside of the individual properties that it has. And in order for us to compare value objects, we simply compare all of its properties, and if they all match, then we can consider these two value objects to be equal. We also learned about domain services and these are interesting because domain services give you a place to put logic and behavior that you can\u0026rsquo;t find a home for in the entities and value objects in your domain. ‑And the last term that we want to review is side effects. Side effects are changes that occur in your application or any kind of interaction with the outside world. Now, technically any change to the state of the application can be considered a side effect, but generally when we\u0026rsquo;re talking about them, we\u0026rsquo;re talking about things that changed other than the main intent of the operation that you\u0026rsquo;re performing. For instance, it\u0026rsquo;s often a good idea to keep operations that query information separate from those that change state, and if you follow this practice, then any queries that you make, that result in changes to state would be said to have side effects. That brings us to this module\u0026rsquo;s key takeaways. Most of this module was focused on value objects, which are used in your domain model to measure quantify or describe something in the domain. Value objects typically don\u0026rsquo;t exist alone, they\u0026rsquo;re usually applied to an entity to describe something about it. ‑Value objects should be compared using only their values. They don\u0026rsquo;t have an identity. Any two value objects that share the same values should be considered equal. And value objects in our domain should be designed to be immutable taking all of their needed values in their constructor and they shouldn\u0026rsquo;t have any side effects. ‑We looked at a few examples of value objects in this module. We mentioned the .NET Framework string type that you\u0026rsquo;ve no doubt used. Strings and datetimes are value objects that are available to any .NET application and can be used as a model for how you should design your own value objects. We also looked at a couple of custom value objects we used in our sample application, the datetime range and the animal type objects. ‑Finally, we wrapped up the module by introducing domain services, which are used to orchestrate operations between different parts of your domain model. Remember that domain services should generally only be used if you don\u0026rsquo;t have an entity or value object where the behavior makes sense. Overuse of domain services can lead to an anemic domain model. In the next module, you\u0026rsquo;ll learn how to build aggregates from entities and value objects while respecting their relationships. Here are some links and resources relevant to the topics of value objects and domain services that we discussed in this module. Thanks for watching Domain‑Driven Design Fundamentals.\nTackling Complexity with Aggregates Introduction and Overview Hello, this is Julie Lerman. ‑And this is Steve Smith. ‑Welcome back to Domain‑Driven Design Fundamentals. In this module, you\u0026rsquo;ll learn more about aggregates and the associations between entities. ‑We\u0026rsquo;ve talked about the domain model and the need to have effective communication in order to ensure the model is a useful representation of the customer\u0026rsquo;s problem space. However, most problems that weren\u0026rsquo;t using domain‑driven design can be quite complex. So now we\u0026rsquo;re going to specifically look at some patterns and techniques that can be used to manage this complexity. ‑We\u0026rsquo;ll cover several new terms along the way, including aggregates and aggregate roots. You\u0026rsquo;ll learn about invariants and the aggregate roots\u0026rsquo; responsibility for them. Aggregates often contain related data, so we will explore how to model relationships, often referred to as associations in DDD. ‑Then, we\u0026rsquo;ll look at our application and see how thinking about the aggregate roots pattern helps us revise and simplify our model. ‑And finally, we\u0026rsquo;ll walk through how we\u0026rsquo;ve implemented this pattern in our code.\nTackling Data Complexity Let\u0026rsquo;s start by considering data complexity. If you\u0026rsquo;ve ever worked on a relatively large or mature application, you\u0026rsquo;ve probably seen some fairly complex data models. One way to reduce the complexity that we already talked about is using aggregates and aggregate roots, which you\u0026rsquo;ve seen in the DDD mind map. Another is by limiting how many bidirectional relationships you have in that data model. ‑If your design doesn\u0026rsquo;t have any clear notion of aggregates, the dependencies between your entities may grow out of control, resulting in a model like this one. And if your object model reflects a data model like this one, trying to populate all of the dependent objects of one object might result in trying to load the entire database into memory. And the same problem exists when it comes time to save changes. With a model like this, there\u0026rsquo;s just no limit to which areas of the data model might be affected. ‑Even though in the real world at the highest levels of your system all of these things really do interrelate, we need to be able to separate them to keep the complexity of the system in check. ‑I\u0026rsquo;ve gone into a lot of clients where their entity data model looks like this, and they\u0026rsquo;re using this one big, huge single model throughout their entire system. So, one of the things that I work on with them is breaking this down and using the whole concept of bounded contexts to start looking at what makes sense for smaller models. ‑Yeah, a system that\u0026rsquo;s designed like this is what we tend to call a big ball of mud because everything is just kind of slapped together, and it collapses under its own weight once it gets to a certain level of complexity. ‑Great. So, let\u0026rsquo;s see how we can use aggregates to help solve the problem.\nIntroducing Aggregates and Aggregate Roots Aggregates consist of one or more entities and value objects that change together. We need to treat them as a unit for data changes, and we need to consider the entire aggregate\u0026rsquo;s consistency before we apply changes. In the examples shown here, the address is part of the customer and the component is quite literally a part of the product. We can treat a set of changes to a customer and their address as a single transaction. Every aggregate must have an aggregate root, which is the parent object of all members of the aggregate, and it\u0026rsquo;s possible to have an aggregate that consists of just one object, in which case that object would still be the aggregate root. ‑In some cases, the aggregate may have rules that enforce data consistency that apply across multiple objects. For instance, maybe our product consists of a collection of components, but in order to be in a valid state, it needs to have a specific set of such components. As an example, if the product is a Lego minifig, the collection of parts won\u0026rsquo;t be a valid product unless it includes a head, an upper torso, a lower torso, two arms, two hands, and two legs. If we allowed the collection of components to be modified independently of the product it was associated with, we could easily end up with consistency problems. If we want to modify the composition of a product, in this example, we should do so as a transaction, so that we start and end with a valid product. Data changes to the aggregate should follow ACID, that is they should be atomic, consistent, isolated, and durable. It\u0026rsquo;s also the responsibility of the aggregate root to maintain its invariants, such as the number and type of components it requires in the example. An invariant is a condition that should always be true for the system to be in a consistent state. When considering whether particular objects should be treated as an aggregate root, you should think about whether deleting it should cascade, in other words, if you need to also delete the other objects in its aggregate hierarchy. If so, it\u0026rsquo;s likely the object in question should be considered an aggregate root. ‑Another way to think about whether it makes sense to have an object as an aggregate root is to ask, does it make sense to have just this object detached from its parent? In the example shown here, if you\u0026rsquo;re deleting the minifig, then you have to delete all of its parts. Conversely, if you have to delete a head, maybe it got broken, you don\u0026rsquo;t need to delete the rest of the parts. Therefore it doesn\u0026rsquo;t make sense for the head to be the root of this aggregate. ‑In the Domain‑Driven Design book, Eric Evans states this pretty simply, he says, an aggregate is a cluster of associated objects that we treat as a unit for the purpose of data changes.\nConsidering Associations in Aggregates When considering aggregates, which, as Evan says is a cluster of associated objects, it\u0026rsquo;s also important to think about relationships between those associated objects, especially those which exist within the aggregate. Before diving into how related entities participate in an aggregate, it\u0026rsquo;s important to learn some important concepts that DDD brings to us when considering relationships among entities. ‑Many developers, myself included, tend to define relationships between classes in both directions. For example, an order has a line item and a line item has an order, a pet owner has pets and a pet has an owner. Many of us tend to think in bidirectional relationships by default. Because domain‑driven design aims for simplicity in the model, we start recognizing more quickly that the bidirectional relationships can often make things overly complex. For instance, I\u0026rsquo;ve often found this to be true when it comes to adding in my persistence layer, and I happen to mostly use an ORM Entity Framework, which brings along its own behavior and assumptions about how relationships are managed. Sometimes the fact that my model includes navigation properties that may not be totally necessary can be the cause of some grief that\u0026rsquo;s led me to take some time to consider if I really need that navigation or not. ‑Domain‑driven design guides you to default to one way, or unidirectional relationships. That\u0026rsquo;s not to say that you shouldn\u0026rsquo;t ever have bidirectional relationships, but that because of the extra complexity involved, you should spend some time considering if that complexity is justified. ‑A relationship, also known as an association, should be part of a type\u0026rsquo;s definition, and we do that using properties that allow us to traverse from one end of the relationship to the other. In this example, we have a client type with a Patients property, and in a patient type, we have a Client property; not just an ID value, but a property that leads to a complete object or set of objects. If you introduce a bidirectional relationship, as shown in this code, using properties that let you traverse in both directions, you should only do so when neither object can be defined without the other. If that\u0026rsquo;s not the case, then you need to be specific about the direction of the relationship, also called the traversal direction, to keep your model design simple. ‑Eric Evans puts it this way, \u0026ldquo;A bidirectional association means that both objects can be understood only together. When application requirements do not call for traversal in both directions, adding a traversal direction reduces interdependence and simplifies the design.\u0026rdquo; ‑So with a DDDI, we can look at our model and ask, can we define a client without identifying their pets? Can we define a pet without identifying the client who\u0026rsquo;s responsible for them? ‑This may sound like a simple set of questions, but it could lead to a whole lot of debate. For example, why would a person be scheduling an appointment if they didn\u0026rsquo;t have a pet? So in the context of scheduling appointments, a client doesn\u0026rsquo;t make a whole lot of sense without one or more pets or patients. ‑Or from another perspective, a cat can\u0026rsquo;t pay a bill or call to make an appointment, so how can we define a pet without a client? These are both pretty reasonable arguments, but neither one gets us anywhere. ‑So, let\u0026rsquo;s start again with defaulting to a one‑way relationship. A client would need a patient to schedule an appointment. A client would not need a patient to pay a bill. ‑Okay, and if we started from the patient end, a patient doesn\u0026rsquo;t schedule an appointment, so that becomes a moot point. Nor does a patient pay the bill. And, you know, because my dog doesn\u0026rsquo;t have a credit card. He can\u0026rsquo;t use the phone very well, either. So, when would you start with a patient and need to know something about the client responsible for that patient? That\u0026rsquo;s an interesting question. So, in the context of scheduling an appointment, one could argue that we should define the traversal from client to patient and that we gain nothing by having a way to traverse from a patient back to a client. You may balk at that notion, but remember that all we care about right now is scheduling an appointment, not all the other possible scenarios where it might make sense to traverse from patient to client. ‑Sure. It\u0026rsquo;s another example of YAGNI, you\u0026rsquo;re not going to need it. In fact, we originally had owner as a property on patient in this context, but we realized it wasn\u0026rsquo;t necessary, so we removed it. However, we kept the ID because we had some scenarios where it was useful. ‑So in the end, we chose to define relationships that traverse from appointment to doctor, patient, and client, and to define one that traverses from client to patients or their pets, but not the other way. ‑You may have experienced another type of bidirectional relationship problem if you\u0026rsquo;ve seen related data gets serialized in your applications. When objects are serialized, the serializer typically traverses all of the object\u0026rsquo;s properties recursively, If there is a bidirectional relationship, it can create a loop that will cause serialization to fail. You can think of saving aggregates in much the same way, and in fact, depending on how your persistence layer is implemented, serialization may actually be required as part of how your app persists its aggregates. In our aggregates, the single direction that we would use would go from the root to its dependents, and never the other way around.\nHandling Relationships that Span Aggregates Aggregates serve as boundaries between logical groupings within our application. We enforce these boundaries by prohibiting direct references to objects within an aggregate that aren\u0026rsquo;t the root of the aggregate. Consider the customer with the address. It\u0026rsquo;s perfectly okay for customer to reference address. Address might be an entity, or it might be a value object; it doesn\u0026rsquo;t really matter in this scenario. What\u0026rsquo;s important, though, is that the only way to get to the address in this aggregate is through the customer. We won\u0026rsquo;t be referencing an address by some identity outside of this aggregate, but that\u0026rsquo;s not the case for customer. Since the customer is the aggregate root, it can be referenced from other aggregates. ‑In this common example, an order might reference a customer. Depending on our context, it might make sense for a customer to reference an order. In this case, let\u0026rsquo;s assume it only makes sense for the order to be central to the application\u0026rsquo;s design. What\u0026rsquo;s not okay is for the order to reference a customer\u0026rsquo;s address directly. This violates the integrity of the customer aggregate. ‑Remember that aggregates and aggregate roots only apply to objects, not data. And when we\u0026rsquo;re talking about references, we\u0026rsquo;re talking about object references, properties that use an object directly. This is especially important with ORMs. For example, if you were to save an address that had a customer object attached to the customer property, there are scenarios in which Entity Framework would involve the customer in the database INSERT or UPDATE, possibly even a DELETE. And this behavior leads to a lot of confusion. I frequently advise developers to just remove the navigation property and use the foreign key ID instead. It\u0026rsquo;s a little more work, but removing some of the ORM magic results in more control over the behavior. And this aligns perfectly with the fact that one common way to enforce aggregates is to replace direct navigation properties in the model\u0026rsquo;s non‑root types with key references, and this reduces the number of dependency relationships within the model.\nEvolving the Appointments Aggregate Since we\u0026rsquo;re dealing with appointment scheduling, our initial design might look something like this. An appointment involves bringing together a patient and a doctor in an exam room for a particular type of exam, and since we\u0026rsquo;ll typically need to know the owner\u0026rsquo;s information when we deal with the scheduling, it\u0026rsquo;s important to have a reference to the client from the patient also. So if we model our system this way, any time we saved an appointment, it\u0026rsquo;s going to scan all of these objects for changes and save them as well. So modeling it this way, the scope of our domain for appointment scheduling is much greater than it needs to be since, in our case, we don\u0026rsquo;t expect to modify any of the other objects when we\u0026rsquo;re creating an appointment. ‑Right, an appointment is basically just a list of resources tied to a particular timespan, it models who, what, when, and where, but it doesn\u0026rsquo;t ever need to change any of these associated concepts. As a result, we can simplify our design by eliminating most of these object relationships from the appointment classes designed. Recall that for an object to be a good candidate for being an aggregate root, it should be the case that deleting an object should also delete the other objects within the aggregate. In the design shown here, if a customer cancels an appointment and we delete it from the system, it doesn\u0026rsquo;t make sense that this should delete all of the associated objects. ‑So here is another perspective on that same model. By simply including the IDs of the related concepts rather than object references, we\u0026rsquo;re able to ensure that creating and changing appointments has a minimal impact on our system when we persist the appointment. This relationship works because an appointment in the real world is really just a note that includes a place, time, and additional details. Adding and removing appointments shouldn\u0026rsquo;t impact the people and places involved, and this revised design reflects this.\nUsing Invariants to Better Understand Our Aggregate We do still have a bit more learning to do with this model though. Somewhere in our design, we need to enforce certain invariants about appointments like that they shouldn\u0026rsquo;t be double booked. Our current thinking is that appointments need to include this rich behavior with regard to how they\u0026rsquo;re scheduled. It\u0026rsquo;s the aggregate roots responsibility to verify any invariance the aggregate may have, and in this case, the appointment is still acting as an aggregate root, even if we have eliminated the navigation properties to the other objects that it might be working with. Let\u0026rsquo;s make sure we\u0026rsquo;re clear on invariants and then we\u0026rsquo;ll see how invariants in our application impact our design. An example of an invariant in the real world is the speed of light, which is a constant that you just can\u0026rsquo;t break in terms of the physics of the universe as we know it. Some things in your system must be true in order for the model to be consistent or valid. Other examples of invariants might be that the total of the items on a purchase order do not exceed the PO amount, or that appointments do not overlap, or that an end date on an object must follow the begin date on that object. Sometimes an invariant only involves a single object, maybe a particular property or field such as name is required. In this case, we may model the system such that one can\u0026rsquo;t even create the object without the required information. Our value objects are like this. For example, you can\u0026rsquo;t create an instance of a datetime range object without defining both the start and end time. However, sometimes the invariants involved how multiple objects relate to one another. ‑In the example here, the purchase order and the individual line items would most likely be modeled as separate objects, however, the purchase order would be the aggregate root, and as such, it would be responsible for verifying this invariant. The individual line items on the purchase order probably don\u0026rsquo;t know anything about one another nor should they, so it wouldn\u0026rsquo;t make sense to put the responsibility for enforcing this invariant in the line item object. What about appointments? How does one appointment know whether it overlaps another?\nModeling Breakthroughs and Refactoring As we focused on these invariants and where they belong in our design, it became clear to us that the appointment didn\u0026rsquo;t really make sense as an aggregate root. If you apply this thinking to our appointment scheduling context, it follows that one appointment doesn\u0026rsquo;t really know anything about other appointments, but the schedule knows about such things. Let\u0026rsquo;s evolve our domain model to follow this pattern and see where that leads us. ‑This feels like a big change to the model, and these kind of epiphanies happen when you\u0026rsquo;re working on the model. But that\u0026rsquo;s not a bad thing. It\u0026rsquo;s not like you\u0026rsquo;ve wasted a lot of time focusing on appointment as an aggregate root. This is the beauty of modeling your domain, having conversations with different people, with the domain experts, because ideas like this bubble up, and suddenly, something big like this becomes clear. So, you\u0026rsquo;re not going to get it 100% right the first time. Your understanding will evolve as you learn more about the domain. And from time to time, you\u0026rsquo;ll realize there are big changes that can dramatically improve your design. In the Domain‑Driven Design book, Eric Evans talks about these breakthroughs in his section about refactoring toward deeper insight. This is really an important part of domain‑driven design, and about a quarter of the book is dedicated to it.\nRecognizing Signs of a Misidentified Aggregate Let\u0026rsquo;s take a look at the signs that Steve and I eventually recognized in our domain, which led us to shift our appointment aggregate to a schedule aggregate. ‑Originally, our solution had the appointment as the central focus of the design. I had figured it would be its own aggregate with appointment at the root and its various properties as its children. As we\u0026rsquo;ve just discussed, that doesn\u0026rsquo;t really work as well as I\u0026rsquo;d hoped, so now we\u0026rsquo;re refactoring the design to introduce a new type, the schedule. Before we show that, though, let\u0026rsquo;s review the original structure and some of the reasons it didn\u0026rsquo;t work as well as an aggregate in our solution. ‑You can see the original structure had appointment in its own folder and marked with the IAggregateRoot interface, which is required for it to be accessible from our repository methods. It has essentially the same properties as the later version, except for ScheduleId, since there\u0026rsquo;s no schedule type yet. And it has the same basic set of methods for modifying its room, doctor, time, and other properties. None of that really changed since all of those operations only had to deal with this single appointment instance. ‑However, when the appointment tried to enforce the invariant that appointments whose times overlap for the same pet should be marked as potentially conflicting, things were a bit messier. You see, this appointment doesn\u0026rsquo;t actually have any association with any other appointments, so the only way to enforce this is to use a repository to get those other appointments for the same date as this one. Since entities don\u0026rsquo;t support dependency injection through their constructor, this means an instance of the repository needs to be passed into this method. Creating this repository instance was the responsibility of the calling code, which may not otherwise have needed it. Note also that because the repository\u0026rsquo;s interface is async, this method must now be async as well, even though no other methods on the appointment entity are async. ‑The real problem here, from a DDD perspective, is that cross‑aggregate invariants should not be enforced by any one aggregate. In the case of something like a unique constraint between all aggregates, you might need to use a domain service, or another approach. However, in other cases, the need to do this may indicate that you\u0026rsquo;ve missed an important part of your model. ‑Right. In this case, the whole thing that the user is interacting with is the clinic schedule, but nothing in our original model referred to the schedule itself. Since some of our business rules, like what to do with appointments that conflict, only make sense at this higher level, it made sense to introduce a change to our model, the schedule aggregate.\nConsidering Schedule as Our New Aggregate So, even though the initial design we had was about scheduling, the schedule itself was never part of our model. Once we include schedule as its own explicit object in our model, it makes the design much simpler. Appointments no longer need to know anything about other appointments. The responsibility for ensuring that appointments are not double booked and similar invariants can be performed by the schedule, which is the aggregate root. ‑So, let\u0026rsquo;s see if this passes our other tests about defining aggregate roots. A schedule will certainly help us ensure that appointments don\u0026rsquo;t overlap one another. When we save changes to a schedule, does it make sense to update any changed appointments? Yes, it does make sense. And if we were to delete an entire schedule, would it make sense to delete all of its appointments? Yeah, I think that would make sense also. ‑Yeah, I think this is the schedule for a particular clinic. At the moment, we only have one clinic, but if we imagine a scenario in which multiple clinics each have their own schedule, it wouldn\u0026rsquo;t make sense to delete a clinic\u0026rsquo;s schedule but then keep its appointments floating around. So I think that works. ‑Great. And if a schedule exists for each clinic, then it makes sense to persist the schedule, which means that it needs an ID, and therefore is truly an entity. And when we retrieve a schedule, we\u0026rsquo;ll most likely be filtering which related appointments we want to look at, for example today\u0026rsquo;s schedule or this week\u0026rsquo;s schedule. That would mean we want all of today\u0026rsquo;s or all of this week\u0026rsquo;s appointments from a particular clinic\u0026rsquo;s schedule. It really does make a lot more sense to me to tie the appointments to a schedule than directly to a clinic. Now, let\u0026rsquo;s see how this effects our design.\nExploring the Schedule Aggregate in Our Application Now I\u0026rsquo;ll show you the new schedule aggregate implementation in our application. In the refactored solution, we\u0026rsquo;ve renamed the folder so that now it\u0026rsquo;s ScheduleAggregate. This folder only includes schedule and appointment, as well as related guards and specifications. In larger applications, it can help to organize your domain model by grouping everything related to a particular aggregate in its folder. Looking at the ScheduleAggregate\u0026rsquo;s code, you can see that it inherits from our common BaseEntity type and uses a GUID for its id key, just like appointment. This lets us set the key ourselves, rather than relying on a database to do it for us. The class is also marked as an aggregate root with an interface. In the next module, you\u0026rsquo;ll see how we use that to protect the integrity of our aggregates. ‑Right. We\u0026rsquo;ll see how that works when we look at our repository and specification implementations. ‑Next, the Schedule\u0026rsquo;s constructor just takes in its id, its dateRange, and its associated clinicId. In our sample, the clinicId is always hard‑coded but in a real application, there might be several clinics using the same software, and they would each have their own ids. The constructor is responsible for ensuring that the incoming values are valid so that it\u0026rsquo;s always created in a consistent state. Schedule has just a few properties. There is the ClinicId, the associated set of appointments, and the DateRange. We\u0026rsquo;re careful to only expose a read‑only IEnumerable of appointments because our aggregate must encapsulate its internal state. We don\u0026rsquo;t want other parts of our application to add or delete appointments without going through the schedule\u0026rsquo;s explicit methods designed for this purpose. Also, the date range isn\u0026rsquo;t persisted since it can vary with any given instantiate ation of the schedule. ‑Yeah, and for performance reasons, you wouldn\u0026rsquo;t really want to load the ScheduleAggregate with every appointment that had ever been made included in it. By using a property like this, we make it clear to the rest of the domain what set of dates this instance of the aggregate holds. The actual population of the appointments that match this range is left as a responsibility of the specification and repository classes that are used to retrieve the schedule from the database. ‑Yes. And the configuration of the aggregate\u0026rsquo;s persistent details is done in the infrastructure project\u0026rsquo;s Data Config folder. This is where every entity\u0026rsquo;s EF Core‑specific mappings and configuration is performed, which keeps these details out of our domain model. You can see here that we\u0026rsquo;re also letting EF Core know that we don\u0026rsquo;t want the database to supply an id when we create a new schedule. We\u0026rsquo;ve marked that property as ValueGeneratedNever. ‑Getting back to the schedule, let\u0026rsquo;s have a look at its methods. The first method is for adding new appointments. Our design forces all new appointments to come through this method, so we don\u0026rsquo;t have to have duplicate behavior anywhere else in the application to take care of whatever should happen when a new appointment is added. It\u0026rsquo;s all right here in one place, easy to understand, and easy to test. The method validates the inputs to ensure we\u0026rsquo;re not adding bad data to our aggregate, and then it adds the appointment. When a new appointment is added, the schedule is responsible for marking any appointments that might be conflicting. It\u0026rsquo;s the right place for this behavior to live, since the schedule knows about all the appointments and knows anytime appointments are added or removed. After marking any conflicts, an appointmentScheduledEvent is added to the aggregate\u0026rsquo;s event collection. We\u0026rsquo;ll see how this works in the module on domain events. The DeleteAppointment method is similar. After deleting an appointment, the schedule needs to once more mark any appointments that might be conflicting. There\u0026rsquo;s also a TODO comment here. These are left as exercises for you to learn more about how to work with the patterns introduced in this course. You\u0026rsquo;ll find a number of TODO exercises scattered throughout the sample. ‑We hope you\u0026rsquo;ll take some time to download the code, run it locally, and try implementing some of the TODO tasks using the existing functionality as a guide. There are a couple more in the MarkConflictingAppointments method, which, remember, was originally on the appointment type when we started out with that as its own aggregate. This method is responsible for detecting and marking appointments that might conflict. The basic rule, shown here, just checks whether the patient has two appointments that overlap. If any such appointments are found, they are updated to set their conflicting property to true. Then, the current appointment\u0026rsquo;s property is set based on whether there are any other appointments that conflict with it. ‑This is an important part of the business logic for this application, and it\u0026rsquo;s encapsulated right in our schedule aggregate. In a lot of data‑driven applications, this kind of logic might be in a stored procedure, or perhaps just implemented in the user interface. But in a domain‑driven application, we want these rules to be explicit and defined in our domain model. ‑The last method on schedule provides a hook for its appointments to use to notify it when changes are made to one of them. Because we don\u0026rsquo;t have navigation properties from appointment back to schedule, we can\u0026rsquo;t directly call methods on the aggregate root from appointment methods. There are a few different patterns we can use to accomplish this task. For this sample, we chose this one because it\u0026rsquo;s simple and easy to follow. This handler simply calls MarkConflictingAppointments, but it\u0026rsquo;s exposed as its own separate method because it could do other things as well, and we don\u0026rsquo;t want to expose the internal behavior of the schedule to the rest of the app. To see how it\u0026rsquo;s used, let\u0026rsquo;s look at the appointment class\u0026rsquo;s UpdateStartTime method. When the application needs to update the start time for an appointment, it will call this method. Because appointment is part of a scheduling aggregate, we know the app will already have loaded the schedule before calling this method. So the second parameter in the method asks for the handler on the schedule that will be called. The call to update the schedule is made after updating the TimeRange property on the appointment, so when mark conflicting appointments is called, it will use the new value for the time range. There are a lot of other ways you can set up this communication, using C# events, static domain events, or some kind of double dispatch approach. They all have trade‑offs, and when you need to do this in your apps, you should choose the one that works best for your app and your team. ‑Let\u0026rsquo;s see the final result in the application. This change to our model of adding in a schedule aggregate made a big difference to how the domain model is organized. It gave us a much better place to put the logic of enforcing business rules around combinations of appointments and business logic that needs to run when appointments are added or removed. ‑Right. Without the schedule, we would have had to use a domain service or something to add behavior around the newly added or removed appointments. But with this design, we can go into the schedule, add a new appointment for Rosie, and then add another one, and you can see the notifications being triggered by the events, as well as the red outline representing the conflict in these two appointments. Not only is our domain model clean and easy to test, but even more important, it actually works! ‑And notice that as we move one of those conflicting appointments to another spot, the red alerts disappear. Good job, Steve! I am so grateful that you let me off the hook for working on the front‑end of this application. You know I\u0026rsquo;m more of a back‑end developer.\nSharing Our Tips for Aggregate Design So let\u0026rsquo;s step back a moment and review some of the things we\u0026rsquo;ve just learned about designing aggregates. First of all, aggregates exist to reduce complexity. You might not always need an aggregate. Don\u0026rsquo;t add complexity just for the sake of using an aggregate. Another is that entities with an aggregate can only reference the root entity of another aggregate. ‑But you can always use foreign key values as a reference to entities inside another aggregate. It\u0026rsquo;s perfectly okay to use this, and it will avoid the need for when you go to save that aggregate for it to cascade its persistence into other aggregates. If you find you\u0026rsquo;re needing to use a lot of foreign key references to aggregate children often, you may need to reconsider the design of your aggregate in your domain model. ‑Another pointer was don\u0026rsquo;t be afraid to have an aggregate of one, in other words, an aggregate that only has one object in it. ‑And finally, don\u0026rsquo;t forget the rule of cascading deletes. Remember, one test for whether or not a particular object makes sense as an aggregate root is to consider whether deleting that object should also delete all of the other child objects in that object\u0026rsquo;s hierarchy. If it doesn\u0026rsquo;t, then you have probably chosen the wrong structure for your aggregate.\nReview and Resources Once again, we have covered quite a bit in this module. Let\u0026rsquo;s review some of the terms that you learned in this video. The first thing we talked about was an aggregate. An aggregate is a group of related objects that work together in a transaction. The root becomes the entry point through which you do any work with the aggregate, and the root also is what\u0026rsquo;s in charge of making sure that all of the rules that apply to that graph of objects are met. ‑Each of the rules that describes the state that the system must be in in order to be valid is called an invariant. Within our aggregates, we have objects that are related to one another. In DDD, we refer to these relationships as associations. If you use an ORM, you may hear the term navigation properties, which refers to those properties that reference the related objects in the model. And we talked about the importance of defaulting to one‑way relationships, which we also refer to as unidirectional relationships. ‑In addition to these important terms, Steve and I shared a lot of guidance around creating aggregates and roots in your domain models. Nobody wants to work with a big ball of mud. We use aggregates to organize our model. An aggregate is a set of related objects that live in a single transaction while encapsulating the rules and enforcing invariance of that transaction, making sure that the system is in a consistent state. When designing how related objects work together, your job will be easier with one‑way relationships. Use those as a default, and only introduce bidirectional navigation if you really need to. ‑And most importantly, don\u0026rsquo;t resist updating your model as you and your team of domain experts learn more about the domain. Hopefully, most of this will happen early on, and then just once in a while you might have a big breakthrough, like we did when we realized that the schedule made more sense as an aggregate root than trying to have each appointment be its own aggregate. Up next, you\u0026rsquo;ll learn about repositories which are a critical pattern in domain‑driven design. This is Steve Smith, ‑and I\u0026rsquo;m Julie Lerman. Thanks for watching Domain‑Driven Design Fundamentals.\nWorking with Repositories Introduction and Overview ‑Hello. I\u0026rsquo;m Julie Lerman. ‑And this is Steve Smith. ‑In this module of Domain‑Driven Design Fundamentals, you\u0026rsquo;ll learn about repositories, another critical pattern for Domain‑Driven Design. ‑We\u0026rsquo;ll start by defining what repositories are, and then we\u0026rsquo;ll provide some tips for working with them, as well as talking about some of their benefits. There are different ways to define repositories and plenty of debate around their use. We\u0026rsquo;ll address some of these points. ‑Next, we\u0026rsquo;ll introduce you to the specification pattern and how it can be really helpful when you\u0026rsquo;re implementing repositories. Then we\u0026rsquo;ll open up Visual Studio again and show you how we\u0026rsquo;ve implemented some repositories in the scheduling app.\nIntroducing Repositories ‑Now, Julie, if this were an in‑person class, I\u0026rsquo;d definitely ask for a show of hands who has heard of the repository design pattern. I would expect most hands to go up. ‑I hope so too. I think the repository pattern is by far the most popular element of DDD to be practiced outside of Domain‑Driven Design. They can be valuable in so many applications as a way to simplify data access and enforce separation of concerns. When I began learning about repositories and implementing them in my own software design, it had a huge impact on my application architecture. Along with automated testing practices, it really forced me to consider separation of concerns with each method and behavior added to my software. ‑Personally, I love the pattern, and I find it makes it much easier for me to write good, testable code. We\u0026rsquo;re going to talk about using repositories within a DDD application, but if you want to learn more about the pattern itself, you can look in the design patterns library, and I know Julie also discusses using them with Entity Framework in her Entity Framework in the Enterprise course. ‑You can see the repositories are part of the DDD mind map, as they\u0026rsquo;re used to access entities and aggregates. Any system that needs to persist between restarts has some kind of persistent storage for the state of the system, like a database. Many applications focus a great deal of effort on the mechanics of querying, fetching, and translating data to and from objects to the point where it distracts from the model that these objects are meant to represent. And having ad hoc access to the data source also promotes having developers query for any bit of data they want anytime they want, rather than using aggregates. This makes it pretty difficult to manage the consistency of aggregates by enforcing their invariants. At best, the logic for enforcing the integrity of the model becomes scattered among many queries, and at worst, it\u0026rsquo;s not done at all. ‑Applying Model‑First design and separation of concerns means pushing persistence behavior into its own set of abstractions, which we refer to as repositories. Only certain objects, like specifically aggregate roots, should be available via global requests. Repositories provide this access, and through omission, prevent access to non‑aggregate objects, except through their aggregate roots. They give you the ability to constrain the data access, so you avoid lots of random data access code throughout your application. ‑When you think about the life cycle of an object in your application, you should consider two cases. In the first case, you have objects that are not persisted. These objects are created, perform some work, and then they\u0026rsquo;re destroyed. In the second case, you have objects that are persisted. These objects have a slightly more involved lifecycle since after the object is created, it must be reconstituted with whatever state it had when it was last saved. Then it can perform whatever work the application needs it to do, after which it may need to save its state to some persistent storage before finally being destroyed. You can use repositories to manage the lifecycle of your persistent objects without the objects having to know anything about their persistence. We call these objects persistence ignorant because they\u0026rsquo;re ignorant of how they\u0026rsquo;re stored into and retrieve from a data store. ‑In his book, Domain‑Driven Design, Eric Evans speaks quite a bit about repositories. They can be summed up by saying that a repository represents all objects of a certain type as a conceptual set, like a collection with more elaborate querying capability.\nRepository Benefits ‑Repositories can add a number of benefits to our application. First of all, they provide a common abstraction for all of our persistence concerns, which provides a means for clients to very simply obtain model objects and to manage their lifecycle. They also promote separation of concerns. The domain logic and the user interface can both vary independently from the data in the back‑end data source that is used by the application. ‑The public interface of a repository very clearly communicates our design decisions. Only certain objects should be accessed directly, so repositories provide and control this access. Another important benefit is that repositories make it easier to test our code. They reduce tight coupling to external resources like database, which would normally make unit testing difficult. Having a repository separate from client code and domain logic means that we can easily make improvements to optimize data access for this application, tuning for performance, adding caching behavior, etc. is all much easier and safer when the code for data access is all encapsulated in one or more well‑known classes. All of this makes your code easier to maintain.\nRepository Tips ‑Here\u0026rsquo;s some basic guidance you should keep in mind when designing repositories. First, a repository should have the illusion of a collection of a specific type of object. You\u0026rsquo;ll be adding the objects to the collection, removing them, and retrieving objects from the collection, but that it is an illusion of a collection is important to keep in mind. When you interact with the repository, these are the types of methods you\u0026rsquo;ll be calling, add, remove, and retrieve. Your calling code doesn\u0026rsquo;t care how the repository performs those actions. So in the repository, you might have code that responds to a retrieve method, goes out to a database and gets data, but it could be getting data that\u0026rsquo;s already in memory, or it might be grabbing data from a text file on your computer. ‑Another important recommendation for repositories is to set up access through a well‑known global interface. That way, developers that need to interact with the repository will be familiar with a common pattern for using it. ‑Here\u0026rsquo;s a simple repository interface example. Depending on the size and complexity of your software, you may have a few layers of interfaces. ‑For example, if you anticipate having a number of repositories for a schedule aggregate used in different bounded contexts, you might want an IScheduleRepository interface that not only implements the lower‑level interface, but defines some other methods or properties that every schedule repository is required to have regardless of the bounded context it might reside in. Because a repository acts like a collection, you\u0026rsquo;ll want methods to add and remove objects to encapsulate the underlying data insertion and deletion operations. We\u0026rsquo;ve got these defined in our IRepository. It is up to each concrete implementation to define how add and remove will actually work. ‑It\u0026rsquo;s not unusual to need to add specific query methods to individual repositories. Whether you need a custom subset of entities or a specific way to load entities\u0026rsquo; relationships, custom methods are a simple way to achieve this. For example, if we wanted to fetch a schedule instance with all the appointments for a given day, we could add a method to the ScheduleRepository that might have an EF Core implementation like this one. ‑Likewise, if we just wanted to be able to fetch a client with their patients, we could add a method like this one, which will eager load the patients when it loads the client. Be careful with this approach though, as it can grow out of hand, and your repositories may end up with many different query methods. A simple way to address this is to use specifications instead, which we\u0026rsquo;ll cover later in this module. In addition to these specific tips for implementing repositories, you should also keep in mind these more overarching tips. First, be sure to provide repositories only for aggregate roots that require direct access. And next, keep the clients focused on the model, while delegating all of the object storage and access concerns to the repositories.\nAvoiding Repository Blunders We\u0026rsquo;re not always going to land on the happy path, so we do want to share with you some common problems that you might run into, how to recognize them, and most importantly, how to avoid them. ‑Remember your client code can be ignorant of the implementation of your repositories, ‑but developers cannot. ‑It\u0026rsquo;s important that developers understand how your specific repository is implemented, otherwise, they can run into a number of different problems. ‑So we\u0026rsquo;re talking about not just the developers who are implementing the repository, but also the developers who are using the repository. ‑One of the common repository problems the developers working with repositories often encounter is called an N+1 query error. This is where in order to display a list of rows from the database, you end up calling one query to get the list and then a number of queries equal to the count of that list to fetch each item individually. ‑Another one that I see a lot is when people are fetching related data. With Entity Framework, they\u0026rsquo;re either using eager loading or lazy loading, and especially with lazy loading, there are a lot of developers who don\u0026rsquo;t really know what to expect from it and just because it\u0026rsquo;s easy and it just works, they use it and then run into all kinds of problems because of it. ‑And depending on how your data is structured, sometimes if you\u0026rsquo;re trying to fetch just one or two properties that are represented in a particular column in a data table, you might end up fetching more data than required if you pull back the entire row which might include dozens of columns and a lot of actual data there. These are things that knowing how your underlying data is persisted and how your repository is implemented, how those things work, can make a huge difference in your application. ‑Most of these blunders impact how data is accessed in a data store and that means that one of the best tools you have for surfacing these problems is profiling your data store. Many of the IDEs we use for managing databases have profilers built in, some examples are SQL Server Profiler, Jetbrains DataGrip, and Azure Data Studio. Many of the APIs we use also have logging capabilities that can relate database activity. As a .NET developer, I often use the .NET Core logging API or some of the features built into Entity Framework Core, but most any language you use can do this and all of the cloud providers have ways to trace activity in their various data stores. There are even third‑party tools dedicated to database profiling. The suite of profilers from Hibernating Rhinos is a great example. They have profilers for RavenDB, Azure CosmosDB, and the EF Core, and Hibernate ORMs.\nAddressing the Debates Around Using Repositories Many developers have strong opinions about the use, and some might say overuse, of the repository design pattern. Let\u0026rsquo;s consider some of the common arguments made about repositories. It\u0026rsquo;s worth remembering that like Bjarne Stroustrup\u0026rsquo;s famous quote about programming languages, there are two kinds of design patterns, too. It\u0026rsquo;s no surprise, really, that as the repository pattern grew in popularity, that there would be many complaints about when and how to implement it. ‑Here\u0026rsquo;s one that really gets me. EF Core, the .NET ORM which we\u0026rsquo;re using this course, has a built‑in repository for its data access. It\u0026rsquo;s called the DbContext. I\u0026rsquo;ve heard and read comments from so many people who say never use a repository on top of EF Core because it already has a repository built in. And then I hear others who say you should always use a repository to interact with EF Core. I am not a fan of the words always and never. Maybe it\u0026rsquo;s because I\u0026rsquo;m a libra, who knows. So, these strongly held opinions really frustrate me. What Steve and I want to do here is give you the information you need so that you can make educated decisions about when to use repository and when to opt for something else. ‑Let\u0026rsquo;s remember for a moment what repositories are and where they live in a domain‑driven application. Repositories are abstractions. They\u0026rsquo;re part of your domain model. They define the persistence operations the model will use. That\u0026rsquo;s it. There\u0026rsquo;s nothing in the domain model patterns produced through model‑driven design espousing the use of Entity Framework, or NHibernate, or any other specific vendor tool for doing persistence. It doesn\u0026rsquo;t even know if you\u0026rsquo;re doing Java or .NET. It\u0026rsquo;s meant to be totally abstract and just types. ‑The domain model should be persistence ignorant, and it shouldn\u0026rsquo;t depend on implementation details. ‑Right. One of the things I really appreciate about DDD and the way it isolates domain expressions within a layered architecture is that it aligns perfectly with SOLID design principles, like the dependency inversion principle. ‑You are a big fan of SOLID, Steve. ‑Guilty! In this case, in terms of SOLID, using an abstraction for persistence enables us to follow dependency inversion because we can define an abstraction in our domain model and then implement it in another project that depends on the domain model. We can also write our application and its user interface so that it depends on our persistence abstraction, too, rather than on the implementation details. That\u0026rsquo;s the heart of dependency inversion. ‑And that makes it easier to follow the interface segregation principle, which I also learned about from your SOLID course. This principle prefers smaller interfaces, so if your app is using a DbContext directly, that is not a small interface. Along with DbContext repository features, it exposes a lot of other functionality. Using an abstraction that limits what your app needs to do with regard to persistence makes for a much simpler design in our model, reducing complexity. ‑Right. In that way, it\u0026rsquo;s similar to the facade pattern because it lets us work with a much simpler view of what could otherwise be a potentially very complex and powerful persistence library. ‑So, when we\u0026rsquo;re following DDD, our domain model shouldn\u0026rsquo;t know anything about EF Core, or whatever APIs you\u0026rsquo;re using for your data persistence. If our model requires persistence, like most do, we should define abstractions in the model that describe what our needs are without specifying how they\u0026rsquo;re done. ‑Exactly. The abstraction defines what needs done, the specific implementation is all about how to do it. ‑And one really popular and powerful way to do persistence in .NET is with Entity Framework Core. And because it implements methods that map pretty closely to most common persistence abstractions, it\u0026rsquo;s usually pretty easy to implement a particular abstraction with a class that calls into EF Core. ‑Definitely. ‑EF Core works great for this in most of the apps I work on, but we should never couple it tightly to our domain model. ‑Exactly. The whole point of DDD is that we shouldn\u0026rsquo;t be coupling our domain problems with our persistence problems.\nReturning IQueryables: Pros and Cons Another question I get all the time, and which I\u0026rsquo;ve discussed in some of my other Entity Framework courses, is whether repositories should return IQueryable, and yes, I do have my opinions on that. ‑Yes, this is another source of some debate. On the face of it, it sounds like it would be a great idea. Your most basic repository abstraction might not provide much in the way of complex filtering options and you can avoid having to think about that sort of thing if you just return an IQueryable. ‑Right, because then any code that consumes an IQueryable can extend the expression adding additional filters or projections to the query before it\u0026rsquo;s actually executed. On the surface, it sounds pretty good, right? ‑Well, it turns out that a lot of query logic is actually business logic, and if you return an IQueryable, it has two not‑so‑good effects. It can leak a lot of the implementation details so your application code\u0026rsquo;s behavior changes significantly based on the implementation of the repository and it tends to put the business rules for querying all over the application. ‑Let\u0026rsquo;s say we have an MVC application with a controller so that\u0026rsquo;s the server‑side logic of the UI layer and it returns a view to the UI. The controller calls into a service to get its list of customers and the service contains a customer repository interface. That repository calls into an infrastructure project and the infrastructure project is where we\u0026rsquo;re using EF Core and it\u0026rsquo;s DBContext, but to limit what\u0026rsquo;s exposed outside of the infrastructure project, there is a repository there as well. The repository and the service makes its calls to the repository in the infrastructure layer. It sounds like a lot of layers, but that\u0026rsquo;s not a problem because we have reduced coupling and made a maintainable solution. The real problem here is where can we put our query logic in this example? ‑Well obviously the repository, and it wouldn\u0026rsquo;t be unusual for the method in the service to further modify the query, but since it\u0026rsquo;s also returning an IQueryable, the controller action could further modify that same expression tree, and assuming the controller just passes that same IQueryable to the view, which we\u0026rsquo;ve both seen teams do, even the view could further refine the query. So is this a good thing or a bad thing? ‑Well on the plus side, we get a lot of flexibility without having to write a lot of code for our repository. We\u0026rsquo;re also able to tailor the data we need to the specific place it\u0026rsquo;s used and even modify the query from multiple steps in the app. At the same time, we get to reuse a simple repository interface everywhere in our app. ‑Right, but on the other hand, that query logic is now spread out everywhere. Every class that\u0026rsquo;s adding query logic, in addition to whatever else it\u0026rsquo;s doing, is now violating the single responsibility principle. Then there is separation of concerns. Query logic should be separate from other concerns in most of these classes. ‑And another problem I see a lot with this approach is confusion about when the actual query is executed and what runs on the database server versus in‑memory in the application. ‑Many developers will assume the query runs inside the repository and the result they get back is from the data store. And of course that\u0026rsquo;s true for most calls, but not necessarily for those that return IQueryable. ‑Right, the query will execute the first time any code tries to enumerate the result. That could happen inside the repository, but it could also happen in the service, or in the controller, or even in the view. ‑Yeah, I see that a lot. a related issue is that developers at any step of this process can add additional logic that may compile just fine, but then at runtime when EF tries to interpret it, it blows up. ‑Anything you add to the query expression that Entity Framework doesn\u0026rsquo;t know how to translate into SQL is likely to cause an exception, at least with recent versions of EF Core. ‑And it may be redundant at this point, but it\u0026rsquo;s probably worth adding here that there is no encapsulation when you use this approach. ‑There is a way we can fix at least some of these issues though. For example, instead of returning IQueryable, we can still create flexible repository methods by passing in predicates. Then in the implementation, this predicate can be passed along to the DBContext as its Where expression providing the necessary filter. If you\u0026rsquo;re not familiar with the term predicate, but you\u0026rsquo;ve used the link where method, that\u0026rsquo;s what the method takes as its parameter, which is why we\u0026rsquo;re able to pass it right to the WHERE clause. ‑That does help part of the problem. Where before the query could have been executed at any of these points, at least now we know that whatever comes back from the repository will be the in‑memory result. The actual query is always executed in the repository itself. Of course, if the service takes in a predicate, it still means that any code anywhere in the system could be responsible for creating the query logic with the possible exception of the view if it\u0026rsquo;s just being passed an IEnumerable at this point. ‑Okay, so with predicates, they\u0026rsquo;re still very flexible, but they\u0026rsquo;re not as easy to build up from multiple locations in your application, especially compared to IQueryable. The rest of the good points still hold though. ‑The only thing we\u0026rsquo;ve really changed on the bad side is confusion about when the query actually executes. Being a fan of solid and encapsulation and knowing some other patterns we\u0026rsquo;ll share later in this module, I\u0026rsquo;m usually going to vote against this approach too. ‑Well another way we tend to solve this conundrum is going the custom query route. We even suggested this as a tip earlier, but you can definitely take it too far. Every little change to a query means another method, customer with orders, customers by shoe size, by shoe size, customers by favorite Netflix show. Hey, you never know what problems your domain experts are going to share with you. ‑The problem with this approach if it goes beyond one or two methods, is that you really start to feel the pain of the open/closed principle violation. Every time another custom query requirement comes in, you have to change the repository abstraction and all of its implementations, and the bigger the type gets, the more it violates the interface segregation principle, too. The more complex your problem is, the more query methods you\u0026rsquo;ll be adding to your solution. This can surely be an untenable situation, and we will show you some better alternatives a little later in this module.\nConsidering Generic Repositories and Interfaces Using generic interfaces for persistence is great from a code‑reuse point of view. With just one simple interface, any entity can be persisted using a standard set of operations. If you\u0026rsquo;re using aggregates, you can use generic constraints in this simple marker interface to ensure that only aggregate roots can be persisted using your interface. It can work really well. ‑But there are trade‑offs. What if you have certain aggregates that should never be deleted, but your generic repository includes a delete method? Does it make sense to have operations defined in your domain model that should never be used? This is where you need to make a judgment call. Is the convenience of having a single consistent way of dealing with persistence throughout your model more valuable than having only the necessary and appropriate persistence operations exposed? There\u0026rsquo;s no one right answer. Pick what makes sense for your app, your model, and your team. ‑In our demo, partially for the sake of simplicity, we are using a single generic repository for all of our operations, even though, yes, this means there are operations on some aggregates that are never called and some that never should be called, for example, deleting the entire schedule. ‑If we didn\u0026rsquo;t go that route, our model would need to include separate repository interfaces for each of the aggregates in our model, including schedule, doctor, room, client, and appointment type. Each would define only the operations that were actually needed by the application. For a larger model, this could result in quite a few interfaces, and possibly implementations, but would provide a more pure representation of the domain model. ‑If you do choose to create a generic repository interface, that doesn\u0026rsquo;t necessarily mean you\u0026rsquo;ll implement it generically. You might only choose to create implementations for each aggregate root, which would comply with DDD recommendations. However, it can be convenient to create a generic Repository of T implementation class that you can then use with any entity. ‑This is what we\u0026rsquo;re using in our sample, both for the front desk app and for the clinic management app. In both cases, if you review the sample, you\u0026rsquo;ll see there\u0026rsquo;s very little persistence‑specific code in either solution. ‑If you really like the code reuse you get from having a generic repository implementation, one way to keep it from allowing too much access to the internals of your aggregates would be to use a marker interface, perhaps one that simply extends the entity interface to identify your aggregate roots. Then you can update your generic repository to require this interface, rather than working with any entity. ‑At that point, code that uses the repository won\u0026rsquo;t be able to instantiate the generic repository with non‑root entities, so we\u0026rsquo;re able to use our repository to restrict access to non‑root entities from client‑server model. Using marker interfaces to identify aggregate roots is one way you can enforce your design decisions in your model using the compiler rather than relying on code reviews or other less effective practices. ‑Repository abstractions, especially generic ones, can sometimes get to be pretty large. Large interfaces violate the interface segregation principle, one of the solid principles that I cover in my Solid Principles for C# Developers course. One way to keep these interfaces smaller and more focused is to split them into read and write operations. This is related to the concept of Command Query Responsibility Segregation, or CQRS. Read operations are queries, write operations are commands. There are many benefits to leveraging CQRS that we don\u0026rsquo;t have time to cover in this course, but one area where you may immediately benefit is with modifying behavior related to these kinds of operations. Queries often benefit from data caching, and it\u0026rsquo;s very easy to add data caching to just the read operations. ‑Commands often benefit from being performed asynchronously using a queue, and having a separate interface for commands makes it easy to implement this behavior. These are just two ways you can quickly leverage splitting up your repository definitions between reads and writes. Of course, if you have a lot of different read methods, this can make it more and more difficult to implement custom caching logic, since every new method will also need to be added to the caching layer. Fortunately, this is easily solved by using the specification pattern.\nExploring Repositories in our Application Steve is going to give you a guided tour of how data access and persistence are handled in the FrontDesk application using repository abstractions. Because he\u0026rsquo;s been fine tuning versions of this demo application for many years, it\u0026rsquo;s quite impressive, and he truly is the best guide for walking you through this implementation. ‑We\u0026rsquo;ll start from the front end of the application, which is our Blazor client. Let\u0026rsquo;s take a look at editing an appointment. Here\u0026rsquo;s an appointment for Julie\u0026rsquo;s dog, Samson. You can see that on the edit screen, in addition to showing the details for the appointment, it also provides us with a list of the doctors and appointment types. When we hit the drop‑down list, we can see all of the different doctors who are available that we could schedule to work with this particular appointment. That\u0026rsquo;s actually accomplished through a back end API that\u0026rsquo;s coming from a different project. Let\u0026rsquo;s take a look at that. We\u0026rsquo;ll start by examining the API using our Swagger endpoint. Looking at Swagger for DoctorEndpoints, you can see that there are two endpoints, one to get a specific doctor by ID and another one that returns a list of doctors. We just saw the list of doctors in action. Let\u0026rsquo;s go ahead and run it again from Swagger. Here you can see the resulting set of three doctors, just like we saw in the drop‑down list. You\u0026rsquo;ll find the code for this particular endpoint inside the FrontDesk.Api project. Within there, there\u0026rsquo;s an Endpoints folder with subfolders for each of the different types of entities that we expose API endpoints for. Inside of Doctor, you can see there\u0026rsquo;s a GetById and a List, and we\u0026rsquo;re looking at the List endpoint here. When we define an endpoint, we simply inherit from BaseAsyncEndpoint, and specify the request type, if any, and the response type, if any. We can also do dependency injection through the constructor, just as you would with a controller. Each endpoint has a single Handle or HandleAsync method, and this is where the actual work of the endpoint is done. You can see in this example that we are simply awaiting on the repository\u0026rsquo;s ListAsync method in order to get our list of doctors. Once we have the list, we map it to our DTO that we\u0026rsquo;re going to actually return, and pass that back as part of that response type. The response, as we just saw in Swagger, includes the Doctors as JSON, as well as a Count property that includes the total number of those doctors. Now let\u0026rsquo;s look a little bit more closely at that repository. You can see in the dependency injection that\u0026rsquo;s occurring in the constructor that we\u0026rsquo;re depending on an IReadRepository, but where is that defined? For that, we need to look at our SharedKernel project. Inside the separate SharedKernel project, which FrontDesk references as a NuGet package, you can see that we have defined an IReadRepository interface. This inherits from IReadRepositoryBase, which is actually itself defined in another NuGet package, the Ardalis.Specification type. The reason why we\u0026rsquo;re creating our own interface here is so that we have complete control over it and we can add additional behavior. For example, in this case we\u0026rsquo;re adding a generic constraint. We\u0026rsquo;ve said that this particular interface will only work with types that have the IAggregateRoot interface attached to them or applied to them. Looking at that particular interface, you can see that there\u0026rsquo;s nothing to it. It\u0026rsquo;s simply a marker. It\u0026rsquo;s a way that we tell the compiler that our intent for a particular class or entity is that it should be treated as an aggregate root. We use that marker to enforce our design and our encapsulation to make it so that we don\u0026rsquo;t accidentally just load up a child entity out of an aggregate, when instead we\u0026rsquo;ve made a design choice that we want to work with that entire aggregate as a unit. You can see that we\u0026rsquo;ve also implemented IRepository similarly. It also inherits from a type that comes from Ardalis.Specification, and also has the same IAggregateRoot restriction. Now let\u0026rsquo;s return to our FrontDesk application and see how we implement this. First, we should look at the DefaultInfrastructureModule. This is an artifact module that defines how we\u0026rsquo;re going to wire up our abstractions with their implementations. And here you can see all the important bits of how we wire up EfRepository to IRepository, as well as IReadRepository. But notice for the IReadRepository we\u0026rsquo;re actually wiring up a different type, a CachedRepository. This acts as a decorator around the underlying EfRepository, and will provide additional caching logic. Inside of the CachedRepository, when we asked for a list of doctors, it actually checked the cache first, and then if it wasn\u0026rsquo;t in the cache, it would go and fetch the result from the EfRepository, which in turn would make the request to the database. We can see in this example here that the logging is showing us that we\u0026rsquo;re actually hitting CachedRepository, and some of the times we\u0026rsquo;re fetching the source data and other times were fetching the data from the cache. The actual EfRepository that is also defined inside of FrontDesk.Infrastructure is shown here, and once more, you can see that there\u0026rsquo;s not much to it. Most of the behavior we\u0026rsquo;re simply inheriting from the EfRepository that exists in the Ardalis.Specification package. It\u0026rsquo;s called RepositoryBase. However, when we inherited it, we were able to add additional constraints, and so you\u0026rsquo;ll see here as well that we specify that this only works with IAggregateRoot. You can see the definition of the RepositoryBase in the Ardalis.Specification NuGet package, which is available on GitHub. The details of it are shown here. The ListAsync method simply delegates to dbContext.Set of the appropriate T type, and then calls its ToListAsync, passing along a cancellationToken if one was provided. Now the last piece of the puzzle is our own AppDbContext. Inside our AppDbContext, we define the DB sets that we\u0026rsquo;re working with and we also pass in some additional configuration. One thing to notice and take away from this example is how many places in our solution we have to reference AppDbContext or EntityFramework. It\u0026rsquo;s almost nowhere in the entire code base. The only place that we talk about it at all is inside of AppDbContext, EfRepository, and some related folders such as Configuration and Migrations. Everywhere else, and especially in our domain model, we\u0026rsquo;re completely persistence ignorant, relying only on abstractions that we\u0026rsquo;ve defined.\nIntroducing the Specification Pattern Eric Evans introduces the specification pattern in the original book on domain‑driven design. Although it\u0026rsquo;s covered in Evans\u0026rsquo;s DDD blue book, the specification pattern isn\u0026rsquo;t listed in the book\u0026rsquo;s mind map, and honestly, it doesn\u0026rsquo;t get the attention it deserves. Factories are in the book\u0026rsquo;s mind map, but specifications aren\u0026rsquo;t? Even though in my experience they play a much larger role in producing a clean domain model design. ‑In the book, Evans says that specifications mesh smoothly with repositories, which are the building‑block mechanisms for providing query access to domain objects and encapsulating the interface to the database. It\u0026rsquo;s this powerful combination of specification and repository patterns that truly result in a clean, extensible, and testable design. Let\u0026rsquo;s dig a little more into the specification pattern and how it integrates with repositories before we show you how we\u0026rsquo;ve implemented it in the front desk application. ‑Specifications are used to specify the state of an object, and as such, are primarily used in three ways, validation, selection and querying, and creation for a specific purpose. In our app, we are primarily leveraging specifications in our queries. Create explicit predicate‑like value objects for specialized purposes. A specification is a predicate that determines if an object satisfies some criteria, according to Eric Evans. The most basic specification simply provides a method typically named IsSatisfiedBy, which accepts some object and returns a Boolean. These methods perform their logic in memory, and unfortunately, in remote data querying scenarios, this approach would require every row to be transferred to the application before the specification logic could be run against it. ‑However, more sophisticated specifications can be used in conjunction with ORMs like Entity Framework Core to encapsulate the details of a query while still allowing EF Core to translate the query into SQL that executes on the database server. Our sample application uses such a specification in the form of a NuGet package, ardalis.specification, which is maintained by, guess who, Steve Smith. ‑Recall that one of the benefits of using the repository pattern and abstraction was that it prevented query logic from being spread throughout the application. This was also the reason for not returning IQueryable from repository methods. The same logic can be applied to repositories that accept arbitrary predicates since, again, that means the complexity of these predicates would need to live in the code calling the repository, which might be in the user interface for example. Using repository interfaces that accept specifications instead of custom predicates addresses this problem very elegantly. ‑What about the issue we learned about earlier in this module where generic repositories weren\u0026rsquo;t suited to aggregates with custom query needs? So, individually typed repository interfaces were required, and each additional custom query needed to be added to this new specific interface. Well, specifications solves that problem too. Generic methods accepting generic specifications allows for custom queries where needed for any given aggregate. ‑A few more benefits of specifications. They\u0026rsquo;re named classes that live in your domain model. You can easily unit test them in isolation, or if necessary, integration test them with a test database. They\u0026rsquo;re highly reusable. They keep persistence logic out of your domain and your user interface. They keep business logic out of your database and persistence layer. They help your entities and aggregates follow the single responsibility principle by keeping complex filtering or validation logic out of them. You can easily create your own specification interface and implementation. Feel free to look at the source for ardalis.specification on GitHub and take just the bits you find useful. Or, you can reference that package and leverage all of its features and just start adding the specifications that your domain needs. It\u0026rsquo;s up to you. Either way, you will need to write the specifications themselves. These belong in your domain model. When you don\u0026rsquo;t have many of them, you might just put them in a root specifications folder. However, as your model grows, if you\u0026rsquo;re using aggregates, it may make sense to have each aggregate include in its own folder the specifications that go with it. This makes them easy to locate as they grow in number. ‑Each specification class is a value object, so it should be immutable. Generally, they do all of their work in their constructor. Any variable part of the specification should be supplied as a constructor argument. And once constructed, the specification needs to be supplied to your query implementation. You can use specifications directly with EF Core or you can use a repository abstraction that supports them. In either case, pass the specification to the query object and it will be used to build the query, which is then executed and results are returned. The resulting code for most queries turns into one line to create the specification and another line to execute the query by passing the specification to a repository or a DbContext method. Note that our sample is built on top of a repository abstraction that\u0026rsquo;s provided with the ArdalisSpecification package, and so it\u0026rsquo;s fully compatible with its specification types. We\u0026rsquo;ll look at the code more in the next section. ‑Here\u0026rsquo;s an updated mind map that I have created which shows how specifications work with repositories to define the queries for aggregates and entities. If you\u0026rsquo;ve been using repositories without specifications and have experienced any of the pain points we\u0026rsquo;ve described in this module, try refactoring to use specifications and I\u0026rsquo;ll bet you\u0026rsquo;ll be surprised what a positive difference it makes.\nUsing Specifications with Repositories in Our App Now it\u0026rsquo;s time to see just how specifications are implemented in the sample app. While the application code does lean on Steve\u0026rsquo;s specification API, there is still plenty to see. Most of what you\u0026rsquo;ll see here is the application\u0026rsquo;s code, but occasionally you\u0026rsquo;ll also see some of the code that\u0026rsquo;s in the Ardalis.Specification API. Once again, Steve is going to walk you through this demo, and he\u0026rsquo;ll do so from the perspective of how the app retrieves data, starting with the front‑end. ‑When we first load the schedule page in the FrontDesk app, it loads our Blazor WebAssembly application, which then makes some API calls to fetch the appointments and related data. One of those calls is shown here. It\u0026rsquo;s used to get the list of appointments for the schedule. Looking at Swagger, we can see there are a bunch of appointment endpoints. Our API is designed to serve the needs of the client app. Its endpoints won\u0026rsquo;t necessarily match up with how our domain model is constructed, so it\u0026rsquo;s perfectly fine to have an endpoint for appointments, even though appointment is not an aggregate root. It just means we need to pass in the aggregate root ID as part of the request so that we can get the schedule that owns the appointments. If we test the list AppointmentsEndpoint, we can pass in the same schedule ID that Blazor was using, and we get back a list of appointments as expected, and these are, in fact, the same appointments that are being used in the front end. Looking at the source code for this endpoint, you can see that, again, it\u0026rsquo;s in the API project in the Endpoints folder in an Appointment folder, and within that, we\u0026rsquo;re looking at the List endpoint. Now, when we pass in the request, we\u0026rsquo;re specifying a ScheduleId, and if that ScheduleId is missing or empty, then we\u0026rsquo;re going to return NotFound from this API. Otherwise, it uses the ScheduleByIdWithAppointmentSpec to encapsulate the query that it\u0026rsquo;s going to use. On the page in question, we only want the appointments for one day. It\u0026rsquo;s worth noting that this specification does not perform any filtering by date; it returns all appointments for this schedule. We\u0026rsquo;ve left a to do task here for you to implement this behavior by creating a new specification. Now, the specification that we\u0026rsquo;re using here is passed to the repository method, GetBySpecAsync. We\u0026rsquo;ll look at that in a moment. For now, let\u0026rsquo;s take a look at this specification. All of the schedule specifications are in the ScheduleAggregate folder in the Core project. The ScheduleByIdWithAppointmentSpec is pretty simple and has just three details worth pointing out. First, it has a WHERE clause, making sure it only matches schedules that have a matching ID. Second, it eager loads it\u0026rsquo;s associated appointments by using it .Include statement. And third, it implements another marker interface, ISingleResultSpecification. This interface is used to mark specifications that are expected to only return a single result. It is required when passing a specification to a repository method that only returns a single instance of a type rather than a collection or enumerable. Considering that this is being called from a List endpoint on the API, this may seem strange, but remember, we are only loading a single schedule aggregate, and it is then just the container for the set of appointments that the endpoint is going to return. The method the endpoint is calling, GetBySpecAsync, is defined in Ardalis.Specification, as shown here. Note that it has a generic constraint requiring any specification passed to it to have that ISingleResultSpecification marker interface. The sample code is calling this first method, which just works with one entity type and then returns it. If you need to use projection, though, you can use the second method, which operates on your entity type, but returns a different type using a .select. You can use this to optimize queries to return only needed properties. Remember that specifications are useful to define the expected shape of returned data in a query. This doesn\u0026rsquo;t just mean filtering the number of rows using a WHERE clause, but also determining which associations should be brought back with the query, and even which columns should be included. Let\u0026rsquo;s see an example of that. Returning to the specifications for the schedule, there\u0026rsquo;s another one called ScheduleForClinicAndDateWithAppointmentsSpec. One of the newer features in EF Core is \u0026ldquo;filtered includes,\u0026rdquo; and so by adding an include filter, we can make sure that this schedule, which is being used with a particular ClinicId, will only load in its appointments where they are for a given date that gets passed into the specification. You can use this specification, by the way, as an example when you complete that to do task that we just saw in the list endpoint. Compare this code to how we solve this problem in the previous version of this course using custom SQL queries and a custom ScheduleRepository. The specification has replaced all of that with a single specification class containing all the query logic, and the calling code simply needs to create the specification and then pass it to the repository. Unlike custom LINQ expressions that might be anywhere in our application, specifications are easily tested in isolation. In the IntegrationTests project, you\u0026rsquo;ll see several different tests that demonstrate the various schedule specifications and ensures they work as expected. These tests use a real database, since .include logic can\u0026rsquo;t be tested with an in‑memory collection. For the last specification that we looked at, which only includes the appointments for a given date, you\u0026rsquo;ll see that there\u0026rsquo;s an integration test that adds a number of appointments on different dates and then uses a repository to fetch back a schedule using the ScheduleForClinicAndDateWithAppointmentsSpec and a specific date, and it verifies that we only get back the appointments for that date and not the appointments that are on different dates, which verify the behavior of many of the abstractions and implementations in our domain model.\nReview and Resources Once again, let\u0026rsquo;s begin a review with some of the important terms you learned in this module. First, and most importantly, the focus of the module, repositories, which encapsulate the data persistence logic, add, update, delete, and retrieve. In the case of domain‑driven design, we use repositories to focus on aggregate roots. Key to building flexible repositories is the specification pattern, which guides you to encapsulate business rules in a way that they can be passed around and acted upon in other methods, classes or APIs. You learned about persistence ignorance, which describes objects being ignorant about how they are persisted into data storage. It\u0026rsquo;s another critical aspect of domain‑driven design. Steve and I also talked about ACID, an acronym to describe transactions as being atomic, consistent, isolated, and durable. Another acronym we talked about is SOLID, which is a collection of software design patterns. ‑After introducing you to repositories and how they fit into the DDD mind map, you learned about their benefits and some tips for designing them. ‑We also addressed some of the debates around repositories, not only if you should even use them, but how to use them, for example, whether or not to return IQueryables. Many of these debates exist because of the complexity of balancing clean repositories with repositories that help you achieve the variations of queries required by your domain. ‑We introduced you to an often overlooked pattern, the specification, that plays a critical role in solving this problem with DDD. Remember that you are not on your own building specifications. You can lean on the NuGet packages that I created or just dig into my GitHub repo to pick and choose what you want to adopt. Links are coming up. ‑Steve gave you a great tour of how repositories are implemented in the FrontDesk application and then more deeply to see how these repositories are using specifications to provide the rich querying needed in the application. ‑Here are a number of links to not only my GitHub repo and NuGet packages, but a number of other resources we referenced, as well as some additional ones that we think you\u0026rsquo;ll find useful. ‑In the next module, you\u0026rsquo;ll learn about two more critical pieces of the DDD mind map, domain events and anti‑corruption layers, both which help provide some data pathways between the various parts of your software. Thanks again for watching Domain‑Driven Design Fundamentals. I\u0026rsquo;m Julie Lerman, ‑and I\u0026rsquo;m Steve Smith. Thanks for watching.\nAdding in Domain Events and Anti-corruption Layers Introduction and Overview Hi, this is Steve Smith. ‑And this is Julie Lerman. ‑In this module of Domain‑Driven Design Fundamentals, you will learn about domain events and anti‑corruption layers, two patterns for decoupling how the domain model communicates internally and with other systems. ‑We\u0026rsquo;ll start with domain events, which can be used to separate concerns, allowing different areas of the application to evolve independently, and sometimes helping with scalability as well. You\u0026rsquo;ll learn how to identify domain events in your system, and how to design domain event classes. Then we\u0026rsquo;ll show you domain events being used in a simple application, so you can get a feel for the structure and the workflow. ‑Then, you\u0026rsquo;ll get to see the domain events we built in our sample application, which are a bit more realistic. After this, we\u0026rsquo;ll turn our attention to another important element of domain modeling, anti‑corruption layers, which can be used as translators between bounded contexts and Legacy APIs.\nIntroducing Domain Events Domain events are a critical part of a bounded context. They provide a way to describe important activities or state changes that occur in the system. Then, other parts of the domain can respond to these events in a loosely coupled manner. ‑In this way, the objects that are raising the events don\u0026rsquo;t need to worry about the behavior that needs to occur when the event happens. And likewise, the event handling objects don\u0026rsquo;t need to know where the event came from. This is similar to how repositories allow us to encapsulate all of our data access codes, so the rest of the domain doesn\u0026rsquo;t need to know about it. ‑We can also use events to communicate outside of our domain, which we\u0026rsquo;ll look at in just a moment. Another thing that\u0026rsquo;s worth remembering is that domain events are encapsulated as objects. This may be different from how you\u0026rsquo;re used to coding events. It certainly was different for me when I first started learning about them. For example, in a user interface, events are more commonly written as some form of a delegate in another class, but here they\u0026rsquo;re first class members of the domain model. ‑Right. Although you can implement domain events using techniques, like the event keyword in C#, the domain events themselves should be full‑fledged classes. In fact, all of these parts of domain‑driven design are defined as objects in our domain model. ‑Vaughn Vernon describes domain events simply, saying we should use a domain event to capture an occurrence of something that happened in the domain. The domain events should be part of our ubiquitous language. The customer or domain expert should understand what you\u0026rsquo;re talking about when you say when an appointment is confirmed, an appointment confirmed event is raised. ‑You may already be familiar with the idea of events from working with user interfaces. ‑Many user interface clients, like .NET Windows Forms, Electron, or web pages, like the one shown here, make heavy use of events and event handlers. In this example, there\u0026rsquo;s a single page with a single button, and in the markup, you can see there\u0026rsquo;s an onclick attribute in the button that leads to a little JavaScript method defining what the app should do in response to a user clicking the button. ‑Events are helpful because they let us avoid a lot of conditional logic. Instead, we can write code that signals a certain thing has happened, and we can have other code in our system listen for these signals and take action accordingly. So in this kind of code, you don\u0026rsquo;t have a separate class for an onclick event, and it may take some getting used to that now in our model, we\u0026rsquo;re going to create a whole class to represent an event. Domain events offer the same advantages to our model as the events in the user interface. Rather than having to include all of the behavior that might need to occur whenever the state of one of our objects changes, instead, we can raise an event. Then, we could write separate code to deal with the event, keeping the design of our model simple, and helping to ensure that each of our classes has only one responsibility. Essentially, a domain event is a message, a record about something that occurred in the past, which may be of interest to other parts of our application, or even other applications entirely.\nIdentifying Domain Events in Our System ‑Be especially attentive to these kinds of phrases when discussing the application with your domain experts. When this happens, then something else should happen. If that happens, notify the user when, or inform the user if, these types of phrases frequently refer to situations that are important to the domain expert, the system, or the user. It might therefore be worth modeling these types of things as domain events. You may also discover behavior in the application that will benefit from being treated as domain events that may be the domain expert isn\u0026rsquo;t initially aware of. ‑Remember that domain events represents something that happened. Since we can\u0026rsquo;t generally alter history, this means they should be immutable. It\u0026rsquo;s a good idea to name the event using terms from the bounded context\u0026rsquo;s ubiquitous language describing clearly what occurred. If they\u0026rsquo;re fired as part of a command on a domain object, be sure to use the command name. Here\u0026rsquo;s some examples. ‑Depending on the application, it might be important to have events to represent when a user has authenticated, when an appointment has been confirmed, or when a payment has been received. Be sure to only create events as you need them in your model. You should follow the YAGNI principle, that\u0026rsquo;s you ain\u0026rsquo;t gonna need it. In other words, don\u0026rsquo;t create domain events unless you have some behavior that needs to occur when the event takes place, and you want to decouple the behavior from its trigger. You really only need to do this when the behavior doesn\u0026rsquo;t belong in the class that\u0026rsquo;s triggering it.\nDesigning Domain Events Here\u0026rsquo;s some more things to keep in mind when you\u0026rsquo;re creating domain events. We\u0026rsquo;ve already mentioned that domain events are objects, but to be more specific, each domain event should be its own class. It\u0026rsquo;s also usually a good idea to note when the event took place since frequently the code that\u0026rsquo;s handling the event might run some time after the event occurred. It can be helpful to create an interface or a base class that defines the common requirements of your domain events. For example, capturing the date and time the event occurred. ‑Also, when you\u0026rsquo;re designing your event, you need to think about the event‑specific details you want to capture. If it\u0026rsquo;s related to an entity, you might want to include the current state of the entity in the events definition. Think about what information you would need to trigger the event again. This can provide you with the set of information that is important to this event. Similarly, you may need to know the identities of any aggregates involved in the event, even if you don\u0026rsquo;t include the entire aggregate itself. This will allow event handlers to pull the information back from the system that they might require when they\u0026rsquo;re handling the event. Ideally, domain event objects should be lightweight, so you want to be sure you capture sufficient information to handle the event, but not so much that the event object itself becomes bloated. Since the main events are immutable, they\u0026rsquo;re typically fully instantiated via their constructors. And since they\u0026rsquo;re simply noting that something has happened in the system, they don\u0026rsquo;t usually have any behavior or side effects of their own.\nApplying Domain Events to a Simple App We\u0026rsquo;ve put together a simple console application that we\u0026rsquo;re going to use to demonstrate the value that domain events can have in your application. The idea behind this is to strip things down to as small a level as possible. Then, we\u0026rsquo;ll also show how domain events are playing a real role in a more real‑world way when we get to our veterinary scheduling application. This is a .NET console application with dependency injection. The main program just loads the needed services and runs the app. The app has a simple run method, which goes through the following steps. We can step through it with the debugger, so you can see the output in real time. The app loads services and starts running. It shows what happens when an appointment is created using a service. The service calls a factory method that creates the appointment. After instantiating the appointment, the factory method sends an email, which you can imagine includes code like what is in the comments here. Then, it similarly sends a notification to the user interface, again, with code like what\u0026rsquo;s in the comments before finally returning to the service. The service, then saves the new appointment in the database. Then, the app creates a different appointment and saves it directly using a repository instead of a service. And once more, the notifications and the save occur in the same order. Finally, the appointment is confirmed, which triggers some UI notification, and then that change, too, is saved. The main thing to take away from this example so far is that the Appointment class has a lot of concerns. The act of creating an appointment, especially, involves a lot of code that could fail. It\u0026rsquo;s also worth noting that notifications and emails are going out before the state of the entity is saved. So if something goes wrong, users will have been told the operation was successful, and people may have been notified via email when, in fact, the update itself might never go through. ‑The reason we\u0026rsquo;re showing the behavior both from a service and with the appointment directly is because our domains should be designed to work either way. Earlier in this course when you learned about domain services, we explained that forcing all operations on your domain to go through a set of services tends to lead to an anemic domain. Ideally, your aggregates and entities should behave correctly, whether they\u0026rsquo;re being used directly or through a set of services. One way we can improve this design would be to move the responsibilities of actually sending emails or updating the UI to help our methods or other services. Then, we could call them from appointment.create instead of having all the code in here. This would make for less code inside of Appointment. ‑That would definitely be better, but it would still mean that appointment would need to be updated every time a new requirement came along. There\u0026rsquo;s a principle we can use to avoid that, though, called the Hollywood principle. ‑I love the name of this principle. Its name comes from an old saying from Hollywood agents, don\u0026rsquo;t call us, we\u0026rsquo;ll call you. ‑Exactly. Applied to software, the principle is closely related to dependency inversion from solid. Instead of forcing appointment.create to have to know about and call every possible thing that might be involved in the appointment creation workflow, instead, it can just let the app know something happened and let the app respond by calling handlers. ‑Instead of putting all the logic into this method, potentially making it huge and complicated and really hard to read, we move that logic into handlers, and the app calls the handlers. We don\u0026rsquo;t call the handlers, the app calls us. And beyond just reducing the amount of code and responsibility inside Appointment, this approach also lets us make sure that notifications to the user don\u0026rsquo;t occur until persistence is successful. And it still keeps the model\u0026rsquo;s behavior consistent without requiring a service to perform any of the work. Let\u0026rsquo;s see how it works. ‑Domain events is a pretty simple pattern, but you do need to have some plumbing code to support it. You also need to think about whether you want your events to fire before or after persistence. In many cases, what you really want is postpersistence events for the reasons we mentioned above. You want to make sure your persistance succeeds before you send any notifications outside of your app. Also, although occasionally I\u0026rsquo;ve used them for validation in the past, ideally, your domain events and handlers should never fail. That is, don\u0026rsquo;t build your behavior around exceptions that might be thrown from event handlers. Use a different pattern if you need that type of behavior. ‑In this simple demo, which mirrors how our sample app works, we just need a collection of events on each entity. We\u0026rsquo;re creating simplistic types to represent domain events and the respective handlers. You can implement the logic to find and call handlers whenever an event is dispatched in a number of ways. For this sample, we\u0026rsquo;re using the MediatR NuGet package created by Jimmy Bogard. Steve mentioned that you\u0026rsquo;ll need some plumbing to start, and that plumbing is the interfaces or base classes, if you prefer, for handler and domain event classes. In our example, we\u0026rsquo;re using interfaces. Here\u0026rsquo;s the IDomainEvent interface and the IHandle interface. ‑Once you\u0026rsquo;ve set up your event and handler interfaces or base types, it\u0026rsquo;s time to create some events and their associated handlers. ‑For this scenario, there are two things happening, an appointment is scheduled or created and an appointment is confirmed. An event is something that already happened. So we name our events in the past tense, and we have AppointmentCreated and AppointmentConfirmed. The event classes are pretty simple and just include the instance that triggered them, so handlers have access to any properties they might need from it. Once the events have been defined, you just take each individual responsibility out of the original method and create a separate handler for it. It\u0026rsquo;s fine to have multiple handlers for the same event. Ideally, your design shouldn\u0026rsquo;t depend on the order in which the handlers execute. But if it does, you can think about adding a sequence to your handler interface and ensuring they\u0026rsquo;re called in sequence order. ‑The last thing you need to do is register or record the events on the entity. In this sample, that just means adding them to the list of events that are on that entity. The actual implementation for dispatching the events is done in the repository after the save is successful. And in our veterinary sample, this work is done in the DbContext SaveChanges method. ‑Let\u0026rsquo;s step through the code again now that it\u0026rsquo;s using domain events. ‑The app starts up as before. We enter the appointment.create method. ‑And look how much smaller that method is now. ‑Definitely. It\u0026rsquo;s way easier to see what\u0026rsquo;s going on here. Now the domain event is added to the collection, but notice that when we step over this, nothing actually happens yet. ‑Right, it\u0026rsquo;s just holding it until after the entity is persisted. ‑Which is now. Notice that we\u0026rsquo;re in the repository Save method. And for every event that we have stored on this entity, we\u0026rsquo;re using MediatR to publish it at this point in time. ‑This is still in process on the same thread. There\u0026rsquo;s no out‑of‑process queue or anything involved here. ‑Right, there\u0026rsquo;s nothing to install using this pattern except for MediatR, and that just runs in‑memory. And, of course, you could wire this up with your own code that simply loops over your set of events and then dispatches out to your handlers. There\u0026rsquo;s nothing that says you have to use MediatR. Notice in the output that the DATABASE Saved occurred, and then the UI and email notifications. ‑As expected, we only triggered side effects outside our domain after persisting. Now let\u0026rsquo;s see the version that uses the repository directly and doesn\u0026rsquo;t bother going through the service. ‑We basically see the same behavior, DATABASE Saved, UI, EMAIL. ‑All that\u0026rsquo;s left now is the confirm and save, which should look similar, entity saved, and then the UI is updated. ‑That\u0026rsquo;s basically it. I created a small GitHub repo, which has just this sample in it. It\u0026rsquo;s at github.com/ardalis/DomainEventsConsole. There\u0026rsquo;s a branch there showing how things work without events. Of course, you can also download it from the course details. ‑If you want to start your solution with all of this plumbing already in place, you can use Steve\u0026rsquo;s CleanArchitecture solution template, which is also on GitHub. He is one productive guy. Everything shown here is already in place in the template, which is designed for you to use as a starting point for your app.\nExploring Domain Events in Our Application Now let\u0026rsquo;s look at how we\u0026rsquo;re leveraging domain events in the veterinary FrontDesk scheduling app that we\u0026rsquo;ve been working with. Again, we\u0026rsquo;ll start by showing you the code, and then we\u0026rsquo;ll debug through it so you can see it in action. ‑In our Appointment class, we\u0026rsquo;re going to record a domain event when certain changes are made to the appointment. So, if we scroll down and take a look at the UpdateRoom method, you\u0026rsquo;ll see that it creates and saves an appointmentUpdatedEvent. The same is true for the other update methods like UpdateDoctor, UpdateStartTime, etc. They each will create an appointmentUpdatedEvent and pass it the current instance of the appointment, and then this is saved into the entity\u0026rsquo;s Events collection. ‑In the case of the Confirm method, it\u0026rsquo;s similar, but it creates a different event, an appointmentConfirmedEvent. Essentially, the appointment entity can trigger two kinds of events directly, change and confirmed. And you\u0026rsquo;ll notice it only does so if an actual change takes place. Calling an update that doesn\u0026rsquo;t change the current value will not trigger a new event. ‑Let\u0026rsquo;s take a look at the appointmentUpdatedEvent, and this is similar to the one we saw in the simpler console app in the previous demo. It inherits from BaseDomainEvent, which is defined in our shared kernel, and it adds a UTC timestamp property called DateOccurred that is set when the event is created. This can be useful for debugging purposes. The only other property the class takes is the appointment itself. The AppointmentConfirmedEvent, shown here, is similar. ‑Notice that these domain events are all defined in the core project with our domain model. For this sample, they\u0026rsquo;re in an Events folder in the root. However, in a large application with many events, it might make more sense to put them with the aggregate that they correspond to. In this case, the ScheduleAggregate. There\u0026rsquo;s one more domain event in our sample, which is the AppointmentScheduled event. It\u0026rsquo;s similar in structure to the others, but it\u0026rsquo;s actually created elsewhere. ‑Once you start working in event‑driven applications, it can be a bit more difficult to follow the flow of execution in the app where events are concerned. It really just takes some getting used to, and then you\u0026rsquo;ll find it to be second nature. The best way to see where events are raised and where they are handled is by looking at an individual event and examining its references. Looking at AppointmentScheduled, you can see that it is handled in the API project and in the core project. It is only created inside of the ScheduleAggregate itself. Let\u0026rsquo;s have a look at where that happens. ‑In Schedule, the AddNewAppointment method creates and saves the AppointmentScheduled event after adding the appointment to its collection and marking whether or not it\u0026rsquo;s conflicting. Once the schedule is saved, any appointments that have had domain events added to their respective collections will have them dispatched after the save to persistence is complete. ‑Before we step through the code, let\u0026rsquo;s have a look at one of the AppointmentScheduledEvent handlers. The thing to notice is that these handlers don\u0026rsquo;t get created or called anywhere in our code. That\u0026rsquo;s that Hollywood agent again from the Hollywood principle saying, don\u0026rsquo;t call us, we\u0026rsquo;ll call you. The event dispatching logic, in this case, using MediatR, is what calls these handlers at runtime. But at compile time, nothing references them directly. ‑Now let\u0026rsquo;s see the flow of domain events in our application when we change an appointment. We\u0026rsquo;ll modify this appointment for my little baby, Sampson, and change the appointment from a wellness exam to a diagnostic exam. But a diagnostic exam takes more time, and this will automatically change the duration of the visit, which should trigger a conflict with one of Sampson\u0026rsquo;s other appointments. Yes, he likes to go to the vet quite a lot. ‑The change initially hits the AppointmentUpdate endpoint. It loads the schedule and the appropriate appointment and calls its Update methods. In this case, the only one that has a change is the change to the appointment type. This intern adds an appointmentUpdatedEvent. Once the change is saved, the event is dispatched. The API project also has a handler, AppointmentUpdateHandler, that responds to this event by sending a message to the Blazor client using a SignalR hub. This will trigger a real‑time notification in the app. ‑What about communication between bounded context or apps using events? Applications and microservices frequently use events to communicate, too, but these aren\u0026rsquo;t domain events since they extend beyond a single domain. They\u0026rsquo;re frequently called integration events, and they may be defined as part of your domain or in a separate project or package. For simplicity, ours are here in this IntegrationEvents folder. ‑The FrontDesk has just two integration events, the AppointmentConfirmLinkClickedIntegrationEvent is published by another app and consumed by this one, and AppointmentScheduledIntegrationEvent is an event this app publishes and another app consumes. It\u0026rsquo;s important that the structure of the published and consumed types match, which is why frequently a shared package is used to define these kinds of events. ‑We don\u0026rsquo;t have time to dive deeply into distributed application architecture, but one thing you need to remember when designing integration events is that they typically will be enriched and denormalized when compared to a similar domain event. For instance, the AppointmentScheduled domain event just has a reference to appointment, and that only has IDs for the client, patient, and doctor. However, the integration event includes many more details like client name and email, patient name, and doctor name. The reason for this is to ensure that consumers of the event have enough information from the event to perform whatever actions they need to without having to immediately call back to the publishing app to ask it for more details. You can imagine that the performance of a system would suffer if every time an appointment event was published, one or possibly many apps that were consuming that event, turned around and immediately had to make calls to this app\u0026rsquo;s API asking for client details, patient details, and doctor details. Hence, we have a handler that is responsible for taking in a domain event and enriching it with the additional details shown here on the integration event. We\u0026rsquo;ll put these integration events to use in the next module.\nIntroducing Anti-Corruption Layers The last topic we want to discuss in this module is anti‑corruption layers. An anti‑corruption layer, as the name implies, helps to prevent corruption in your domain model. ‑Right, just like superheroes help to fight corruption, these layers provide a sense of security to your model when it needs to interact with other systems or bounded contexts. ‑Returning to our mind map, you can see that the anti‑corruption layer is used to translate and insulate as part of a context map, mapping between a bounded context and foreign systems. ‑When your system needs to communicate with other systems, especially legacy applications that weren\u0026rsquo;t written or modeled as well as your current system, you need to be careful not to let assumptions and design decisions from that system bleed into your model. For instance, if the other system\u0026rsquo;s model includes a customer, even if that customer refers to the same actual business customer, it\u0026rsquo;s likely that it will be modeled differently than a customer in your system. It\u0026rsquo;s best to have a layer that can translate to and from other systems\u0026rsquo; models. In DDD, this is the job of an anti‑corruption layer. ‑Right, like we mentioned in the beginning of the course, even other bounded contexts in your own system may be different enough to merit having an anti‑corruption layer in place to protect the two distinct models from one another. And, of course, legacy applications frequently use very different models from newer systems. An anti‑corruption layer isn\u0026rsquo;t a design pattern, however, it\u0026rsquo;s usually comprised of several design patterns. The job of the layer is simply to translate between the foreign system\u0026rsquo;s model and your own. ‑In addition to translating the objects themselves, the anti‑corruption layer can also clean up the way in which you must communicate with the other system. It may provide a façade to simplify the API or an adapter to make the foreign system behave in a way that is known to your system. You can learn more about these design patterns in the Design Patterns Library on Pluralsight. ‑We\u0026rsquo;re usually most concerned with having an anti‑corruption layer in place when communicating with legacy systems. Eric Evans notes why that\u0026rsquo;s important. ‑Even when the other system is well designed, it is not based on the same model as the client, and often the other system is not well designed. ‑Since this is a fundamentals course, we\u0026rsquo;re not going to dig deeply into anti‑corruption layers, because they can be fairly complex, as well as very customized to each scenario, but here\u0026rsquo;s an example structure of one which comes from Eric Evans\u0026rsquo; book, showing how an anti‑corruption layer can connect your beautiful system on the left with a not so beautiful system on the right. ‑I really like this diagram. I think Eric had some fun putting it together. ‑Gee, what gives you that impression, Steve? ‑Of course, in the middle you can see how the anti‑corruption layer is using a façade and some adapters, but on the right it\u0026rsquo;s protecting us from a big complicated interface, some messy classes, and some things we just don\u0026rsquo;t even want to know about. ‑Right, and of course, your own system is comprised of an elegant class, a very expressive class, and of course even more good stuff, and maybe even some stuff we should be refactoring as well. ‑There\u0026rsquo;s no one way to create an anti‑corruption layer. Whatever you need in order to insulate your system from the systems it works with is what you should put inside of this layer, which should allow you to simplify how you interact with other systems, ensure that their domain decisions do not bleed into your design, and ensure any necessary translation is done along the way.\nReview and Resources We\u0026rsquo;ve covered some new topics in this module, and there\u0026rsquo;s a few new terms that we want to make sure we review. Domain events are a type of object that actually represents something that occurred within the domain that other parts of the system may find interesting and want to tie their behavior to. And this is a great way to keep your system decoupled and to keep your individual objects simpler because they don\u0026rsquo;t have to know about all of the behavior that might occur when some event takes place. We also referred to the Hollywood principle, which can be summed up as don\u0026rsquo;t call us, we\u0026rsquo;ll call you. This principle is related to the dependency inversion principle from SOLID and is frequently used to decouple systems from one another. Instead of us putting all the logic we need in our code, we architect the system so that it calls back to us at the appropriate time. And we put our code into handlers that the app calls, rather than directly coupling our model to these actions. ‑And finally, we looked at anti‑corruption layers, which can be used to ensure that our model that we worked so hard to produce doesn\u0026rsquo;t become polluted by the models of other systems we work with based on objects they wanted to return to us or the type of API that they want us to code to. So we put anti‑corruption layers in place to shield our model from those other systems or bounded contexts that we might work with from our bounded context. ‑In this module, we introduced domain events, and hopefully, you have a good idea of what they are at this point. ‑We\u0026rsquo;ve talked about how you can identify opportunities to use domain events based on the kinds of requirements your customers give you, as well as when you see code in your model that\u0026rsquo;s doing too much and could be more loosely coupled. ‑We gave you some tips for designing and naming domain events, and then we showed them in action, both in a relatively simple console app, as well as in our much larger veterinary clinic sample application. ‑Finally, we introduced the concept of anti‑corruption layers, which use a variety of design patterns to insulate our model from the design choices of other applications or bounded contexts. Here are a number of resources where you can learn more about domain events and anti‑corruption layers. Some of these, including a few Pluralsight courses, we mentioned in this module, but there are others that we find to be relevant, even if we didn\u0026rsquo;t explicitly mention them. ‑Up next, we\u0026rsquo;re going to wrap up this course by adding a new feature to the application. Because of our clean architecture and well‑designed domain model, it\u0026rsquo;s going to be pretty easy to integrate into our existing app. I\u0026rsquo;m Steve Smith, ‑and I\u0026rsquo;m Julie Lerman, and thanks for watching this module of our Domain‑Driven Design Fundamentals course.\nEvolving the Application Easily Thanks to DDD Introduction and Overview Hello, this is Julie Lerman, ‑and this is Steve Smith. In this module, we\u0026rsquo;re going to wrap up our course on Domain‑Driven Design Fundamentals by showing how we can reap the benefits of our design when it\u0026rsquo;s time to add additional functionality to the system. ‑In this module, we\u0026rsquo;ll first review our current system design and see how it incorporates DDD patterns and practices. Then, we\u0026rsquo;ll circle back to our customer, Michelle, to see how the new vet clinic appointment management system is working out. ‑During that quick conversation, we\u0026rsquo;ll learn about a new feature, and we\u0026rsquo;ll show how we can implement that feature. ‑We\u0026rsquo;ll leverage message queues to implement this feature, so we\u0026rsquo;ll definitely be sure to share with you some of the basics about message queues before we show you that code. ‑The main benefit of our design choices is the ease with which the system can be extended and maintained in the future. And we hope you\u0026rsquo;ll agree that adding to the current design is quite straightforward.\nReviewing Our Current System Design So far, our system is pretty simple, though it\u0026rsquo;s fairly complex, as most course demo apps go. ‑The system is currently two different web applications, although the user interface makes it look like a single app. Our main focus has been the application used by clinic employees to schedule appointments. There\u0026rsquo;s a lot of complexity with scheduling, so this benefited from domain‑driven design. There\u0026rsquo;s also a clinic management application that\u0026rsquo;s used to do simpler data‑in/data‑out tasks like record keeping and maintaining information about doctors, clients, patients, and more. Let\u0026rsquo;s review the scheduling app a little more closely. ‑We have a single aggregate for a schedule, which contains a number of appointments. We limit access to the schedule through the schedule repository class, which is responsible for retrieving and storing the schedule in our database. We\u0026rsquo;ve identified a couple of value objects that allow us to better model concepts in the domain, and we\u0026rsquo;re making use of domain events to allow our domain in other parts of our system to respond to changes in the state of our model. ‑It\u0026rsquo;s taken us a while to get to this point, but now that we\u0026rsquo;re here, the design of the system is very clean, and it reflects the customers domain, as well as we\u0026rsquo;ve been able to model it so far, of course, given some time constraints. ‑Yes, we do have to ship the app, I mean, this course, at some point. ‑Right, of course, as we build on this application, our model would continue to evolve. But we\u0026rsquo;ve shown you techniques you can use to ensure that you can grow the application without being overwhelmed by the complexity you\u0026rsquo;re trying to model. ‑Actually, as it turns out, the customer does have one more request for us. She said something about customers forgetting their appointments. Let\u0026rsquo;s have another quick conversation.\nAddressing a New Feature with the Domain Expert As it turns out, the customer does have one more request for us. She said something about customers forgetting their appointments. Let\u0026rsquo;s have another quick conversation. ‑Hey, Michelle, great to see you. How are things going with the new scheduling application? ‑It\u0026rsquo;s been fantastic. We\u0026rsquo;re really able to see very easily who scheduled each day, and book new appointments, and move things around is needed, and the front desk folks really appreciate that it highlights the appointments that are conflicting or unconfirmed. That makes it much easier for them. But one thing that\u0026rsquo;s still a problem is the fact that sometimes our clients forget their appointments. It probably happens at least a couple of times every day, and our staff really don\u0026rsquo;t have the time to call every client to make sure they remember ahead of time. ‑So, you\u0026rsquo;d like the system to call them then? ‑Well, we understand there\u0026rsquo;s services that\u0026rsquo;ll do that sort of thing and we might move to that eventually, but for now, if we could just send an email that would probably help remind clients to put it in their calendar. ‑Oh, okay, so, do you want an email to go out when they schedule the appointment or on the day before they\u0026rsquo;re scheduled to come in, or maybe even both? ‑Oh wow, if we could do both, that would be great, one to let them know when they\u0026rsquo;ve booked so that they know that we\u0026rsquo;ve got it in our schedule and another one to remind them that they have an appointment the next day, just in case they forgot. ‑That shouldn\u0026rsquo;t be too hard. Our model already handles certain events that occur, like when appointments are scheduled, and appointments already support being marked as confirmed too. ‑Sure, and I think all we\u0026rsquo;ll really need to build that\u0026rsquo;ll be new is some kind of service for sending the emails and some way for clients to click a link in the email so they can confirm the appointment. Since it\u0026rsquo;s email, it shouldn\u0026rsquo;t be a problem to send these out the day before, even if that day isn\u0026rsquo;t a week day or a work day, right? ‑No, I think that should be fine. It shouldn\u0026rsquo;t hurt anything to send an email on a Sunday or a holiday, and of course, we\u0026rsquo;ll ask our clients to opt into these reminders so we\u0026rsquo;re not sending anything unsolicited. ‑Sounds good. We\u0026rsquo;ll get started, and should have something for you to review real soon.\nPlanning Our Implementation Steps Before we get into the gory details of the implementation, we just want to make sure that you understand the very high level of what we\u0026rsquo;re doing here. The first thing is triggered when the appointment is scheduled. And in response to that, our system will send a confirmation email to a client. ‑Once the client gets that confirmation email, they can click a link to confirm that they\u0026rsquo;re going to make it to the appointment, and the system will then mark that appointment as confirmed so that on the schedule, the staff will see that it\u0026rsquo;s got a green box around it, and they should expect the client will actually show up. ‑What\u0026rsquo;s nice about this implementation is that it benefits so much from a lot of the infrastructure we already have in place. And thanks to our DDD‑based architecture, it\u0026rsquo;s just as easy to add in a few extra features that we need to make this work. ‑So as we go through this, you\u0026rsquo;ll see us using some existing and some new domain events, some application events, a number of event handlers and services. One new tool you\u0026rsquo;ll see is something we haven\u0026rsquo;t talked about yet, messaging queues to communicate between separate applications. The application we\u0026rsquo;ve been working with will need to communicate with a public website that the customers will interact with when they confirm their appointment.\nIntroducing Message Queues Before we go any further, we did just mention something new, which is message queues. And we just want to talk about that a little bit. It\u0026rsquo;s a pretty advanced topic for this fundamentals course, so we\u0026rsquo;re going to talk about it at pretty much a high level. ‑Message queues are nice to use between applications for a number of reasons. They can help decouple them and make it so that one of the applications can just drop off something into a message queue and continue on with its work and not have to worry about what happens to the message after that. ‑Right, or if whichever application or applications it\u0026rsquo;s trying to communicate with, it doesn\u0026rsquo;t need to worry if that application is available and listening at that very moment. The message can sit in the queue and when the other application is ready to grab it, it does. With a message queue, we\u0026rsquo;re really just dealing with a single message. One application drops it, and the other one takes it, and then the message is gone. ‑Yeah, and there\u0026rsquo;s lots of different implementations of message queues that you can find online. Some of them are free. Most of the cloud services that are out there now have these types of things built in as well. ‑And what we\u0026rsquo;re doing here is dealing with a single message at a time in something of a silo app since we control both applications that are communicating with each other. But sometimes you need to have a lot more flexibility than that, you might actually have a number of applications that are interested in that message and you may not even know in advance or control those applications. So this is when something called a service bus comes into play. ‑Right, so you\u0026rsquo;ll frequently hear about something called an enterprise service bus. And there\u0026rsquo;s, again, a number of examples of these that you can find available. It usually sits on top of message queues and other features. And one of the responsibilities it has is making sure that messages get delivered to the different applications that care about that message. ‑It might even be an application that didn\u0026rsquo;t even exist or you didn\u0026rsquo;t know about when you were first setting up the message queue. So even at that point, because service bus allows you to decouple the routing of the message, it\u0026rsquo;s possible to go ahead and hook up other applications to listen to the queue. ‑Right, so you\u0026rsquo;ll see in our scenario that we have our scheduling application raising an event that an appointment was created. And it might be that maybe in the future we would want to add some other application that wants to react to that event. ‑We could publish it to social media, hey, I\u0026rsquo;m going to go see the vet. ‑Exactly. If we had a service bus, we could simply wire up in our service bus for this new social media notifier service, pick up that event. But with just message queues, as you\u0026rsquo;ll see in our implementation, we would have to change our scheduler application to know about this new app and write to its queue because we don\u0026rsquo;t have any advanced routing, everything\u0026rsquo;s hardcoded in our simple scenario. The message queue we are using is RabbitMQ. It\u0026rsquo;s a mature, open‑source message broker that you can get set up and running with zero install by using a prebuilt Docker container. It has a lot of capabilities, but we\u0026rsquo;re keeping it simple and just using it to define a few specific queues, which are separate bounded contexts we\u0026rsquo;ll use to publish and consume events.\nSending a Message to the Queue Now let\u0026rsquo;s take a look at how we\u0026rsquo;re adding message queues into our solution. The first part of the process happens when the appointment is scheduled. And you\u0026rsquo;ve already seen our AddNewAppointment method inside the schedule aggregate root. And you saw how the domain uses domain events and domain services to notify the user interface if there\u0026rsquo;s a conflict in the schedule. In the previous module, we showed you MediatR, which we\u0026rsquo;re using to publish these domain events. And we also talked about integration events, which are structured to be shared between different applications. So what we\u0026rsquo;re going to do in our system is add RabbitMQ into the mix at the same point where MediatR is publishing the domain events. But we\u0026rsquo;ll ask RabbitMQ to publish our integration events. These events will be formatted as JSON data before they\u0026rsquo;re inserted into the queue. So let\u0026rsquo;s see what this looks like in the application. We\u0026rsquo;ll be looking at the code that makes all of this work a little further on in this module. We\u0026rsquo;ll go ahead and create a new appointment. Let\u0026rsquo;s bring Sampson in to see Dr. Jones again. So there\u0026rsquo;s the appointment. Nothing has changed from the perspective of the user. RabbitMQ includes a user interface to inspect the queues, and in the Front Desk app the menu has a link so that you can open up this admin page and see what\u0026rsquo;s going on with the queues that are associated with this application. We\u0026rsquo;ll head to the Queues page and then drill into the vetclinicpublic queue, which is a queue that we set up to handle communication between the Front Desk app and the VetClinicPublic app. And you can see that the one and only message that RabbitMQ is tracking is in that queue. So we\u0026rsquo;ll drill into that queue and then scroll down to see the details of the message itself. And the most interesting part, the payload, which is the JSON expression of the event data. You can see the GUID value of the AppointmentId, the ClientName is Julie Lerman, an email address, which is not really my email address, the PatientName is Sampson, and other relevant details that came from the integration event. So the Front Desk app knew to publish the message to this queue, and our VetClinicPublic app knows to read from this very specific queue in order to perform the task of emailing the client.\nReading From the Message Queue and Acting on the Message Now that the message is waiting in the message queue, it\u0026rsquo;s time to read the message and act on it. And acting on it is the next step in a workflow, sending an email to the client to let them know about the appointment they\u0026rsquo;ve just scheduled. We can\u0026rsquo;t do this easily from our scheduler application because we need for the user to be able to click on a link that specifies that they want to confirm their appointment, so it needs to be publicly accessible. So we\u0026rsquo;ve decided to put this on the veterinary clinic\u0026rsquo;s public website, and so that will be responsible both for sending the emails and for hosting the link that the customer will click. The public site uses a hosted service to periodically check for new things in its queue. Once it finds a message on the queue, it will retrieve the information from that message to create a confirmation email using code like what you see here. One of the most important pieces of this email is a link back to the public website, not really localhost, which includes the GUID that represents the appointment ID. The website then sends the email. That\u0026rsquo;s what the user will end up clicking on in their email and trigger a confirmation using the website. Alright, so now we\u0026rsquo;re looking at the vet clinic public website, which is a super simple demo solution that we put together. And one of the things it does when it starts is start checking for messages, which you can see here. But we don\u0026rsquo;t have it running quite yet because it would\u0026rsquo;ve already pulled the message out of the queue. First, we\u0026rsquo;ll show you the code that\u0026rsquo;s making this all work, and in a bit, we\u0026rsquo;ll step through while debugging. The public website has a hosted service called FrontDeskRabbitMqService, which periodically checks the message queue to see if anything new has arrived. As soon as it finds one of those messages off of the message queue, it\u0026rsquo;s going to send an email, and we\u0026rsquo;re going to use a tool called Papercut, which will emulate a local email server for the purpose of testing. Rather than installing this on our dev machines, we\u0026rsquo;re running a Docker container to host Papercut. You can view emails Papercut has received by clicking the Sent Emails link from the FrontDesk app\u0026rsquo;s menu. Currently, there aren\u0026rsquo;t any emails in Papercut, but as soon as we start the web application, it\u0026rsquo;s going to check our message queue and then send an email that we should see appear in Papercut. There\u0026rsquo;s a message, the same message that we sent out for Sampson\u0026rsquo;s appointment. There\u0026rsquo;s a hyperlink that leads us back to being able to confirm. Let\u0026rsquo;s see first, high level, what happens when we click on that CONFIRM button, and then we\u0026rsquo;ll come back and click it and watch it in action. So now the user has the email, and their beautiful CONFIRM link in the email. When they click that, it opens up the website, browsing directly to the GUID that was their appointment. And in response, the website calls its own method called confirm, which takes the relevant appointment ID and pushes it into another one of the queues. You\u0026rsquo;ve seen the message queue that was used for relaying the message from FrontDesk to the public website, and that was named fdvcp‑vetclinicpublic‑in. Try to say that five times fast. But you can have as many queues defined in your system as you need. And one of the other queues that we\u0026rsquo;ve defined is for relaying messages from the public website, in other words, when the client has clicked on the button to confirm their appointment back to the FrontDesk app.\nUsing Multiple Queues to Handle Various Communications Now that the email\u0026rsquo;s been sent, let\u0026rsquo;s see what happens when the client clicks on the CONFIRM link in that email. ‑When we click on that, we\u0026rsquo;ve now confirmed the appointment. Once the user clicks on the CONFIRM link, it drops the message with the confirmation back into the scheduler queue, and you can see that message right here. ‑Yeah, this middle queue shows that there\u0026rsquo;s one message. Let\u0026rsquo;s look at it. We\u0026rsquo;ll scroll down to the Get Message(s) button, and the message is retrieved and displayed. We\u0026rsquo;ve seen this before where the payload is the JSON data we\u0026rsquo;re looking for, and this one contains the appointment ID that\u0026rsquo;s just been confirmed. Now you can see that the two different applications are communicating back and forth with each other using their two separate message queues. We\u0026rsquo;ve named the queues so that it\u0026rsquo;s clear which applications are using them to communicate and in which direction. The initial acronym specifies which two applications are involved. Fdvcp means frontdesk and vet clinic public. The latter part of the queue\u0026rsquo;s name says which app is listening to it. The last step now is for this confirmation information that\u0026rsquo;s sitting in the queue to get back to the scheduling app. ‑Now in our scheduler application, we have implemented a hosted service just like you saw in the public website This one is called the VetClinicPublicRabbitMQService, and it listens to the appropriate queue to see if there are incoming messages that it needs to deal with. When it finds one, it responds to the AppointmentConfirmLinkClickedIntegrationEvent, yes, it\u0026rsquo;s a long name, with the email confirmation handler. The handler looks up the appointment from the AppointmentId that was contained inside of the message, and from there, it calls Appointment.Confirm. Appointment, as you recall, is our entity, and its confirm method also then triggers some domain events, which for instance, our user interface listens to. And when it sees that that event has been fired, it triggers a change in the UI, enhancing the appointment with a green bar across the top to show that the appointment has been confirmed. Okay, so all that\u0026rsquo;s going to happen at this point is that when the message comes through, it\u0026rsquo;s going to make the Sampson appointment right here have a green border and pop up a dialog to let us know that a change has occurred. ‑It\u0026rsquo;s very slick. This is actually really easy to implement because we already had the website listening for events. Remember how it was able to display new appointments and display conflicts? We\u0026rsquo;ve implemented another design role based on a particular property of the appointment, which is confirm. All we did was set up another event handler. ‑We wrote the original sample for the first version of this course in 2013. At the time, things like SignalR and WebSocket, as well as emails with confirmation links were relatively rare, although we certainly didn\u0026rsquo;t invent these kinds of app interactions. ‑Right, but now, every time I make an appointment for my dentist or hair and even for Sampson in real life to go to the vet, I\u0026rsquo;m getting texts or emails with exactly these kinds of confirmation links. ‑I know, I guess maybe a lot of businesses watched our course.\nDebugging to See the Detailed Implementation in Code Now we\u0026rsquo;re going to take a deep dive into the code that makes all this work, and we\u0026rsquo;ll go through it step by step so that you can see how all this is wired together. And we\u0026rsquo;ll do that by literally just debugging through the whole process, so you can see how all the code links up. Remember, all of the code for this sample is available on GitHub, and we encourage you to run it yourself to really understand how it works. The README file has instructions for running the solution using Docker, which is the recommended approach if you just want to see it running. There are also instructions for using Visual Studio or VS Code, which you will need if you want to debug the apps as we\u0026rsquo;re about to do. For instance, I need to run RabbitMQ and PaperCut using the Docker commands shown here, before I can debug the app, as we\u0026rsquo;re about to see. We\u0026rsquo;re back in the vet manager, and the user is on the phone with Steve who wants to make an appointment with Darwin. Everything works just the same way it\u0026rsquo;s worked before. We\u0026rsquo;ll go ahead and add a new appointment and save the appointment, which triggers the ScheduleAggregate root\u0026rsquo;s AddNewAppointment method. We\u0026rsquo;ll leave the Locals window open while we\u0026rsquo;re debugging so that if you want to pause the video and take a look at any of those values, you can do that. We haven\u0026rsquo;t changed anything in the method. The only thing that\u0026rsquo;s different is that now we\u0026rsquo;ve got an additional subscriber that\u0026rsquo;s listening for this domain event, this particular domain event, the AppointmentScheduled event, to be raised. So we\u0026rsquo;ll go ahead and raise the event and watch what happens. At this point, we\u0026rsquo;re looking at a new class that we created, which is this RelayAppointmentScheduled service, and what it\u0026rsquo;s responsible for is creating the event that is going to get pushed onto the message queue that the public website is listening to. This is the new piece of logic that\u0026rsquo;s listening for the event that we just raised. You can see it\u0026rsquo;s listening for AppointmentScheduledEvent, a domain event, and in the method, the first thing we do is to create the AppointmentScheduledIntegrationEvent that represents our cross‑domain message that will be sent using RabbitMQ. The functionality we need from this event right now is to be able to send an email to the client, so we make sure to include all of the data that such an email would require. Now we\u0026rsquo;re in the Publish method that lives inside of RabbitMessagePublisher, and that\u0026rsquo;s inside of an infrastructure project. We\u0026rsquo;ve moved out of the core domain, but this is still part of the main front desk scheduling application. Yes, and what it\u0026rsquo;s responsible for doing is actually getting that message into a structure, a format that RabbitMQ can use. That means putting things into JSON format in this case, and then actually sending the message. Once this fires, we should be able to inspect the message queue in RabbitMQ, and verify that our message has actually been queued up for the VetClinicPublic input queue as expected. That\u0026rsquo;s what we did before, but this time we\u0026rsquo;re actually seeing the code that\u0026rsquo;s making all of this happen. Alright, so that completes the actual thread of the UI. The response is complete for this part of the application. Now we\u0026rsquo;ll pause this and switch over to the VetClinicPublic application. We\u0026rsquo;ve just started it up again, and we\u0026rsquo;ve shown this to you before. Now we\u0026rsquo;re going to watch the flow of the code after the hosted service starts up. Jumping to the next breakpoint, you can see now we\u0026rsquo;re inside of the actual HandleMessage method, which gets the message as a string. It\u0026rsquo;s responsible for parsing the string using JSON, and deserializing it into an appropriate type. This is just demo code, so it\u0026rsquo;s not the most reusable or elegant, but it works for this app. Remember that any change to the integration event in the front desk app will require changes here as well, which is one reason why a shared package can be useful for keeping applications in sync. Once we\u0026rsquo;ve deserialized the message into a command, we use mediator to send the command, and a separate handler to actually send the email. This keeps extra code out of the hosted service, and lets the handler use dependency injection to get any services it needs. In this case, it\u0026rsquo;s an implementation of, I send confirmation emails, called ConfirmationEmailSender. It\u0026rsquo;s the service that builds the email with its details, including the URL behind the CONFIRM link in the email that the client receives. Remember, the whole reason why we need a separate app to implement this feature is that the end user needs to be able to click a link that goes to a public location on the internet. The front desk app is an internal app that runs inside the vet clinic\u0026rsquo;s network so it\u0026rsquo;s not accessible. The public website is a good place to send users, and while they\u0026rsquo;re there, they can get more details about the clinic, or buy something from its theoretical online store, etc. After the email has been sent, we can see it in PaperCut, and opening it, we can see the CONFIRM hyperlink. Clicking the link brings us back into the VetClinicPublic application\u0026rsquo;s, AppointmentController class. This endpoint simply creates a new event. This is the one with a really long name, AppointmentConfirmLinkClickedIntegrationEvent. Unlike the name of the event, the message itself is really simple, and just includes the appointment ID that was confirmed, and when it happened. The controller action then sends the event using a RabbitMQ messagePublisher that\u0026rsquo;s identical to the one we just saw the front desk app use. However, this publisher\u0026rsquo;s destination is actually a different queue, the front desk input queue. Technically, the front desk has two input queues, one for messages from the ClinicManagement app, and another for messages from the VetClinicPublic app. In this case, we\u0026rsquo;re talking about the VetClinicPublic one. Back in the front desk scheduling app\u0026rsquo;s hosted service, it discovers the message on the queue, and calls into the HandleMessage method in the service we\u0026rsquo;ve seen a number of times, the VetClinicPublicRabbitMqService. Here, it parses the message and extracts the appointment ID, which it then uses to create and publish that really long‑named event again, AppointmentConfirmLinkClickedIntegrationEvent internally. This integration event triggers a call to the EmailConfirmationHandler, which loads the schedule aggregate, then locates the appropriate appointment, and calls its Confirm method. Finally, it saves the schedule. The appointment.confirm method makes an appointmentConfirmed domain event, which is fired once the aggregate is saved, and this event in turn triggers a handler in the UI. The appointmentConfirmed handler in the FrontDesk UI sends a message via SignalR, indicating the message was confirmed. This results in the browser showing a notification, and changing the format of the appointment to have a green border. You already saw similar logic used for the AppointmentUpdate and AppointmentScheduled handlers. That\u0026rsquo;s the full round trip for how creating an appointment, getting an email, clicking a link, and confirming that appointment works for this application.\nConsidering Microservices Since we published our original version of this course, which if you haven\u0026rsquo;t watched, you\u0026rsquo;ll find a link from either of our author pages, microservices have become incredibly popular. There are some benefits to microservices, even if they\u0026rsquo;re probably a bit overhyped at the moment, and there are some obvious parallels between microservice design and DDD. ‑Microservices should be self‑contained and should not depend on other microservices. They should be independently deployable. Changing the internal behavior of a microservice should not break services that work with it, as long as it maintains compatibility with its external APIs and message interfaces. ‑So, basically what you\u0026rsquo;re saying is each microservice should have a boundary around it, and within that boundary it should focus on a specific set of behaviors that its free to model however it sees fit. ‑That\u0026rsquo;s right. ‑It\u0026rsquo;s almost like each microservice can be considered its own context, and it has its own terminology and even language for how it\u0026rsquo;s designed. ‑It is a lot like that, it\u0026rsquo;s true, and it\u0026rsquo;s not unusual for teams to treat individual microservices like bounded context with their own ubiquitous language and everything else that goes along with being a bounded context. But, beware of assuming that microservices and bounded context always have a perfect alignment. There can be plenty of scenarios where this could be a problem. My brilliant friend, Vladik Khononov, not to be confused with the also brilliant Pluralsight author, Vladimir Khorikov, has shared his experiences along these lines in his blog and also in recorded conference presentations. We\u0026rsquo;ll include links to his content in the resources at the end of this module. ‑Now, this isn\u0026rsquo;t a microservices course, but obviously if you\u0026rsquo;re working on microservices, it would be helpful for you to have a good understanding of DDD concepts, because many of the problems that microservices solve are also solved by domain‑driven design. ‑In our sample application, there is an obvious candidate for a microservice. In fact, it\u0026rsquo;s almost there already, the confirmation email sending logic that currently runs inside the public website. ‑We put the hosted service in that existing web application because it was convenient and because the two are loosely related since the emails include a clickable link that goes to a page on that public website. ‑But we could easily move that hosted service into its own process and treat it like a separate microservice, and that would simplify the public web app, so it would no longer need to have a two‑way relationship with a front desk app by way of message queues. Also, the front desk app is likely to be updated more frequently than the confirmation email logic, so it\u0026rsquo;s possible that changes to the front desk application could break the email logic. ‑Yes, one of my favorite benefits of carving out a microservice is that if it\u0026rsquo;s something stable and working, you get the benefit of just leaving it the heck alone. Updates to other parts of the app or system are much less likely to break a microservice that is in production and working, and not being deployed frequently. ‑Right, and the email sending logic is about as micro as a microservice can get, but in the future we might want to add other kinds of customer emails to send, and it would be a logical place to hold that logic. ‑Exactly, and since it has no user‑facing logic, it\u0026rsquo;s a pretty simple change to make. Maybe some of our students could do that as another exercise.\nSharing Some Tips for Extending and Running the Sample Application As we wrap up the course, we want to remind you, once more, that there are a number of to‑do items in the sample that you can use as ideas for ways to extend this demo app. Doing so would help you gain real experience working with the architecture and patterns you\u0026rsquo;ve learned in this course. You\u0026rsquo;re sure to learn and retain more from actually working with the code than from just listening to us or watching us show you the code. ‑We do have detailed instructions in the README for how to run the app. You can run the individual solutions in Visual Studio, but if you do so, keep in mind, you\u0026rsquo;ll also need to make sure you have a local SQL Server running, and you\u0026rsquo;ll need to update the connection strings and app settings for the applications to access it. You\u0026rsquo;ll also need your own RabbitMQ and Papercut or similar test email server running, either as Docker containers or locally‑installed services. There\u0026rsquo;s definitely a bit of effort involved in getting all of this set up and running the first time. ‑Alternatively, if you just want to run the app and see everything working, you should be able to do so with just two commands, assuming you have Docker installed. Just run docker‑compose build ‑‑parallel and then docker‑compose up. Each of these commands might take a few minutes. It usually takes about 2 minutes for the build step on my machine, and it\u0026rsquo;s normal to see some errors when the docker‑compose up command runs until all of the services are up and running. Once the process stops outputting messages to the log window, you should be able to hit the application. To do that, take a look at the ports that are shown in the README file. And in the Docker column, you\u0026rsquo;ll see the ports for all of the different applications and utilities that are used.\nConsidering the UI in the Domain Design The control we used solved a number of the problems we thought we were going to have when embarking on this application. But the fact that the UI kind of impacted how we designed our domain begs the question about, well, if you\u0026rsquo;re totally focused on the domain, why would you even be thinking about the UI? But thinking about the UI while we\u0026rsquo;re working on the domain is not the anti‑pattern you may think it is. ‑Yes, we\u0026rsquo;ve been focusing on the domain, but frequently the user interface needs to be considered, especially in the early stages of planning. You don\u0026rsquo;t want to try to flesh out the whole domain design before you start thinking about the UI. ‑In a TechEd session I attended in 2013, Jimmy Nilsson, who\u0026rsquo;s the author of the book Applying Domain‑Driven Design and Patterns, talked about the importance of thinking about the UI in the early stages of planning and revisiting it while modeling the domain, rather than ignoring it until the end. In his session, he describes how even the UI sketching he does in the early stages of his application planning can affect the whole design of the system. As we were building this scheduler sample for this course, we actually discovered a huge benefit to considering the UI early in the process. We initially had expected to encounter a lot of complexity in the appointment scheduling problem, but we found a UI control that helped visualize the schedule for the user, such that the system no longer needed to be as complex. In our scenario, scheduling is a big part of the application, but it isn\u0026rsquo;t our domain, our domain is the veterinary clinic. We consider scheduling to be more of a cross‑cutting concern, and one that could be partially solved through a rich user interface. ‑By considering and using a rich user interface, we were able to do things like allowing conflicting appointments while making it obvious to the user that this had occurred. This gives the user more information, and they can make decisions about whether or not they need to correct the problem. When we initially considered the problem of appointment conflicts, we had thought the domain model would throw exceptions anytime something like that occurred. But this would have resulted in a much worse user experience. Frequently, in domain‑driven design, you need to consider the user experience, which at times may need to allow for models that are, at least temporarily, in an invalid or incomplete state. Keep this in mind as you design your domain model, and be careful not to make it too rigid to support scenarios your users may benefit from. ‑Thinking about the UI up front and discovering this kind of solution kept us from wasting a lot of time trying to solve certain scheduling problems in our domain. Of course, you don\u0026rsquo;t want your UI to totally drive how you model your domain, but as Jimmy Nilsson notes, you shouldn\u0026rsquo;t ignore it, either.\nModeling with Event Storming and Other Techniques When you\u0026rsquo;re developing apps using DDD, it can be helpful to visualize how processes communicate both within a bounded context and between context as part of a business process. As we mentioned earlier in this course, Alberto Brandolini has done a lot of work on a related practice called event storming. Event storming can be used by all parts of a business, not just developers, to describe how a part of the business works and to make the whole thing visible. Once this is done, later iterations of the diagrams and artifacts produced can be useful for modeling the software that will be used by the business. ‑You might recall the image we showed earlier of Julie facilitating an event storming workshop with a client. The result of that first iteration, called chaotic discovery, is not so easily captured, but it provides guidance for the later modeling you might do. ‑There are many ways to model your system. Another method, Event Modeling, championed by Adam Dymitruk, is another process, and this focuses on the inputs and outputs of events and how each of those events changes the system and changes state. And you can describe an entire system with this flow. ‑We\u0026rsquo;ve used the wonderful online tool called a Miro board at miro.com to show one perspective of the scheduling system as information flows through the front desk application and into the VetClinicPublic website bounded context. The colors used here correspond to different things in our model, like aggregates, events, and other processes. ‑And there are other modeling processes that have been invented, adopted, and adapted within the DDD community. And many of us rely on a combination of processes and tools to help us and help our clients better understand their systems before embarking on design. But as always, balance is important. You\u0026rsquo;ll want to beware of analysis paralysis. ‑Definitely. That reminds me of something Eric Evans talked to us about.\nEric Evans on the Fallacy of Perfectionism Steve and I believe that it would be fitting to leave you with one last thought from the father of domain‑driven design, Eric Evans. Eric was kind enough to talk to us about DDD when we originally created this course so that we could share with you some of his wisdom. Eric talked about the fallacy of perfectionism, which aligns with our own sentiments about considering what you\u0026rsquo;ve learned here to be guidance to help you solve complex software problems, not a roadblock to productivity. ‑Eric shared with us that what he\u0026rsquo;s noticed is that there seems to be something about DDD that brings out the perfectionist in people, and they say, this model is not really good enough and churn and churn, trying to improve it. He says, no model is ever going to be perfect. ‑Eric goes on to say that we need to know what we\u0026rsquo;re doing with this thing, the scenarios we\u0026rsquo;re trying to address. We want a model that helps us do that, that makes it easier to make software that solves those problems. That\u0026rsquo;s it. ‑This reminds me of the saying, all models are wrong, but some are useful. Our domain models don\u0026rsquo;t need to be perfect. They just need to help us build the software that helps people solve problems and get work done. Don\u0026rsquo;t strive for a perfect model, but rather just aim to develop a useful one.\nLessons Learned Since Our 2014 Course Julie and I wanted to finish this course by spending a couple of minutes talking about some of the things we\u0026rsquo;ve learned since we published the first edition of the course in 2014. ‑We\u0026rsquo;ve received a ton of positive feedback from so many of you over the last few years, and we really appreciate it. So we did our best not to change the overall flow of this course too much since we know the last one was so well‑received. ‑Definitely. If you watched the original version, hopefully you found this one to be fresh, but familiar, and I suspect a lot of students will end up watching both as a way to cement some of these concepts or just to spend more time with us, right, Julie? ‑Maybe. Now let\u0026rsquo;s highlight some of the things that have changed in the last few years. From a strict DDD perspective, there are a lot of new resources and techniques that have emerged as more and more companies are adopting DDD. Things like event storming an event modeling, which we\u0026rsquo;ve touched on in this course, are starting to become mainstream parts of DDD for many organizations. ‑Yes, and the industry\u0026rsquo;s use of some patterns have shifted too. There\u0026rsquo;s a lot of pushback against the repository pattern these days. I think, in part, because it became very popular, but was often used without the context of DDD or other complementary patterns like the specification, and these can really help it shine. Our first course didn\u0026rsquo;t really talk much about specification as a core DDD pattern, but it\u0026rsquo;s something I use on most of my projects now. ‑From a technology perspective, our previous course was built for .NET developers, and at the same time, that meant .NET 4. The original veterinary application used ASP .NET, MVC, and Web API, and an early version of SignalR. And for data access, we used Entity Framework 6. ‑Since then, .NET Core, which is now .NET 5, has shipped and become the new standard for .NET developers, and the latest versions of EF Core have added a number of features that we\u0026rsquo;re leveraging to help improve the design of our model like owned objects and filtered includes. We also shifted our use of domain events from being prepersistence to postpersistence. There are valid use cases for both kinds of domain events, but the latter is safer for any events that communicate outside of the domain, so we\u0026rsquo;re defaulting to that this time around. ‑Right, especially since one of our key demos involve sending emails to the client. The original sample also used SQL Server for its message broker, which we chose because we didn\u0026rsquo;t want to force our students to have to install a custom tool. But Docker is another technology that wasn\u0026rsquo;t mainstream in 2014, but it is today, and it makes it a breeze to use custom bits of infrastructure. In this update to the course, we\u0026rsquo;re definitely leveraging Docker to provide RabbitMQ messaging with 0 install, as well as to capture emails during development using Papercut in another Docker container. ‑Yeah, Docker should really make it trivial for students to run the application locally, even though it has a bunch of moving parts. If you don\u0026rsquo;t have Docker, you can still run it in your IDE or from the command line, but with Docker, it\u0026rsquo;s just a lot simpler to get going. ‑And along with Docker and containers, microservices have become a huge buzzword in the industry. Of course, Docker makes it much easier to deploy microservices, and DDD principles really shine when designing them. So all of these things, I think, are really complimentary. ‑Definitely, although I do think some companies are too quick to jump to microservices without fully understanding their domain and where to separate out different contexts. And on the topic of separation, our previous sample put everything in one giant solution, too, mostly to make it easier to find things. ‑This time, we went with something that should resemble a real‑world application even more with separate solutions for each bounded context. We even published the shared kernel as a NuGet package, in our case, hosted on nuget.org, although typically, your organization would probably have a private NuGet feed. ‑If you\u0026rsquo;re still working with .NET Framework apps and you haven\u0026rsquo;t watched the previous course, we encourage you to give it a look. Its samples are geared more toward that framework, and you should find a link to it on Julie or my author page here, on Pluralsight, or at this bit.ly link here. ‑And don\u0026rsquo;t feel bad if it feels like there\u0026rsquo;s still a lot you have to learn about DDD. It\u0026rsquo;s a big topic. And as we\u0026rsquo;ve just shared, Steve and I are constantly learning new ways to apply it, too. Be sure to check out other DDD courses here, on Pluralsight, and if you need direct help for you or your team, you can reach out to Steve or me, directly.\nReview and Resources If you remember nothing else from this particular module, the one thing to keep in mind is how simple it was for us to add in what was potentially a really complicated feature. Because of our DDD implementation and some of the infrastructure we had already built, it wasn\u0026rsquo;t really very challenging to plug these new puzzle pieces into the application. ‑Right, we introduced a couple of new concepts. We talked about message queues, and those fit really nicely into our existing architecture because we were already using events to correspond to interesting things happening within our application. ‑And the message queue allowed us to stick a message in an external place by one application, and another application can come along and retrieve that message. So the message queue allows our applications to communicate with each other, but they can do it in a disconnected way. ‑And then we mentioned, but we didn\u0026rsquo;t show, this concept of a service bus, often called an enterprise service bus, which you may want to introduce if you start having more than just a couple applications needing to talk to one another. ‑At the risk of being redundant, let\u0026rsquo;s just pay homage one more time to how the decisions we made earlier on, when implementing the vet clinic solution, allowed us to add in a potentially complicated new feature, email notifications and responses into the application. ‑While we had used mediator to transfer domain events within the FrontDesk application, this time we took advantage of message queues to help us move events back and forth between applications. ‑Using RabbitMQ\u0026rsquo;s API, we created three different queues that were specific to the cross‑application communications we needed. For example, a queue that the vet clinic public app could publish messages into for the FrontDesk application to retrieve so it could update the UI. ‑It\u0026rsquo;s also important to note that we leveraged existing tools like RabbitMQ and Papercut to perform certain tasks. In DDD, we would refer to these as generic domains. You\u0026rsquo;ve got to look under the covers to see how the code was making all the communication between the apps and the message keys possible, but without our domain model having to know about any of the details. ‑And then we shared some additional knowledge as we wrapped up the course. We talked about modeling practices like event storming and tools like MURAL. We talked about all of the new ideas that have evolved since we first published this course in 2014 and how they impacted this new version of the course and the sample application. ‑And we ended with some more wisdom from Eric Evans, to whom we are eternally grateful not only for bringing DDD to the software community, but also for spending time with us when we created the original course so that we could share his perspective and insights with you. ‑Like the end of a fireworks display when they shoot up many, many fireworks at once, we\u0026rsquo;re sharing here a lot of resources and links because of the great many topics we brought into this last module. There are two pages of links here to articles and videos and other Pluralsight courses, so you might want to pause the video to be sure that you see them all. ‑So, from me, Steve Smith, ‑and from me, Julie Lerman, thanks so much for taking this journey with us through Domain‑Driven Design Fundamentals.Course Overview Welcome to Pluralsight. My name is Julie Lerman, and this is Steve Smith. Together, we\u0026rsquo;d like to welcome you to our course, Domain‑Driven Design Fundamentals. Steve is a trainer and architect with NimblePros and spends a lot of time helping teams write better code, faster. And Julie is well known in the DDD community for helping reluctant teams embrace domain‑driven design. In this course, we give you a strong foundation for learning how to build applications and microservices using domain‑driven design. DDD has proven to be a very effective approach for managing complex requirements. The original version of this course has helped many thousands of learners leverage domain‑driven design, and they have shared amazing feedback. Now, we\u0026rsquo;ve updated the course and its sample application to reflect ideas and tools that have emerged since that first version. Some of the major topics that we\u0026rsquo;ll cover include what are the essential ideas of domain‑driven design? What are the main patterns used in domain models? We\u0026rsquo;ll also talk about how to break up concepts into smaller parts and how these smaller aggregates and contexts communicate with one another. By the end of this course, you\u0026rsquo;ll know how to break down customer requirements into a maintainable domain model and structure a solution using domain‑driven design. Before beginning the course, you should at least be familiar with software development, ideally using C#. From here, you should feel comfortable diving into DDD and design patterns with courses on the DDD learning path and the design patterns learning path. We hope you\u0026rsquo;ll join us on this journey to learn domain‑driven design with the Domain‑Driven Design Fundamentals course, at Pluralsight.\nIntroducing Domain-Driven Design Introduction and Overview Hi, this is Steve Smith ‑and this is Julie Lerman. Welcome to our course, Domain‑Driven Design Fundamentals. ‑We\u0026rsquo;re looking forward to sharing our experience with DDD and how it\u0026rsquo;s helped us and our clients. You\u0026rsquo;re welcome to reach out to us online. ‑You can find me online at thedatafarm.com or on Twitter @julielerman. ‑And I\u0026rsquo;m online at ardalis.com or on Twitter as @ardalis. ‑Eric Evans coined the term Domain‑Driven Design in his groundbreaking book with the same title published in 2004. Since then, other titles have followed, including great books expanding on the subject by Jimmy Nilsson and Vaughn Vernon and so many who are now also great experts at DDD. And there are also now a number of fantastic DDD conferences and even a well‑established virtual meetup. ‑There\u0026rsquo;s definitely continued and renewed interest in Domain‑Driven Design as both the demand for and complexity of software continues to grow. Domain‑Driven Design is commonly referred to as DDD and even has its own Twitter hashtag, dddesign. Although DDD has been around for so long, it continues to be a great approach to building software that we both enjoy employing and sharing with others. And as more minds have gotten involved in DDD, it continues to evolve.\nWhat to Expect from This Course and This Module Domain‑Driven Design is a huge topic. Our focus will be on the developer perspective and the technical and coding aspects of DDD more so than architectural concerns. We\u0026rsquo;ll start by talking about why we think you should even be watching this course. Next, we\u0026rsquo;ll jump right into an existing solution so you can get a concept of what the code and the architecture of an application written using DDD practices looks like. Then we\u0026rsquo;ll start digging into the big DDD concepts like modeling problems of the domain, what the various technical components of DDD are, and how you can use DDD to manage complex projects. Throughout the course, we\u0026rsquo;ll use the existing solution so you can see how some of this process works. ‑With this in hand, we\u0026rsquo;ll walk through extending the sample based on a new request from the client. Since this is a fundamentals course, we certainly don\u0026rsquo;t expect to turn you into an expert by the end of it; however, you should be well on your way to understanding the value behind Domain‑Driven Design and how some of the practices can be employed to improve your success with complex software projects. Right now, if you\u0026rsquo;re new to DDD, you don\u0026rsquo;t even know what you don\u0026rsquo;t know yet. However, once you\u0026rsquo;re done with this course, you\u0026rsquo;ll know more about DDD, but of course, you\u0026rsquo;ll also realize how much more there is to learn. That\u0026rsquo;s one of the great things about our industry. The more you know, the more you realize how much more there is you don\u0026rsquo;t know. ‑In this module, we\u0026rsquo;ll focus on the value of Domain‑Driven Design. You\u0026rsquo;ll learn what the term represents and what problems DDD can help you with in your software building process. ‑Not only will we share the benefits of DDD, but we will be sure to highlight some of the potential drawbacks. Finally, you\u0026rsquo;ll get a look at a small application that we\u0026rsquo;ll be using throughout the course as you learn DDD.\nUnderstanding the Value of Domain-Driven Design Domain‑Driven Design focuses on the problems of the business domain that you\u0026rsquo;re attempting to solve. Its a critical shift from decades of focusing on how to store your data and then letting that drive how the software is designed. But that workflow added a lot of unnecessary complexity to the task of building software. So why should you watch this course? Why should you care about learning Domain‑Driven Design. Steve and I have both been designing and developing software for a very long time. Without giving away our ages, we\u0026rsquo;ve got over 40 years of experience between the two of us, and we\u0026rsquo;ve both been very inspired by Domain‑Driven Design. In many ways, it aligns very naturally with ideas that we\u0026rsquo;ve each come to from our own experience. It also takes these ideas and lays them out in a way that\u0026rsquo;s not only illuminating, but it\u0026rsquo;s repeatable. When Eric Evans wrote his book, his goal was to understand what was behind the successes he had achieved with large‑scale, complex software projects and what were the patterns. That\u0026rsquo;s what he laid out in the book. ‑This is why we care about DDD, and we hope that you can gain from our experience, which is why we put together this course. DDD provides principles and patterns to help us tackle difficult software problems and even business problems. These are patterns that are being used successfully to solve very complex problems. The more we\u0026rsquo;ve learned about DDD, the more we found these ideas aligned with the approaches we\u0026rsquo;ve learned from our many combined years of experience. DDD provides us with a clean representation of the problem in code that we can readily understand and verify through tests. We developers live to code. When starting on a new project, we\u0026rsquo;re eager to jump in and start coding so that we can build some software. But you can\u0026rsquo;t build software unless you truly understand the client\u0026rsquo;s needs. DDD places as much emphasis on not only comprehending what your client wants, but working with them as full partners through a project. The ultimate goal isn\u0026rsquo;t to write code, not even to build software, but to solve problems. ‑You need to realize that nobody really wants your program. They want what it can give them. There\u0026rsquo;s a famous saying in sales. Buy a quarter‑inch drill, they want to buy quarter‑inch holes. Your client\u0026rsquo;s not interested in building software, but in being successful at their mission. Software provides a more efficient means to this end.\nGaining a High-Level Understanding of DDD Domain‑driven design is for solving complex problems. Evans put a lot of thought into the subtitle of his DDD book and came up with Tackling Complexity in the Heart of Software. But DDD itself is a complex topic. To start with, we think it\u0026rsquo;s helpful to look at it from a very high level. We call it the 10,000 foot view here in the US, but that\u0026rsquo;s probably 3,048 meters to the rest of you. ‑One of the critical pieces of DDD is to encourage better interaction with domain experts. These are the people who live and breed the business or process or whatever you are targeting with the software you\u0026rsquo;re planning to write. You may be thinking, but we already talked to them. Perhaps, but probably you\u0026rsquo;re using your terms, not theirs, and maybe talking in the language of tables in a database rather than domain concepts. Or you may presume that after some standard requirements gathering, you can infer enough about the problem at hand to design the solution on your own. After our own history in the business of developing software, we know that that rarely ends well. DDD guides us to engage with the domain experts at much greater length and through much more of the process than many software teams are used to doing. ‑When talking with Eric Evans about this, he told us that you really need to cultivate your ability to communicate with business people in order to free up their creative modeling. Another core theme in DDD is to focus on a single subdomain at a time. Say you\u0026rsquo;re asked to build software for a spaceship manufacturer. They describe their business tasks such as purchasing materials, engineering, managing employees, advertising their spaceships and share with you their dreams about mass producing spaceships when the market\u0026rsquo;s ready. Each one of these tasks are in themselves a complex subdomain filled with their own specific tasks, terminology, and challenges, and those subdomains may have only minimal interaction between them. Many applications just try to do too many things at once, then adding additional behavior gets more and more difficult and expensive. With DDD, you\u0026rsquo;ll divide and conquer. By separating the problem into separate subdomains, each problem can be tackled independently, making the problem much easier to solve. This lets us focus on the problem of employee management separately from the problem of sourcing materials for producing the spaceships. The term modeling is important in DDD and refers to how you decipher and design each subdomain. You\u0026rsquo;ll learn much more about this as you progress through the course. ‑The final theme in our high‑level perspective of DDD is writing the code to implement each subdomain. The principle of separation of concerns not only plays a critical role in identifying the subdomains, but within each subdomain, we use it as well. Many applications spread the domain logic between the persistence layer and the user interface, making it much more difficult to test and to keep all of the business logic consistent. DDD applies separation of concerns to help steer you clear of this problem by focusing on the domain and not on details like how to persist data into a database or how to connect to a service in the cloud. Those become implementation details that you can worry about separately. While implementing these subdomains, the focus is on the subdomain, the problems of the subdomain you are trying to solve with your software. You don\u0026rsquo;t get bogged down worrying about infrastructure concerns.\nExploring the Benefits and Potential Drawbacks of DDD Domain‑Driven Design is a big commitment. While Steve and I have both chosen to leverage pieces of DDD as we learn more about the wider scope, one thing we\u0026rsquo;re both confident about is that it\u0026rsquo;s providing a lot of benefits to our work. Because DDD guides us to focus on small, individual, nearly autonomous pieces of our domain, our process and the resulting software is more flexible. We can easily move or modify the small parts with little or no side effects. It even lets us be more flexible with our project resources as we\u0026rsquo;re building the software. ‑The resulting software also tends to be more closely mapped to the customer\u0026rsquo;s understanding of the problem. DDD gives you a clear and manageable path through a very complex problem. When you look at the code, you can see that it\u0026rsquo;s generally well organized and easily tested, and the business logic all lives in one place. Even if you don\u0026rsquo;t use full DDD for a project, there are many patterns and practices that you can use by themselves to benefit your application. So keep watching, even if you don\u0026rsquo;t think you\u0026rsquo;ll need all of it. ‑We often describe DDD as a way to take big, messy problems and transform them into small, contained, solvable problems. But DDD is not a path for every project. It\u0026rsquo;s real benefit is for complex domains. Even Eric Evans explicitly states that DDD isn\u0026rsquo;t suitable for problems when there\u0026rsquo;s substantial technical complexity, but little business domain complexity. Using DDD is most beneficial when the complexity of the domain makes it challenging for the domain experts to communicate their needs to the software developers. By investing your time and effort into modeling the domain and coming up with a set of terminology that\u0026rsquo;s understood for each subdomain, the process of understanding and solving the problem becomes much simpler and smoother. ‑But all this comes at a cost. You\u0026rsquo;ll spend a lot of time talking about the domain and the problems that need to be solved, and you\u0026rsquo;ll spend plenty of time sorting out what is truly domain logic and what is just infrastructure. The easy example there is data persistence, or for the sake of our spaceship manufacturer, maybe it\u0026rsquo;s how to communicate with an external service that helps to verify that potential buyers are properly vetted for space travel. ‑You\u0026rsquo;ll have a big learning curve as you learn new principles, patterns, and processes. There\u0026rsquo;s no question about that. DDD is a big topic and gaining expertise from end to end is a big commitment. This course doesn\u0026rsquo;t aim to make you an end‑to‑end expert in DDD, but to give you a big step forward that will allow you to not only comprehend the concepts, but you\u0026rsquo;ll gain a lot of new tools that you can use right away, whether or not you choose to dig further. And it\u0026rsquo;s worth restating that DDD is not always the correct path for your applications. And it\u0026rsquo;s helpful to keep in mind some of the scenarios where DDD is just going to be overkill. For example, if you have an application or a subdomain that\u0026rsquo;s just a data‑driven app and doesn\u0026rsquo;t need much more than a lot of CRUD logic, there\u0026rsquo;s really no need to use DDD. It would be a waste of time and effort. ‑And be clear about the difference between complexity in your business domain and technical complexity. DDD is designed to help with complex domains. If your domain is simple, even if you have a lot of technical challenges to overcome, DDD still may not be the right path. For example, if you are writing a tic‑tac‑toe game for a touch screen with a new complex API, the complexity lies in the touch interactions of the two players on the screen. The domain itself is well known and just comes down to Xs and Os. Getting others to follow the DDD approach can also be a drawback. There may be some politics involved in this decision. It really depends on your team and your organization. We hope that another takeaway from this course will be to help you understand the concrete benefits of DDD, which you can show to your coworkers to help convince them.\nInspecting a Mind Map of Domain-Driven Design In his DDD book, Evans included a really useful diagram of how many of the concepts and patterns of DDD are interrelated. Let\u0026rsquo;s take a look at that mind map. ‑Evans refers to this as a navigation map, and it lays out all of the pieces of Domain‑Driven Design and how they relate to one another. We want you to see it so that you have a concept of the big picture, even though in this course we\u0026rsquo;ll spend most of our time on a subset. We will be defining many of these terms later on in the course, so don\u0026rsquo;t panic. We\u0026rsquo;ve mentioned modeling the domain and subdomains a few times. Modeling is an intense examination of the problem space. Key to this is working together with the subject matter experts to identify the core domain and other subdomains that you\u0026rsquo;ll be tackling. Another important aspect of modeling is identifying what\u0026rsquo;s called bounded contexts. And within each of these bounded contexts, you focus on modeling a particular subdomain. As a result of modeling a bounded context, you\u0026rsquo;ll identify entities, value objects, aggregates, domain events, repositories, and more and how they interact with each other. ‑In the image, there\u0026rsquo;s more than just these subdomains, however. For example, there is a concept of an anti‑corruption layer, which allows subdomains to communicate with one another from behind their boundaries. The model also has notes for each element, such as free teams to go separate ways. This is something that can be accomplished once you\u0026rsquo;ve identified the boundaries of each subdomain. Or avoid overinvesting in generic subdomains. That could be something like a credit card verification service that you could choose to use rather than building yourself. As you begin focusing on specific subdomains, another very important DDD concept surfaces, driven by the need for clear, concise communication. It\u0026rsquo;s called the ubiquitous language. A simple definition of a ubiquitous language is to come up with terms that\u0026rsquo;ll be commonly used when discussing a particular subdomain. And they will most likely be terms that come from the problem space, not the software world, but they have to be agreed upon so that as discussions move forward, there is no confusion or misunderstanding created by the terminology used by various members of the team. ‑We invite you to pause this video to look over this map and read the notes associated with the various elements and contemplate what they might mean. We\u0026rsquo;ll revisit this throughout the course, and we hope that the map will make more and more sense as you work through the course.\nIntroducing Our Sample Application Now we want to switch over and show you a relatively small DDD‑based solution that we\u0026rsquo;ll be working on for the rest of the course. This app represents an appointment scheduling system for a veterinary clinic. It\u0026rsquo;s \u0026ldquo;small\u0026rdquo;, but since DDD requires a certain amount of complexity to warrant its use, it\u0026rsquo;s bigger than most demos you\u0026rsquo;ll see in other courses or presentations. For this course, we decided that we would use a veterinary clinic management system because it has a decent amount of complexity, and that means that we can apply some of the DDD principles, but it also gives us an excuse to show off pictures of our pets. ‑And our friends pets too. We\u0026rsquo;ve got a whole bunch of pet pictures from other Pluralsight authors in here, and they\u0026rsquo;re all so cute. ‑We\u0026rsquo;ve got Ben Franklin here from Michael Jenkins. We\u0026rsquo;ve got Patrick Neborg\u0026rsquo;s dog here, Sugar. Aren\u0026rsquo;t these guys cute? And, of course, Julie\u0026rsquo;s got Sampson. ‑Oh, my handsome boy. ‑And I\u0026rsquo;ve got Darwin, the silly poodle. He was just a puppy when we recorded the first version of this course, and he\u0026rsquo;s got a new friend, Rosie. Rosie is just a puppy. I guess every time I get a puppy we have to update this course. ‑So the idea behind this application is that if you\u0026rsquo;re working at the front desk of a vet clinic and someone walks in, maybe they want to schedule an appointment, or the phone rings with someone who wants to schedule an appointment for their pet, the first thing you\u0026rsquo;re going to do is look that client up, the person, in the system. ‑So the user starts by looking up the client, and from there, they can choose which of the clients, animals or patients, they\u0026rsquo;re going to schedule. So here\u0026rsquo;s Julie with Sampson. Here\u0026rsquo;s Kim with Roxy. Next, the user is just going to click on an open slot in the schedule, which opens up the create appointment window. ‑Oh, Roxy, you\u0026rsquo;re such a cutie. We can set up Roxy for a wellness exam with Dr. Smith. ‑Now notice before we save this appointment, it isn\u0026rsquo;t yet confirmed. We\u0026rsquo;ll get to that in a minute. So we save, and the appointment shows up. Now the complexity in this system comes into play when we have to do some checks for certain things. We want to make sure, for instance, that Roxy isn\u0026rsquo;t already scheduled in one of the other rooms at this exact time. We also want to send an email notification to Kim to let her know that Roxy has this appointment scheduled. We\u0026rsquo;ll add a link in the email the client can click to confirm. And in a real system, perhaps it would add it to their calendar of choice. The idea is to cut down on no‑show appointments for the clinic. ‑Of course, there are other features of this application. We\u0026rsquo;re focused on the schedule right now, but we do need to be able to manage client data and manage their pet data, the clinic\u0026rsquo;s patients, and things like that. Admins need to be able to manage doctors and rooms and appointment type since these all might change over time or from one clinic to another that uses the same software. But those are mostly CRUD tasks, which means we\u0026rsquo;re just talking about adding and removing records and maybe making some edits without a whole lot of complexity. We\u0026rsquo;ll talk about those tasks in a different compartment of the application than the schedule, which, of course, has a lot more complexity.\nExploring the Sample App\u0026rsquo;s High-level Structure So why don\u0026rsquo;t we take a look at the structure of our app? This is a distributed application built with ASP.NET Core on .NET 5. It\u0026rsquo;s running Blazor WebAssembly in the front end, which is talking to APIs running on ASP.NET Core. There are three different web apps that the system uses. Two are used internally by client staff, and then there\u0026rsquo;s the public‑facing website for the clinic, which is needed for the confirmation links that users will click. The two clinic apps, Front Desk and Clinic Management, each have their own database, and all three apps communicate with one another using messages transported by RabbitMQ. Like I said, it\u0026rsquo;s maybe a little more complicated than most demos. We want the sample app to be something you spend some time with and extend as part of your experience with this course, so please be sure to check it out and run it locally. It should just work if you have Docker installed. ‑Now let\u0026rsquo;s take a quick look at how the code is organized. The full solution is hosted on Steve\u0026rsquo;s GitHub account. Here\u0026rsquo;s the URL, but we\u0026rsquo;ll definitely also have that URL in the resources slides at the end of this module. PLURALSIGHT DDD FUNDAMENTALS is the name of the root of our GitHub repository. In here, you can see the three web apps, ClinicManagement, FrontDesk, and the public‑facing website, VetClinicPublic. ‑There\u0026rsquo;s also a folder for SharedKernel, which we\u0026rsquo;ll talk about a little bit later. The first app we\u0026rsquo;re going to focus on though is the FrontDesk app. ‑Our main focus for this course is going to be the front desk application and its scheduling functionality. Looking at the solution, you can see it\u0026rsquo;s broken up into seven projects, which seems like a lot, but three of them are just there to support Blazor The server‑side code, where our domain model resides, is just three projects. ‑The most important project is FrontDesk.Core. That\u0026rsquo;s where the domain model is defined. All of the app\u0026rsquo;s infrastructure needs, like how it talks to its database or RabbitMQ, are kept in the FrontDesk.Infrastructure project. In the front end, in this case, ASP.NET Core and its API endpoints, is in the FrontDesk.Api project. This is the front end from the server\u0026rsquo;s perspective. The system is using a clean architecture design which you may also hear referred to as onion architecture or ports and adapters. I cover this in my N‑Tier Applications in C# course, and I have a popular GitHub solution template you can use to set up a new project using this approach. ‑With clean architecture, the project dependencies all point towards the domain model in the core project, so both the API and infrastructure projects have a dependency on Core. Core should never depend on infrastructure concerns, but it can leverage NuGet packages that don\u0026rsquo;t couple it to infrastructure concerns. ‑In this case, it\u0026rsquo;s using a couple of utility packages, as well as the SharedKernel package that\u0026rsquo;s shared by other apps. We\u0026rsquo;ll talk more about SharedKernel later. The ClinicManagement app uses the same kind of structure and also has a Blazor front end because why not? It\u0026rsquo;s pretty much just CRUD, so we don\u0026rsquo;t focus too much on its domain model, but it is a distinct app with its own database, and we do need to build into our design a way to propagate changes from it to the FrontDesk app. ‑Finally, there\u0026rsquo;s the public web app. It\u0026rsquo;s just one project, and it\u0026rsquo;s pretty simple. This is responsible for sending emails, which this demonstration fakes using a tool called PaperCut, and it hosts the link that clients click to confirm appointments. The public web app also needs to communicate with the front desk, but it doesn\u0026rsquo;t have a database of its own, nor does it access any of the other app\u0026rsquo;s databases. ‑That\u0026rsquo;s it in a nutshell. We\u0026rsquo;ll demonstrate the confirmation emails and more complex use cases later in the course. But for now, that should give you an idea of how the ideas we\u0026rsquo;re sharing are put into practice.\nReview and Resources So, as we\u0026rsquo;ve talked about, creating applications is not about writing code, even though often that\u0026rsquo;s a really, really fun part for us developers, but it\u0026rsquo;s about solving problems. And the more complex the problems are, the more difficult the whole project becomes. So Domain‑Driven Design gives us some great patterns and practices for attacking these more complex problems, and they get us to really focus on interacting with the domain experts, breaking apart our domain, and working on things in smaller units and in a very organized fashion. And in the end, it gives us a much more efficient and effective path to success in creating our solutions. ‑Yeah, we talked about some of the benefits that Domain‑Driven Design provides, as well as some of the drawbacks. Specifically, your team just needs to know Domain‑Driven Design, and your domain experts need to be available to work with you on these systems. Domain‑Driven Design is a big topic. We looked at some of the different concepts that are involved in DDD, and we\u0026rsquo;re going to look at a lot more of them in depth through this course. But remember that this is just an introduction to Domain‑Driven Design, so some of these aspects that are a little more advanced, we\u0026rsquo;re not going to be able to cover with a great deal of depth. ‑In the next module, we\u0026rsquo;ll start exploring the process of discovering and modeling domains. Here are some links to resources that we mentioned this module and others that we find relevant. ‑This is Steve Smith ‑and this is Julie Lerman, and thanks for watching Domain‑Driven Design Fundamentals.\nModeling Problems in Software Introduction and Overview Hi. This is Steve Smith. ‑And this is Julie Lerman. Welcome back to our Domain‑Driven Design Fundamentals course. This module will focus on modeling problems in software, and you\u0026rsquo;re welcome to reach out to us online. You can find me online at thedatafarm.com or on Twitter @julielerman. ‑And I\u0026rsquo;m at ardalis.dot com or on Twitter as @ardalis. In this module, we\u0026rsquo;re going to take a look at how we decompose the model for the veterinary office domain. We\u0026rsquo;ll talk about the importance of domain experts in DDD. ‑We\u0026rsquo;ll drive this point home with a play in which we\u0026rsquo;ll consider a few different scenarios for how the project might have gone, which should provide you with examples of ways to involve the domain expert in the design of the system. ‑Next, we\u0026rsquo;ll talk about the domain model and some of the elements that typically are found in this part of the application. It\u0026rsquo;s important to separate the core domain model from related subdomains, and we\u0026rsquo;ll talk about how bounded contexts can help us accomplish this separation. ‑And then we\u0026rsquo;ll wrap things up by talking about ubiquitous language and how this seemingly small thing with a big name can have a large impact on your model, your design, and, of course, your application. So let\u0026rsquo;s get started.\nIntroducing Our Domain Steve and I both have a love for animals. In fact, Steve\u0026rsquo;s wife, Michelle, is a veterinarian. In thinking about a sample application we could use for this course, we wanted to use something complex enough to justify the use of DDD. The veterinary clinic management domain made a lot of sense, allowing us to leverage our own experience as pet owners, as well as having a domain expert available in the form of Michelle, or Dr. Smith as we\u0026rsquo;ll be referring to her in the course. ‑There are many different pieces involved in managing a typical veterinary clinic. The staff needs to be able to schedule appointments. They likely need to schedule their own working shifts as well. They need to be able to invoice for their services and collect payments and, in many cases, send out bills. They\u0026rsquo;ll also need to be able to store and retrieve medical records, as well as work with external labs and specialty clinics. Most veterinary practices also have products for sale and may need to track inventory, as well as sales. And there are often follow‑ups and reminders that may need to be sent by mail, phone, or perhaps email. There is certainly sufficient complexity in this domain to merit the use of domain‑driven design.\nPlanning Ahead to Learn About the Domain Of course, it\u0026rsquo;s a good idea to speak with a domain expert about the systems requirements before diving in and beginning to code a solution. Whether you\u0026rsquo;re tasked with building a full system or just adding a new feature, an overall understanding of the client\u0026rsquo;s business is a critical start. Of course, it\u0026rsquo;s just the beginning. It\u0026rsquo;s also important that you have a continuous conversation with the domain expert throughout the development of the system. The simple system we showed in the last module needs some updates. So we\u0026rsquo;re going to share some conversations we had with the domain expert to help validate our initial assumptions. ‑An important part of this conversation is going to be identifying the things that aren\u0026rsquo;t included in the scope of the project or feature. To that end, we\u0026rsquo;ll try to identify subdomains within the overall problem domain and then determine whether or not we need to concern ourselves with these subdomains at the moment. If not, we can consciously remove them from the scope with the customer\u0026rsquo;s approval and avoid confusion and possible missed expectations later. To get started though, we do want to know a little bit about the big picture.\nConversation with a Domain Expert: Exploring the Domain and Its Subdomains As Julie already mentioned, my wife, Michelle, is a veterinarian. In addition, she has a deep understanding of software development processes, having successfully managed software teams at NimblePros and Teller. She has graciously agreed to play the role of domain expert for our course. In real life, she knows quite a bit about software and technology, but for the purposes of this course, she\u0026rsquo;s playing the more traditional role of a veterinarian with little background in software development. Hi Dr. Smith. Thanks for your time today. Julie and I would like to learn more about what goes on in your veterinary clinic. Can you share some of the big picture processes involved in the day‑to‑day operation of a clinic? ‑So the biggest thing is probably scheduling patients and keeping track of them once they arrive. Clients will usually call ahead unless it\u0026rsquo;s an emergency, and then we need to get them entered into our system. Of course, surgical procedures need to be scheduled in advance. And when they\u0026rsquo;re here, we need to record information about the patient, our observations, notes, and diagnoses. ‑Wow, that\u0026rsquo;s quite a list. Probably not what you were dreaming about when you started vet school. So many of these are all secondary to the core reason for being a vet, keeping pets healthy. And, I think it sets you apart from other businesses that have to manage clients and schedule appointments. But, you can\u0026rsquo;t run a business without it. Is that all? ‑So when the appointment is over, they also have to pay. So most of the time that\u0026rsquo;s done immediately, but we do have some billing that\u0026rsquo;s done after the fact, and when they\u0026rsquo;re checking out, they may need to buy some things for their pets, toys or prescriptions, or maybe some prescription food as well, and we need to track all of that as well. For some of the lab work, we need to send that out and get the results back, and some prescriptions go out to outside pharmacies as well. So we need to manage all of those through the system. ‑Okay, so payments, billing, point of sale, labs, prescriptions, anything else? ‑I think that\u0026rsquo;s about it. Oh, we also use the system to note which staff members are working when, and right now our website isn\u0026rsquo;t integrated into the system at all, but we were thinking it would be great if clients could view information about their pets, maybe schedule appointments, look up prescriptions, and we can make updates to the site without having to go through our computer contractor. ‑Okay, great. So, we\u0026rsquo;ll add staff scheduling and content management to the list. I don\u0026rsquo;t want to assume you know what a content management system is. We also call it a CMS, you might have heard of that. It\u0026rsquo;s a type of software system that lets the owner, that\u0026rsquo;s you, be in charge of the information that\u0026rsquo;s displayed. A blog is a really good example of a CMS that can be managed by its owner. ‑I have a blog, so I understand exactly what you mean. Something like that would be really great for us to have so we can make updates right in‑house. But it\u0026rsquo;s kind of like a blog, especially something that\u0026rsquo;s more professional than my personal blog. ‑Cool. So I think that\u0026rsquo;s probably enough of a big picture view for us to consider at the moment. Now let\u0026rsquo;s try and think about which of these are connected to the others so we can determine which ones we need to worry about for our application\u0026rsquo;s needs. ‑We started with this fairly complicated view of the overall problem domain, but now we\u0026rsquo;ve segregated these into different areas and we know which ones we need to focus on right now and which ones we can treat as external collaborators. ‑Determining where we can safely draw the line between what problem our immediate application needs to solve and what is outside of its area is certainly helpful. It\u0026rsquo;s also important that this be well understood and communicated among everyone involved in the project.\nConversation with a Domain Expert: Exploring the Scheduling Subdomain Now that we have a better understanding of the domain and the other subdomains around the scheduling system, it\u0026rsquo;s time to focus more on understanding the scheduling subdomain. We had another meeting with Dr. Smith, and you can listen in. ‑Hi guys, welcome back to the clinic. How are things going with the computer system? ‑We\u0026rsquo;re making good progress, and now we\u0026rsquo;re ready to look at another more complex feature. ‑We know there\u0026rsquo;s a lot that goes on here, but today we want to focus on appointment scheduling because we realize we\u0026rsquo;re still a little confused about it. ‑Since we\u0026rsquo;ve both owned pets for a long time, we figure we probably have a rough idea of what\u0026rsquo;s needed, but it\u0026rsquo;ll be good to talk through it with you. Do your patients usually schedule their appointments over the phone? ‑Okay, so yeah our patients aren\u0026rsquo;t usually involved in the scheduling. Usually, it\u0026rsquo;s the clients that call in for appointments for their pets. And yeah, usually it\u0026rsquo;s on the phone or in person when they\u0026rsquo;re checking out after an office visit. Julie and I talked about that earlier. ‑Yeah, so Steve, the patients are the animals, and the clients are the people or the pet owners. ‑Right, right, of course, that\u0026rsquo;ll be important to get right. ‑Remember, we talked about that. So the client needs to make an appointment for their pet. They\u0026rsquo;ll talk to a staff member who will schedule the appointment. What kind of information do they need in order to do that? ‑So that really depends on the type of appointment. It could be an office visit, or it could be a surgery. Why don\u0026rsquo;t we talk about the office visits first. If it\u0026rsquo;s just for a wellness exam, that\u0026rsquo;s pretty standard. They just need to choose an available time slot with one of the doctors. Some of the visits can be scheduled with just a technician though, so if they need just their toenails trimmed, for example. ‑Or painted, like Samson. He gets his toenails painted. ‑Does he really? ‑No, I\u0026rsquo;m joking. I just want to, pink. ‑I\u0026rsquo;m sure he\u0026rsquo;d love that. Okay, so office visits might be an exam requiring the doctor or another kind of appointment that only requires a technician. ‑Right. We also have to worry about our rooms too. We only have five exam rooms available, and we try not to overbook. We don\u0026rsquo;t like for our clients to have to wait too long in the reception area, especially if we have a lot of cats and big dogs out there at the same time. It makes them all really nervous. ‑What about other staff? ‑So our technicians will float between the exam rooms and other areas of the clinic as needed, except, of course, for those scheduled technician visits. We do have a schedule for the staff, but it\u0026rsquo;s separate from how we schedule our appointments. ‑Okay, so what about the surgeries? ‑Well, if it\u0026rsquo;s a surgery, those are only scheduled on certain days, and they require that the operating room be available, as well as some recovery space in the kennel area. It also depends on what kind of surgery or procedure we\u0026rsquo;re going to be doing. Something simple like a dental cleaning takes less time and fewer people than a caesarean section for a bulldog. ‑Okay, so an appointment is either an office visit or a surgery. Office visits happen in the exam room; surgeries require the operating room and recovery space. Is that right? ‑Right. And depending on the reason for the visit or the surgery, different staff might need to be involved. ‑So we\u0026rsquo;ll probably want to have separate classes for appointments and surgeries. ‑Classes? No, we refer our clients to obedience and puppy preschool classes at other facilities. We don\u0026rsquo;t actually schedule any of those in the clinic themselves. ‑I\u0026rsquo;m sorry. That\u0026rsquo;s a software term. In software, we have different classifications of concepts in the program, which are called classes. I\u0026rsquo;m just getting ahead of myself here. Sorry. ‑Don\u0026rsquo;t worry. We\u0026rsquo;re not going to make you learn our software terms. Steve and I will try to have a little bit more self control with that. We do want to make sure we\u0026rsquo;re all speaking the same language when it comes to concepts in the application though. ‑Okay, so I have another quick question. Do we have to worry about multiple staff members scheduling appointments at the same time? ‑No, there should only ever be one person doing the scheduling at a time, although I could see if we grew in the future that could change. But I don\u0026rsquo;t think that\u0026rsquo;ll happen in the next couple of years. Okay, then we don\u0026rsquo;t have to worry about the rare occurrence of two people creating a conflict if they\u0026rsquo;re trying to schedule an appointment for different patients in the same room or with the same doctor. That\u0026rsquo;ll keep things a lot simpler. And we need to know before an appointment if certain resources are available, like rooms and doctors. And then if they are and we want to schedule the appointment, then we need to be able to book the doctor, the room, and any other resources. Hey, is it okay if we refer to doctors as resources? ‑Sure, that makes sense. You know, I think it makes sense to use the term resources to refer to the doctors, the rooms, and the technicians since those are all things that can affect whether or not an appointment can be scheduled. But remember, sometimes it\u0026rsquo;ll be just a vet tech in a room, and other times it might be the doctor in the room, but sometimes you might need the doctor, the technician, and a room. ‑Wow, this is a lot more complicated than we\u0026rsquo;d realized, but it\u0026rsquo;s interesting. This is going to be cool to model in the application.\nReviewing Key Takeaways from Meeting with Domain Expert(s) Some of the things we learned in that initial high‑level discussion with the domain expert included the fact that patients and clients are not the same thing to a veterinarian. ‑Yeah, that\u0026rsquo;s pretty obvious in hindsight. But in most other medical professions, it is the patients who make appointments and pay the bills. It\u0026rsquo;s good we were able to get on the same page with the customer on that early on in the process. ‑I think it helped Dr. Smith put some of the processes she uses into explicit terms that we could program against also. A lot of times just describing the process to someone who is unfamiliar with it can really help improve the understanding of it. It\u0026rsquo;s like that idea that when you have to teach something to someone else, it makes you learn it a lot better. Listen to what Dr. Smith had to say at the end of our conversation about this. ‑Yeah, I never really thought about the details of how we do some of these things since it\u0026rsquo;s just something we do, and we don\u0026rsquo;t really think about it. Being more explicit about what the rules are that determine how we do are scheduling could help us avoid some of the occasional scheduling problems we\u0026rsquo;ve had. This is going to be great. ‑We also need to remember not to use too much programmer jargon, especially when there are programming terms that might have a different meaning in the customer\u0026rsquo;s domain. ‑I agree. It\u0026rsquo;s a little early for us to be worrying about how things might end up looking in the code anyway. At this stage, the main focus is on understanding the domain. We\u0026rsquo;ll get to building the software soon enough. But first, we want to make sure we know what problem it\u0026rsquo;s going to be solving. One of the most important things we can do as we explore the problem with the domain expert is to try and make their implicit knowledge about the process they use now explicit. Once we\u0026rsquo;re able to capture the process and its rules and exceptions with some detail, we can start to work on modeling a solution using this information. Building software is hard. One of my favorite sayings is as software developers, we fail in two ways. We build the thing wrong, or we build the wrong thing. By making sure we understand what the customer needs and, of course, working closely with the customer throughout the development process, we can dramatically reduce the likelihood of the second kind of failure, which is much harder to fix typically. ‑Hey, Steve. I like the way you quote yourself here, but it really is a great quote.\nTaking a First Pass at Modeling our Subdomain After talking to Dr. Smith about how appointments work, we\u0026rsquo;ve identified a few high‑level elements of our model. The central concept in this application seems to be the appointment itself. Typically, an appointment is scheduled by a client for a patient. Booking an appointment often requires an exam room and a doctor, but may involve other resources. Appointments might be for office visits or vaccinations, or they might be surgeries, which are a separate kind of thing entirely with their own rules which involved different kinds of procedures. Surgeries require different resources too, like operating rooms and recovery rooms. ‑That\u0026rsquo;s a pretty good high‑level view of the model we have so far for the appointment management part of our application. I think it\u0026rsquo;s worth noting that some of the concerns of this application are going to also play a part in other subdomains. For instance, I\u0026rsquo;m pretty sure we\u0026rsquo;re also going to be working with clients and patients in a lot of the different parts of this application. ‑Yeah, I think it\u0026rsquo;s time we introduce the idea of bounded contexts.\nUsing Bounded Contexts to Untangle Concepts that Appear to Be Shared As you develop your model, remember to identify its bounded context. That is, where is this model valid? If you don\u0026rsquo;t put boundaries around your model, eventually, pieces of it will be used where they don\u0026rsquo;t fit. Concepts that make sense in one part of the application may not make sense in another, even if they have the same name and sometimes even if they literally refer to the same thing. ‑For example, as we built out the appointment scheduling portion of this system, we needed to know some very basic information about clients. But in the context of appointment scheduling, these are very simple concepts with little behavior beyond their names. However, in the billing context, we\u0026rsquo;ll want to include contact and payment information for clients, but that\u0026rsquo;s information we don\u0026rsquo;t care about back in the appointment scheduling context. If we try to reuse the same exact client model in multiple places, it\u0026rsquo;s likely to cause inconsistent behavior in our system. ‑That\u0026rsquo;s right. For instance, we might decide to include some form of validation on clients to ensure we have enough information to bill them. If we\u0026rsquo;re not careful, that validation might inadvertently prevent us from being able to use clients to schedule appointments, which certainly isn\u0026rsquo;t the desired behavior. Maybe the billing system requires that clients have a valid credit card in order to save changes for them, but it wouldn\u0026rsquo;t make sense for a lack of a credit card to prevent us from saving an appointment for a client in the appointment scheduling system. In this example, we have two contexts, but the boundaries between them are blurred and overlapping. Eric Evans notes that models are only valid within specific contexts. Therefore, it\u0026rsquo;s best to explicitly define the context within which a model applies. We should be able to avoid compromising the model within this context, keeping it strictly consistent within these bounds and avoiding distractions or confusion from outside issues. ‑Once we explicitly define our bounded contexts, we can easily see whether or not we have elements of our model that are trying to span multiple contexts. In this example, we\u0026rsquo;d want to keep a simple view of a client in the appointment scheduling up and a richer version of the client with contact and billing information in the billing context. We would define these two views of a client in two separate classes, and they will most likely live in separate applications. In fact, Evans recommends that bounded contexts maintain their separation by giving each context its own team, codebase, and database schema. ‑While this is ideal, in many real‑world apps, we need to work on systems where this level of separation is not present, usually due to resource constraints or for political reasons within the organization. Remember though, if you have multiple contexts, you\u0026rsquo;ll want to keep them bounded. And one way to maintain this separation is to keep their data, code, and team members distinct from one another, although in real world, I\u0026rsquo;ve never seen something with that level of separation. ‑Yeah, but I think even if it\u0026rsquo;s not possible to literally do that with your company and your team, just having that concept in mind really helps in your brain have that idea of separation. ‑I agree. I know that just thinking about the fact that these things ought to be separated and trying to figure out a way to do it means that even if you can\u0026rsquo;t get to the ultimate level where everything is is completely separate, you can still introduce separations through things like namespaces, separate folders, separate projects, anything you can do to make it clear that these are different contexts that shouldn\u0026rsquo;t be sharing too much information. ‑You know, I think that\u0026rsquo;s also really important point about this course in general and DDD in general. For me, it\u0026rsquo;s really hard to think of all of these things we\u0026rsquo;re learning as hard and fast rules, like you have to do it this way or you\u0026rsquo;re not doing it right. I like to see all of this as really good guidance. So, you know, it helps me keep my eye on the prize, and when there\u0026rsquo;s places where I can\u0026rsquo;t truly achieve exactly what DDD kind of directs me to do, you know, I\u0026rsquo;m using my own experience, my own intelligence to make decisions about how to do things, and I\u0026rsquo;m letting DDD guide me in a lot of scenarios. ‑Sure. And some of these ideals, I think of like 100% test coverage. It\u0026rsquo;s almost impossible in most real‑world applications to achieve 100% test coverage. But just because that ideal is not something you can ever achieve doesn\u0026rsquo;t mean that you shouldn\u0026rsquo;t strive for more test coverage. ‑Yeah, yeah, totally, totally agree with that.\nConversation with Eric Evans on Subdomains and Bounded Contexts When learning about DDD, most of us have a hard time understanding how subdomains and bounded contexts are different. We asked Eric Evans about this and got some great insight. He explained that a subdomain is a view on the problem space, how you\u0026rsquo;ve chosen to break down the business or domain activity, whereas a bounded context represents the solution space, how the software and the development of that software has been organized. Quite often, these will match up perfectly, but not always. ‑Eric helped us understand this further with the example of a room that you want to cover with carpeting. The room is the problem space, so it\u0026rsquo;s like a subdomain. You could install a wall‑to‑wall carpet that matches the shape of the room perfectly. This would be like when the subdomain and the bounded context encompass the same thing. But other times you might just use some area rugs to cover the floor, and the area rugs solve the problem. They cover the part of the floor where you walk, and you don\u0026rsquo;t have to worry about cold feet in the winter. And that\u0026rsquo;s a scenario where the area rugs are like bounded contexts that don\u0026rsquo;t match the subdomain, but they solve the problem even though they\u0026rsquo;re not an exact match to the shape of the room.\nIntroducing Context Maps If your organization has multiple bounded contexts, and ideally these are separated, there can be confusion when the different teams are talking to one another. Again, DDD focuses at least as much on effective communication as it does on anything specifically related to the code we produce. Evans recommends using context maps to visualize and demonstrate to all teams where the boundaries between their context lie. ‑Think about a complex topographical map. It will frequently include a legend, like the one shown here, in order to explain what each of the lines and symbols on the map mean. However, this legend is only valid within the context of the map with which it appears. Trying to use this legend on another map would be confusing at best. ‑A good first step for an existing application is to create a map that shows how things are. Remember that the names of your contexts are also important as you\u0026rsquo;ll refer to them frequently when discussing different parts of the application. It may be that things are not as separate as they should be, and that\u0026rsquo;s worth noting. If you have separate teams responsible for different contexts that share resources, it\u0026rsquo;s important that each team understands which aspects of the application they can change on their own and which are shared dependencies they\u0026rsquo;ll need to coordinate with other teams to avoid breaking things. If we look at these two sets of concepts, we can see some obvious overlap. For one thing, Client appears in both contexts, but we know that for appointment scheduling we really only care about the client\u0026rsquo;s name, whereas in the billing system they\u0026rsquo;ll want additional information like address and payment details. However, although the details involved vary, we know that Mr. Jones, the client on the left, is the same actual person as Mr. Jones, the client on the right. However, we also have a concept of notifications on both sides, and in this case, they\u0026rsquo;re referring to different things. On the left, we\u0026rsquo;re talking about sending a notification when an appointment is booked as a reminder, and on the right, we\u0026rsquo;re talking about notifying the client that their payment was received or perhaps that it\u0026rsquo;s past due. ‑Especially in smaller organizations, it\u0026rsquo;s common to have one team responsible for several contexts of the same overall application. In such cases, it\u0026rsquo;s also common for the team to use a single codebase for the bounded context that they\u0026rsquo;re working with and store it in a single repository, such as GitHub. Usually, there will also be a shared database. As we\u0026rsquo;ve already noted, this is not ideal since it makes it much more difficult to maintain the boundaries between the separate contexts. ‑Part of creating a context map involves explicitly identifying its boundaries. If we try to draw the boundaries around these two bounded contexts, we can see there are now several resources that belong to each bounded context. This isn\u0026rsquo;t ideal if the two contexts really are meant to be kept separate. ‑In the ideal case for a large complex system, we would have bounded contexts like these, with their own teams, codebases, and database. For instance, on the left, we have an appointment scheduler application. It\u0026rsquo;s being worked on by Team Awesome, and they\u0026rsquo;re storing all of their code in their own repository called vet‑app‑sched. And, of course, this application has its own database. This team is free to change anything they want with their model or any other part of their system without worrying about breaking anything outside the boundaries for the team on the right, which is working on a billing system, and their team has decided to call themselves Team Ultimate, store their code in a repository called vet‑billing, and, of course, using their own database. By having this separation, this can greatly increase team velocity and reduce integration bugs. ‑Of course, you\u0026rsquo;re probably wondering how the two systems will interoperate. There are a number of patterns that can be applied to enable this kind of integration. We won\u0026rsquo;t be covering all of them in this course, but one question that frequently comes up is how to share cross‑cutting concerns like blogging and shared abstractions such as people names that are used by multiple bounded contexts. For this scenario, a common approach is to designate these shared concepts or resources as what we call a shared kernel. Team Awesome and Team Ultimate agreed to share the subset of the domain model. Since they\u0026rsquo;re sharing it, they also agree not to change it without coordinating with the other team first. Frequently, the shared kernel will either be a part of the customer\u0026rsquo;s core domain, or some set of generic subdomains, or even both, though it could be any part of the model that both teams require. Using a shared kernel is a tradeoff between code reuse and consistency and the overhead involved in integrating changes to the shared kernel across multiple teams and bounded contexts. It works best when the shared model is relatively stable.\nAddressing the Question of Separate Databases per Bounded Context The concept of having separate databases for each bounded context often throws people for a loop. But with the advent of microservices, which also, by definition, each have their own database, teams are beginning to get more accustomed to the idea. Here\u0026rsquo;s what Eric Evans said to us when we talked with him about the problems created by trying to share a database across teams. \u0026ldquo;If you\u0026rsquo;re in a company where you share your database and it gets updated by hundreds of different processes, it\u0026rsquo;s very hard to create the kind of models that we\u0026rsquo;re talking about and then write software that does anything interesting with those models.\u0026rdquo; Given that sharing a database across bounded contexts is really not a great idea, then we have another important question. ‑Another question that comes up often is how to sync data between the individual databases that are tied to each of the bounded contexts. Some different patterns you can use are publisher/subscriber, commonly referred to as pub/sub, and two‑way synchronization. Pub/sub is definitely simpler and preferable when you can manage it. You can use different implementations like message queues, database processes, batch jobs, or synchronous API calls. It\u0026rsquo;s really up to you how you want to design your synchronization between bounded contexts. The point is just that you don\u0026rsquo;t get the integration for free from using a shared database.\nSpecifying Bounded Contexts in our Application We talked with Eric again to get his perspective on defining context boundaries. Some of the key points he shared were that first, it\u0026rsquo;s important to understand that it\u0026rsquo;s never a simple task whether you\u0026rsquo;re new to it or not. And he\u0026rsquo;s seen stumbling blocks of all sorts. The most common is not having a clear enough context boundary, so the effort of applying DDD isn\u0026rsquo;t clearly separated from other tasks related to building software. ‑He also reminded us that the bounded context is such an essential ingredient that is probably the biggest stumbling block. And it\u0026rsquo;s not often one that an individual on a project can usually addressed by themselves. It kind of has to be dealt with at the team level or even the organizational level. In our application, we\u0026rsquo;ve organized the solution to make it clear where the boundaries are between our contexts. The main area that we are currently focused on is the appointment scheduling bounded context. ‑We\u0026rsquo;ve identified two other bounded contexts that are involved in the overall application or will be eventually. For instance, it\u0026rsquo;ll be important for users to be able to manage clients and their patients. The staff of the clinic also needs a way to manage their schedules so they know who\u0026rsquo;s working on different days. We\u0026rsquo;re referring to these two bounded contexts as client patient management and resource scheduling. ‑We also have a few parts of the application that are common to several bounded contexts. These are cross‑cutting concerns that we have consciously chosen to share. In DDD, we isolate such code into its own package referred to as a shared kernel, and it\u0026rsquo;s worth noting that a bounded context does not always mean a separate application, even though we\u0026rsquo;ve identified several different bounded contexts. ‑It\u0026rsquo;s also a great opportunity to consider packaging logic up into microservices. Do keep in mind, however, that there\u0026rsquo;s not always a 1:1 alignment between bounded contexts and microservices or applications. Also, let\u0026rsquo;s not forget that our application will definitely need a front end.\nUnderstanding the Ubiquitous Language of a Bounded Context We\u0026rsquo;ve mentioned already that an important part of DDD is an emphasis on effective communication among the stakeholders in the project. And remember, if you\u0026rsquo;re a programmer, count yourself as one of the stakeholders in whatever you\u0026rsquo;re working on since you certainly have a stake in its success. The language we use to describe the problem and how we choose to model it is key to the shared understanding we want to have with our domain experts in order to be successful. Having a single, shared, ubiquitous language helps avoid unnecessary confusion and translation within the team building the software and is one of the fundamental practices of Domain‑Driven Design. And when I talk about the team building the software, I don\u0026rsquo;t just mean the programmers. I mean the whole team, including the business people that are deriving what the software should do. The discovery of the Rosetta Stone allowed us to unlock several different languages by showing the same message in three different texts. We don\u0026rsquo;t want to have to have a Rosetta Stone or any other sort of tool to help us translate between what the business is talking about and what the programmers are talking about. We want to make sure that everyone is speaking the same language the whole time so that translation is unnecessary. ‑Think about if you\u0026rsquo;ve ever used an online translation tool to round trip a sentence. You can run into similar communication issues in your application if you\u0026rsquo;re constantly having to translate to and from the domain expert terms or the programmer\u0026rsquo;s terms. Here\u0026rsquo;s an example of a user story for a sample system about creating appointments. ‑We have a lot of developer friends in Nigeria, so I thought it would be fun to try out Igbo for our translation. We used a website to translate between English and Igbo a few times, and in the end, the user story has changed just enough to create confusion. Translation software is pretty good these days, and we were hoping for a more humorous result, but according to animal experts, it\u0026rsquo;s close, but not the same as a veterinary technician. ‑But the point here, of course, isn\u0026rsquo;t just relating to different international languages, but to the different languages spoken by business experts and programmers. ‑Incidentally, a great practice when you\u0026rsquo;re discussing your system requirements with customers is to always try and explain back to them what you think it is they want the system to do so they have an opportunity to correct your understanding of what they think they just told you. ‑Definitely. Remember, one of the key benefits of using a ubiquitous language is that all parties can understand it without having to perform any translation. This means when you show a test or some code to a domain expert, you don\u0026rsquo;t have to explain that in the system you call something an animal when the domain expert calls it a patient. ‑Evans cautions that a project faces serious problems when it\u0026rsquo;s language is fractured. When domain experts stick to using their jargon while the technical team members have their own language tuned to discussing the domain terms in the design, translation errors will manifest as software bugs. Neither the customers nor the developer\u0026rsquo;s language is sufficient for all parties to discuss the application effectively. What is needed is a shared common language that incorporates and uses terms defined in the domain model. The use of this language must be ubiquitous, and the more the language is used, the more will force deficiencies in the model into the open. ‑And by ubiquitous, we mean it must be used everywhere within the bounded context. The vocabulary of the language includes the names of model classes and prominent operations. The team should use these common terms in code, in diagrams, on the whiteboard, in design documents, and especially when discussing the system. ‑Yeah, pretty much ubiquitous means everywhere, all the time. Even in that one email you\u0026rsquo;re sending off to another developer, stick to using the terms that you\u0026rsquo;ve agreed makes sense for this bounded context.\nConversation with a Domain Expert: Working on our Ubiquitous Language You\u0026rsquo;ve heard some of our conversations that helped lead to a ubiquitous language for the scheduling app. There was another important one that happened early on between Michelle and me that we want to share with you now. ‑Pay attention to not only the clarification of the terms, but also to the fact that Julie and Michelle are equal partners in this conversation. Although Julie is trying to lead the conversation towards the goal of identifying the correct terms, she\u0026rsquo;s careful not to make assumptions about Michelle\u0026rsquo;s domain. ‑So Michelle, last time you and Steve and I got together to talk, Steve and I have been working on just kind of fleshing things out and planning things, and I realized that we had some confusion over some of the common terms, like things that, as real pet owners, we would kind of assume the terms are, but then when we\u0026rsquo;re thinking about business and software, we\u0026rsquo;re thinking of the terms a little differently. So I was wondering if we could just sort that out with you so that we\u0026rsquo;re all on the same page and using the same terms and using terms that none of us have to stop and think about what we\u0026rsquo;re talking about. We\u0026rsquo;ll always know what they mean. ‑Sure. ‑The first thing is we have these clients, those are the people who own the pet. So when thinking about the software and business, we think of them as clients, but kind of in the real world, and me, I have a pet, I go to the vet all the time. I think of myself as a pet owner. So what do you refer to those people who bring the pets, pay their bills, call and make the appointments, etc? ‑Most of the time, I mean those would be listed as as clients. ‑Okay, so you do call them clients. You don\u0026rsquo;t worry about calling them owners, and of course, it sounds kind of weird to say I own a dog, right? ‑He kind of owns you. ‑Yeah, that\u0026rsquo;s more like it. You\u0026rsquo;re the pro you know. So then what about that dog, like are they patients, are they pets, are they clients? What do you refer to the pets as? ‑So for the purpose of the medical record, we refer to them as the patient. ‑Okay. So it would be client and patient. ‑Exactly. And actually in veterinary medicine they talk a lot about this triad, the veterinary client/patient relationship, where all three are really important in that. ‑Okay. So those are actually terms that are commonly used in your industry. Industry, that sounds so weird, but with that. Cool. Alright, so the next one we were also going back and forth on was an appointment or an office visit. When somebody is scheduling a visit, scheduling to come in, how do you refer to that? ‑So there would be two big subsets of what they might be scheduling to come in for. They might schedule a surgery, which is an easy one to define. They\u0026rsquo;re going to come in, we\u0026rsquo;re going to do some sort of a procedure. Usually, there is going to be some anesthetic involved. That would be a surgery and that would be outside of our normal office hours. ‑Oh, okay. So what about when they just come in for regular stuff? ‑So when they come in for regular appointments, you could call those office visits or appointments, and there are a few different subsets of those. You may have an appointment that\u0026rsquo;s a wellness exam, and in that exam, we would be doing, of course, a physical examination and generally wellness treatments like vaccination, some blood work, generally your healthy pet who is coming in for a routine checkup. ‑So that\u0026rsquo;s an office visit and there is a couple other things that come under the umbrella of office visit, but if I, I\u0026rsquo;m also thinking about scheduling because that\u0026rsquo;s the thing we\u0026rsquo;re really going to be focused on is the scheduling portion of the app. So we\u0026rsquo;re always scheduling an appointment, an appointment for a surgery, an appointment for an office visit, whatever type of office visit that is, so is using the term appointment, does that make sense? Would you, if if I said appointment would you think that could be a surgery, that could be a checkup, that could be whatever. This thing to be scheduled is what I want to define. ‑Yeah, I mean I think you could call them all appointments, but I would differentiate between the surgery and something that\u0026rsquo;s done in the office, but then I would further differentiate in the office between a wellness exam, an exam for somebody that\u0026rsquo;s coming in with a problem, or an exam that doesn\u0026rsquo;t need to see a doctor, but could just be done by a technician like a toenail trim. ‑Oh good. Yeah, we always need those, clickety‑clack on the floors. Alright, so I think then we\u0026rsquo;ll use just the overall umbrella of we\u0026rsquo;ll schedule an appointment and then we\u0026rsquo;ll be more explicit about what type of an appointment that\u0026rsquo;s going to be. Would that feel okay to you? ‑Yeah, that makes sense to me. ‑Great. Excellent. Alright, so I\u0026rsquo;ll get back to Steve and then we\u0026rsquo;ve got another meeting set up I think in a few days to just hash out some more details after Steve and I\u0026rsquo;ve gotten some more of our ducks in a row. ‑Sounds great! ‑Excellent. Thanks Michelle. Bye bye. ‑Thank you. Bye. ‑Now we have a stake in the ground for our ubiquitous language. As we continue working with Michelle, not only will we learn more items for the bounded context, but there is also a chance that the ubiquitous language will evolve. Eric Evans guides us to pay attention to those changes because a change in the ubiquitous language is also likely to mean a change in the domain model. We have to update our design to accommodate what we\u0026rsquo;ve learned.\nReviewing Important Concepts from This Module We\u0026rsquo;ve covered quite a few concepts in this module. One of the most important ones is just understanding the problem domain and the overall thing that your software is working within. ‑‑And breaking things apart. I know that when I started out, I had a really hard time really understanding differences between the core domain, the subdomains, and the bounded context, especially the subdomains and the bounded context because at first glance, they looked like the same thing to me. ‑‑Sure, it\u0026rsquo;s really easy to have an application where you have some kind of a concept, like a customer that you know is used by every system that your organization uses. And it ends up becoming this like God object in your database and in your different applications where any given application might only care about a tiny subset of that concept. ‑‑Yeah. So, for me, I think the most important thing is really focusing on the bounded context. Getting down to that and understanding about the boundaries. One thing that helps me a lot is just stating within the context of this and then suddenly like, oh right, that\u0026rsquo;s what a context is. It\u0026rsquo;s not like some mysterious new term that Eric Evans invented. He just is leveraging what makes sense. Within the context of appointment scheduling, this is what a client looks like. Within the context of billing, this is what a client looks like. ‑‑Sure, I think that makes a lot of sense. And it\u0026rsquo;s valuable, even when you have an application, like a legacy application that wasn\u0026rsquo;t built with domain‑driven design. Let\u0026rsquo;s go ahead and look at some more terms here. For instance, we\u0026rsquo;ve got what you were just talking about, I think of as context mapping. And even in a legacy application, it can be valuable to kind of map out what are all the concepts in this application and where are the overlaps with different subdomains that maybe we haven\u0026rsquo;t even defined in this legacy application. ‑‑Yeah. Even if you\u0026rsquo;re not planning on making huge changes to it, it\u0026rsquo;s still really, really helpful to just kind of update your perspective on things. Sometimes it just leads to new understandings. ‑‑I think the shared kernel is a really important part of this, too, because in almost every real‑world organization I\u0026rsquo;ve worked with, there are different types of cross‑cutting concerns, and we talked about one of them being the authentication piece, and that\u0026rsquo;s definitely a really common one. But there are usually others too that you want to share. ‑‑Yeah, and, again, it\u0026rsquo;s another one of those things that sounds like it might be a big, scary, mysterious thing because you haven\u0026rsquo;t referred to it that way, but if you really just start out thinking of it as the common stuff, but then‑‑‑I think one of the important things, though, is even within the context of domain‑driven design, we have a ubiquitous language because if I say common, you might have a different idea of what I mean by common, but if I say shared kernel, we\u0026rsquo;ve got an agreed‑upon understanding of what we\u0026rsquo;re talking about there. So at first, I really kind of pushed back against using these terms because I felt like a lot of the DDD experts were just throwing them around all the time. And then I started really getting a better understanding of why it\u0026rsquo;s important to use those terms. It\u0026rsquo;s about‑‑‑it\u0026rsquo;s the ubiquitous language of domain‑driven design so everybody\u0026rsquo;s on the same page. ‑‑Yeah, I do agree that that\u0026rsquo;s an important part of learning about DDD and other areas of software development, like, for instance, design patterns. These things give us these terms that we can use that are very, very dense. If we talk about shared kernel, it would take me three or four sentences to describe what I meant by that. But in these two words, you know exactly what I mean, just like if I talk about using a strategy design pattern, that is much easier to convey than if I were to try and describe it with words and have to draw a UML diagrams to say what I mean. ‑‑And it\u0026rsquo;s the same, again, with the ubiquitous language because now I really have a better understanding of the fact that what it means is the language is ubiquitous throughout a particular bounded context. When we\u0026rsquo;re talking about a scheduling app, we\u0026rsquo;re going to use these terms all the way through, like you were saying before, we use it not just when we\u0026rsquo;re talking to the domain expert but in our class names, in our methods, it\u0026rsquo;s just ubiquitous throughout all of the pieces of the things that are involved in that bounded context from one end all the way to the other of it. ‑‑And I think as we\u0026rsquo;ll see when we look at the code again, some of the constructs in .NET, like namespaces, are really appropriate to ubiquitous language because when you prefix that same term in your code with a particular namespace, that tells all the other programmers that if I say SchedulingApp.notification, we know that that has a different meaning that if I\u0026rsquo;m talking about EmailReminder.notification. ‑‑Or SchedulingApp.client versus Billing.client. ‑‑Exactly.\nReview and Resources In this module, we learned about our domain, in this case, a veterinary practice. We talked about it at length with a real live domain expert and identified the core elements of our domain model. We identified a variety of subdomains and focused in on the key area that we would be addressing first with our application. ‑We spent some time designing the system based on our conversations with Michelle, identifying boundaries between different contexts, and noting how sometimes the same object with the same name might mean something different within a different context. ‑Finally, we talked about the importance of communication in general and in particular having a ubiquitous language. We know that Domain‑Driven Design can help us avoid many design errors and wasted time miscommunicating as we work on a complex project. ‑Steve and I are so grateful to Eric Evans for spending time with us while we were creating this course in order to share his luminous advice and insights. In the next module, we\u0026rsquo;ll drill into the domain model so you can have a good understanding of its critical elements. ‑This is Steve smith, ‑and this is Julie Lerman. Thanks again for watching Domain‑Driven Design Fundamentals.\nElements of a Domain Model Introduction and Overview Hello, this is Julie Lerman, ‑and this is Steve Smith. ‑In this module, we\u0026rsquo;re going to focus on the elements of a domain model which are in our bounded context. ‑You\u0026rsquo;ve seen these in the mind map. It\u0026rsquo;s patterns like entities and aggregates and more. ‑You can find me online at ardalis.com or on Twitter as @ardalis. ‑And you can find me online at thedatafarm.com or on Twitter at @julielerman. ‑In this module, we\u0026rsquo;ll focus on the technical aspects involved when modeling a bounded context. We use these terms while modeling, and these same terms refer to patterns we\u0026rsquo;ll use when we code. The concepts flow through the entire process, which is great. You don\u0026rsquo;t have to keep switching hats or mindsets. ‑We\u0026rsquo;ll start by grounding ourselves in the domain and understand why it\u0026rsquo;s important to stay focused there. DDD models are driven by behaviors, not classes and properties. This is another very cool shift in thinking for those of us who have always focused on objects. Then you\u0026rsquo;ll learn about some terms used to describe domain models, rich and anemic. You learn what the terms mean at a conceptual level and what the code that they\u0026rsquo;re describing looks like. ‑Entities are the key types in your system, but not every type in your system is an entity. ‑You\u0026rsquo;ll learn how entities fit into DDD, how to differentiate entities that have complex needs from simpler entities that might only need some basic CRUD logic, and you\u0026rsquo;ll be able to see how we\u0026rsquo;re implementing all of these concepts in our code.\nThe Importance of Understanding DDD Terms Domain‑Driven Design is filled with lots of specific terms. Much like the ubiquitous language that we use to make it easier to communicate while working within a bounded context, understanding and using the terms of DDD makes it easier to talk about the process. We\u0026rsquo;ll spend the bulk of this module focusing on some of the concepts behind modeling bounded contexts, concepts that are critical to this process, but, unfortunately, often misunderstood. ‑I\u0026rsquo;ve definitely had my challenges with some of the DDD concepts. Some of my issues were because the terms overlap with other technologies I use. For example, I do a lot of work with Microsoft\u0026rsquo;s ORM called Entity Framework. Entities are a key element in Entity Framework, and they\u0026rsquo;re also a key element in DDD. So I thought my understanding of entities from Entity Framework was enough to translate to DDD entities, but it really wasn\u0026rsquo;t, and my less than solid grasp on DDD entities caused problems when I was trying to model domains and implement the model and code. We also have the concept of a context in Entity Framework. While the real goal of that context is to provide interaction with the database, it also does provide a boundary around a model. But it\u0026rsquo;s very different than the concept of a bounded context, and that definitely confused me for a while. Another important element in a DDD model is value objects. These got me pretty confused at first, and my ego was saved by discovering that others have also been confused by value objects. But I\u0026rsquo;ve worked on my DDD education and sorted these problems out, so in this module, it\u0026rsquo;s really important to both Steve and I that you start off on the right foot with a proper understanding of entities, value objects, and some of the other DDD puzzle pieces so that Domain‑Driven Design can help you with your complex problems, not complicate them even more.\nFocusing on the Domain It\u0026rsquo;s important to remember that first D in DDD stands for Domain, and yeah, the other two Ds, Driven and Design. But we really want to focus on Domain here. ‑By now, you\u0026rsquo;ve probably heard us talk about this plenty, but both Julie and I find that we constantly have to remind ourselves to focus on the domain. We hear ourselves begin to talk about the user interaction with the app and have to ask, well, what part of the vet clinic domain is this user? Yeah, obviously we care about the user and how the actual application will work from their perspective, but that\u0026rsquo;s for another conversation, and we have to draw ourselves back to focusing on modeling the domain. ‑I have quite a long history with data access, and I catch myself worrying about how our domain model will translate to the database so that things definitely get persisted correctly. That\u0026rsquo;s when Steve needs to give me that look, you\u0026rsquo;re doing it again, Julie, and I have to bring my focus back to the domain of the vet clinic again. So while it may seem redundant to harp on domain, domain, domain, this diligent focus will help you avoid the complications and distractions that come from thinking outside of the domain or the subdomain that you\u0026rsquo;re focused on. ‑Here\u0026rsquo;s an important quote from Eric Evans\u0026rsquo; book about this focus on the domain. \u0026ldquo;The Domain Layer is responsible for representing concepts of the business, information about the business situation, and business rules. State that reflects the business situation is controlled and used here, even though the technical details of storing it are delegated to the infrastructure. This layer of the domain is the heart of business software.\u0026rdquo; ‑Just to reiterate, the domain model is the heart of the business software. This is the whole point behind Domain‑Driven Design. Focus on the domain, not the technical details of how the software will work. ‑In a typical database‑driven app, we\u0026rsquo;re used to focusing on properties or attributes of classes. Our apps sometimes become all about editing property values and the state of our objects. However, when we are modeling a domain, we need to focus on the behaviors of that domain, not simply about changing the state of objects. ‑Michelle didn\u0026rsquo;t talk to us about setting the name of a dog or editing the time of an appointment. She told us that she needs to schedule an appointment, and when she does that, she needs to book a room and create a schedule item on a doctor\u0026rsquo;s calendar as well. So scheduling appointment is a lot more than setting the attributes of the objects involved, the appointment time and identity of the pet we\u0026rsquo;re making the appointment for. We\u0026rsquo;re talking instead about how the system behaves. In response to scheduling an appointment, the system should also book a room and do something to the calendars of the doctor and any vet techs that might be involved.\nIdentifying Events Leads to Understanding Behaviors An important way to identify behaviors in your system is by focusing on events. Doing so gives you a great path to understanding the behaviors of your domain. Alberto Brandolini devised a great way to brainstorm with clients, which is referred to as event storming. It begins by having a somewhat chaotic brainstorming session with a good number of domain experts writing events on Post‑its and sticking them on a wall. The format of what they write is in the past tense. For example, an appointment was booked, a client contacted the office, or a dog was weighed in. I facilitated quite a few event storming workshops with clients, and I\u0026rsquo;m a big fan of using this process to help get a picture of the domain, discover bounded contexts, and even discover key problems that should be addressed. Another interesting methodology for modeling a system based on events is called Event Modeling. Adam Dymitruk came up with this workflow and has had great success using it to help teams collaborate on learning about the domain and designing the flow of software. I was fortunate to participate in a three‑day workshop with Adam to learn about Event Modeling. We won\u0026rsquo;t be teaching you about event storming or Event Modeling in this course, those are beyond the scope of our goals here, but we did want to be sure you were aware of them. You\u0026rsquo;ll find links for more information about event storming and Event Modeling at the end of this module.\nComparing Anemic and Rich Domain Models In order to understand the difference between design that\u0026rsquo;s focused on attributes versus design focused on behaviors, it will help to understand two commonly‑used terms in domain‑driven design, anemic domain models and rich domain models. An anemic domain model is a domain model that is focused on the state of its objects, which is the antithesis of DDD. While the term is somewhat negative indicating a deficiency, you don\u0026rsquo;t need to perceive it that way. There is nothing wrong with anemic classes when all you need to do is some CRUD logic, but if you are creating a domain model, you\u0026rsquo;ve already made the decision that your domain is too complex for simple CRUD. So anemia in a domain model is considered an anti‑pattern. ‑Martin Fowler writes about anemic domain models with such drama that you may never mistakenly use them in your domain model. He says the basic symptom of an anemic domain model is that at first blush it looks like the real thing. There are objects, many named after the nouns in the domain space, and these objects are connected with the rich relationships and structure that true domain models have. The catch comes when you look at the behavior and you realize that there is hardly any behavior on these objects making them little more than bags of getters and setters. Indeed, often these models come with design rules that say you are not to put any domain logic in the domain objects. Instead, there are a set of service objects would capture all the domain logic. These services live on top of the domain model and use the domain model for data. ‑What we aim for then is rich domain models, not anemic domain models when we are modelling our domain. Rich domain models will represent the behaviors and business logic of your domain. Classes that simply affect state are considered an anti‑pattern in a domain model, and therefore, get the nasty label of anemic, even though they are perfectly fine in a CRUD model. Martin Fowler doesn\u0026rsquo;t mince words when it comes to anemic domain models saying the fundamental horror of this anti‑pattern is that it\u0026rsquo;s so contrary to the basic idea of object‑oriented design, which is to combine data and process together. I have to say I agree and I\u0026rsquo;ve worked with many teams who have had to deal with the self‑inflicted pain of treating their domain entities like DTOs lacking any encapsulation or behavior. That can work for simple CRUD apps, but it\u0026rsquo;s often a disaster in a DDD model. ‑While Martin Fowler and other DDDers have strong words to say about anemic domain models, we\u0026rsquo;d like to share a gentler message, which is to strive for rich domain models and have an awareness of the strengths and weaknesses of those that are not so rich.\nUnderstanding Entities Even though a DDD app is driven by behavior, we still need objects. DDD expresses two types of objects, those which are defined by an identity and those which are defined by their values. We\u0026rsquo;ll focus first on the objects that are defined by their identity. These objects are called entities. ‑An entity is something we need to be able to track, locate, retrieve, and store, and we do that with an identity key. Its properties may change, so we can\u0026rsquo;t use its properties to identify the object. If you\u0026rsquo;ve done any type of data persistence in software, you\u0026rsquo;re probably pretty familiar with entities and their keys. When we are modeling a problem, we can talk about entities without having to think about how they are implemented in the resulting software. But when it is time to start coding, there are patterns to follow to ensure that these objects have the technical attributes of Domain‑Driven Design entities. ‑As you can see from this section of the DDD navigation map, entities are pretty integral to our software. So, before we can learn about these other elements, domain events, repositories, factories, and more, you should have a very good understanding of an entity. ‑The most important entity in our model is Appointment. This is what we will be creating, editing, and retrieving in the context of scheduling appointments. Appointment inherits from a base class we\u0026rsquo;ve created called Entity. We\u0026rsquo;ll look at that more in just a bit. Notice that all of the classes shown here are inheriting from the identity base class. However, although the other classes are entities, after our discussions with Michelle, we came to the conclusion that we would like to have a separate utility for managing client and patient information and to manage information about staff and staff scheduling. Thus, we don\u0026rsquo;t need very much information or behavior related to these collaborating entities within the bounded context of appointment scheduling.\nDifferentiating CRUD from Complex Problems that Benefit from DDD ‑Let\u0026rsquo;s take a closer look at that data that supports scheduling appointments in our system. ‑We determined that managing the client, patient, and staff information, which is external to this model, was well‑suited to just simple CRUD. We didn\u0026rsquo;t identify complex rules or behaviors for creating and editing that data. Thus, the concepts of doctors, rooms, clients, and patients are managed outside of the scheduling bounded context. ‑For comparison, look at the CRUD classes for Patient and Client in the other bounded context. They\u0026rsquo;re very simple. They don\u0026rsquo;t inherit from our entity base class, and most interestingly, their ID properties are integers. We\u0026rsquo;ll let the database assign the IDs when we create these classes. So these classes are not designed using domain‑driven design. Now let\u0026rsquo;s go back to the appointment scheduling context. The client, patient, doctor, and room classes here are completely different from the CRUD classes we just saw. However, they do have a subset of the same fields from those CRUD classes. All we need to know about these objects when we\u0026rsquo;re scheduling is their IDs, their names, and maybe a few other details. But here, they\u0026rsquo;re simply used as look‑up data, and they\u0026rsquo;reread‑only.\nSwitching Between Contexts in a UI Even though our domain is split up into a number of bounded context, the user interface can be designed in a way that moving from one context to another is seamless to the end users, they don\u0026rsquo;t need to know that these things are in separate bounded contexts. While maintaining client and patient data is a completely separate task from scheduling appointments, Michelle wanted to be sure that anyone working at the front desk is able to easily move between these tasks in the software without disrupting their workflow. So let\u0026rsquo;s say the person at the clinic who does the scheduling is on the phone with Kim and about to make an appointment for Roxy to come in, but then the other line rings, they put Kim on hold, and it\u0026rsquo;s me. And in the nicest way possible, I\u0026rsquo;ve called to just let her know they\u0026rsquo;ve got my last name spelled wrong. That happens all the time. People just want to put that h in there. Even though they\u0026rsquo;re in the middle of scheduling and scheduling has its own backend, its own bounded context, and is totally separate from client management, they can still drive the app right over to the Client Management area and very quickly fix my name and save that. Then they can just flip back to the schedule. Notice that Kim is still the active scheduling client that\u0026rsquo;s showing up in the left‑hand corner and the change to the spelling of my last name is already visible on the schedule. And so now that person can go ahead and finish up with Kim scheduling the very adorable Roxy for a wellness exam. To the user, there is no real difference between doing the scheduling and doing the client management, it\u0026rsquo;s just a nice smooth flow between the two, it doesn\u0026rsquo;t feel like, oh, now we have to open up a different application in order to do this other thing and doesn\u0026rsquo;t break everything they\u0026rsquo;re in the middle of, but for the purposes of designing our application, everything is bound within its own individual context. And when designing this context, we don\u0026rsquo;t have to worry about switching from one context to another. ‑So remember, we\u0026rsquo;re talking about what makes these all entities. An appointment object needs to be located and tracked and we need to be able to edit them easily. Using a unique identity allows us to persist and retrieve an appointment even if some of its values change. Appointment is definitely an entity in our system. We actually had to think a little more about client, patient, doctor, and room in this particular context. Our discussions highlighted the fact that when creating appointments, we only need access to some of the high‑level information about the client, patient, doctor, and room, but these objects won\u0026rsquo;t be edited. So we wanted these stripped down read‑only types that give us minimal amount of detail for each. We do still need to be able to uniquely identify them though, they do have some identity. If the client\u0026rsquo;s name changes, a change we would make in the client management system, that new name will need to be reflected when we look at the appointment scheduling for that client. There should only ever be one record to represent a particular client in this bounded context. So client and the other types that are reference types in this context are still entities. We triple checked our decision with another kind of domain expert, Vaughn Vernon, a DDD expert, and we were happy to get his thumbs up on this particular decision. So Julie, Michelle, and I also talked about how to name the types that are simply reference types in this particular bounded context. At first, we were worried that we might get confused by having different definitions of client, patient, doctor, and room. We wanted to call them client details or client view or something like that, but thanks to the ubiquitous language, the fact that we are in the scheduling context drives our comprehension of what a client means in this particular space. ‑A client in scheduling is still a client, so we use the same name, even though it\u0026rsquo;s a differently defined pipe than the client we work with in the Client/Patient Management app. ‑Right, and thanks to namespaces in our code, we\u0026rsquo;re able to keep it clear which ones are which in the code.\nUsing GUIDs or Ints for Identity Values So, all these types inherit from our base entity class. However, notice that those reference types use int for their base entity\u0026rsquo;s ID and not the GUID that\u0026rsquo;s used by appointment. That\u0026rsquo;s because all of the management of those other types happens to be done using CRUD, and with CRUD, it\u0026rsquo;s easy to just use database‑generated ints. Appointment is built using DDD principles, and you\u0026rsquo;ll see that it\u0026rsquo;s much easier to use GUIDs when building DDD entities and their related logic rather than relying on the database to provide the identity values. Not only is it easier, but it follows DDD principals more clearly, since we will build all of our domain logic around appointments without involving the database. We would have a hard time working with appointments in our model and in our unit tests as we develop the application if we always needed a database to assign their IDs. ‑So that\u0026rsquo;s not to say that you can\u0026rsquo;t use integer IDs If you\u0026rsquo;re going to use a DDD style of application; it just makes it a little harder. Wouldn\u0026rsquo;t you say, Julie? ‑Yeah, yeah, and I\u0026rsquo;ve definitely come up against that. With the stuff that I do with Entity Framework, I\u0026rsquo;ve made sure that I show patterns for continuing to use the database‑generated ints because I didn\u0026rsquo;t want to give people the impression that they had to throw away, like, for me like 25 years of this dependency. And like all of a sudden I have to go cold turkey and move over to GUIDs. ‑Sure, I mean, there\u0026rsquo;s trade‑offs in what you choose to use for your ID, but having an ID that we can generate in the client and just in our code has a lot of value. ‑Every time we\u0026rsquo;ve been working on some of our different unit tests and we needed as part of the test to instantiate something that was an int, we were like, ugh, now we have to find another way to get that in there because we were protecting it and it was a problem. As our own experience grew, we realized there\u0026rsquo;s another way to bridge this conflict by using both GUIDs and database‑generated ints in an entity. This way, while creating objects, you\u0026rsquo;ve got the control over key generation with the GUIDs, and they\u0026rsquo;re not depending on the database. However, once the data has been created in the database and int keys exist for it, then you can benefit from those when adding indexes and performing queries in the database.\nTalking with Eric Evans About the Responsibility of Entities We talked with Eric Evans to gain some additional insight into entities. Specifically, I asked him how entities align with the single responsibility principle. ‑‑If you\u0026rsquo;re not familiar with this object‑oriented programming principle, you can learn more about it in Steve\u0026rsquo;s SOLID course right here, on Pluralsight. ‑‑One of the questions that I\u0026rsquo;ve heard is, What is the single responsibility for an entity? Or to put it another way, does having an entity that has a lot of business logic in it violate the single responsibility principle? ‑‑Eric told us that entities are very central, and so it\u0026rsquo;s natural that they get heaped up with lots of functionality. ‑‑But there\u0026rsquo;s a downside to this. As you build out the system, there are more and more conflicting demands for these central entities, so they end up being huge. Evans said that the main responsibility is the identity and the lifecycle. ‑‑Eric also told us that single responsibility is a good principle to apply to entities, and it points you towards the sort of responsibility that an entity should retain. Anything that doesn\u0026rsquo;t fall into that category, we ought to put somewhere else.\nImplementing Entities in Code Let\u0026rsquo;s take a look at an entity in our veterinary appointment scheduling application, FrontDesk. We\u0026rsquo;re going to look at the Appointment class, which defines all the information that we need to schedule an appointment for a particular animal or patient. It associates the patient with the doctor, room, and appointment type, and also includes the start and end time for the appointment. Now, the Appointment class inherits from BaseEntity, which is a generic base class. In this case, it\u0026rsquo;s BaseEntity, as you can see here. The GUID is defining the type of our identity property, our ID. ‑Right. And we talked about that earlier when we were looking at the structure of the different entities in this model. We wanted Appointment to have a GUID because we\u0026rsquo;re creating new appointments on the fly. So, let\u0026rsquo;s take a look at that BaseEntity class. First of all, it\u0026rsquo;s an abstract class. So we can\u0026rsquo;t just create a BaseEntity object, we have to create something that is a BaseEntity, such as an appointment. And using generics, we\u0026rsquo;re saying that the BaseEntity is going to use whatever type we ask it to, and that type is for defining the ID. So for Appointment, we said BaseEntity is going to be using a GUID as its identity. I mentioned this earlier, why I would need GUID for appointment in this context because I need to be able to create new appointments in this context, and I\u0026rsquo;m not going to be waiting for the database to generate the ID for me. So using a GUID lets me create that ID right up front as I\u0026rsquo;m creating that new appointment. So I\u0026rsquo;m giving it its ID. The BaseEntity class also has a property to hold a list of domain events that will define explicitly for each of the types that inherit from this base entity. You\u0026rsquo;ll learn more about domain events further on in this course. ‑All right, so let\u0026rsquo;s take a look back at the rest of Appointment. Now, since Appointment has more behavior than just state, we don\u0026rsquo;t want to have it just be a bag of properties that our application can get and set however they would like. ‑Because that would be an anemic domain model. ‑Yes, because that would tend to lead us toward a more anemic domain model. ‑And we want a rich one. ‑Now, in particular, we\u0026rsquo;re also constraining how we create this appointment. We want to ensure we create appointments in a valid state, so that means passing in the minimum necessary elements an appointment needs to have. Sometimes we\u0026rsquo;ll want to update an appointment. Remember, these aren\u0026rsquo;t value objects. They\u0026rsquo;re not immutable, so we can change them. When we need to modify an appointment, we\u0026rsquo;re going to do that through methods. And so, for instance, if we decide we want to modify what room an appointment is scheduled in, we\u0026rsquo;re going to do that through a method rather than just a setter. We do this because there\u0026rsquo;s additional behavior we may want to do. In this case, we have some guards, again to ensure a valid value is being passed. ‑These guards are a set of reusable functions that you\u0026rsquo;ll find in the shared kernel of our solution. ‑And we also want to raise an appointmentUpdatedEvent, that we might handle and send a notification or perform some other action as a result of what happened. ‑And that also gives us the flexibility in the future to change what type of logic we want to trigger. ‑And that\u0026rsquo;s something we can\u0026rsquo;t do very easily If we just let anybody in the application set the value. ‑Right. ‑By providing a method to use to update room explicitly and otherwise making the setter private, we force all interaction with the model to use this method, which gives us just one place to model behavior that should be associated with this operation. It\u0026rsquo;s the same as with the constructor, we need to do our best to keep our domain model in a consistent state so the rest of the application can count on it being correct. ‑Right, because otherwise somebody could satisfy the requirement that they pass in the room ID, but they might pass it in as 0, which would be invalid. So, we\u0026rsquo;re further constraining that they don\u0026rsquo;t do that either. The appointment would be invalid if it had a room ID that didn\u0026rsquo;t correspond to an actual room entity. And in any case, the database wouldn\u0026rsquo;t let that fly since there\u0026rsquo;s a foreign key relationship between appointment and room. ‑Yes, but we want to make at least some effort to catch such problems in our code, rather than relying on the persistent store to inform us of a user error. Overall, using guard clauses, like the ones you\u0026rsquo;ve seen here, help us ensure our entities aren\u0026rsquo;t partially constructed and inconsistent. Once we\u0026rsquo;ve created an appointment, we need to record it as part of the clinic schedule, which involves some additional rich behavior. So, if we scroll down to the bottom, we have this method called Schedule. And this is where we\u0026rsquo;re going to do the additional work involved with actually saving an appointment and ensuring it fits in with other appointments that have already been scheduled. We\u0026rsquo;re not going to worry about the code at the moment, but the idea is that this method would query the database for other appointments that might be near this one and make sure there is an available slot in the schedule that this one fits into. Then it will save the appointment and raise an event, letting the rest of the app know that a new appointment has been scheduled. In the next module, we\u0026rsquo;ll investigate this design further and revise it a little bit. Now, let\u0026rsquo;s look at one more simple entity that this bounded context needs, the Doctor class. You can see that Doctor inherits from BaseEntity as well, but in this case it\u0026rsquo;s using an int for its key. The only other property it has is a string Name property. ‑This is a minimal implementation of the Doctor type that satisfies the scheduling bounded context. It\u0026rsquo;s essentially no more than a reference type. Doctor and the other similar types, Patient, Room, etc., are all organized into this folder called SyncedAggregates.\nSynchronizing Data Across Bounded Contexts Let\u0026rsquo;s dig a little more into how these reference types in the scheduling bounded context are getting their data from the Clinic Management app, especially if the two BCs aren\u0026rsquo;t sharing a database. If you recall from seeing the class descriptions of all of these classes, the AppointmentType, Client, Doctor, Patient, and Room, we had explicitly decided that these are reference entities where we\u0026rsquo;re actually doing their maintenance elsewhere so they\u0026rsquo;re not adding any unneeded complexity to the Front Desk application. ‑‑Right. And they\u0026rsquo;re just READONLY. So we\u0026rsquo;re never having to create or modify them. ‑‑And we\u0026rsquo;re using the ints that were created by the database when we persisted these with a CRUD context in a different application, but there are still entities here, just entities of type integer. The Clinic Management bounded context is responsible for updating these types. When changes are made, application events are published by Clinic Management, and this Front Desk bounded context subscribes to those events and updates its copies of the entities. ‑‑One of the questions we get all the time when we describe how bounded contexts have separate databases is, How do we synchronize changes between these two apps? This is one of the simplest and most common approaches. One app is responsible for updates, and the other apps just subscribe to the changes and are notified when they occur. ‑‑This is an example of eventual consistency. The two systems aren\u0026rsquo;t immediately kept in sync using a transaction or something similar, but through message queues, eventually the different bounded contexts are updated to the new state when a change is made.\nReview and Resources We\u0026rsquo;ve covered a lot of ground in this module and you\u0026rsquo;ve learned a lot of new terms, so we just want to review some of them with you before we move onto the next module. The first is a pair of terms that often go hand in hand, anemic domain models versus rich domain models. And remember the anemic domain models, while often looked down upon from the perspective of DDD, they\u0026rsquo;re perfectly fine for CRUD. These are models that look a lot more like a database schema than a class that has lots of methods and rich behavior in it. On the other side of that is a rich domain model, which is what we strive for in domain‑driven design, and that\u0026rsquo;s a model that really is focused on behavior, not just changing the values of properties. ‑Then we talked about entities and entities tend to be one of the core pieces of our domain model. The key thing that distinguishes an entity from other types in our model is that it has some kind of identity that we can use to track it over time and to bring it in and out of persistence. This module provided you with your first look at implementing a bounded context in code, an important part of tactical design. You learned about the difference between anemic models and rich models, and that while anemic models have their place, focusing on behavior with rich domain models is how DDD lets us solve complex problems. Entities are the classes in our domain models that are tracked by an identifier allowing us to build graphs and eventually persist and retrieve that data. ‑Sometimes we are working with entities whose behavior and rules are critical to the bounded context in which we\u0026rsquo;re working. Other entities may only provide supporting or reference data. You learned how to help identify the differences between them. Then you got to look at the appointment class in our scheduling app to see how we have applied rules and behaviors in that entity. You also looked at one of the reference entities and learned how we use message queues to ensure the reference and the data that is maintained in the clinic management app is made available to the scheduling bounded context, even though they do not share a database. ‑In the next module, we\u0026rsquo;ll focus on some more important elements of a domain model, value objects and domain services. We\u0026rsquo;ve referenced a lot of interesting and helpful resources in this module and here are two pages of links for you to follow up with if you want to dig in a little further, including Steve\u0026rsquo;s Pluralsight course on SOLID principles of object‑oriented design and information on event storming and event modeling. This is Julie Lerman ‑and this is Steve Smith, and thanks for watching our course, Domain‑Driven Design Fundamentals.\nUnderstanding Value Objects \u0026amp; Services in the Model Introduction and Overview Hello! I\u0026rsquo;m Julie Lerman. ‑And I\u0026rsquo;m Steve Smith. Welcome back to Domain‑Driven Design Fundamentals. In this module, we\u0026rsquo;ll continue exploring the elements of a domain model as we dig into value objects and domain services. ‑Value objects are a confusing concept. So we\u0026rsquo;ll begin by looking at where they fit into the mind map and introducing what makes an object a value object, and how they relate to entities in a model. ‑We\u0026rsquo;ll share some more guidance from Eric Evans and Vaughn Vernon, and then show how we\u0026rsquo;ve implemented value objects in our code. ‑Next, you\u0026rsquo;ll gain a high‑level understanding of domain services, and solidify that by exploring their features, and then some examples of domain services.\nGetting Acquainted with Value Objects When introducing entities, Steve and I talked about objects that were defined by a thread of continuity and identity, not defined by their values. So, what about objects that are defined by their values? These are called value objects, and they play an equally important role in a domain model, as entity objects do. ‑A value object has very specific characteristics. It is an object that is used to measure, quantify, or describe something in your domain. Rather than having an identity key, its identity is based on the composition of the values of all of its properties. Because the property values define a value object, it should be immutable. In other words, you shouldn\u0026rsquo;t be able to change any of the properties once you\u0026rsquo;ve created one of these objects. Instead, you would simply create another instance with the new values. If you need to compare two value objects to determine if they are equal, you should do so by comparing all of the values. Value objects may have methods and behavior, but they should never have side effects. Any methods on the value objects should only compute things; they shouldn\u0026rsquo;t change the state of the value object, since it\u0026rsquo;s immutable, or the system. If a new value is needed, a new value object should be returned. Don\u0026rsquo;t confuse the value object\u0026rsquo;s pattern with C# and .NET support for value types and reference types. Custom value types in C# are defined with structs, while reference types are defined as classes. In DDD, both entities and value objects are typically defined as classes. Classes have advantages over structs when it comes to encapsulation and support for inheritance‑based extension and reuse.\nRecognizing Commonly Used Value Objects To help you better understand the basics of value objects, let\u0026rsquo;s take a look at some value objects that you probably use all the time as a developer. The most commonly employed value object is a string. In .NET and many other languages, a string type is immutable, and you now know that immutability is one of the key attributes of a value object. A string is a collection of characters, and the combination of all those characters give that string meaning. For example, C‑A‑R in English, a car. If a string were mutable, we could change the R to T. Now the string is C‑A‑T, a cat, which has a very different meaning than a car. Or we could add a letter, maybe put an S in front of it, turning CAR to SCAR, also completely changing the meaning of car. But it\u0026rsquo;s not just the array of characters that gives a string its meaning, the order of them is also critical. Just think of the word dog, d‑o‑g. Shifting its letters around gives us something with a very different meaning. ‑So one of the things that .NET makes it really easy to do is to modify strings, like you can change the length of it or make one all upper case. But when you call, for example, ToUpper on a string, it doesn\u0026rsquo;t just change that string object, it gives you a new instance of a string that now has all uppercase characters. ‑Many developers say that monetary values in financial systems have been perfect candidates for value objects in their system. And Ward Cunningham provides us with a really helpful example, a company\u0026rsquo;s worth. If a company is worth 50 million dollars, that means something, 50 million dollars. It\u0026rsquo;s a very specific measurement. Fifty million on its own is not a measurement, it has no meaning without the unit, which in this case is dollars. But dollars alone doesn\u0026rsquo;t describe worth either. In fact, dollars doesn\u0026rsquo;t really help, does it, because is it US dollars or Canadian dollars, Australian dollars? It only makes sense when you put the two together as 50 million US dollars. There\u0026rsquo;s actually one more factor to take into account, is the point in time of this 50 million dollars because of the way financial systems work and the fluidity of monetary values. ‑We could still just have the two properties in this Company class, but by creating a value object you also protect and constrain the measurement. For instance, we might have a class called Company. It might have one decimal property that represents the worth amount and another string property that represents the worth unit. The problem with this approach is that it doesn\u0026rsquo;t tie these properties together in any way. These two properties appear to be independent of one another, but they\u0026rsquo;re obviously closely related. If an update is made just to the Worth Unit string, it could obviously have a tremendous impact on the company\u0026rsquo;s worth as a combination of these two concepts. Fifty million rupees has a very different worth than 50 million US dollars. To ensure nobody can set the unit without also specifying the amount, a separate value object can be introduced to represent the entire worth concept. This ensures the entire object must be updated as a whole. Since the worth type is immutable, the only way to make updates to the Worth property on the Company class is by replacing the whole instance with a new one, not just changing an isolated field. ‑A value object is not always for a measurement though. It can be another type of description. Eric Evans calls out dates as a great example for value objects. I\u0026rsquo;ve used this one often, DateTimeRange, and it was perfect for the vet appointment scheduling app. We usually set a start and an end time together and can\u0026rsquo;t really set one without the other. Also, we often need to pass the two values, start and end time, around from one method to another. So we\u0026rsquo;ve encapsulated them in a value object called DateTimeRange. The properties have private setters, which makes the object immutable since we can\u0026rsquo;t change them. We aren\u0026rsquo;t showing the full logic of the class here, but when we look at the value objects in our application you\u0026rsquo;ll see more of how we implement a value object in our software to ensure that it meets all of the attributes, not just immutability, but how we handle equality, comparison, and other logic.\nGetting More Insight from Eric Evans and Vaughn Vernon In his book, Implementing Domain‑Driven Design, Vaughn Vernon recommends that we should try to use value objects, instead of entities, wherever possible. He says, it may surprise you to learn that we should strive to model using value objects instead of entities wherever possible. Even when a domain concept must be modeled as an entity, the entity\u0026rsquo;s design should be biased towards serving as a value container rather than a child entity container. What this means is that you\u0026rsquo;ll find that your design will have a number of entities who have very little logic of their own or very few primitives as their properties, but instead will have a number of properties that each are themselves a value object. ‑So he\u0026rsquo;s not saying everything should be value objects, but that it\u0026rsquo;s probably our natural instinct to start by thinking of things as entities and then maybe once in a while go, oh, maybe that should be a value object. So what Vaughn is suggesting is really start by thinking every time should this be a value object and you will surprise yourself at how many times something that you originally might have thought of as an entity really does make a lot more sense as a value object. ‑Or sometimes when you\u0026rsquo;re looking at an entity, there might be a couple of properties that seem to always go together, you might be able to bundle these properties into a single value object. It\u0026rsquo;s interesting to note that identity values can be treated as value objects as well. In many systems, entities have a primitive type, usually int or GUID as their ID, but this means that it\u0026rsquo;s easy to substitute a client ID for a patient ID if developers are not careful. By creating actual value objects for client ID and patient ID, which can still be stored as ints or GUIDs, it can eliminate this kind of error from our design. ‑Here is an example of a Client class that\u0026rsquo;s inheriting from base entity, but specifying that the type will be ClientIdValueObject rather than a scalar type like int or GUID, that\u0026rsquo;s followed by a service class that has a CreateAppointmentFor method which takes a clientId and a patientId. If those IDs were both GUIDs, the runtime code would allow you to accidentally pass them in in the wrong order because the signature is only constraining that you pass in two GUIDs and that could create a big problem when you\u0026rsquo;re trying to build an appointment. But with the specialized value objects, you can tightly constrain the parameters to avoid this problem rather than adding a lot of extra logic elsewhere to protect you from making that mistake. For me, this highlights the beauty of DDD thinking. With this little bit of upfront work, you\u0026rsquo;re removing the complexity of solving the kind of problem that could be created by accidentally transposing the client id and patient id. In our conversations with Eric Evans, we asked him for his thoughts on putting logic into value objects. He told us that he thinks value objects are a really good place to put methods and logic because we can do our reasoning without side effects and especially the complications that identity brings along, all those things that make logic tricky. We can put functions on those value objects and then do the pure reasoning right there in the value object. ‑Eric also called out date libraries as a good example of a value object. They perform common functions on dates so we don\u0026rsquo;t have to keep coding them ourselves in our entities or services. For example, a date library could be used for calculating a person\u0026rsquo;s age from their birth date. As long as the library causes no side effects to the date in question, it can work well as a value object.\nImplementing Value Objects in Code Our primary demo involves scheduling appointments. Appointments have a start and an end time. These two things always go together, so they make sense to extract as a value object. Here\u0026rsquo;s a closer look at the DateTimeRange ValueObject we created for the course\u0026rsquo;s demo. We also have a DateTimeOffsetRange, which is identical, but includes support for time zones. Because DateTimeRange is a pretty low‑level concept that could be useful in a number of different applications, it\u0026rsquo;s implemented in the shared kernel package. The class inherits from a ValueObject base class that provides flexible equality checking behavior, so we don\u0026rsquo;t need to clutter our class with overloads for Equals, GetHashCode, et cetera. It was written by fellow author and DDD expert, Vladimir Khorikov. ‑Because this is a ValueObject, you can see that all of its properties are read only. Recent versions of C# and Entity Framework Core do allow us to avoid even having a setter in there when we want to define read‑only properties, and we also now have the use of records in C#. EF Core can comprehend read‑only properties that don\u0026rsquo;t have any setters at all, and it takes advantage of fields. But here we\u0026rsquo;ve written our value objects in a more generalized way that\u0026rsquo;s not taking advantage of any specific or specialized features. However, you can adapt these samples to benefit from those specific APIs and language versions that you\u0026rsquo;re working with. The important goal here, though, however you implement it, is that the state of the value object should not be changed once it\u0026rsquo;s been created and as part of the domain model. ‑Right. Value objects should get all of their state through their constructor, and any invariants that need to be checked should happen in a constructor as well. In this case, the date time range is guarding against having a start time that exceeds its end time. If it does, an exception will be thrown. The second constructor that takes a timespan calls the first one using constructor chaining, so in either case, the guard will always be enforced. Since the DateTimeRange is immutable and cannot be created in an invalid state, the rest of the domain model can count on it being valid. ‑Our DateTimeRange type does have some additional methods that let us create new DateTimeRange instances from existing ones, much like the DateTime type provides options to create new date times by adding time to an existing instance. In our type, for example, to change an appointment set to end at 10:30 instead of ending at 11:00, a new instance of DateTimeRange can be created using the newEnd method. Finally, the base ValueObject class requires overriding a GetEqualityComponents method. This is used when comparing two instances of the ValueObject, and it\u0026rsquo;s up to you to decide which properties should or shouldn\u0026rsquo;t be included. In the case of DateTimeRange, the start and end times are sufficient. If two DateTimeRange instances have the same start and end values, they should be considered equal. ‑Custom logic needed to determine whether one appointment overlaps with another is another area where the ValueObject can help. The whole appointment isn\u0026rsquo;t needed to determine if there is an overlap in appointments. Only the DateTimeRange is used in such a calculation. Thus, the Overlaps method, shown here, has been moved out of the Schedule and Appointment classes and into the ValueObject, where it is more reusable, and it reduces the complexity and responsibilities of the other domain types. ‑We asked Eric to share his thoughts on moving logic out of entities into value objects. He agreed that it\u0026rsquo;s a good idea. What he said was if there\u0026rsquo;s logic that\u0026rsquo;s really the classic software logic, I like to add that in value objects. You can really test value objects much easier than entities, and you can use them much more freely. So your entity becomes this critical piece of glue, an orchestrator among different value objects. But that doesn\u0026rsquo;t mean that you won\u0026rsquo;t have some logic in the entity. It\u0026rsquo;ll just be very concise. ‑Eric also said that it\u0026rsquo;s a nice way to work towards the ubiquitous language to the point where you look in the methods of the entity and you see higher‑level things. They read like use case level communication, rather than nitty gritty detail. My personal takeaway from this is to keep an eye on the properties of your entities, and specifically, their types. If you find that they\u0026rsquo;re all primitive types, like ints and strings, think about if any of those primitive things could be grouped together as value objects instead. Another value object that we can point out here is the AnimalType. This is just to give you an idea that our value objects can be extremely simple. In this case, AnimalType is just a combination of the species and the breed of a particular pet or patient that we\u0026rsquo;re dealing with at the vet clinic. And there\u0026rsquo;s not a whole lot of other behavior here. But it does provide us with a container by encapsulating these two related properties together as a single value object.\nUnderstanding Domain Services When an operation is important to the model but doesn\u0026rsquo;t necessarily belong on any one entity or value object, a service is often appropriate. But don\u0026rsquo;t be too quick to give up on finding a natural home for the operation on an existing entity or value object or you may end up with a very procedural anemic model. Frequently, domain services serve as orchestrators for operations that require several different collaborating entities or value objects. Evans notes that good domain services must first and foremost not be a natural part of an existing entity or value object. Again, we don\u0026rsquo;t want to shift all of our rich behavior from our entities and value objects to our services. Services should also have a defined interface that\u0026rsquo;s comprised of domain model elements. And finally, domain services should be stateless, though they may have side effects. What this means is we should always be able to simply create a new instance of a service to perform an operation, rather than having to rely on any previous history that might have occurred within a particular service instance. But of course, the result of calling a method on a service might result in changes to the state of the system itself. These rules apply specifically to domain services which belong in the core of our application. Your software will likely also use services to perform work related to infrastructure or as part of the front end of the application. ‑Here are some examples of the kinds of services we might find in different layers of a DDD application. The UI layer represents the front end of the system and should have as little business logic as possible. It is frequently combined with the application layer, which should be concerned with behavior necessary for the application, but unrelated to the customer\u0026rsquo;s problem domain. For example, the application may need to work with file formats or parse some XML, and it might have services for these purposes, but these are unrelated to the domain. In the core of the application where we store our core model and domain objects, we will define any domain services for operations that don\u0026rsquo;t belong somewhere else. These services will frequently involve operations on multiple domain elements or may be responsible for orchestrating some kind of workflow. For instance, processing an order might involve a series of steps and multiple domain elements as the system checks inventory, verifies customer information, maybe charges a credit card, and then sends messages to ship the order, notify the customer, and reduce inventory. Finally, we have infrastructure‑level services. These will usually implement interfaces that are defined in the core of the domain, such as I send email. But since they require access to external dependencies, like file systems, databases, or network resources, they live in the infrastructure layer of the system. With respect to our domain, you may find infrastructure not very interesting, ‑although the people who create the internal workings of those services might find them quite fascinating. We\u0026rsquo;ll look at implementing services in our application later on in the course.\nReview and Resources Let\u0026rsquo;s review some of the important terms you learned in this module. You heard us talk about immutability, which is a really critical attribute for value objects. And immutability just means once an object has been instantiated, you can\u0026rsquo;t change the value of any of its properties. ‑Another important term we learned about is the value object. A value object is an immutable class that is defined by the sum of the different properties that it has. We don\u0026rsquo;t need an identity for a particular value object. In fact, a value object doesn\u0026rsquo;t have any identity outside of the individual properties that it has. And in order for us to compare value objects, we simply compare all of its properties, and if they all match, then we can consider these two value objects to be equal. We also learned about domain services and these are interesting because domain services give you a place to put logic and behavior that you can\u0026rsquo;t find a home for in the entities and value objects in your domain. ‑And the last term that we want to review is side effects. Side effects are changes that occur in your application or any kind of interaction with the outside world. Now, technically any change to the state of the application can be considered a side effect, but generally when we\u0026rsquo;re talking about them, we\u0026rsquo;re talking about things that changed other than the main intent of the operation that you\u0026rsquo;re performing. For instance, it\u0026rsquo;s often a good idea to keep operations that query information separate from those that change state, and if you follow this practice, then any queries that you make, that result in changes to state would be said to have side effects. That brings us to this module\u0026rsquo;s key takeaways. Most of this module was focused on value objects, which are used in your domain model to measure quantify or describe something in the domain. Value objects typically don\u0026rsquo;t exist alone, they\u0026rsquo;re usually applied to an entity to describe something about it. ‑Value objects should be compared using only their values. They don\u0026rsquo;t have an identity. Any two value objects that share the same values should be considered equal. And value objects in our domain should be designed to be immutable taking all of their needed values in their constructor and they shouldn\u0026rsquo;t have any side effects. ‑We looked at a few examples of value objects in this module. We mentioned the .NET Framework string type that you\u0026rsquo;ve no doubt used. Strings and datetimes are value objects that are available to any .NET application and can be used as a model for how you should design your own value objects. We also looked at a couple of custom value objects we used in our sample application, the datetime range and the animal type objects. ‑Finally, we wrapped up the module by introducing domain services, which are used to orchestrate operations between different parts of your domain model. Remember that domain services should generally only be used if you don\u0026rsquo;t have an entity or value object where the behavior makes sense. Overuse of domain services can lead to an anemic domain model. In the next module, you\u0026rsquo;ll learn how to build aggregates from entities and value objects while respecting their relationships. Here are some links and resources relevant to the topics of value objects and domain services that we discussed in this module. Thanks for watching Domain‑Driven Design Fundamentals.\nTackling Complexity with Aggregates Introduction and Overview Hello, this is Julie Lerman. ‑And this is Steve Smith. ‑Welcome back to Domain‑Driven Design Fundamentals. In this module, you\u0026rsquo;ll learn more about aggregates and the associations between entities. ‑We\u0026rsquo;ve talked about the domain model and the need to have effective communication in order to ensure the model is a useful representation of the customer\u0026rsquo;s problem space. However, most problems that weren\u0026rsquo;t using domain‑driven design can be quite complex. So now we\u0026rsquo;re going to specifically look at some patterns and techniques that can be used to manage this complexity. ‑We\u0026rsquo;ll cover several new terms along the way, including aggregates and aggregate roots. You\u0026rsquo;ll learn about invariants and the aggregate roots\u0026rsquo; responsibility for them. Aggregates often contain related data, so we will explore how to model relationships, often referred to as associations in DDD. ‑Then, we\u0026rsquo;ll look at our application and see how thinking about the aggregate roots pattern helps us revise and simplify our model. ‑And finally, we\u0026rsquo;ll walk through how we\u0026rsquo;ve implemented this pattern in our code.\nTackling Data Complexity Let\u0026rsquo;s start by considering data complexity. If you\u0026rsquo;ve ever worked on a relatively large or mature application, you\u0026rsquo;ve probably seen some fairly complex data models. One way to reduce the complexity that we already talked about is using aggregates and aggregate roots, which you\u0026rsquo;ve seen in the DDD mind map. Another is by limiting how many bidirectional relationships you have in that data model. ‑If your design doesn\u0026rsquo;t have any clear notion of aggregates, the dependencies between your entities may grow out of control, resulting in a model like this one. And if your object model reflects a data model like this one, trying to populate all of the dependent objects of one object might result in trying to load the entire database into memory. And the same problem exists when it comes time to save changes. With a model like this, there\u0026rsquo;s just no limit to which areas of the data model might be affected. ‑Even though in the real world at the highest levels of your system all of these things really do interrelate, we need to be able to separate them to keep the complexity of the system in check. ‑I\u0026rsquo;ve gone into a lot of clients where their entity data model looks like this, and they\u0026rsquo;re using this one big, huge single model throughout their entire system. So, one of the things that I work on with them is breaking this down and using the whole concept of bounded contexts to start looking at what makes sense for smaller models. ‑Yeah, a system that\u0026rsquo;s designed like this is what we tend to call a big ball of mud because everything is just kind of slapped together, and it collapses under its own weight once it gets to a certain level of complexity. ‑Great. So, let\u0026rsquo;s see how we can use aggregates to help solve the problem.\nIntroducing Aggregates and Aggregate Roots Aggregates consist of one or more entities and value objects that change together. We need to treat them as a unit for data changes, and we need to consider the entire aggregate\u0026rsquo;s consistency before we apply changes. In the examples shown here, the address is part of the customer and the component is quite literally a part of the product. We can treat a set of changes to a customer and their address as a single transaction. Every aggregate must have an aggregate root, which is the parent object of all members of the aggregate, and it\u0026rsquo;s possible to have an aggregate that consists of just one object, in which case that object would still be the aggregate root. ‑In some cases, the aggregate may have rules that enforce data consistency that apply across multiple objects. For instance, maybe our product consists of a collection of components, but in order to be in a valid state, it needs to have a specific set of such components. As an example, if the product is a Lego minifig, the collection of parts won\u0026rsquo;t be a valid product unless it includes a head, an upper torso, a lower torso, two arms, two hands, and two legs. If we allowed the collection of components to be modified independently of the product it was associated with, we could easily end up with consistency problems. If we want to modify the composition of a product, in this example, we should do so as a transaction, so that we start and end with a valid product. Data changes to the aggregate should follow ACID, that is they should be atomic, consistent, isolated, and durable. It\u0026rsquo;s also the responsibility of the aggregate root to maintain its invariants, such as the number and type of components it requires in the example. An invariant is a condition that should always be true for the system to be in a consistent state. When considering whether particular objects should be treated as an aggregate root, you should think about whether deleting it should cascade, in other words, if you need to also delete the other objects in its aggregate hierarchy. If so, it\u0026rsquo;s likely the object in question should be considered an aggregate root. ‑Another way to think about whether it makes sense to have an object as an aggregate root is to ask, does it make sense to have just this object detached from its parent? In the example shown here, if you\u0026rsquo;re deleting the minifig, then you have to delete all of its parts. Conversely, if you have to delete a head, maybe it got broken, you don\u0026rsquo;t need to delete the rest of the parts. Therefore it doesn\u0026rsquo;t make sense for the head to be the root of this aggregate. ‑In the Domain‑Driven Design book, Eric Evans states this pretty simply, he says, an aggregate is a cluster of associated objects that we treat as a unit for the purpose of data changes.\nConsidering Associations in Aggregates When considering aggregates, which, as Evan says is a cluster of associated objects, it\u0026rsquo;s also important to think about relationships between those associated objects, especially those which exist within the aggregate. Before diving into how related entities participate in an aggregate, it\u0026rsquo;s important to learn some important concepts that DDD brings to us when considering relationships among entities. ‑Many developers, myself included, tend to define relationships between classes in both directions. For example, an order has a line item and a line item has an order, a pet owner has pets and a pet has an owner. Many of us tend to think in bidirectional relationships by default. Because domain‑driven design aims for simplicity in the model, we start recognizing more quickly that the bidirectional relationships can often make things overly complex. For instance, I\u0026rsquo;ve often found this to be true when it comes to adding in my persistence layer, and I happen to mostly use an ORM Entity Framework, which brings along its own behavior and assumptions about how relationships are managed. Sometimes the fact that my model includes navigation properties that may not be totally necessary can be the cause of some grief that\u0026rsquo;s led me to take some time to consider if I really need that navigation or not. ‑Domain‑driven design guides you to default to one way, or unidirectional relationships. That\u0026rsquo;s not to say that you shouldn\u0026rsquo;t ever have bidirectional relationships, but that because of the extra complexity involved, you should spend some time considering if that complexity is justified. ‑A relationship, also known as an association, should be part of a type\u0026rsquo;s definition, and we do that using properties that allow us to traverse from one end of the relationship to the other. In this example, we have a client type with a Patients property, and in a patient type, we have a Client property; not just an ID value, but a property that leads to a complete object or set of objects. If you introduce a bidirectional relationship, as shown in this code, using properties that let you traverse in both directions, you should only do so when neither object can be defined without the other. If that\u0026rsquo;s not the case, then you need to be specific about the direction of the relationship, also called the traversal direction, to keep your model design simple. ‑Eric Evans puts it this way, \u0026ldquo;A bidirectional association means that both objects can be understood only together. When application requirements do not call for traversal in both directions, adding a traversal direction reduces interdependence and simplifies the design.\u0026rdquo; ‑So with a DDDI, we can look at our model and ask, can we define a client without identifying their pets? Can we define a pet without identifying the client who\u0026rsquo;s responsible for them? ‑This may sound like a simple set of questions, but it could lead to a whole lot of debate. For example, why would a person be scheduling an appointment if they didn\u0026rsquo;t have a pet? So in the context of scheduling appointments, a client doesn\u0026rsquo;t make a whole lot of sense without one or more pets or patients. ‑Or from another perspective, a cat can\u0026rsquo;t pay a bill or call to make an appointment, so how can we define a pet without a client? These are both pretty reasonable arguments, but neither one gets us anywhere. ‑So, let\u0026rsquo;s start again with defaulting to a one‑way relationship. A client would need a patient to schedule an appointment. A client would not need a patient to pay a bill. ‑Okay, and if we started from the patient end, a patient doesn\u0026rsquo;t schedule an appointment, so that becomes a moot point. Nor does a patient pay the bill. And, you know, because my dog doesn\u0026rsquo;t have a credit card. He can\u0026rsquo;t use the phone very well, either. So, when would you start with a patient and need to know something about the client responsible for that patient? That\u0026rsquo;s an interesting question. So, in the context of scheduling an appointment, one could argue that we should define the traversal from client to patient and that we gain nothing by having a way to traverse from a patient back to a client. You may balk at that notion, but remember that all we care about right now is scheduling an appointment, not all the other possible scenarios where it might make sense to traverse from patient to client. ‑Sure. It\u0026rsquo;s another example of YAGNI, you\u0026rsquo;re not going to need it. In fact, we originally had owner as a property on patient in this context, but we realized it wasn\u0026rsquo;t necessary, so we removed it. However, we kept the ID because we had some scenarios where it was useful. ‑So in the end, we chose to define relationships that traverse from appointment to doctor, patient, and client, and to define one that traverses from client to patients or their pets, but not the other way. ‑You may have experienced another type of bidirectional relationship problem if you\u0026rsquo;ve seen related data gets serialized in your applications. When objects are serialized, the serializer typically traverses all of the object\u0026rsquo;s properties recursively, If there is a bidirectional relationship, it can create a loop that will cause serialization to fail. You can think of saving aggregates in much the same way, and in fact, depending on how your persistence layer is implemented, serialization may actually be required as part of how your app persists its aggregates. In our aggregates, the single direction that we would use would go from the root to its dependents, and never the other way around.\nHandling Relationships that Span Aggregates Aggregates serve as boundaries between logical groupings within our application. We enforce these boundaries by prohibiting direct references to objects within an aggregate that aren\u0026rsquo;t the root of the aggregate. Consider the customer with the address. It\u0026rsquo;s perfectly okay for customer to reference address. Address might be an entity, or it might be a value object; it doesn\u0026rsquo;t really matter in this scenario. What\u0026rsquo;s important, though, is that the only way to get to the address in this aggregate is through the customer. We won\u0026rsquo;t be referencing an address by some identity outside of this aggregate, but that\u0026rsquo;s not the case for customer. Since the customer is the aggregate root, it can be referenced from other aggregates. ‑In this common example, an order might reference a customer. Depending on our context, it might make sense for a customer to reference an order. In this case, let\u0026rsquo;s assume it only makes sense for the order to be central to the application\u0026rsquo;s design. What\u0026rsquo;s not okay is for the order to reference a customer\u0026rsquo;s address directly. This violates the integrity of the customer aggregate. ‑Remember that aggregates and aggregate roots only apply to objects, not data. And when we\u0026rsquo;re talking about references, we\u0026rsquo;re talking about object references, properties that use an object directly. This is especially important with ORMs. For example, if you were to save an address that had a customer object attached to the customer property, there are scenarios in which Entity Framework would involve the customer in the database INSERT or UPDATE, possibly even a DELETE. And this behavior leads to a lot of confusion. I frequently advise developers to just remove the navigation property and use the foreign key ID instead. It\u0026rsquo;s a little more work, but removing some of the ORM magic results in more control over the behavior. And this aligns perfectly with the fact that one common way to enforce aggregates is to replace direct navigation properties in the model\u0026rsquo;s non‑root types with key references, and this reduces the number of dependency relationships within the model.\nEvolving the Appointments Aggregate Since we\u0026rsquo;re dealing with appointment scheduling, our initial design might look something like this. An appointment involves bringing together a patient and a doctor in an exam room for a particular type of exam, and since we\u0026rsquo;ll typically need to know the owner\u0026rsquo;s information when we deal with the scheduling, it\u0026rsquo;s important to have a reference to the client from the patient also. So if we model our system this way, any time we saved an appointment, it\u0026rsquo;s going to scan all of these objects for changes and save them as well. So modeling it this way, the scope of our domain for appointment scheduling is much greater than it needs to be since, in our case, we don\u0026rsquo;t expect to modify any of the other objects when we\u0026rsquo;re creating an appointment. ‑Right, an appointment is basically just a list of resources tied to a particular timespan, it models who, what, when, and where, but it doesn\u0026rsquo;t ever need to change any of these associated concepts. As a result, we can simplify our design by eliminating most of these object relationships from the appointment classes designed. Recall that for an object to be a good candidate for being an aggregate root, it should be the case that deleting an object should also delete the other objects within the aggregate. In the design shown here, if a customer cancels an appointment and we delete it from the system, it doesn\u0026rsquo;t make sense that this should delete all of the associated objects. ‑So here is another perspective on that same model. By simply including the IDs of the related concepts rather than object references, we\u0026rsquo;re able to ensure that creating and changing appointments has a minimal impact on our system when we persist the appointment. This relationship works because an appointment in the real world is really just a note that includes a place, time, and additional details. Adding and removing appointments shouldn\u0026rsquo;t impact the people and places involved, and this revised design reflects this.\nUsing Invariants to Better Understand Our Aggregate We do still have a bit more learning to do with this model though. Somewhere in our design, we need to enforce certain invariants about appointments like that they shouldn\u0026rsquo;t be double booked. Our current thinking is that appointments need to include this rich behavior with regard to how they\u0026rsquo;re scheduled. It\u0026rsquo;s the aggregate roots responsibility to verify any invariance the aggregate may have, and in this case, the appointment is still acting as an aggregate root, even if we have eliminated the navigation properties to the other objects that it might be working with. Let\u0026rsquo;s make sure we\u0026rsquo;re clear on invariants and then we\u0026rsquo;ll see how invariants in our application impact our design. An example of an invariant in the real world is the speed of light, which is a constant that you just can\u0026rsquo;t break in terms of the physics of the universe as we know it. Some things in your system must be true in order for the model to be consistent or valid. Other examples of invariants might be that the total of the items on a purchase order do not exceed the PO amount, or that appointments do not overlap, or that an end date on an object must follow the begin date on that object. Sometimes an invariant only involves a single object, maybe a particular property or field such as name is required. In this case, we may model the system such that one can\u0026rsquo;t even create the object without the required information. Our value objects are like this. For example, you can\u0026rsquo;t create an instance of a datetime range object without defining both the start and end time. However, sometimes the invariants involved how multiple objects relate to one another. ‑In the example here, the purchase order and the individual line items would most likely be modeled as separate objects, however, the purchase order would be the aggregate root, and as such, it would be responsible for verifying this invariant. The individual line items on the purchase order probably don\u0026rsquo;t know anything about one another nor should they, so it wouldn\u0026rsquo;t make sense to put the responsibility for enforcing this invariant in the line item object. What about appointments? How does one appointment know whether it overlaps another?\nModeling Breakthroughs and Refactoring As we focused on these invariants and where they belong in our design, it became clear to us that the appointment didn\u0026rsquo;t really make sense as an aggregate root. If you apply this thinking to our appointment scheduling context, it follows that one appointment doesn\u0026rsquo;t really know anything about other appointments, but the schedule knows about such things. Let\u0026rsquo;s evolve our domain model to follow this pattern and see where that leads us. ‑This feels like a big change to the model, and these kind of epiphanies happen when you\u0026rsquo;re working on the model. But that\u0026rsquo;s not a bad thing. It\u0026rsquo;s not like you\u0026rsquo;ve wasted a lot of time focusing on appointment as an aggregate root. This is the beauty of modeling your domain, having conversations with different people, with the domain experts, because ideas like this bubble up, and suddenly, something big like this becomes clear. So, you\u0026rsquo;re not going to get it 100% right the first time. Your understanding will evolve as you learn more about the domain. And from time to time, you\u0026rsquo;ll realize there are big changes that can dramatically improve your design. In the Domain‑Driven Design book, Eric Evans talks about these breakthroughs in his section about refactoring toward deeper insight. This is really an important part of domain‑driven design, and about a quarter of the book is dedicated to it.\nRecognizing Signs of a Misidentified Aggregate Let\u0026rsquo;s take a look at the signs that Steve and I eventually recognized in our domain, which led us to shift our appointment aggregate to a schedule aggregate. ‑Originally, our solution had the appointment as the central focus of the design. I had figured it would be its own aggregate with appointment at the root and its various properties as its children. As we\u0026rsquo;ve just discussed, that doesn\u0026rsquo;t really work as well as I\u0026rsquo;d hoped, so now we\u0026rsquo;re refactoring the design to introduce a new type, the schedule. Before we show that, though, let\u0026rsquo;s review the original structure and some of the reasons it didn\u0026rsquo;t work as well as an aggregate in our solution. ‑You can see the original structure had appointment in its own folder and marked with the IAggregateRoot interface, which is required for it to be accessible from our repository methods. It has essentially the same properties as the later version, except for ScheduleId, since there\u0026rsquo;s no schedule type yet. And it has the same basic set of methods for modifying its room, doctor, time, and other properties. None of that really changed since all of those operations only had to deal with this single appointment instance. ‑However, when the appointment tried to enforce the invariant that appointments whose times overlap for the same pet should be marked as potentially conflicting, things were a bit messier. You see, this appointment doesn\u0026rsquo;t actually have any association with any other appointments, so the only way to enforce this is to use a repository to get those other appointments for the same date as this one. Since entities don\u0026rsquo;t support dependency injection through their constructor, this means an instance of the repository needs to be passed into this method. Creating this repository instance was the responsibility of the calling code, which may not otherwise have needed it. Note also that because the repository\u0026rsquo;s interface is async, this method must now be async as well, even though no other methods on the appointment entity are async. ‑The real problem here, from a DDD perspective, is that cross‑aggregate invariants should not be enforced by any one aggregate. In the case of something like a unique constraint between all aggregates, you might need to use a domain service, or another approach. However, in other cases, the need to do this may indicate that you\u0026rsquo;ve missed an important part of your model. ‑Right. In this case, the whole thing that the user is interacting with is the clinic schedule, but nothing in our original model referred to the schedule itself. Since some of our business rules, like what to do with appointments that conflict, only make sense at this higher level, it made sense to introduce a change to our model, the schedule aggregate.\nConsidering Schedule as Our New Aggregate So, even though the initial design we had was about scheduling, the schedule itself was never part of our model. Once we include schedule as its own explicit object in our model, it makes the design much simpler. Appointments no longer need to know anything about other appointments. The responsibility for ensuring that appointments are not double booked and similar invariants can be performed by the schedule, which is the aggregate root. ‑So, let\u0026rsquo;s see if this passes our other tests about defining aggregate roots. A schedule will certainly help us ensure that appointments don\u0026rsquo;t overlap one another. When we save changes to a schedule, does it make sense to update any changed appointments? Yes, it does make sense. And if we were to delete an entire schedule, would it make sense to delete all of its appointments? Yeah, I think that would make sense also. ‑Yeah, I think this is the schedule for a particular clinic. At the moment, we only have one clinic, but if we imagine a scenario in which multiple clinics each have their own schedule, it wouldn\u0026rsquo;t make sense to delete a clinic\u0026rsquo;s schedule but then keep its appointments floating around. So I think that works. ‑Great. And if a schedule exists for each clinic, then it makes sense to persist the schedule, which means that it needs an ID, and therefore is truly an entity. And when we retrieve a schedule, we\u0026rsquo;ll most likely be filtering which related appointments we want to look at, for example today\u0026rsquo;s schedule or this week\u0026rsquo;s schedule. That would mean we want all of today\u0026rsquo;s or all of this week\u0026rsquo;s appointments from a particular clinic\u0026rsquo;s schedule. It really does make a lot more sense to me to tie the appointments to a schedule than directly to a clinic. Now, let\u0026rsquo;s see how this effects our design.\nExploring the Schedule Aggregate in Our Application Now I\u0026rsquo;ll show you the new schedule aggregate implementation in our application. In the refactored solution, we\u0026rsquo;ve renamed the folder so that now it\u0026rsquo;s ScheduleAggregate. This folder only includes schedule and appointment, as well as related guards and specifications. In larger applications, it can help to organize your domain model by grouping everything related to a particular aggregate in its folder. Looking at the ScheduleAggregate\u0026rsquo;s code, you can see that it inherits from our common BaseEntity type and uses a GUID for its id key, just like appointment. This lets us set the key ourselves, rather than relying on a database to do it for us. The class is also marked as an aggregate root with an interface. In the next module, you\u0026rsquo;ll see how we use that to protect the integrity of our aggregates. ‑Right. We\u0026rsquo;ll see how that works when we look at our repository and specification implementations. ‑Next, the Schedule\u0026rsquo;s constructor just takes in its id, its dateRange, and its associated clinicId. In our sample, the clinicId is always hard‑coded but in a real application, there might be several clinics using the same software, and they would each have their own ids. The constructor is responsible for ensuring that the incoming values are valid so that it\u0026rsquo;s always created in a consistent state. Schedule has just a few properties. There is the ClinicId, the associated set of appointments, and the DateRange. We\u0026rsquo;re careful to only expose a read‑only IEnumerable of appointments because our aggregate must encapsulate its internal state. We don\u0026rsquo;t want other parts of our application to add or delete appointments without going through the schedule\u0026rsquo;s explicit methods designed for this purpose. Also, the date range isn\u0026rsquo;t persisted since it can vary with any given instantiate ation of the schedule. ‑Yeah, and for performance reasons, you wouldn\u0026rsquo;t really want to load the ScheduleAggregate with every appointment that had ever been made included in it. By using a property like this, we make it clear to the rest of the domain what set of dates this instance of the aggregate holds. The actual population of the appointments that match this range is left as a responsibility of the specification and repository classes that are used to retrieve the schedule from the database. ‑Yes. And the configuration of the aggregate\u0026rsquo;s persistent details is done in the infrastructure project\u0026rsquo;s Data Config folder. This is where every entity\u0026rsquo;s EF Core‑specific mappings and configuration is performed, which keeps these details out of our domain model. You can see here that we\u0026rsquo;re also letting EF Core know that we don\u0026rsquo;t want the database to supply an id when we create a new schedule. We\u0026rsquo;ve marked that property as ValueGeneratedNever. ‑Getting back to the schedule, let\u0026rsquo;s have a look at its methods. The first method is for adding new appointments. Our design forces all new appointments to come through this method, so we don\u0026rsquo;t have to have duplicate behavior anywhere else in the application to take care of whatever should happen when a new appointment is added. It\u0026rsquo;s all right here in one place, easy to understand, and easy to test. The method validates the inputs to ensure we\u0026rsquo;re not adding bad data to our aggregate, and then it adds the appointment. When a new appointment is added, the schedule is responsible for marking any appointments that might be conflicting. It\u0026rsquo;s the right place for this behavior to live, since the schedule knows about all the appointments and knows anytime appointments are added or removed. After marking any conflicts, an appointmentScheduledEvent is added to the aggregate\u0026rsquo;s event collection. We\u0026rsquo;ll see how this works in the module on domain events. The DeleteAppointment method is similar. After deleting an appointment, the schedule needs to once more mark any appointments that might be conflicting. There\u0026rsquo;s also a TODO comment here. These are left as exercises for you to learn more about how to work with the patterns introduced in this course. You\u0026rsquo;ll find a number of TODO exercises scattered throughout the sample. ‑We hope you\u0026rsquo;ll take some time to download the code, run it locally, and try implementing some of the TODO tasks using the existing functionality as a guide. There are a couple more in the MarkConflictingAppointments method, which, remember, was originally on the appointment type when we started out with that as its own aggregate. This method is responsible for detecting and marking appointments that might conflict. The basic rule, shown here, just checks whether the patient has two appointments that overlap. If any such appointments are found, they are updated to set their conflicting property to true. Then, the current appointment\u0026rsquo;s property is set based on whether there are any other appointments that conflict with it. ‑This is an important part of the business logic for this application, and it\u0026rsquo;s encapsulated right in our schedule aggregate. In a lot of data‑driven applications, this kind of logic might be in a stored procedure, or perhaps just implemented in the user interface. But in a domain‑driven application, we want these rules to be explicit and defined in our domain model. ‑The last method on schedule provides a hook for its appointments to use to notify it when changes are made to one of them. Because we don\u0026rsquo;t have navigation properties from appointment back to schedule, we can\u0026rsquo;t directly call methods on the aggregate root from appointment methods. There are a few different patterns we can use to accomplish this task. For this sample, we chose this one because it\u0026rsquo;s simple and easy to follow. This handler simply calls MarkConflictingAppointments, but it\u0026rsquo;s exposed as its own separate method because it could do other things as well, and we don\u0026rsquo;t want to expose the internal behavior of the schedule to the rest of the app. To see how it\u0026rsquo;s used, let\u0026rsquo;s look at the appointment class\u0026rsquo;s UpdateStartTime method. When the application needs to update the start time for an appointment, it will call this method. Because appointment is part of a scheduling aggregate, we know the app will already have loaded the schedule before calling this method. So the second parameter in the method asks for the handler on the schedule that will be called. The call to update the schedule is made after updating the TimeRange property on the appointment, so when mark conflicting appointments is called, it will use the new value for the time range. There are a lot of other ways you can set up this communication, using C# events, static domain events, or some kind of double dispatch approach. They all have trade‑offs, and when you need to do this in your apps, you should choose the one that works best for your app and your team. ‑Let\u0026rsquo;s see the final result in the application. This change to our model of adding in a schedule aggregate made a big difference to how the domain model is organized. It gave us a much better place to put the logic of enforcing business rules around combinations of appointments and business logic that needs to run when appointments are added or removed. ‑Right. Without the schedule, we would have had to use a domain service or something to add behavior around the newly added or removed appointments. But with this design, we can go into the schedule, add a new appointment for Rosie, and then add another one, and you can see the notifications being triggered by the events, as well as the red outline representing the conflict in these two appointments. Not only is our domain model clean and easy to test, but even more important, it actually works! ‑And notice that as we move one of those conflicting appointments to another spot, the red alerts disappear. Good job, Steve! I am so grateful that you let me off the hook for working on the front‑end of this application. You know I\u0026rsquo;m more of a back‑end developer.\nSharing Our Tips for Aggregate Design So let\u0026rsquo;s step back a moment and review some of the things we\u0026rsquo;ve just learned about designing aggregates. First of all, aggregates exist to reduce complexity. You might not always need an aggregate. Don\u0026rsquo;t add complexity just for the sake of using an aggregate. Another is that entities with an aggregate can only reference the root entity of another aggregate. ‑But you can always use foreign key values as a reference to entities inside another aggregate. It\u0026rsquo;s perfectly okay to use this, and it will avoid the need for when you go to save that aggregate for it to cascade its persistence into other aggregates. If you find you\u0026rsquo;re needing to use a lot of foreign key references to aggregate children often, you may need to reconsider the design of your aggregate in your domain model. ‑Another pointer was don\u0026rsquo;t be afraid to have an aggregate of one, in other words, an aggregate that only has one object in it. ‑And finally, don\u0026rsquo;t forget the rule of cascading deletes. Remember, one test for whether or not a particular object makes sense as an aggregate root is to consider whether deleting that object should also delete all of the other child objects in that object\u0026rsquo;s hierarchy. If it doesn\u0026rsquo;t, then you have probably chosen the wrong structure for your aggregate.\nReview and Resources Once again, we have covered quite a bit in this module. Let\u0026rsquo;s review some of the terms that you learned in this video. The first thing we talked about was an aggregate. An aggregate is a group of related objects that work together in a transaction. The root becomes the entry point through which you do any work with the aggregate, and the root also is what\u0026rsquo;s in charge of making sure that all of the rules that apply to that graph of objects are met. ‑Each of the rules that describes the state that the system must be in in order to be valid is called an invariant. Within our aggregates, we have objects that are related to one another. In DDD, we refer to these relationships as associations. If you use an ORM, you may hear the term navigation properties, which refers to those properties that reference the related objects in the model. And we talked about the importance of defaulting to one‑way relationships, which we also refer to as unidirectional relationships. ‑In addition to these important terms, Steve and I shared a lot of guidance around creating aggregates and roots in your domain models. Nobody wants to work with a big ball of mud. We use aggregates to organize our model. An aggregate is a set of related objects that live in a single transaction while encapsulating the rules and enforcing invariance of that transaction, making sure that the system is in a consistent state. When designing how related objects work together, your job will be easier with one‑way relationships. Use those as a default, and only introduce bidirectional navigation if you really need to. ‑And most importantly, don\u0026rsquo;t resist updating your model as you and your team of domain experts learn more about the domain. Hopefully, most of this will happen early on, and then just once in a while you might have a big breakthrough, like we did when we realized that the schedule made more sense as an aggregate root than trying to have each appointment be its own aggregate. Up next, you\u0026rsquo;ll learn about repositories which are a critical pattern in domain‑driven design. This is Steve Smith, ‑and I\u0026rsquo;m Julie Lerman. Thanks for watching Domain‑Driven Design Fundamentals.\nWorking with Repositories Introduction and Overview ‑Hello. I\u0026rsquo;m Julie Lerman. ‑And this is Steve Smith. ‑In this module of Domain‑Driven Design Fundamentals, you\u0026rsquo;ll learn about repositories, another critical pattern for Domain‑Driven Design. ‑We\u0026rsquo;ll start by defining what repositories are, and then we\u0026rsquo;ll provide some tips for working with them, as well as talking about some of their benefits. There are different ways to define repositories and plenty of debate around their use. We\u0026rsquo;ll address some of these points. ‑Next, we\u0026rsquo;ll introduce you to the specification pattern and how it can be really helpful when you\u0026rsquo;re implementing repositories. Then we\u0026rsquo;ll open up Visual Studio again and show you how we\u0026rsquo;ve implemented some repositories in the scheduling app.\nIntroducing Repositories ‑Now, Julie, if this were an in‑person class, I\u0026rsquo;d definitely ask for a show of hands who has heard of the repository design pattern. I would expect most hands to go up. ‑I hope so too. I think the repository pattern is by far the most popular element of DDD to be practiced outside of Domain‑Driven Design. They can be valuable in so many applications as a way to simplify data access and enforce separation of concerns. When I began learning about repositories and implementing them in my own software design, it had a huge impact on my application architecture. Along with automated testing practices, it really forced me to consider separation of concerns with each method and behavior added to my software. ‑Personally, I love the pattern, and I find it makes it much easier for me to write good, testable code. We\u0026rsquo;re going to talk about using repositories within a DDD application, but if you want to learn more about the pattern itself, you can look in the design patterns library, and I know Julie also discusses using them with Entity Framework in her Entity Framework in the Enterprise course. ‑You can see the repositories are part of the DDD mind map, as they\u0026rsquo;re used to access entities and aggregates. Any system that needs to persist between restarts has some kind of persistent storage for the state of the system, like a database. Many applications focus a great deal of effort on the mechanics of querying, fetching, and translating data to and from objects to the point where it distracts from the model that these objects are meant to represent. And having ad hoc access to the data source also promotes having developers query for any bit of data they want anytime they want, rather than using aggregates. This makes it pretty difficult to manage the consistency of aggregates by enforcing their invariants. At best, the logic for enforcing the integrity of the model becomes scattered among many queries, and at worst, it\u0026rsquo;s not done at all. ‑Applying Model‑First design and separation of concerns means pushing persistence behavior into its own set of abstractions, which we refer to as repositories. Only certain objects, like specifically aggregate roots, should be available via global requests. Repositories provide this access, and through omission, prevent access to non‑aggregate objects, except through their aggregate roots. They give you the ability to constrain the data access, so you avoid lots of random data access code throughout your application. ‑When you think about the life cycle of an object in your application, you should consider two cases. In the first case, you have objects that are not persisted. These objects are created, perform some work, and then they\u0026rsquo;re destroyed. In the second case, you have objects that are persisted. These objects have a slightly more involved lifecycle since after the object is created, it must be reconstituted with whatever state it had when it was last saved. Then it can perform whatever work the application needs it to do, after which it may need to save its state to some persistent storage before finally being destroyed. You can use repositories to manage the lifecycle of your persistent objects without the objects having to know anything about their persistence. We call these objects persistence ignorant because they\u0026rsquo;re ignorant of how they\u0026rsquo;re stored into and retrieve from a data store. ‑In his book, Domain‑Driven Design, Eric Evans speaks quite a bit about repositories. They can be summed up by saying that a repository represents all objects of a certain type as a conceptual set, like a collection with more elaborate querying capability.\nRepository Benefits ‑Repositories can add a number of benefits to our application. First of all, they provide a common abstraction for all of our persistence concerns, which provides a means for clients to very simply obtain model objects and to manage their lifecycle. They also promote separation of concerns. The domain logic and the user interface can both vary independently from the data in the back‑end data source that is used by the application. ‑The public interface of a repository very clearly communicates our design decisions. Only certain objects should be accessed directly, so repositories provide and control this access. Another important benefit is that repositories make it easier to test our code. They reduce tight coupling to external resources like database, which would normally make unit testing difficult. Having a repository separate from client code and domain logic means that we can easily make improvements to optimize data access for this application, tuning for performance, adding caching behavior, etc. is all much easier and safer when the code for data access is all encapsulated in one or more well‑known classes. All of this makes your code easier to maintain.\nRepository Tips ‑Here\u0026rsquo;s some basic guidance you should keep in mind when designing repositories. First, a repository should have the illusion of a collection of a specific type of object. You\u0026rsquo;ll be adding the objects to the collection, removing them, and retrieving objects from the collection, but that it is an illusion of a collection is important to keep in mind. When you interact with the repository, these are the types of methods you\u0026rsquo;ll be calling, add, remove, and retrieve. Your calling code doesn\u0026rsquo;t care how the repository performs those actions. So in the repository, you might have code that responds to a retrieve method, goes out to a database and gets data, but it could be getting data that\u0026rsquo;s already in memory, or it might be grabbing data from a text file on your computer. ‑Another important recommendation for repositories is to set up access through a well‑known global interface. That way, developers that need to interact with the repository will be familiar with a common pattern for using it. ‑Here\u0026rsquo;s a simple repository interface example. Depending on the size and complexity of your software, you may have a few layers of interfaces. ‑For example, if you anticipate having a number of repositories for a schedule aggregate used in different bounded contexts, you might want an IScheduleRepository interface that not only implements the lower‑level interface, but defines some other methods or properties that every schedule repository is required to have regardless of the bounded context it might reside in. Because a repository acts like a collection, you\u0026rsquo;ll want methods to add and remove objects to encapsulate the underlying data insertion and deletion operations. We\u0026rsquo;ve got these defined in our IRepository. It is up to each concrete implementation to define how add and remove will actually work. ‑It\u0026rsquo;s not unusual to need to add specific query methods to individual repositories. Whether you need a custom subset of entities or a specific way to load entities\u0026rsquo; relationships, custom methods are a simple way to achieve this. For example, if we wanted to fetch a schedule instance with all the appointments for a given day, we could add a method to the ScheduleRepository that might have an EF Core implementation like this one. ‑Likewise, if we just wanted to be able to fetch a client with their patients, we could add a method like this one, which will eager load the patients when it loads the client. Be careful with this approach though, as it can grow out of hand, and your repositories may end up with many different query methods. A simple way to address this is to use specifications instead, which we\u0026rsquo;ll cover later in this module. In addition to these specific tips for implementing repositories, you should also keep in mind these more overarching tips. First, be sure to provide repositories only for aggregate roots that require direct access. And next, keep the clients focused on the model, while delegating all of the object storage and access concerns to the repositories.\nAvoiding Repository Blunders We\u0026rsquo;re not always going to land on the happy path, so we do want to share with you some common problems that you might run into, how to recognize them, and most importantly, how to avoid them. ‑Remember your client code can be ignorant of the implementation of your repositories, ‑but developers cannot. ‑It\u0026rsquo;s important that developers understand how your specific repository is implemented, otherwise, they can run into a number of different problems. ‑So we\u0026rsquo;re talking about not just the developers who are implementing the repository, but also the developers who are using the repository. ‑One of the common repository problems the developers working with repositories often encounter is called an N+1 query error. This is where in order to display a list of rows from the database, you end up calling one query to get the list and then a number of queries equal to the count of that list to fetch each item individually. ‑Another one that I see a lot is when people are fetching related data. With Entity Framework, they\u0026rsquo;re either using eager loading or lazy loading, and especially with lazy loading, there are a lot of developers who don\u0026rsquo;t really know what to expect from it and just because it\u0026rsquo;s easy and it just works, they use it and then run into all kinds of problems because of it. ‑And depending on how your data is structured, sometimes if you\u0026rsquo;re trying to fetch just one or two properties that are represented in a particular column in a data table, you might end up fetching more data than required if you pull back the entire row which might include dozens of columns and a lot of actual data there. These are things that knowing how your underlying data is persisted and how your repository is implemented, how those things work, can make a huge difference in your application. ‑Most of these blunders impact how data is accessed in a data store and that means that one of the best tools you have for surfacing these problems is profiling your data store. Many of the IDEs we use for managing databases have profilers built in, some examples are SQL Server Profiler, Jetbrains DataGrip, and Azure Data Studio. Many of the APIs we use also have logging capabilities that can relate database activity. As a .NET developer, I often use the .NET Core logging API or some of the features built into Entity Framework Core, but most any language you use can do this and all of the cloud providers have ways to trace activity in their various data stores. There are even third‑party tools dedicated to database profiling. The suite of profilers from Hibernating Rhinos is a great example. They have profilers for RavenDB, Azure CosmosDB, and the EF Core, and Hibernate ORMs.\nAddressing the Debates Around Using Repositories Many developers have strong opinions about the use, and some might say overuse, of the repository design pattern. Let\u0026rsquo;s consider some of the common arguments made about repositories. It\u0026rsquo;s worth remembering that like Bjarne Stroustrup\u0026rsquo;s famous quote about programming languages, there are two kinds of design patterns, too. It\u0026rsquo;s no surprise, really, that as the repository pattern grew in popularity, that there would be many complaints about when and how to implement it. ‑Here\u0026rsquo;s one that really gets me. EF Core, the .NET ORM which we\u0026rsquo;re using this course, has a built‑in repository for its data access. It\u0026rsquo;s called the DbContext. I\u0026rsquo;ve heard and read comments from so many people who say never use a repository on top of EF Core because it already has a repository built in. And then I hear others who say you should always use a repository to interact with EF Core. I am not a fan of the words always and never. Maybe it\u0026rsquo;s because I\u0026rsquo;m a libra, who knows. So, these strongly held opinions really frustrate me. What Steve and I want to do here is give you the information you need so that you can make educated decisions about when to use repository and when to opt for something else. ‑Let\u0026rsquo;s remember for a moment what repositories are and where they live in a domain‑driven application. Repositories are abstractions. They\u0026rsquo;re part of your domain model. They define the persistence operations the model will use. That\u0026rsquo;s it. There\u0026rsquo;s nothing in the domain model patterns produced through model‑driven design espousing the use of Entity Framework, or NHibernate, or any other specific vendor tool for doing persistence. It doesn\u0026rsquo;t even know if you\u0026rsquo;re doing Java or .NET. It\u0026rsquo;s meant to be totally abstract and just types. ‑The domain model should be persistence ignorant, and it shouldn\u0026rsquo;t depend on implementation details. ‑Right. One of the things I really appreciate about DDD and the way it isolates domain expressions within a layered architecture is that it aligns perfectly with SOLID design principles, like the dependency inversion principle. ‑You are a big fan of SOLID, Steve. ‑Guilty! In this case, in terms of SOLID, using an abstraction for persistence enables us to follow dependency inversion because we can define an abstraction in our domain model and then implement it in another project that depends on the domain model. We can also write our application and its user interface so that it depends on our persistence abstraction, too, rather than on the implementation details. That\u0026rsquo;s the heart of dependency inversion. ‑And that makes it easier to follow the interface segregation principle, which I also learned about from your SOLID course. This principle prefers smaller interfaces, so if your app is using a DbContext directly, that is not a small interface. Along with DbContext repository features, it exposes a lot of other functionality. Using an abstraction that limits what your app needs to do with regard to persistence makes for a much simpler design in our model, reducing complexity. ‑Right. In that way, it\u0026rsquo;s similar to the facade pattern because it lets us work with a much simpler view of what could otherwise be a potentially very complex and powerful persistence library. ‑So, when we\u0026rsquo;re following DDD, our domain model shouldn\u0026rsquo;t know anything about EF Core, or whatever APIs you\u0026rsquo;re using for your data persistence. If our model requires persistence, like most do, we should define abstractions in the model that describe what our needs are without specifying how they\u0026rsquo;re done. ‑Exactly. The abstraction defines what needs done, the specific implementation is all about how to do it. ‑And one really popular and powerful way to do persistence in .NET is with Entity Framework Core. And because it implements methods that map pretty closely to most common persistence abstractions, it\u0026rsquo;s usually pretty easy to implement a particular abstraction with a class that calls into EF Core. ‑Definitely. ‑EF Core works great for this in most of the apps I work on, but we should never couple it tightly to our domain model. ‑Exactly. The whole point of DDD is that we shouldn\u0026rsquo;t be coupling our domain problems with our persistence problems.\nReturning IQueryables: Pros and Cons Another question I get all the time, and which I\u0026rsquo;ve discussed in some of my other Entity Framework courses, is whether repositories should return IQueryable, and yes, I do have my opinions on that. ‑Yes, this is another source of some debate. On the face of it, it sounds like it would be a great idea. Your most basic repository abstraction might not provide much in the way of complex filtering options and you can avoid having to think about that sort of thing if you just return an IQueryable. ‑Right, because then any code that consumes an IQueryable can extend the expression adding additional filters or projections to the query before it\u0026rsquo;s actually executed. On the surface, it sounds pretty good, right? ‑Well, it turns out that a lot of query logic is actually business logic, and if you return an IQueryable, it has two not‑so‑good effects. It can leak a lot of the implementation details so your application code\u0026rsquo;s behavior changes significantly based on the implementation of the repository and it tends to put the business rules for querying all over the application. ‑Let\u0026rsquo;s say we have an MVC application with a controller so that\u0026rsquo;s the server‑side logic of the UI layer and it returns a view to the UI. The controller calls into a service to get its list of customers and the service contains a customer repository interface. That repository calls into an infrastructure project and the infrastructure project is where we\u0026rsquo;re using EF Core and it\u0026rsquo;s DBContext, but to limit what\u0026rsquo;s exposed outside of the infrastructure project, there is a repository there as well. The repository and the service makes its calls to the repository in the infrastructure layer. It sounds like a lot of layers, but that\u0026rsquo;s not a problem because we have reduced coupling and made a maintainable solution. The real problem here is where can we put our query logic in this example? ‑Well obviously the repository, and it wouldn\u0026rsquo;t be unusual for the method in the service to further modify the query, but since it\u0026rsquo;s also returning an IQueryable, the controller action could further modify that same expression tree, and assuming the controller just passes that same IQueryable to the view, which we\u0026rsquo;ve both seen teams do, even the view could further refine the query. So is this a good thing or a bad thing? ‑Well on the plus side, we get a lot of flexibility without having to write a lot of code for our repository. We\u0026rsquo;re also able to tailor the data we need to the specific place it\u0026rsquo;s used and even modify the query from multiple steps in the app. At the same time, we get to reuse a simple repository interface everywhere in our app. ‑Right, but on the other hand, that query logic is now spread out everywhere. Every class that\u0026rsquo;s adding query logic, in addition to whatever else it\u0026rsquo;s doing, is now violating the single responsibility principle. Then there is separation of concerns. Query logic should be separate from other concerns in most of these classes. ‑And another problem I see a lot with this approach is confusion about when the actual query is executed and what runs on the database server versus in‑memory in the application. ‑Many developers will assume the query runs inside the repository and the result they get back is from the data store. And of course that\u0026rsquo;s true for most calls, but not necessarily for those that return IQueryable. ‑Right, the query will execute the first time any code tries to enumerate the result. That could happen inside the repository, but it could also happen in the service, or in the controller, or even in the view. ‑Yeah, I see that a lot. a related issue is that developers at any step of this process can add additional logic that may compile just fine, but then at runtime when EF tries to interpret it, it blows up. ‑Anything you add to the query expression that Entity Framework doesn\u0026rsquo;t know how to translate into SQL is likely to cause an exception, at least with recent versions of EF Core. ‑And it may be redundant at this point, but it\u0026rsquo;s probably worth adding here that there is no encapsulation when you use this approach. ‑There is a way we can fix at least some of these issues though. For example, instead of returning IQueryable, we can still create flexible repository methods by passing in predicates. Then in the implementation, this predicate can be passed along to the DBContext as its Where expression providing the necessary filter. If you\u0026rsquo;re not familiar with the term predicate, but you\u0026rsquo;ve used the link where method, that\u0026rsquo;s what the method takes as its parameter, which is why we\u0026rsquo;re able to pass it right to the WHERE clause. ‑That does help part of the problem. Where before the query could have been executed at any of these points, at least now we know that whatever comes back from the repository will be the in‑memory result. The actual query is always executed in the repository itself. Of course, if the service takes in a predicate, it still means that any code anywhere in the system could be responsible for creating the query logic with the possible exception of the view if it\u0026rsquo;s just being passed an IEnumerable at this point. ‑Okay, so with predicates, they\u0026rsquo;re still very flexible, but they\u0026rsquo;re not as easy to build up from multiple locations in your application, especially compared to IQueryable. The rest of the good points still hold though. ‑The only thing we\u0026rsquo;ve really changed on the bad side is confusion about when the query actually executes. Being a fan of solid and encapsulation and knowing some other patterns we\u0026rsquo;ll share later in this module, I\u0026rsquo;m usually going to vote against this approach too. ‑Well another way we tend to solve this conundrum is going the custom query route. We even suggested this as a tip earlier, but you can definitely take it too far. Every little change to a query means another method, customer with orders, customers by shoe size, by shoe size, customers by favorite Netflix show. Hey, you never know what problems your domain experts are going to share with you. ‑The problem with this approach if it goes beyond one or two methods, is that you really start to feel the pain of the open/closed principle violation. Every time another custom query requirement comes in, you have to change the repository abstraction and all of its implementations, and the bigger the type gets, the more it violates the interface segregation principle, too. The more complex your problem is, the more query methods you\u0026rsquo;ll be adding to your solution. This can surely be an untenable situation, and we will show you some better alternatives a little later in this module.\nConsidering Generic Repositories and Interfaces Using generic interfaces for persistence is great from a code‑reuse point of view. With just one simple interface, any entity can be persisted using a standard set of operations. If you\u0026rsquo;re using aggregates, you can use generic constraints in this simple marker interface to ensure that only aggregate roots can be persisted using your interface. It can work really well. ‑But there are trade‑offs. What if you have certain aggregates that should never be deleted, but your generic repository includes a delete method? Does it make sense to have operations defined in your domain model that should never be used? This is where you need to make a judgment call. Is the convenience of having a single consistent way of dealing with persistence throughout your model more valuable than having only the necessary and appropriate persistence operations exposed? There\u0026rsquo;s no one right answer. Pick what makes sense for your app, your model, and your team. ‑In our demo, partially for the sake of simplicity, we are using a single generic repository for all of our operations, even though, yes, this means there are operations on some aggregates that are never called and some that never should be called, for example, deleting the entire schedule. ‑If we didn\u0026rsquo;t go that route, our model would need to include separate repository interfaces for each of the aggregates in our model, including schedule, doctor, room, client, and appointment type. Each would define only the operations that were actually needed by the application. For a larger model, this could result in quite a few interfaces, and possibly implementations, but would provide a more pure representation of the domain model. ‑If you do choose to create a generic repository interface, that doesn\u0026rsquo;t necessarily mean you\u0026rsquo;ll implement it generically. You might only choose to create implementations for each aggregate root, which would comply with DDD recommendations. However, it can be convenient to create a generic Repository of T implementation class that you can then use with any entity. ‑This is what we\u0026rsquo;re using in our sample, both for the front desk app and for the clinic management app. In both cases, if you review the sample, you\u0026rsquo;ll see there\u0026rsquo;s very little persistence‑specific code in either solution. ‑If you really like the code reuse you get from having a generic repository implementation, one way to keep it from allowing too much access to the internals of your aggregates would be to use a marker interface, perhaps one that simply extends the entity interface to identify your aggregate roots. Then you can update your generic repository to require this interface, rather than working with any entity. ‑At that point, code that uses the repository won\u0026rsquo;t be able to instantiate the generic repository with non‑root entities, so we\u0026rsquo;re able to use our repository to restrict access to non‑root entities from client‑server model. Using marker interfaces to identify aggregate roots is one way you can enforce your design decisions in your model using the compiler rather than relying on code reviews or other less effective practices. ‑Repository abstractions, especially generic ones, can sometimes get to be pretty large. Large interfaces violate the interface segregation principle, one of the solid principles that I cover in my Solid Principles for C# Developers course. One way to keep these interfaces smaller and more focused is to split them into read and write operations. This is related to the concept of Command Query Responsibility Segregation, or CQRS. Read operations are queries, write operations are commands. There are many benefits to leveraging CQRS that we don\u0026rsquo;t have time to cover in this course, but one area where you may immediately benefit is with modifying behavior related to these kinds of operations. Queries often benefit from data caching, and it\u0026rsquo;s very easy to add data caching to just the read operations. ‑Commands often benefit from being performed asynchronously using a queue, and having a separate interface for commands makes it easy to implement this behavior. These are just two ways you can quickly leverage splitting up your repository definitions between reads and writes. Of course, if you have a lot of different read methods, this can make it more and more difficult to implement custom caching logic, since every new method will also need to be added to the caching layer. Fortunately, this is easily solved by using the specification pattern.\nExploring Repositories in our Application Steve is going to give you a guided tour of how data access and persistence are handled in the FrontDesk application using repository abstractions. Because he\u0026rsquo;s been fine tuning versions of this demo application for many years, it\u0026rsquo;s quite impressive, and he truly is the best guide for walking you through this implementation. ‑We\u0026rsquo;ll start from the front end of the application, which is our Blazor client. Let\u0026rsquo;s take a look at editing an appointment. Here\u0026rsquo;s an appointment for Julie\u0026rsquo;s dog, Samson. You can see that on the edit screen, in addition to showing the details for the appointment, it also provides us with a list of the doctors and appointment types. When we hit the drop‑down list, we can see all of the different doctors who are available that we could schedule to work with this particular appointment. That\u0026rsquo;s actually accomplished through a back end API that\u0026rsquo;s coming from a different project. Let\u0026rsquo;s take a look at that. We\u0026rsquo;ll start by examining the API using our Swagger endpoint. Looking at Swagger for DoctorEndpoints, you can see that there are two endpoints, one to get a specific doctor by ID and another one that returns a list of doctors. We just saw the list of doctors in action. Let\u0026rsquo;s go ahead and run it again from Swagger. Here you can see the resulting set of three doctors, just like we saw in the drop‑down list. You\u0026rsquo;ll find the code for this particular endpoint inside the FrontDesk.Api project. Within there, there\u0026rsquo;s an Endpoints folder with subfolders for each of the different types of entities that we expose API endpoints for. Inside of Doctor, you can see there\u0026rsquo;s a GetById and a List, and we\u0026rsquo;re looking at the List endpoint here. When we define an endpoint, we simply inherit from BaseAsyncEndpoint, and specify the request type, if any, and the response type, if any. We can also do dependency injection through the constructor, just as you would with a controller. Each endpoint has a single Handle or HandleAsync method, and this is where the actual work of the endpoint is done. You can see in this example that we are simply awaiting on the repository\u0026rsquo;s ListAsync method in order to get our list of doctors. Once we have the list, we map it to our DTO that we\u0026rsquo;re going to actually return, and pass that back as part of that response type. The response, as we just saw in Swagger, includes the Doctors as JSON, as well as a Count property that includes the total number of those doctors. Now let\u0026rsquo;s look a little bit more closely at that repository. You can see in the dependency injection that\u0026rsquo;s occurring in the constructor that we\u0026rsquo;re depending on an IReadRepository, but where is that defined? For that, we need to look at our SharedKernel project. Inside the separate SharedKernel project, which FrontDesk references as a NuGet package, you can see that we have defined an IReadRepository interface. This inherits from IReadRepositoryBase, which is actually itself defined in another NuGet package, the Ardalis.Specification type. The reason why we\u0026rsquo;re creating our own interface here is so that we have complete control over it and we can add additional behavior. For example, in this case we\u0026rsquo;re adding a generic constraint. We\u0026rsquo;ve said that this particular interface will only work with types that have the IAggregateRoot interface attached to them or applied to them. Looking at that particular interface, you can see that there\u0026rsquo;s nothing to it. It\u0026rsquo;s simply a marker. It\u0026rsquo;s a way that we tell the compiler that our intent for a particular class or entity is that it should be treated as an aggregate root. We use that marker to enforce our design and our encapsulation to make it so that we don\u0026rsquo;t accidentally just load up a child entity out of an aggregate, when instead we\u0026rsquo;ve made a design choice that we want to work with that entire aggregate as a unit. You can see that we\u0026rsquo;ve also implemented IRepository similarly. It also inherits from a type that comes from Ardalis.Specification, and also has the same IAggregateRoot restriction. Now let\u0026rsquo;s return to our FrontDesk application and see how we implement this. First, we should look at the DefaultInfrastructureModule. This is an artifact module that defines how we\u0026rsquo;re going to wire up our abstractions with their implementations. And here you can see all the important bits of how we wire up EfRepository to IRepository, as well as IReadRepository. But notice for the IReadRepository we\u0026rsquo;re actually wiring up a different type, a CachedRepository. This acts as a decorator around the underlying EfRepository, and will provide additional caching logic. Inside of the CachedRepository, when we asked for a list of doctors, it actually checked the cache first, and then if it wasn\u0026rsquo;t in the cache, it would go and fetch the result from the EfRepository, which in turn would make the request to the database. We can see in this example here that the logging is showing us that we\u0026rsquo;re actually hitting CachedRepository, and some of the times we\u0026rsquo;re fetching the source data and other times were fetching the data from the cache. The actual EfRepository that is also defined inside of FrontDesk.Infrastructure is shown here, and once more, you can see that there\u0026rsquo;s not much to it. Most of the behavior we\u0026rsquo;re simply inheriting from the EfRepository that exists in the Ardalis.Specification package. It\u0026rsquo;s called RepositoryBase. However, when we inherited it, we were able to add additional constraints, and so you\u0026rsquo;ll see here as well that we specify that this only works with IAggregateRoot. You can see the definition of the RepositoryBase in the Ardalis.Specification NuGet package, which is available on GitHub. The details of it are shown here. The ListAsync method simply delegates to dbContext.Set of the appropriate T type, and then calls its ToListAsync, passing along a cancellationToken if one was provided. Now the last piece of the puzzle is our own AppDbContext. Inside our AppDbContext, we define the DB sets that we\u0026rsquo;re working with and we also pass in some additional configuration. One thing to notice and take away from this example is how many places in our solution we have to reference AppDbContext or EntityFramework. It\u0026rsquo;s almost nowhere in the entire code base. The only place that we talk about it at all is inside of AppDbContext, EfRepository, and some related folders such as Configuration and Migrations. Everywhere else, and especially in our domain model, we\u0026rsquo;re completely persistence ignorant, relying only on abstractions that we\u0026rsquo;ve defined.\nIntroducing the Specification Pattern Eric Evans introduces the specification pattern in the original book on domain‑driven design. Although it\u0026rsquo;s covered in Evans\u0026rsquo;s DDD blue book, the specification pattern isn\u0026rsquo;t listed in the book\u0026rsquo;s mind map, and honestly, it doesn\u0026rsquo;t get the attention it deserves. Factories are in the book\u0026rsquo;s mind map, but specifications aren\u0026rsquo;t? Even though in my experience they play a much larger role in producing a clean domain model design. ‑In the book, Evans says that specifications mesh smoothly with repositories, which are the building‑block mechanisms for providing query access to domain objects and encapsulating the interface to the database. It\u0026rsquo;s this powerful combination of specification and repository patterns that truly result in a clean, extensible, and testable design. Let\u0026rsquo;s dig a little more into the specification pattern and how it integrates with repositories before we show you how we\u0026rsquo;ve implemented it in the front desk application. ‑Specifications are used to specify the state of an object, and as such, are primarily used in three ways, validation, selection and querying, and creation for a specific purpose. In our app, we are primarily leveraging specifications in our queries. Create explicit predicate‑like value objects for specialized purposes. A specification is a predicate that determines if an object satisfies some criteria, according to Eric Evans. The most basic specification simply provides a method typically named IsSatisfiedBy, which accepts some object and returns a Boolean. These methods perform their logic in memory, and unfortunately, in remote data querying scenarios, this approach would require every row to be transferred to the application before the specification logic could be run against it. ‑However, more sophisticated specifications can be used in conjunction with ORMs like Entity Framework Core to encapsulate the details of a query while still allowing EF Core to translate the query into SQL that executes on the database server. Our sample application uses such a specification in the form of a NuGet package, ardalis.specification, which is maintained by, guess who, Steve Smith. ‑Recall that one of the benefits of using the repository pattern and abstraction was that it prevented query logic from being spread throughout the application. This was also the reason for not returning IQueryable from repository methods. The same logic can be applied to repositories that accept arbitrary predicates since, again, that means the complexity of these predicates would need to live in the code calling the repository, which might be in the user interface for example. Using repository interfaces that accept specifications instead of custom predicates addresses this problem very elegantly. ‑What about the issue we learned about earlier in this module where generic repositories weren\u0026rsquo;t suited to aggregates with custom query needs? So, individually typed repository interfaces were required, and each additional custom query needed to be added to this new specific interface. Well, specifications solves that problem too. Generic methods accepting generic specifications allows for custom queries where needed for any given aggregate. ‑A few more benefits of specifications. They\u0026rsquo;re named classes that live in your domain model. You can easily unit test them in isolation, or if necessary, integration test them with a test database. They\u0026rsquo;re highly reusable. They keep persistence logic out of your domain and your user interface. They keep business logic out of your database and persistence layer. They help your entities and aggregates follow the single responsibility principle by keeping complex filtering or validation logic out of them. You can easily create your own specification interface and implementation. Feel free to look at the source for ardalis.specification on GitHub and take just the bits you find useful. Or, you can reference that package and leverage all of its features and just start adding the specifications that your domain needs. It\u0026rsquo;s up to you. Either way, you will need to write the specifications themselves. These belong in your domain model. When you don\u0026rsquo;t have many of them, you might just put them in a root specifications folder. However, as your model grows, if you\u0026rsquo;re using aggregates, it may make sense to have each aggregate include in its own folder the specifications that go with it. This makes them easy to locate as they grow in number. ‑Each specification class is a value object, so it should be immutable. Generally, they do all of their work in their constructor. Any variable part of the specification should be supplied as a constructor argument. And once constructed, the specification needs to be supplied to your query implementation. You can use specifications directly with EF Core or you can use a repository abstraction that supports them. In either case, pass the specification to the query object and it will be used to build the query, which is then executed and results are returned. The resulting code for most queries turns into one line to create the specification and another line to execute the query by passing the specification to a repository or a DbContext method. Note that our sample is built on top of a repository abstraction that\u0026rsquo;s provided with the ArdalisSpecification package, and so it\u0026rsquo;s fully compatible with its specification types. We\u0026rsquo;ll look at the code more in the next section. ‑Here\u0026rsquo;s an updated mind map that I have created which shows how specifications work with repositories to define the queries for aggregates and entities. If you\u0026rsquo;ve been using repositories without specifications and have experienced any of the pain points we\u0026rsquo;ve described in this module, try refactoring to use specifications and I\u0026rsquo;ll bet you\u0026rsquo;ll be surprised what a positive difference it makes.\nUsing Specifications with Repositories in Our App Now it\u0026rsquo;s time to see just how specifications are implemented in the sample app. While the application code does lean on Steve\u0026rsquo;s specification API, there is still plenty to see. Most of what you\u0026rsquo;ll see here is the application\u0026rsquo;s code, but occasionally you\u0026rsquo;ll also see some of the code that\u0026rsquo;s in the Ardalis.Specification API. Once again, Steve is going to walk you through this demo, and he\u0026rsquo;ll do so from the perspective of how the app retrieves data, starting with the front‑end. ‑When we first load the schedule page in the FrontDesk app, it loads our Blazor WebAssembly application, which then makes some API calls to fetch the appointments and related data. One of those calls is shown here. It\u0026rsquo;s used to get the list of appointments for the schedule. Looking at Swagger, we can see there are a bunch of appointment endpoints. Our API is designed to serve the needs of the client app. Its endpoints won\u0026rsquo;t necessarily match up with how our domain model is constructed, so it\u0026rsquo;s perfectly fine to have an endpoint for appointments, even though appointment is not an aggregate root. It just means we need to pass in the aggregate root ID as part of the request so that we can get the schedule that owns the appointments. If we test the list AppointmentsEndpoint, we can pass in the same schedule ID that Blazor was using, and we get back a list of appointments as expected, and these are, in fact, the same appointments that are being used in the front end. Looking at the source code for this endpoint, you can see that, again, it\u0026rsquo;s in the API project in the Endpoints folder in an Appointment folder, and within that, we\u0026rsquo;re looking at the List endpoint. Now, when we pass in the request, we\u0026rsquo;re specifying a ScheduleId, and if that ScheduleId is missing or empty, then we\u0026rsquo;re going to return NotFound from this API. Otherwise, it uses the ScheduleByIdWithAppointmentSpec to encapsulate the query that it\u0026rsquo;s going to use. On the page in question, we only want the appointments for one day. It\u0026rsquo;s worth noting that this specification does not perform any filtering by date; it returns all appointments for this schedule. We\u0026rsquo;ve left a to do task here for you to implement this behavior by creating a new specification. Now, the specification that we\u0026rsquo;re using here is passed to the repository method, GetBySpecAsync. We\u0026rsquo;ll look at that in a moment. For now, let\u0026rsquo;s take a look at this specification. All of the schedule specifications are in the ScheduleAggregate folder in the Core project. The ScheduleByIdWithAppointmentSpec is pretty simple and has just three details worth pointing out. First, it has a WHERE clause, making sure it only matches schedules that have a matching ID. Second, it eager loads it\u0026rsquo;s associated appointments by using it .Include statement. And third, it implements another marker interface, ISingleResultSpecification. This interface is used to mark specifications that are expected to only return a single result. It is required when passing a specification to a repository method that only returns a single instance of a type rather than a collection or enumerable. Considering that this is being called from a List endpoint on the API, this may seem strange, but remember, we are only loading a single schedule aggregate, and it is then just the container for the set of appointments that the endpoint is going to return. The method the endpoint is calling, GetBySpecAsync, is defined in Ardalis.Specification, as shown here. Note that it has a generic constraint requiring any specification passed to it to have that ISingleResultSpecification marker interface. The sample code is calling this first method, which just works with one entity type and then returns it. If you need to use projection, though, you can use the second method, which operates on your entity type, but returns a different type using a .select. You can use this to optimize queries to return only needed properties. Remember that specifications are useful to define the expected shape of returned data in a query. This doesn\u0026rsquo;t just mean filtering the number of rows using a WHERE clause, but also determining which associations should be brought back with the query, and even which columns should be included. Let\u0026rsquo;s see an example of that. Returning to the specifications for the schedule, there\u0026rsquo;s another one called ScheduleForClinicAndDateWithAppointmentsSpec. One of the newer features in EF Core is \u0026ldquo;filtered includes,\u0026rdquo; and so by adding an include filter, we can make sure that this schedule, which is being used with a particular ClinicId, will only load in its appointments where they are for a given date that gets passed into the specification. You can use this specification, by the way, as an example when you complete that to do task that we just saw in the list endpoint. Compare this code to how we solve this problem in the previous version of this course using custom SQL queries and a custom ScheduleRepository. The specification has replaced all of that with a single specification class containing all the query logic, and the calling code simply needs to create the specification and then pass it to the repository. Unlike custom LINQ expressions that might be anywhere in our application, specifications are easily tested in isolation. In the IntegrationTests project, you\u0026rsquo;ll see several different tests that demonstrate the various schedule specifications and ensures they work as expected. These tests use a real database, since .include logic can\u0026rsquo;t be tested with an in‑memory collection. For the last specification that we looked at, which only includes the appointments for a given date, you\u0026rsquo;ll see that there\u0026rsquo;s an integration test that adds a number of appointments on different dates and then uses a repository to fetch back a schedule using the ScheduleForClinicAndDateWithAppointmentsSpec and a specific date, and it verifies that we only get back the appointments for that date and not the appointments that are on different dates, which verify the behavior of many of the abstractions and implementations in our domain model.\nReview and Resources Once again, let\u0026rsquo;s begin a review with some of the important terms you learned in this module. First, and most importantly, the focus of the module, repositories, which encapsulate the data persistence logic, add, update, delete, and retrieve. In the case of domain‑driven design, we use repositories to focus on aggregate roots. Key to building flexible repositories is the specification pattern, which guides you to encapsulate business rules in a way that they can be passed around and acted upon in other methods, classes or APIs. You learned about persistence ignorance, which describes objects being ignorant about how they are persisted into data storage. It\u0026rsquo;s another critical aspect of domain‑driven design. Steve and I also talked about ACID, an acronym to describe transactions as being atomic, consistent, isolated, and durable. Another acronym we talked about is SOLID, which is a collection of software design patterns. ‑After introducing you to repositories and how they fit into the DDD mind map, you learned about their benefits and some tips for designing them. ‑We also addressed some of the debates around repositories, not only if you should even use them, but how to use them, for example, whether or not to return IQueryables. Many of these debates exist because of the complexity of balancing clean repositories with repositories that help you achieve the variations of queries required by your domain. ‑We introduced you to an often overlooked pattern, the specification, that plays a critical role in solving this problem with DDD. Remember that you are not on your own building specifications. You can lean on the NuGet packages that I created or just dig into my GitHub repo to pick and choose what you want to adopt. Links are coming up. ‑Steve gave you a great tour of how repositories are implemented in the FrontDesk application and then more deeply to see how these repositories are using specifications to provide the rich querying needed in the application. ‑Here are a number of links to not only my GitHub repo and NuGet packages, but a number of other resources we referenced, as well as some additional ones that we think you\u0026rsquo;ll find useful. ‑In the next module, you\u0026rsquo;ll learn about two more critical pieces of the DDD mind map, domain events and anti‑corruption layers, both which help provide some data pathways between the various parts of your software. Thanks again for watching Domain‑Driven Design Fundamentals. I\u0026rsquo;m Julie Lerman, ‑and I\u0026rsquo;m Steve Smith. Thanks for watching.\nAdding in Domain Events and Anti-corruption Layers Introduction and Overview Hi, this is Steve Smith. ‑And this is Julie Lerman. ‑In this module of Domain‑Driven Design Fundamentals, you will learn about domain events and anti‑corruption layers, two patterns for decoupling how the domain model communicates internally and with other systems. ‑We\u0026rsquo;ll start with domain events, which can be used to separate concerns, allowing different areas of the application to evolve independently, and sometimes helping with scalability as well. You\u0026rsquo;ll learn how to identify domain events in your system, and how to design domain event classes. Then we\u0026rsquo;ll show you domain events being used in a simple application, so you can get a feel for the structure and the workflow. ‑Then, you\u0026rsquo;ll get to see the domain events we built in our sample application, which are a bit more realistic. After this, we\u0026rsquo;ll turn our attention to another important element of domain modeling, anti‑corruption layers, which can be used as translators between bounded contexts and Legacy APIs.\nIntroducing Domain Events Domain events are a critical part of a bounded context. They provide a way to describe important activities or state changes that occur in the system. Then, other parts of the domain can respond to these events in a loosely coupled manner. ‑In this way, the objects that are raising the events don\u0026rsquo;t need to worry about the behavior that needs to occur when the event happens. And likewise, the event handling objects don\u0026rsquo;t need to know where the event came from. This is similar to how repositories allow us to encapsulate all of our data access codes, so the rest of the domain doesn\u0026rsquo;t need to know about it. ‑We can also use events to communicate outside of our domain, which we\u0026rsquo;ll look at in just a moment. Another thing that\u0026rsquo;s worth remembering is that domain events are encapsulated as objects. This may be different from how you\u0026rsquo;re used to coding events. It certainly was different for me when I first started learning about them. For example, in a user interface, events are more commonly written as some form of a delegate in another class, but here they\u0026rsquo;re first class members of the domain model. ‑Right. Although you can implement domain events using techniques, like the event keyword in C#, the domain events themselves should be full‑fledged classes. In fact, all of these parts of domain‑driven design are defined as objects in our domain model. ‑Vaughn Vernon describes domain events simply, saying we should use a domain event to capture an occurrence of something that happened in the domain. The domain events should be part of our ubiquitous language. The customer or domain expert should understand what you\u0026rsquo;re talking about when you say when an appointment is confirmed, an appointment confirmed event is raised. ‑You may already be familiar with the idea of events from working with user interfaces. ‑Many user interface clients, like .NET Windows Forms, Electron, or web pages, like the one shown here, make heavy use of events and event handlers. In this example, there\u0026rsquo;s a single page with a single button, and in the markup, you can see there\u0026rsquo;s an onclick attribute in the button that leads to a little JavaScript method defining what the app should do in response to a user clicking the button. ‑Events are helpful because they let us avoid a lot of conditional logic. Instead, we can write code that signals a certain thing has happened, and we can have other code in our system listen for these signals and take action accordingly. So in this kind of code, you don\u0026rsquo;t have a separate class for an onclick event, and it may take some getting used to that now in our model, we\u0026rsquo;re going to create a whole class to represent an event. Domain events offer the same advantages to our model as the events in the user interface. Rather than having to include all of the behavior that might need to occur whenever the state of one of our objects changes, instead, we can raise an event. Then, we could write separate code to deal with the event, keeping the design of our model simple, and helping to ensure that each of our classes has only one responsibility. Essentially, a domain event is a message, a record about something that occurred in the past, which may be of interest to other parts of our application, or even other applications entirely.\nIdentifying Domain Events in Our System ‑Be especially attentive to these kinds of phrases when discussing the application with your domain experts. When this happens, then something else should happen. If that happens, notify the user when, or inform the user if, these types of phrases frequently refer to situations that are important to the domain expert, the system, or the user. It might therefore be worth modeling these types of things as domain events. You may also discover behavior in the application that will benefit from being treated as domain events that may be the domain expert isn\u0026rsquo;t initially aware of. ‑Remember that domain events represents something that happened. Since we can\u0026rsquo;t generally alter history, this means they should be immutable. It\u0026rsquo;s a good idea to name the event using terms from the bounded context\u0026rsquo;s ubiquitous language describing clearly what occurred. If they\u0026rsquo;re fired as part of a command on a domain object, be sure to use the command name. Here\u0026rsquo;s some examples. ‑Depending on the application, it might be important to have events to represent when a user has authenticated, when an appointment has been confirmed, or when a payment has been received. Be sure to only create events as you need them in your model. You should follow the YAGNI principle, that\u0026rsquo;s you ain\u0026rsquo;t gonna need it. In other words, don\u0026rsquo;t create domain events unless you have some behavior that needs to occur when the event takes place, and you want to decouple the behavior from its trigger. You really only need to do this when the behavior doesn\u0026rsquo;t belong in the class that\u0026rsquo;s triggering it.\nDesigning Domain Events Here\u0026rsquo;s some more things to keep in mind when you\u0026rsquo;re creating domain events. We\u0026rsquo;ve already mentioned that domain events are objects, but to be more specific, each domain event should be its own class. It\u0026rsquo;s also usually a good idea to note when the event took place since frequently the code that\u0026rsquo;s handling the event might run some time after the event occurred. It can be helpful to create an interface or a base class that defines the common requirements of your domain events. For example, capturing the date and time the event occurred. ‑Also, when you\u0026rsquo;re designing your event, you need to think about the event‑specific details you want to capture. If it\u0026rsquo;s related to an entity, you might want to include the current state of the entity in the events definition. Think about what information you would need to trigger the event again. This can provide you with the set of information that is important to this event. Similarly, you may need to know the identities of any aggregates involved in the event, even if you don\u0026rsquo;t include the entire aggregate itself. This will allow event handlers to pull the information back from the system that they might require when they\u0026rsquo;re handling the event. Ideally, domain event objects should be lightweight, so you want to be sure you capture sufficient information to handle the event, but not so much that the event object itself becomes bloated. Since the main events are immutable, they\u0026rsquo;re typically fully instantiated via their constructors. And since they\u0026rsquo;re simply noting that something has happened in the system, they don\u0026rsquo;t usually have any behavior or side effects of their own.\nApplying Domain Events to a Simple App We\u0026rsquo;ve put together a simple console application that we\u0026rsquo;re going to use to demonstrate the value that domain events can have in your application. The idea behind this is to strip things down to as small a level as possible. Then, we\u0026rsquo;ll also show how domain events are playing a real role in a more real‑world way when we get to our veterinary scheduling application. This is a .NET console application with dependency injection. The main program just loads the needed services and runs the app. The app has a simple run method, which goes through the following steps. We can step through it with the debugger, so you can see the output in real time. The app loads services and starts running. It shows what happens when an appointment is created using a service. The service calls a factory method that creates the appointment. After instantiating the appointment, the factory method sends an email, which you can imagine includes code like what is in the comments here. Then, it similarly sends a notification to the user interface, again, with code like what\u0026rsquo;s in the comments before finally returning to the service. The service, then saves the new appointment in the database. Then, the app creates a different appointment and saves it directly using a repository instead of a service. And once more, the notifications and the save occur in the same order. Finally, the appointment is confirmed, which triggers some UI notification, and then that change, too, is saved. The main thing to take away from this example so far is that the Appointment class has a lot of concerns. The act of creating an appointment, especially, involves a lot of code that could fail. It\u0026rsquo;s also worth noting that notifications and emails are going out before the state of the entity is saved. So if something goes wrong, users will have been told the operation was successful, and people may have been notified via email when, in fact, the update itself might never go through. ‑The reason we\u0026rsquo;re showing the behavior both from a service and with the appointment directly is because our domains should be designed to work either way. Earlier in this course when you learned about domain services, we explained that forcing all operations on your domain to go through a set of services tends to lead to an anemic domain. Ideally, your aggregates and entities should behave correctly, whether they\u0026rsquo;re being used directly or through a set of services. One way we can improve this design would be to move the responsibilities of actually sending emails or updating the UI to help our methods or other services. Then, we could call them from appointment.create instead of having all the code in here. This would make for less code inside of Appointment. ‑That would definitely be better, but it would still mean that appointment would need to be updated every time a new requirement came along. There\u0026rsquo;s a principle we can use to avoid that, though, called the Hollywood principle. ‑I love the name of this principle. Its name comes from an old saying from Hollywood agents, don\u0026rsquo;t call us, we\u0026rsquo;ll call you. ‑Exactly. Applied to software, the principle is closely related to dependency inversion from solid. Instead of forcing appointment.create to have to know about and call every possible thing that might be involved in the appointment creation workflow, instead, it can just let the app know something happened and let the app respond by calling handlers. ‑Instead of putting all the logic into this method, potentially making it huge and complicated and really hard to read, we move that logic into handlers, and the app calls the handlers. We don\u0026rsquo;t call the handlers, the app calls us. And beyond just reducing the amount of code and responsibility inside Appointment, this approach also lets us make sure that notifications to the user don\u0026rsquo;t occur until persistence is successful. And it still keeps the model\u0026rsquo;s behavior consistent without requiring a service to perform any of the work. Let\u0026rsquo;s see how it works. ‑Domain events is a pretty simple pattern, but you do need to have some plumbing code to support it. You also need to think about whether you want your events to fire before or after persistence. In many cases, what you really want is postpersistence events for the reasons we mentioned above. You want to make sure your persistance succeeds before you send any notifications outside of your app. Also, although occasionally I\u0026rsquo;ve used them for validation in the past, ideally, your domain events and handlers should never fail. That is, don\u0026rsquo;t build your behavior around exceptions that might be thrown from event handlers. Use a different pattern if you need that type of behavior. ‑In this simple demo, which mirrors how our sample app works, we just need a collection of events on each entity. We\u0026rsquo;re creating simplistic types to represent domain events and the respective handlers. You can implement the logic to find and call handlers whenever an event is dispatched in a number of ways. For this sample, we\u0026rsquo;re using the MediatR NuGet package created by Jimmy Bogard. Steve mentioned that you\u0026rsquo;ll need some plumbing to start, and that plumbing is the interfaces or base classes, if you prefer, for handler and domain event classes. In our example, we\u0026rsquo;re using interfaces. Here\u0026rsquo;s the IDomainEvent interface and the IHandle interface. ‑Once you\u0026rsquo;ve set up your event and handler interfaces or base types, it\u0026rsquo;s time to create some events and their associated handlers. ‑For this scenario, there are two things happening, an appointment is scheduled or created and an appointment is confirmed. An event is something that already happened. So we name our events in the past tense, and we have AppointmentCreated and AppointmentConfirmed. The event classes are pretty simple and just include the instance that triggered them, so handlers have access to any properties they might need from it. Once the events have been defined, you just take each individual responsibility out of the original method and create a separate handler for it. It\u0026rsquo;s fine to have multiple handlers for the same event. Ideally, your design shouldn\u0026rsquo;t depend on the order in which the handlers execute. But if it does, you can think about adding a sequence to your handler interface and ensuring they\u0026rsquo;re called in sequence order. ‑The last thing you need to do is register or record the events on the entity. In this sample, that just means adding them to the list of events that are on that entity. The actual implementation for dispatching the events is done in the repository after the save is successful. And in our veterinary sample, this work is done in the DbContext SaveChanges method. ‑Let\u0026rsquo;s step through the code again now that it\u0026rsquo;s using domain events. ‑The app starts up as before. We enter the appointment.create method. ‑And look how much smaller that method is now. ‑Definitely. It\u0026rsquo;s way easier to see what\u0026rsquo;s going on here. Now the domain event is added to the collection, but notice that when we step over this, nothing actually happens yet. ‑Right, it\u0026rsquo;s just holding it until after the entity is persisted. ‑Which is now. Notice that we\u0026rsquo;re in the repository Save method. And for every event that we have stored on this entity, we\u0026rsquo;re using MediatR to publish it at this point in time. ‑This is still in process on the same thread. There\u0026rsquo;s no out‑of‑process queue or anything involved here. ‑Right, there\u0026rsquo;s nothing to install using this pattern except for MediatR, and that just runs in‑memory. And, of course, you could wire this up with your own code that simply loops over your set of events and then dispatches out to your handlers. There\u0026rsquo;s nothing that says you have to use MediatR. Notice in the output that the DATABASE Saved occurred, and then the UI and email notifications. ‑As expected, we only triggered side effects outside our domain after persisting. Now let\u0026rsquo;s see the version that uses the repository directly and doesn\u0026rsquo;t bother going through the service. ‑We basically see the same behavior, DATABASE Saved, UI, EMAIL. ‑All that\u0026rsquo;s left now is the confirm and save, which should look similar, entity saved, and then the UI is updated. ‑That\u0026rsquo;s basically it. I created a small GitHub repo, which has just this sample in it. It\u0026rsquo;s at github.com/ardalis/DomainEventsConsole. There\u0026rsquo;s a branch there showing how things work without events. Of course, you can also download it from the course details. ‑If you want to start your solution with all of this plumbing already in place, you can use Steve\u0026rsquo;s CleanArchitecture solution template, which is also on GitHub. He is one productive guy. Everything shown here is already in place in the template, which is designed for you to use as a starting point for your app.\nExploring Domain Events in Our Application Now let\u0026rsquo;s look at how we\u0026rsquo;re leveraging domain events in the veterinary FrontDesk scheduling app that we\u0026rsquo;ve been working with. Again, we\u0026rsquo;ll start by showing you the code, and then we\u0026rsquo;ll debug through it so you can see it in action. ‑In our Appointment class, we\u0026rsquo;re going to record a domain event when certain changes are made to the appointment. So, if we scroll down and take a look at the UpdateRoom method, you\u0026rsquo;ll see that it creates and saves an appointmentUpdatedEvent. The same is true for the other update methods like UpdateDoctor, UpdateStartTime, etc. They each will create an appointmentUpdatedEvent and pass it the current instance of the appointment, and then this is saved into the entity\u0026rsquo;s Events collection. ‑In the case of the Confirm method, it\u0026rsquo;s similar, but it creates a different event, an appointmentConfirmedEvent. Essentially, the appointment entity can trigger two kinds of events directly, change and confirmed. And you\u0026rsquo;ll notice it only does so if an actual change takes place. Calling an update that doesn\u0026rsquo;t change the current value will not trigger a new event. ‑Let\u0026rsquo;s take a look at the appointmentUpdatedEvent, and this is similar to the one we saw in the simpler console app in the previous demo. It inherits from BaseDomainEvent, which is defined in our shared kernel, and it adds a UTC timestamp property called DateOccurred that is set when the event is created. This can be useful for debugging purposes. The only other property the class takes is the appointment itself. The AppointmentConfirmedEvent, shown here, is similar. ‑Notice that these domain events are all defined in the core project with our domain model. For this sample, they\u0026rsquo;re in an Events folder in the root. However, in a large application with many events, it might make more sense to put them with the aggregate that they correspond to. In this case, the ScheduleAggregate. There\u0026rsquo;s one more domain event in our sample, which is the AppointmentScheduled event. It\u0026rsquo;s similar in structure to the others, but it\u0026rsquo;s actually created elsewhere. ‑Once you start working in event‑driven applications, it can be a bit more difficult to follow the flow of execution in the app where events are concerned. It really just takes some getting used to, and then you\u0026rsquo;ll find it to be second nature. The best way to see where events are raised and where they are handled is by looking at an individual event and examining its references. Looking at AppointmentScheduled, you can see that it is handled in the API project and in the core project. It is only created inside of the ScheduleAggregate itself. Let\u0026rsquo;s have a look at where that happens. ‑In Schedule, the AddNewAppointment method creates and saves the AppointmentScheduled event after adding the appointment to its collection and marking whether or not it\u0026rsquo;s conflicting. Once the schedule is saved, any appointments that have had domain events added to their respective collections will have them dispatched after the save to persistence is complete. ‑Before we step through the code, let\u0026rsquo;s have a look at one of the AppointmentScheduledEvent handlers. The thing to notice is that these handlers don\u0026rsquo;t get created or called anywhere in our code. That\u0026rsquo;s that Hollywood agent again from the Hollywood principle saying, don\u0026rsquo;t call us, we\u0026rsquo;ll call you. The event dispatching logic, in this case, using MediatR, is what calls these handlers at runtime. But at compile time, nothing references them directly. ‑Now let\u0026rsquo;s see the flow of domain events in our application when we change an appointment. We\u0026rsquo;ll modify this appointment for my little baby, Sampson, and change the appointment from a wellness exam to a diagnostic exam. But a diagnostic exam takes more time, and this will automatically change the duration of the visit, which should trigger a conflict with one of Sampson\u0026rsquo;s other appointments. Yes, he likes to go to the vet quite a lot. ‑The change initially hits the AppointmentUpdate endpoint. It loads the schedule and the appropriate appointment and calls its Update methods. In this case, the only one that has a change is the change to the appointment type. This intern adds an appointmentUpdatedEvent. Once the change is saved, the event is dispatched. The API project also has a handler, AppointmentUpdateHandler, that responds to this event by sending a message to the Blazor client using a SignalR hub. This will trigger a real‑time notification in the app. ‑What about communication between bounded context or apps using events? Applications and microservices frequently use events to communicate, too, but these aren\u0026rsquo;t domain events since they extend beyond a single domain. They\u0026rsquo;re frequently called integration events, and they may be defined as part of your domain or in a separate project or package. For simplicity, ours are here in this IntegrationEvents folder. ‑The FrontDesk has just two integration events, the AppointmentConfirmLinkClickedIntegrationEvent is published by another app and consumed by this one, and AppointmentScheduledIntegrationEvent is an event this app publishes and another app consumes. It\u0026rsquo;s important that the structure of the published and consumed types match, which is why frequently a shared package is used to define these kinds of events. ‑We don\u0026rsquo;t have time to dive deeply into distributed application architecture, but one thing you need to remember when designing integration events is that they typically will be enriched and denormalized when compared to a similar domain event. For instance, the AppointmentScheduled domain event just has a reference to appointment, and that only has IDs for the client, patient, and doctor. However, the integration event includes many more details like client name and email, patient name, and doctor name. The reason for this is to ensure that consumers of the event have enough information from the event to perform whatever actions they need to without having to immediately call back to the publishing app to ask it for more details. You can imagine that the performance of a system would suffer if every time an appointment event was published, one or possibly many apps that were consuming that event, turned around and immediately had to make calls to this app\u0026rsquo;s API asking for client details, patient details, and doctor details. Hence, we have a handler that is responsible for taking in a domain event and enriching it with the additional details shown here on the integration event. We\u0026rsquo;ll put these integration events to use in the next module.\nIntroducing Anti-Corruption Layers The last topic we want to discuss in this module is anti‑corruption layers. An anti‑corruption layer, as the name implies, helps to prevent corruption in your domain model. ‑Right, just like superheroes help to fight corruption, these layers provide a sense of security to your model when it needs to interact with other systems or bounded contexts. ‑Returning to our mind map, you can see that the anti‑corruption layer is used to translate and insulate as part of a context map, mapping between a bounded context and foreign systems. ‑When your system needs to communicate with other systems, especially legacy applications that weren\u0026rsquo;t written or modeled as well as your current system, you need to be careful not to let assumptions and design decisions from that system bleed into your model. For instance, if the other system\u0026rsquo;s model includes a customer, even if that customer refers to the same actual business customer, it\u0026rsquo;s likely that it will be modeled differently than a customer in your system. It\u0026rsquo;s best to have a layer that can translate to and from other systems\u0026rsquo; models. In DDD, this is the job of an anti‑corruption layer. ‑Right, like we mentioned in the beginning of the course, even other bounded contexts in your own system may be different enough to merit having an anti‑corruption layer in place to protect the two distinct models from one another. And, of course, legacy applications frequently use very different models from newer systems. An anti‑corruption layer isn\u0026rsquo;t a design pattern, however, it\u0026rsquo;s usually comprised of several design patterns. The job of the layer is simply to translate between the foreign system\u0026rsquo;s model and your own. ‑In addition to translating the objects themselves, the anti‑corruption layer can also clean up the way in which you must communicate with the other system. It may provide a façade to simplify the API or an adapter to make the foreign system behave in a way that is known to your system. You can learn more about these design patterns in the Design Patterns Library on Pluralsight. ‑We\u0026rsquo;re usually most concerned with having an anti‑corruption layer in place when communicating with legacy systems. Eric Evans notes why that\u0026rsquo;s important. ‑Even when the other system is well designed, it is not based on the same model as the client, and often the other system is not well designed. ‑Since this is a fundamentals course, we\u0026rsquo;re not going to dig deeply into anti‑corruption layers, because they can be fairly complex, as well as very customized to each scenario, but here\u0026rsquo;s an example structure of one which comes from Eric Evans\u0026rsquo; book, showing how an anti‑corruption layer can connect your beautiful system on the left with a not so beautiful system on the right. ‑I really like this diagram. I think Eric had some fun putting it together. ‑Gee, what gives you that impression, Steve? ‑Of course, in the middle you can see how the anti‑corruption layer is using a façade and some adapters, but on the right it\u0026rsquo;s protecting us from a big complicated interface, some messy classes, and some things we just don\u0026rsquo;t even want to know about. ‑Right, and of course, your own system is comprised of an elegant class, a very expressive class, and of course even more good stuff, and maybe even some stuff we should be refactoring as well. ‑There\u0026rsquo;s no one way to create an anti‑corruption layer. Whatever you need in order to insulate your system from the systems it works with is what you should put inside of this layer, which should allow you to simplify how you interact with other systems, ensure that their domain decisions do not bleed into your design, and ensure any necessary translation is done along the way.\nReview and Resources We\u0026rsquo;ve covered some new topics in this module, and there\u0026rsquo;s a few new terms that we want to make sure we review. Domain events are a type of object that actually represents something that occurred within the domain that other parts of the system may find interesting and want to tie their behavior to. And this is a great way to keep your system decoupled and to keep your individual objects simpler because they don\u0026rsquo;t have to know about all of the behavior that might occur when some event takes place. We also referred to the Hollywood principle, which can be summed up as don\u0026rsquo;t call us, we\u0026rsquo;ll call you. This principle is related to the dependency inversion principle from SOLID and is frequently used to decouple systems from one another. Instead of us putting all the logic we need in our code, we architect the system so that it calls back to us at the appropriate time. And we put our code into handlers that the app calls, rather than directly coupling our model to these actions. ‑And finally, we looked at anti‑corruption layers, which can be used to ensure that our model that we worked so hard to produce doesn\u0026rsquo;t become polluted by the models of other systems we work with based on objects they wanted to return to us or the type of API that they want us to code to. So we put anti‑corruption layers in place to shield our model from those other systems or bounded contexts that we might work with from our bounded context. ‑In this module, we introduced domain events, and hopefully, you have a good idea of what they are at this point. ‑We\u0026rsquo;ve talked about how you can identify opportunities to use domain events based on the kinds of requirements your customers give you, as well as when you see code in your model that\u0026rsquo;s doing too much and could be more loosely coupled. ‑We gave you some tips for designing and naming domain events, and then we showed them in action, both in a relatively simple console app, as well as in our much larger veterinary clinic sample application. ‑Finally, we introduced the concept of anti‑corruption layers, which use a variety of design patterns to insulate our model from the design choices of other applications or bounded contexts. Here are a number of resources where you can learn more about domain events and anti‑corruption layers. Some of these, including a few Pluralsight courses, we mentioned in this module, but there are others that we find to be relevant, even if we didn\u0026rsquo;t explicitly mention them. ‑Up next, we\u0026rsquo;re going to wrap up this course by adding a new feature to the application. Because of our clean architecture and well‑designed domain model, it\u0026rsquo;s going to be pretty easy to integrate into our existing app. I\u0026rsquo;m Steve Smith, ‑and I\u0026rsquo;m Julie Lerman, and thanks for watching this module of our Domain‑Driven Design Fundamentals course.\nEvolving the Application Easily Thanks to DDD Introduction and Overview Hello, this is Julie Lerman, ‑and this is Steve Smith. In this module, we\u0026rsquo;re going to wrap up our course on Domain‑Driven Design Fundamentals by showing how we can reap the benefits of our design when it\u0026rsquo;s time to add additional functionality to the system. ‑In this module, we\u0026rsquo;ll first review our current system design and see how it incorporates DDD patterns and practices. Then, we\u0026rsquo;ll circle back to our customer, Michelle, to see how the new vet clinic appointment management system is working out. ‑During that quick conversation, we\u0026rsquo;ll learn about a new feature, and we\u0026rsquo;ll show how we can implement that feature. ‑We\u0026rsquo;ll leverage message queues to implement this feature, so we\u0026rsquo;ll definitely be sure to share with you some of the basics about message queues before we show you that code. ‑The main benefit of our design choices is the ease with which the system can be extended and maintained in the future. And we hope you\u0026rsquo;ll agree that adding to the current design is quite straightforward.\nReviewing Our Current System Design So far, our system is pretty simple, though it\u0026rsquo;s fairly complex, as most course demo apps go. ‑The system is currently two different web applications, although the user interface makes it look like a single app. Our main focus has been the application used by clinic employees to schedule appointments. There\u0026rsquo;s a lot of complexity with scheduling, so this benefited from domain‑driven design. There\u0026rsquo;s also a clinic management application that\u0026rsquo;s used to do simpler data‑in/data‑out tasks like record keeping and maintaining information about doctors, clients, patients, and more. Let\u0026rsquo;s review the scheduling app a little more closely. ‑We have a single aggregate for a schedule, which contains a number of appointments. We limit access to the schedule through the schedule repository class, which is responsible for retrieving and storing the schedule in our database. We\u0026rsquo;ve identified a couple of value objects that allow us to better model concepts in the domain, and we\u0026rsquo;re making use of domain events to allow our domain in other parts of our system to respond to changes in the state of our model. ‑It\u0026rsquo;s taken us a while to get to this point, but now that we\u0026rsquo;re here, the design of the system is very clean, and it reflects the customers domain, as well as we\u0026rsquo;ve been able to model it so far, of course, given some time constraints. ‑Yes, we do have to ship the app, I mean, this course, at some point. ‑Right, of course, as we build on this application, our model would continue to evolve. But we\u0026rsquo;ve shown you techniques you can use to ensure that you can grow the application without being overwhelmed by the complexity you\u0026rsquo;re trying to model. ‑Actually, as it turns out, the customer does have one more request for us. She said something about customers forgetting their appointments. Let\u0026rsquo;s have another quick conversation.\nAddressing a New Feature with the Domain Expert As it turns out, the customer does have one more request for us. She said something about customers forgetting their appointments. Let\u0026rsquo;s have another quick conversation. ‑Hey, Michelle, great to see you. How are things going with the new scheduling application? ‑It\u0026rsquo;s been fantastic. We\u0026rsquo;re really able to see very easily who scheduled each day, and book new appointments, and move things around is needed, and the front desk folks really appreciate that it highlights the appointments that are conflicting or unconfirmed. That makes it much easier for them. But one thing that\u0026rsquo;s still a problem is the fact that sometimes our clients forget their appointments. It probably happens at least a couple of times every day, and our staff really don\u0026rsquo;t have the time to call every client to make sure they remember ahead of time. ‑So, you\u0026rsquo;d like the system to call them then? ‑Well, we understand there\u0026rsquo;s services that\u0026rsquo;ll do that sort of thing and we might move to that eventually, but for now, if we could just send an email that would probably help remind clients to put it in their calendar. ‑Oh, okay, so, do you want an email to go out when they schedule the appointment or on the day before they\u0026rsquo;re scheduled to come in, or maybe even both? ‑Oh wow, if we could do both, that would be great, one to let them know when they\u0026rsquo;ve booked so that they know that we\u0026rsquo;ve got it in our schedule and another one to remind them that they have an appointment the next day, just in case they forgot. ‑That shouldn\u0026rsquo;t be too hard. Our model already handles certain events that occur, like when appointments are scheduled, and appointments already support being marked as confirmed too. ‑Sure, and I think all we\u0026rsquo;ll really need to build that\u0026rsquo;ll be new is some kind of service for sending the emails and some way for clients to click a link in the email so they can confirm the appointment. Since it\u0026rsquo;s email, it shouldn\u0026rsquo;t be a problem to send these out the day before, even if that day isn\u0026rsquo;t a week day or a work day, right? ‑No, I think that should be fine. It shouldn\u0026rsquo;t hurt anything to send an email on a Sunday or a holiday, and of course, we\u0026rsquo;ll ask our clients to opt into these reminders so we\u0026rsquo;re not sending anything unsolicited. ‑Sounds good. We\u0026rsquo;ll get started, and should have something for you to review real soon.\nPlanning Our Implementation Steps Before we get into the gory details of the implementation, we just want to make sure that you understand the very high level of what we\u0026rsquo;re doing here. The first thing is triggered when the appointment is scheduled. And in response to that, our system will send a confirmation email to a client. ‑Once the client gets that confirmation email, they can click a link to confirm that they\u0026rsquo;re going to make it to the appointment, and the system will then mark that appointment as confirmed so that on the schedule, the staff will see that it\u0026rsquo;s got a green box around it, and they should expect the client will actually show up. ‑What\u0026rsquo;s nice about this implementation is that it benefits so much from a lot of the infrastructure we already have in place. And thanks to our DDD‑based architecture, it\u0026rsquo;s just as easy to add in a few extra features that we need to make this work. ‑So as we go through this, you\u0026rsquo;ll see us using some existing and some new domain events, some application events, a number of event handlers and services. One new tool you\u0026rsquo;ll see is something we haven\u0026rsquo;t talked about yet, messaging queues to communicate between separate applications. The application we\u0026rsquo;ve been working with will need to communicate with a public website that the customers will interact with when they confirm their appointment.\nIntroducing Message Queues Before we go any further, we did just mention something new, which is message queues. And we just want to talk about that a little bit. It\u0026rsquo;s a pretty advanced topic for this fundamentals course, so we\u0026rsquo;re going to talk about it at pretty much a high level. ‑Message queues are nice to use between applications for a number of reasons. They can help decouple them and make it so that one of the applications can just drop off something into a message queue and continue on with its work and not have to worry about what happens to the message after that. ‑Right, or if whichever application or applications it\u0026rsquo;s trying to communicate with, it doesn\u0026rsquo;t need to worry if that application is available and listening at that very moment. The message can sit in the queue and when the other application is ready to grab it, it does. With a message queue, we\u0026rsquo;re really just dealing with a single message. One application drops it, and the other one takes it, and then the message is gone. ‑Yeah, and there\u0026rsquo;s lots of different implementations of message queues that you can find online. Some of them are free. Most of the cloud services that are out there now have these types of things built in as well. ‑And what we\u0026rsquo;re doing here is dealing with a single message at a time in something of a silo app since we control both applications that are communicating with each other. But sometimes you need to have a lot more flexibility than that, you might actually have a number of applications that are interested in that message and you may not even know in advance or control those applications. So this is when something called a service bus comes into play. ‑Right, so you\u0026rsquo;ll frequently hear about something called an enterprise service bus. And there\u0026rsquo;s, again, a number of examples of these that you can find available. It usually sits on top of message queues and other features. And one of the responsibilities it has is making sure that messages get delivered to the different applications that care about that message. ‑It might even be an application that didn\u0026rsquo;t even exist or you didn\u0026rsquo;t know about when you were first setting up the message queue. So even at that point, because service bus allows you to decouple the routing of the message, it\u0026rsquo;s possible to go ahead and hook up other applications to listen to the queue. ‑Right, so you\u0026rsquo;ll see in our scenario that we have our scheduling application raising an event that an appointment was created. And it might be that maybe in the future we would want to add some other application that wants to react to that event. ‑We could publish it to social media, hey, I\u0026rsquo;m going to go see the vet. ‑Exactly. If we had a service bus, we could simply wire up in our service bus for this new social media notifier service, pick up that event. But with just message queues, as you\u0026rsquo;ll see in our implementation, we would have to change our scheduler application to know about this new app and write to its queue because we don\u0026rsquo;t have any advanced routing, everything\u0026rsquo;s hardcoded in our simple scenario. The message queue we are using is RabbitMQ. It\u0026rsquo;s a mature, open‑source message broker that you can get set up and running with zero install by using a prebuilt Docker container. It has a lot of capabilities, but we\u0026rsquo;re keeping it simple and just using it to define a few specific queues, which are separate bounded contexts we\u0026rsquo;ll use to publish and consume events.\nSending a Message to the Queue Now let\u0026rsquo;s take a look at how we\u0026rsquo;re adding message queues into our solution. The first part of the process happens when the appointment is scheduled. And you\u0026rsquo;ve already seen our AddNewAppointment method inside the schedule aggregate root. And you saw how the domain uses domain events and domain services to notify the user interface if there\u0026rsquo;s a conflict in the schedule. In the previous module, we showed you MediatR, which we\u0026rsquo;re using to publish these domain events. And we also talked about integration events, which are structured to be shared between different applications. So what we\u0026rsquo;re going to do in our system is add RabbitMQ into the mix at the same point where MediatR is publishing the domain events. But we\u0026rsquo;ll ask RabbitMQ to publish our integration events. These events will be formatted as JSON data before they\u0026rsquo;re inserted into the queue. So let\u0026rsquo;s see what this looks like in the application. We\u0026rsquo;ll be looking at the code that makes all of this work a little further on in this module. We\u0026rsquo;ll go ahead and create a new appointment. Let\u0026rsquo;s bring Sampson in to see Dr. Jones again. So there\u0026rsquo;s the appointment. Nothing has changed from the perspective of the user. RabbitMQ includes a user interface to inspect the queues, and in the Front Desk app the menu has a link so that you can open up this admin page and see what\u0026rsquo;s going on with the queues that are associated with this application. We\u0026rsquo;ll head to the Queues page and then drill into the vetclinicpublic queue, which is a queue that we set up to handle communication between the Front Desk app and the VetClinicPublic app. And you can see that the one and only message that RabbitMQ is tracking is in that queue. So we\u0026rsquo;ll drill into that queue and then scroll down to see the details of the message itself. And the most interesting part, the payload, which is the JSON expression of the event data. You can see the GUID value of the AppointmentId, the ClientName is Julie Lerman, an email address, which is not really my email address, the PatientName is Sampson, and other relevant details that came from the integration event. So the Front Desk app knew to publish the message to this queue, and our VetClinicPublic app knows to read from this very specific queue in order to perform the task of emailing the client.\nReading From the Message Queue and Acting on the Message Now that the message is waiting in the message queue, it\u0026rsquo;s time to read the message and act on it. And acting on it is the next step in a workflow, sending an email to the client to let them know about the appointment they\u0026rsquo;ve just scheduled. We can\u0026rsquo;t do this easily from our scheduler application because we need for the user to be able to click on a link that specifies that they want to confirm their appointment, so it needs to be publicly accessible. So we\u0026rsquo;ve decided to put this on the veterinary clinic\u0026rsquo;s public website, and so that will be responsible both for sending the emails and for hosting the link that the customer will click. The public site uses a hosted service to periodically check for new things in its queue. Once it finds a message on the queue, it will retrieve the information from that message to create a confirmation email using code like what you see here. One of the most important pieces of this email is a link back to the public website, not really localhost, which includes the GUID that represents the appointment ID. The website then sends the email. That\u0026rsquo;s what the user will end up clicking on in their email and trigger a confirmation using the website. Alright, so now we\u0026rsquo;re looking at the vet clinic public website, which is a super simple demo solution that we put together. And one of the things it does when it starts is start checking for messages, which you can see here. But we don\u0026rsquo;t have it running quite yet because it would\u0026rsquo;ve already pulled the message out of the queue. First, we\u0026rsquo;ll show you the code that\u0026rsquo;s making this all work, and in a bit, we\u0026rsquo;ll step through while debugging. The public website has a hosted service called FrontDeskRabbitMqService, which periodically checks the message queue to see if anything new has arrived. As soon as it finds one of those messages off of the message queue, it\u0026rsquo;s going to send an email, and we\u0026rsquo;re going to use a tool called Papercut, which will emulate a local email server for the purpose of testing. Rather than installing this on our dev machines, we\u0026rsquo;re running a Docker container to host Papercut. You can view emails Papercut has received by clicking the Sent Emails link from the FrontDesk app\u0026rsquo;s menu. Currently, there aren\u0026rsquo;t any emails in Papercut, but as soon as we start the web application, it\u0026rsquo;s going to check our message queue and then send an email that we should see appear in Papercut. There\u0026rsquo;s a message, the same message that we sent out for Sampson\u0026rsquo;s appointment. There\u0026rsquo;s a hyperlink that leads us back to being able to confirm. Let\u0026rsquo;s see first, high level, what happens when we click on that CONFIRM button, and then we\u0026rsquo;ll come back and click it and watch it in action. So now the user has the email, and their beautiful CONFIRM link in the email. When they click that, it opens up the website, browsing directly to the GUID that was their appointment. And in response, the website calls its own method called confirm, which takes the relevant appointment ID and pushes it into another one of the queues. You\u0026rsquo;ve seen the message queue that was used for relaying the message from FrontDesk to the public website, and that was named fdvcp‑vetclinicpublic‑in. Try to say that five times fast. But you can have as many queues defined in your system as you need. And one of the other queues that we\u0026rsquo;ve defined is for relaying messages from the public website, in other words, when the client has clicked on the button to confirm their appointment back to the FrontDesk app.\nUsing Multiple Queues to Handle Various Communications Now that the email\u0026rsquo;s been sent, let\u0026rsquo;s see what happens when the client clicks on the CONFIRM link in that email. ‑When we click on that, we\u0026rsquo;ve now confirmed the appointment. Once the user clicks on the CONFIRM link, it drops the message with the confirmation back into the scheduler queue, and you can see that message right here. ‑Yeah, this middle queue shows that there\u0026rsquo;s one message. Let\u0026rsquo;s look at it. We\u0026rsquo;ll scroll down to the Get Message(s) button, and the message is retrieved and displayed. We\u0026rsquo;ve seen this before where the payload is the JSON data we\u0026rsquo;re looking for, and this one contains the appointment ID that\u0026rsquo;s just been confirmed. Now you can see that the two different applications are communicating back and forth with each other using their two separate message queues. We\u0026rsquo;ve named the queues so that it\u0026rsquo;s clear which applications are using them to communicate and in which direction. The initial acronym specifies which two applications are involved. Fdvcp means frontdesk and vet clinic public. The latter part of the queue\u0026rsquo;s name says which app is listening to it. The last step now is for this confirmation information that\u0026rsquo;s sitting in the queue to get back to the scheduling app. ‑Now in our scheduler application, we have implemented a hosted service just like you saw in the public website This one is called the VetClinicPublicRabbitMQService, and it listens to the appropriate queue to see if there are incoming messages that it needs to deal with. When it finds one, it responds to the AppointmentConfirmLinkClickedIntegrationEvent, yes, it\u0026rsquo;s a long name, with the email confirmation handler. The handler looks up the appointment from the AppointmentId that was contained inside of the message, and from there, it calls Appointment.Confirm. Appointment, as you recall, is our entity, and its confirm method also then triggers some domain events, which for instance, our user interface listens to. And when it sees that that event has been fired, it triggers a change in the UI, enhancing the appointment with a green bar across the top to show that the appointment has been confirmed. Okay, so all that\u0026rsquo;s going to happen at this point is that when the message comes through, it\u0026rsquo;s going to make the Sampson appointment right here have a green border and pop up a dialog to let us know that a change has occurred. ‑It\u0026rsquo;s very slick. This is actually really easy to implement because we already had the website listening for events. Remember how it was able to display new appointments and display conflicts? We\u0026rsquo;ve implemented another design role based on a particular property of the appointment, which is confirm. All we did was set up another event handler. ‑We wrote the original sample for the first version of this course in 2013. At the time, things like SignalR and WebSocket, as well as emails with confirmation links were relatively rare, although we certainly didn\u0026rsquo;t invent these kinds of app interactions. ‑Right, but now, every time I make an appointment for my dentist or hair and even for Sampson in real life to go to the vet, I\u0026rsquo;m getting texts or emails with exactly these kinds of confirmation links. ‑I know, I guess maybe a lot of businesses watched our course.\nDebugging to See the Detailed Implementation in Code Now we\u0026rsquo;re going to take a deep dive into the code that makes all this work, and we\u0026rsquo;ll go through it step by step so that you can see how all this is wired together. And we\u0026rsquo;ll do that by literally just debugging through the whole process, so you can see how all the code links up. Remember, all of the code for this sample is available on GitHub, and we encourage you to run it yourself to really understand how it works. The README file has instructions for running the solution using Docker, which is the recommended approach if you just want to see it running. There are also instructions for using Visual Studio or VS Code, which you will need if you want to debug the apps as we\u0026rsquo;re about to do. For instance, I need to run RabbitMQ and PaperCut using the Docker commands shown here, before I can debug the app, as we\u0026rsquo;re about to see. We\u0026rsquo;re back in the vet manager, and the user is on the phone with Steve who wants to make an appointment with Darwin. Everything works just the same way it\u0026rsquo;s worked before. We\u0026rsquo;ll go ahead and add a new appointment and save the appointment, which triggers the ScheduleAggregate root\u0026rsquo;s AddNewAppointment method. We\u0026rsquo;ll leave the Locals window open while we\u0026rsquo;re debugging so that if you want to pause the video and take a look at any of those values, you can do that. We haven\u0026rsquo;t changed anything in the method. The only thing that\u0026rsquo;s different is that now we\u0026rsquo;ve got an additional subscriber that\u0026rsquo;s listening for this domain event, this particular domain event, the AppointmentScheduled event, to be raised. So we\u0026rsquo;ll go ahead and raise the event and watch what happens. At this point, we\u0026rsquo;re looking at a new class that we created, which is this RelayAppointmentScheduled service, and what it\u0026rsquo;s responsible for is creating the event that is going to get pushed onto the message queue that the public website is listening to. This is the new piece of logic that\u0026rsquo;s listening for the event that we just raised. You can see it\u0026rsquo;s listening for AppointmentScheduledEvent, a domain event, and in the method, the first thing we do is to create the AppointmentScheduledIntegrationEvent that represents our cross‑domain message that will be sent using RabbitMQ. The functionality we need from this event right now is to be able to send an email to the client, so we make sure to include all of the data that such an email would require. Now we\u0026rsquo;re in the Publish method that lives inside of RabbitMessagePublisher, and that\u0026rsquo;s inside of an infrastructure project. We\u0026rsquo;ve moved out of the core domain, but this is still part of the main front desk scheduling application. Yes, and what it\u0026rsquo;s responsible for doing is actually getting that message into a structure, a format that RabbitMQ can use. That means putting things into JSON format in this case, and then actually sending the message. Once this fires, we should be able to inspect the message queue in RabbitMQ, and verify that our message has actually been queued up for the VetClinicPublic input queue as expected. That\u0026rsquo;s what we did before, but this time we\u0026rsquo;re actually seeing the code that\u0026rsquo;s making all of this happen. Alright, so that completes the actual thread of the UI. The response is complete for this part of the application. Now we\u0026rsquo;ll pause this and switch over to the VetClinicPublic application. We\u0026rsquo;ve just started it up again, and we\u0026rsquo;ve shown this to you before. Now we\u0026rsquo;re going to watch the flow of the code after the hosted service starts up. Jumping to the next breakpoint, you can see now we\u0026rsquo;re inside of the actual HandleMessage method, which gets the message as a string. It\u0026rsquo;s responsible for parsing the string using JSON, and deserializing it into an appropriate type. This is just demo code, so it\u0026rsquo;s not the most reusable or elegant, but it works for this app. Remember that any change to the integration event in the front desk app will require changes here as well, which is one reason why a shared package can be useful for keeping applications in sync. Once we\u0026rsquo;ve deserialized the message into a command, we use mediator to send the command, and a separate handler to actually send the email. This keeps extra code out of the hosted service, and lets the handler use dependency injection to get any services it needs. In this case, it\u0026rsquo;s an implementation of, I send confirmation emails, called ConfirmationEmailSender. It\u0026rsquo;s the service that builds the email with its details, including the URL behind the CONFIRM link in the email that the client receives. Remember, the whole reason why we need a separate app to implement this feature is that the end user needs to be able to click a link that goes to a public location on the internet. The front desk app is an internal app that runs inside the vet clinic\u0026rsquo;s network so it\u0026rsquo;s not accessible. The public website is a good place to send users, and while they\u0026rsquo;re there, they can get more details about the clinic, or buy something from its theoretical online store, etc. After the email has been sent, we can see it in PaperCut, and opening it, we can see the CONFIRM hyperlink. Clicking the link brings us back into the VetClinicPublic application\u0026rsquo;s, AppointmentController class. This endpoint simply creates a new event. This is the one with a really long name, AppointmentConfirmLinkClickedIntegrationEvent. Unlike the name of the event, the message itself is really simple, and just includes the appointment ID that was confirmed, and when it happened. The controller action then sends the event using a RabbitMQ messagePublisher that\u0026rsquo;s identical to the one we just saw the front desk app use. However, this publisher\u0026rsquo;s destination is actually a different queue, the front desk input queue. Technically, the front desk has two input queues, one for messages from the ClinicManagement app, and another for messages from the VetClinicPublic app. In this case, we\u0026rsquo;re talking about the VetClinicPublic one. Back in the front desk scheduling app\u0026rsquo;s hosted service, it discovers the message on the queue, and calls into the HandleMessage method in the service we\u0026rsquo;ve seen a number of times, the VetClinicPublicRabbitMqService. Here, it parses the message and extracts the appointment ID, which it then uses to create and publish that really long‑named event again, AppointmentConfirmLinkClickedIntegrationEvent internally. This integration event triggers a call to the EmailConfirmationHandler, which loads the schedule aggregate, then locates the appropriate appointment, and calls its Confirm method. Finally, it saves the schedule. The appointment.confirm method makes an appointmentConfirmed domain event, which is fired once the aggregate is saved, and this event in turn triggers a handler in the UI. The appointmentConfirmed handler in the FrontDesk UI sends a message via SignalR, indicating the message was confirmed. This results in the browser showing a notification, and changing the format of the appointment to have a green border. You already saw similar logic used for the AppointmentUpdate and AppointmentScheduled handlers. That\u0026rsquo;s the full round trip for how creating an appointment, getting an email, clicking a link, and confirming that appointment works for this application.\nConsidering Microservices Since we published our original version of this course, which if you haven\u0026rsquo;t watched, you\u0026rsquo;ll find a link from either of our author pages, microservices have become incredibly popular. There are some benefits to microservices, even if they\u0026rsquo;re probably a bit overhyped at the moment, and there are some obvious parallels between microservice design and DDD. ‑Microservices should be self‑contained and should not depend on other microservices. They should be independently deployable. Changing the internal behavior of a microservice should not break services that work with it, as long as it maintains compatibility with its external APIs and message interfaces. ‑So, basically what you\u0026rsquo;re saying is each microservice should have a boundary around it, and within that boundary it should focus on a specific set of behaviors that its free to model however it sees fit. ‑That\u0026rsquo;s right. ‑It\u0026rsquo;s almost like each microservice can be considered its own context, and it has its own terminology and even language for how it\u0026rsquo;s designed. ‑It is a lot like that, it\u0026rsquo;s true, and it\u0026rsquo;s not unusual for teams to treat individual microservices like bounded context with their own ubiquitous language and everything else that goes along with being a bounded context. But, beware of assuming that microservices and bounded context always have a perfect alignment. There can be plenty of scenarios where this could be a problem. My brilliant friend, Vladik Khononov, not to be confused with the also brilliant Pluralsight author, Vladimir Khorikov, has shared his experiences along these lines in his blog and also in recorded conference presentations. We\u0026rsquo;ll include links to his content in the resources at the end of this module. ‑Now, this isn\u0026rsquo;t a microservices course, but obviously if you\u0026rsquo;re working on microservices, it would be helpful for you to have a good understanding of DDD concepts, because many of the problems that microservices solve are also solved by domain‑driven design. ‑In our sample application, there is an obvious candidate for a microservice. In fact, it\u0026rsquo;s almost there already, the confirmation email sending logic that currently runs inside the public website. ‑We put the hosted service in that existing web application because it was convenient and because the two are loosely related since the emails include a clickable link that goes to a page on that public website. ‑But we could easily move that hosted service into its own process and treat it like a separate microservice, and that would simplify the public web app, so it would no longer need to have a two‑way relationship with a front desk app by way of message queues. Also, the front desk app is likely to be updated more frequently than the confirmation email logic, so it\u0026rsquo;s possible that changes to the front desk application could break the email logic. ‑Yes, one of my favorite benefits of carving out a microservice is that if it\u0026rsquo;s something stable and working, you get the benefit of just leaving it the heck alone. Updates to other parts of the app or system are much less likely to break a microservice that is in production and working, and not being deployed frequently. ‑Right, and the email sending logic is about as micro as a microservice can get, but in the future we might want to add other kinds of customer emails to send, and it would be a logical place to hold that logic. ‑Exactly, and since it has no user‑facing logic, it\u0026rsquo;s a pretty simple change to make. Maybe some of our students could do that as another exercise.\nSharing Some Tips for Extending and Running the Sample Application As we wrap up the course, we want to remind you, once more, that there are a number of to‑do items in the sample that you can use as ideas for ways to extend this demo app. Doing so would help you gain real experience working with the architecture and patterns you\u0026rsquo;ve learned in this course. You\u0026rsquo;re sure to learn and retain more from actually working with the code than from just listening to us or watching us show you the code. ‑We do have detailed instructions in the README for how to run the app. You can run the individual solutions in Visual Studio, but if you do so, keep in mind, you\u0026rsquo;ll also need to make sure you have a local SQL Server running, and you\u0026rsquo;ll need to update the connection strings and app settings for the applications to access it. You\u0026rsquo;ll also need your own RabbitMQ and Papercut or similar test email server running, either as Docker containers or locally‑installed services. There\u0026rsquo;s definitely a bit of effort involved in getting all of this set up and running the first time. ‑Alternatively, if you just want to run the app and see everything working, you should be able to do so with just two commands, assuming you have Docker installed. Just run docker‑compose build ‑‑parallel and then docker‑compose up. Each of these commands might take a few minutes. It usually takes about 2 minutes for the build step on my machine, and it\u0026rsquo;s normal to see some errors when the docker‑compose up command runs until all of the services are up and running. Once the process stops outputting messages to the log window, you should be able to hit the application. To do that, take a look at the ports that are shown in the README file. And in the Docker column, you\u0026rsquo;ll see the ports for all of the different applications and utilities that are used.\nConsidering the UI in the Domain Design The control we used solved a number of the problems we thought we were going to have when embarking on this application. But the fact that the UI kind of impacted how we designed our domain begs the question about, well, if you\u0026rsquo;re totally focused on the domain, why would you even be thinking about the UI? But thinking about the UI while we\u0026rsquo;re working on the domain is not the anti‑pattern you may think it is. ‑Yes, we\u0026rsquo;ve been focusing on the domain, but frequently the user interface needs to be considered, especially in the early stages of planning. You don\u0026rsquo;t want to try to flesh out the whole domain design before you start thinking about the UI. ‑In a TechEd session I attended in 2013, Jimmy Nilsson, who\u0026rsquo;s the author of the book Applying Domain‑Driven Design and Patterns, talked about the importance of thinking about the UI in the early stages of planning and revisiting it while modeling the domain, rather than ignoring it until the end. In his session, he describes how even the UI sketching he does in the early stages of his application planning can affect the whole design of the system. As we were building this scheduler sample for this course, we actually discovered a huge benefit to considering the UI early in the process. We initially had expected to encounter a lot of complexity in the appointment scheduling problem, but we found a UI control that helped visualize the schedule for the user, such that the system no longer needed to be as complex. In our scenario, scheduling is a big part of the application, but it isn\u0026rsquo;t our domain, our domain is the veterinary clinic. We consider scheduling to be more of a cross‑cutting concern, and one that could be partially solved through a rich user interface. ‑By considering and using a rich user interface, we were able to do things like allowing conflicting appointments while making it obvious to the user that this had occurred. This gives the user more information, and they can make decisions about whether or not they need to correct the problem. When we initially considered the problem of appointment conflicts, we had thought the domain model would throw exceptions anytime something like that occurred. But this would have resulted in a much worse user experience. Frequently, in domain‑driven design, you need to consider the user experience, which at times may need to allow for models that are, at least temporarily, in an invalid or incomplete state. Keep this in mind as you design your domain model, and be careful not to make it too rigid to support scenarios your users may benefit from. ‑Thinking about the UI up front and discovering this kind of solution kept us from wasting a lot of time trying to solve certain scheduling problems in our domain. Of course, you don\u0026rsquo;t want your UI to totally drive how you model your domain, but as Jimmy Nilsson notes, you shouldn\u0026rsquo;t ignore it, either.\nModeling with Event Storming and Other Techniques When you\u0026rsquo;re developing apps using DDD, it can be helpful to visualize how processes communicate both within a bounded context and between context as part of a business process. As we mentioned earlier in this course, Alberto Brandolini has done a lot of work on a related practice called event storming. Event storming can be used by all parts of a business, not just developers, to describe how a part of the business works and to make the whole thing visible. Once this is done, later iterations of the diagrams and artifacts produced can be useful for modeling the software that will be used by the business. ‑You might recall the image we showed earlier of Julie facilitating an event storming workshop with a client. The result of that first iteration, called chaotic discovery, is not so easily captured, but it provides guidance for the later modeling you might do. ‑There are many ways to model your system. Another method, Event Modeling, championed by Adam Dymitruk, is another process, and this focuses on the inputs and outputs of events and how each of those events changes the system and changes state. And you can describe an entire system with this flow. ‑We\u0026rsquo;ve used the wonderful online tool called a Miro board at miro.com to show one perspective of the scheduling system as information flows through the front desk application and into the VetClinicPublic website bounded context. The colors used here correspond to different things in our model, like aggregates, events, and other processes. ‑And there are other modeling processes that have been invented, adopted, and adapted within the DDD community. And many of us rely on a combination of processes and tools to help us and help our clients better understand their systems before embarking on design. But as always, balance is important. You\u0026rsquo;ll want to beware of analysis paralysis. ‑Definitely. That reminds me of something Eric Evans talked to us about.\nEric Evans on the Fallacy of Perfectionism Steve and I believe that it would be fitting to leave you with one last thought from the father of domain‑driven design, Eric Evans. Eric was kind enough to talk to us about DDD when we originally created this course so that we could share with you some of his wisdom. Eric talked about the fallacy of perfectionism, which aligns with our own sentiments about considering what you\u0026rsquo;ve learned here to be guidance to help you solve complex software problems, not a roadblock to productivity. ‑Eric shared with us that what he\u0026rsquo;s noticed is that there seems to be something about DDD that brings out the perfectionist in people, and they say, this model is not really good enough and churn and churn, trying to improve it. He says, no model is ever going to be perfect. ‑Eric goes on to say that we need to know what we\u0026rsquo;re doing with this thing, the scenarios we\u0026rsquo;re trying to address. We want a model that helps us do that, that makes it easier to make software that solves those problems. That\u0026rsquo;s it. ‑This reminds me of the saying, all models are wrong, but some are useful. Our domain models don\u0026rsquo;t need to be perfect. They just need to help us build the software that helps people solve problems and get work done. Don\u0026rsquo;t strive for a perfect model, but rather just aim to develop a useful one.\nLessons Learned Since Our 2014 Course Julie and I wanted to finish this course by spending a couple of minutes talking about some of the things we\u0026rsquo;ve learned since we published the first edition of the course in 2014. ‑We\u0026rsquo;ve received a ton of positive feedback from so many of you over the last few years, and we really appreciate it. So we did our best not to change the overall flow of this course too much since we know the last one was so well‑received. ‑Definitely. If you watched the original version, hopefully you found this one to be fresh, but familiar, and I suspect a lot of students will end up watching both as a way to cement some of these concepts or just to spend more time with us, right, Julie? ‑Maybe. Now let\u0026rsquo;s highlight some of the things that have changed in the last few years. From a strict DDD perspective, there are a lot of new resources and techniques that have emerged as more and more companies are adopting DDD. Things like event storming an event modeling, which we\u0026rsquo;ve touched on in this course, are starting to become mainstream parts of DDD for many organizations. ‑Yes, and the industry\u0026rsquo;s use of some patterns have shifted too. There\u0026rsquo;s a lot of pushback against the repository pattern these days. I think, in part, because it became very popular, but was often used without the context of DDD or other complementary patterns like the specification, and these can really help it shine. Our first course didn\u0026rsquo;t really talk much about specification as a core DDD pattern, but it\u0026rsquo;s something I use on most of my projects now. ‑From a technology perspective, our previous course was built for .NET developers, and at the same time, that meant .NET 4. The original veterinary application used ASP .NET, MVC, and Web API, and an early version of SignalR. And for data access, we used Entity Framework 6. ‑Since then, .NET Core, which is now .NET 5, has shipped and become the new standard for .NET developers, and the latest versions of EF Core have added a number of features that we\u0026rsquo;re leveraging to help improve the design of our model like owned objects and filtered includes. We also shifted our use of domain events from being prepersistence to postpersistence. There are valid use cases for both kinds of domain events, but the latter is safer for any events that communicate outside of the domain, so we\u0026rsquo;re defaulting to that this time around. ‑Right, especially since one of our key demos involve sending emails to the client. The original sample also used SQL Server for its message broker, which we chose because we didn\u0026rsquo;t want to force our students to have to install a custom tool. But Docker is another technology that wasn\u0026rsquo;t mainstream in 2014, but it is today, and it makes it a breeze to use custom bits of infrastructure. In this update to the course, we\u0026rsquo;re definitely leveraging Docker to provide RabbitMQ messaging with 0 install, as well as to capture emails during development using Papercut in another Docker container. ‑Yeah, Docker should really make it trivial for students to run the application locally, even though it has a bunch of moving parts. If you don\u0026rsquo;t have Docker, you can still run it in your IDE or from the command line, but with Docker, it\u0026rsquo;s just a lot simpler to get going. ‑And along with Docker and containers, microservices have become a huge buzzword in the industry. Of course, Docker makes it much easier to deploy microservices, and DDD principles really shine when designing them. So all of these things, I think, are really complimentary. ‑Definitely, although I do think some companies are too quick to jump to microservices without fully understanding their domain and where to separate out different contexts. And on the topic of separation, our previous sample put everything in one giant solution, too, mostly to make it easier to find things. ‑This time, we went with something that should resemble a real‑world application even more with separate solutions for each bounded context. We even published the shared kernel as a NuGet package, in our case, hosted on nuget.org, although typically, your organization would probably have a private NuGet feed. ‑If you\u0026rsquo;re still working with .NET Framework apps and you haven\u0026rsquo;t watched the previous course, we encourage you to give it a look. Its samples are geared more toward that framework, and you should find a link to it on Julie or my author page here, on Pluralsight, or at this bit.ly link here. ‑And don\u0026rsquo;t feel bad if it feels like there\u0026rsquo;s still a lot you have to learn about DDD. It\u0026rsquo;s a big topic. And as we\u0026rsquo;ve just shared, Steve and I are constantly learning new ways to apply it, too. Be sure to check out other DDD courses here, on Pluralsight, and if you need direct help for you or your team, you can reach out to Steve or me, directly.\nReview and Resources If you remember nothing else from this particular module, the one thing to keep in mind is how simple it was for us to add in what was potentially a really complicated feature. Because of our DDD implementation and some of the infrastructure we had already built, it wasn\u0026rsquo;t really very challenging to plug these new puzzle pieces into the application. ‑Right, we introduced a couple of new concepts. We talked about message queues, and those fit really nicely into our existing architecture because we were already using events to correspond to interesting things happening within our application. ‑And the message queue allowed us to stick a message in an external place by one application, and another application can come along and retrieve that message. So the message queue allows our applications to communicate with each other, but they can do it in a disconnected way. ‑And then we mentioned, but we didn\u0026rsquo;t show, this concept of a service bus, often called an enterprise service bus, which you may want to introduce if you start having more than just a couple applications needing to talk to one another. ‑At the risk of being redundant, let\u0026rsquo;s just pay homage one more time to how the decisions we made earlier on, when implementing the vet clinic solution, allowed us to add in a potentially complicated new feature, email notifications and responses into the application. ‑While we had used mediator to transfer domain events within the FrontDesk application, this time we took advantage of message queues to help us move events back and forth between applications. ‑Using RabbitMQ\u0026rsquo;s API, we created three different queues that were specific to the cross‑application communications we needed. For example, a queue that the vet clinic public app could publish messages into for the FrontDesk application to retrieve so it could update the UI. ‑It\u0026rsquo;s also important to note that we leveraged existing tools like RabbitMQ and Papercut to perform certain tasks. In DDD, we would refer to these as generic domains. You\u0026rsquo;ve got to look under the covers to see how the code was making all the communication between the apps and the message keys possible, but without our domain model having to know about any of the details. ‑And then we shared some additional knowledge as we wrapped up the course. We talked about modeling practices like event storming and tools like MURAL. We talked about all of the new ideas that have evolved since we first published this course in 2014 and how they impacted this new version of the course and the sample application. ‑And we ended with some more wisdom from Eric Evans, to whom we are eternally grateful not only for bringing DDD to the software community, but also for spending time with us when we created the original course so that we could share his perspective and insights with you. ‑Like the end of a fireworks display when they shoot up many, many fireworks at once, we\u0026rsquo;re sharing here a lot of resources and links because of the great many topics we brought into this last module. There are two pages of links here to articles and videos and other Pluralsight courses, so you might want to pause the video to be sure that you see them all. ‑So, from me, Steve Smith, ‑and from me, Julie Lerman, thanks so much for taking this journey with us through Domain‑Driven Design Fundamentals.\n","permalink":"http://localhost:1313/posts/domain_driven_transcript_from_pluralsight/","summary":"\u003cp\u003eCourse Overview\nWelcome to Pluralsight. My name is Julie Lerman, and this is Steve Smith. Together, we\u0026rsquo;d like to welcome you to our course, Domain‑Driven Design Fundamentals. Steve is a trainer and architect with NimblePros and spends a lot of time helping teams write better code, faster. And Julie is well known in the DDD community for helping reluctant teams embrace domain‑driven design. In this course, we give you a strong foundation for learning how to build applications and microservices using domain‑driven design. DDD has proven to be a very effective approach for managing complex requirements. The original version of this course has helped many thousands of learners leverage domain‑driven design, and they have shared amazing feedback. Now, we\u0026rsquo;ve updated the course and its sample application to reflect ideas and tools that have emerged since that first version. Some of the major topics that we\u0026rsquo;ll cover include what are the essential ideas of domain‑driven design? What are the main patterns used in domain models? We\u0026rsquo;ll also talk about how to break up concepts into smaller parts and how these smaller aggregates and contexts communicate with one another. By the end of this course, you\u0026rsquo;ll know how to break down customer requirements into a maintainable domain model and structure a solution using domain‑driven design. Before beginning the course, you should at least be familiar with software development, ideally using C#. From here, you should feel comfortable diving into DDD and design patterns with courses on the DDD learning path and the design patterns learning path. We hope you\u0026rsquo;ll join us on this journey to learn domain‑driven design with the Domain‑Driven Design Fundamentals course, at Pluralsight.\u003c/p\u003e","title":"Domain driven Design: Learnings"},{"content":"Introduction One of the design considerations stressed upon by Jeffrey richter about APIs (Read more here) is that \u0026ldquo;API is expected to be stable over long period of time\u0026rdquo;. Recently,for a .NET based project, we decided to upgrade some of the ASMX (legacy SOAP based approach) based APIs and were immediately reminded by Customer(s) to avoid any kind of impact on existing users.\nThis means that upgrade must be done keeping in mind,\nNo changes to API Contract (SOAP remains SOAP and so on) No changes to URLs Testing to ensure no impact Initial plan was to move away from SOAP to adopt REST based approach. This thinking was aided by fact that .NET core may not support WCF (framework that supports SOAP apart from ASMX Web Services) in addition to other aspects like simplicity and wide adoption of REST. However, even microsoft has now decided to support WCF in .NET Core via CoreWCF.\nWith this constraints, below alternatives were considered to upgrade ASMX based services to WCF (the only other framework that supports SOAP based services),\nApproach Description Have existing ASMX Service call new WCF Service using Async/Await This involves hosting additional WCF Service and making HTTP requests to it. It also means maintaining both ASMX \u0026amp; WCF endpoints. Also to be mindful of latency introduced due to HTTP communication between the two. New WCF Service and URL Rewrite rules to handle requests to ASMX This involves developing new WCF Service, compatible to current service contract, and configuration to route/re-write incoming requests to new service. Existing ASMX end point can be sunset New WCF Service and mapping .asmx handler to WCF handler This involves developing new WCF Service,compatible to current service contract, and configuration so that requests to .asmx url will be served by WCF handler. Existing ASMX end point can be sunset. Lets go through above approaches in detail.\nWCF service invoked from ASMX asynchronously This involves developing new WCF Service. Existing ASMX based web service will be modified to invoke new WCF Service. Asynchronously invocation should help in this case since whole operation is I/O bound (Asynchrony is a way to get concurrency without multithreading. E.g., freeing up the calling thread instead of blocking it while an I/O operation is in progress Stephen Cleary). Since ASMX is legacy framework and only support Event-based asynchronous pattern (EAP), it is necessary to combine EAP with Task based asynchronous pattern (TAP) which is what async/await uses. Below is sample snippet,\nprivate async Task\u0026lt;string\u0026gt; FooAsync(int arg) { using (var resp = await client.GetAsync(string.Format(\u0026#34;https://jsonplaceholder.typicode.com/todos/{0}\u0026#34;, arg)).ConfigureAwait(false)) { resp.EnsureSuccessStatusCode(); using (var contentStream = await resp.Content.ReadAsStreamAsync().ConfigureAwait(false)) { APIResponse obj = await JsonSerializer.DeserializeAsync\u0026lt;APIResponse\u0026gt;(contentStream).ConfigureAwait(false); string output = string.Format(\u0026#34;{0} at {1}\u0026#34;, obj.Title, DateTime.Now.Ticks); System.Diagnostics.Debug.WriteLine(output); return output; } } } [WebMethod] public IAsyncResult BeginFoo(int arg, AsyncCallback callback, object state) { return FooAsync(arg).ToApm(callback, state); } [WebMethod] public string EndFoo(IAsyncResult result) { try { return ((Task\u0026lt;string\u0026gt;)result).Result; } catch (AggregateException ae) { throw ae.InnerException; } } Where ToApm is extension function from Stephen Toub\u0026rsquo;s excellent blog (link in code as comment),\npublic static Task\u0026lt;TResult\u0026gt; ToApm\u0026lt;TResult\u0026gt;(this Task\u0026lt;TResult\u0026gt; task, AsyncCallback callback, object state) { if (task.AsyncState == state) { if (callback != null) { task.ContinueWith(delegate { callback(task); }, CancellationToken.None, TaskContinuationOptions.None, TaskScheduler.Default); } return task; } var tcs = new TaskCompletionSource\u0026lt;TResult\u0026gt;(state); task.ContinueWith(delegate { if (task.IsFaulted) tcs.TrySetException(task.Exception.InnerExceptions); else if (task.IsCanceled) tcs.TrySetCanceled(); else tcs.TrySetResult(task.Result); if (callback != null) callback(tcs.Task); }, CancellationToken.None, TaskContinuationOptions.None, TaskScheduler.Default); return tcs.Task; } This approach involves,\nhosting and maintaining both (current and new) API end-points. We also came across issues where async/await was not working properly in case code blocks. Measuring and mitigating any latency induced due to this additional hop Additional Monitoring and logging to track WCF end-point We decided to explore alternative approaches instead of this.\nWCF service with URL re-write This requires hosting WCF Service which is backward compatible with ASMX based SOAP implementation.\nTypically this involves,\nsupporting basicHttpBinding Adding namespaces and support for XML Serialization to Service contract like, [ServiceContract(Name = \u0026#34;RequestReplyService\u0026#34;, Namespace = \u0026#34;http://tempuri.org/\u0026#34;),XmlSerializerFormat] Adding Action to OperationContract attribute like, [OperationContract(IsOneWay = false, Action = \u0026#34;http://tempuri.org/DoWork\u0026#34;)] Additional configuration to re-write incoming requests to .asmx to new service in web.config as below,\n\u0026lt;system.webServer\u0026gt; \u0026lt;validation validateIntegratedModeConfiguration=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;rewrite\u0026gt; \u0026lt;rules\u0026gt; \u0026lt;rule name=\u0026#34;asmxtosvc\u0026#34; stopProcessing=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;match url=\u0026#34;^service.asmx(.*)$\u0026#34; /\u0026gt; \u0026lt;action type=\u0026#34;Rewrite\u0026#34; url=\u0026#34;Service.svc{R:1}\u0026#34;/\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/rules\u0026gt; \u0026lt;/rewrite\u0026gt; \u0026lt;/system.webServer\u0026gt; One may want to test above re-write settings in IIS as older versions of it require installation of URL Rewrite module.\nThis is followed by testing new WCF service from existing client(s), be it .NET based clients or other ones with no changes. .NET based clients typically invoke service through generated proxy class. For other clients, we basically simulated it via Postman.\nThis approach provides cleaner implementation vis-a-vis earlier approach such that it is still new WCF based implementation with no ASMX in use.\nWCF service with .asmx extension mapped to WCF handler This approach is very similar to last one with only change being instead of using URL re-write module, we will map .asmx extension to WCF Handler. So the changes are only in web.config as below,\n\u0026lt;system.web\u0026gt; \u0026lt;httpHandlers\u0026gt; \u0026lt;remove path=\u0026#34;.asmx\u0026#34; verb=\u0026#34;*\u0026#34; /\u0026gt; \u0026lt;add path=\u0026#34;*.asmx\u0026#34; verb=\u0026#34;*\u0026#34; type=\u0026#34;System.ServiceModel.Activation.HttpHandler, System.ServiceModel, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089\u0026#34; validate=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/httpHandlers\u0026gt; \u0026lt;compilation debug=\u0026#34;true\u0026#34; targetFramework=\u0026#34;4.8\u0026#34;\u0026gt; \u0026lt;buildProviders\u0026gt; \u0026lt;remove extension=\u0026#34;.asmx\u0026#34;/\u0026gt; \u0026lt;add extension=\u0026#34;.asmx\u0026#34; type=\u0026#34;System.ServiceModel.Activation.ServiceBuildProvider, System.ServiceModel, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089\u0026#34;/\u0026gt; \u0026lt;/buildProviders\u0026gt; \u0026lt;/compilation\u0026gt; \u0026lt;httpRuntime targetFramework=\u0026#34;4.8\u0026#34;/\u0026gt; \u0026lt;/system.web\u0026gt; .... \u0026lt;system.webServer\u0026gt; \u0026lt;handlers\u0026gt; \u0026lt;remove name=\u0026#34;WebServiceHandlerFactory-Integrated\u0026#34;/\u0026gt; \u0026lt;add name=\u0026#34;MyNewAsmxHandler\u0026#34; path=\u0026#34;*.asmx\u0026#34; verb=\u0026#34;*\u0026#34; type=\u0026#34;System.ServiceModel.Activation.HttpHandler, System.ServiceModel.Activation, Version=4.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35\u0026#34; /\u0026gt; \u0026lt;/handlers\u0026gt; \u0026lt;validation validateIntegratedModeConfiguration=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/system.webServer\u0026gt; This was tested in same way as earlier with existing .NET and other clients.\nThis feels like even more cleaner approach than using URL re-write as it doesn\u0026rsquo;t involve using any additional module/library.\nFinally, we went ahead with this approach.\nHopefully,this article will be helpful to anyone involved in legacy modernization initiatives.\n[Update on 21-May-2021]\nASMX supports both SOAP as well as Form POST (i.e. content type application/x-www-form-urlencoded). This implies that there would be consumers of this API who are using either of the two formats to interact with API. Hence, it is necessary that new WCF based API supports both the formats. One way (If you are aware of any other approach, do let me know via comments) is to, Expose both SOAP and HTTP End-points like below,\n\u0026lt;service name=\u0026#34;wcf.Myservice\u0026#34;\u0026gt; \u0026lt;endpoint address=\u0026#34;\u0026#34; binding=\u0026#34;basicHttpBinding\u0026#34; contract=\u0026#34;wcf.IMyserviceSoap\u0026#34; /\u0026gt; \u0026lt;endpoint address=\u0026#34;http\u0026#34; kind=\u0026#34;webHttpEndpoint\u0026#34; endpointConfiguration=\u0026#34;webEndpointWithHelp\u0026#34; contract=\u0026#34;wcf.IMyservice\u0026#34; /\u0026gt; \u0026lt;endpoint address=\u0026#34;mex\u0026#34; binding=\u0026#34;mexHttpBinding\u0026#34; contract=\u0026#34;IMetadataExchange\u0026#34; /\u0026gt; \u0026lt;/service\u0026gt; This exposes SOAP end point at root (/) and HTTP end-point at (/http).\nSince clients are not aware of this new http end point, additional steps are needed to handle non soap requests seamlessly. This can be done in Global.asax as below,\nprotected void Application_BeginRequest(object sender, EventArgs e) { const string httpAddress = \u0026#34;http/\u0026#34;; if (Request.HttpMethod.ToLowerInvariant() == \u0026#34;post\u0026#34;) { if (!Request.ContentType.ToLowerInvariant().Contains(\u0026#34;xml\u0026#34;) \u0026amp;\u0026amp; !Request.Url.AbsolutePath.ToLowerInvariant().Contains(httpAddress)) { List\u0026lt;string\u0026gt; segments = Request.Url.Segments.ToList(); segments.Insert(segments.Count() - 1, httpAddress); var redirPath = String.Join(\u0026#34;\u0026#34;,segments.ToArray()); Context.RewritePath(redirPath); } } } Above function, injects http in path based on Content-type of incoming request and then re-writes it.\nIdeally, i would have liked to do it via URL Rewrite module in web.config. However, i faced issues while setting up the rule that uses Content-type header.\nHowever, this approach still had issues wherein WCF run-time raised errors when ?singlewsdl url was accessed. It seems problem was due to multiple interfaces (one for SOAP and other for REST) and WCF not being able to generate WSDL for it. Additionally, REST handler is also deserves a look as it simply parses payload as Query String and populating properties of request DTO/class has to be done manually,\nResponseDTO IMyservice.Process(Stream input) { string body = new StreamReader(input).ReadToEnd(); NameValueCollection nvc = HttpUtility.ParseQueryString(body); return new ResponseDTO() { cnField = string.Format(\u0026#34;NVCol --\u0026gt; {0}|{1}\u0026#34;, nvc[\u0026#34;prop1\u0026#34;], nvc[\u0026#34;prop2\u0026#34;]) }; } Overall, WCF does not have great support for handling FORM POST requests. Hence, other alternative is to have ASP.NET MVC Web API handle the post requests. This approach is detailed here, check it out. Additionally, it takes changes to BeginRequest in global.asax to re-write incoming request so that Web API controller can process it, like below,\nprotected void Application_BeginRequest(object sender, EventArgs e) { if (Request.HttpMethod.ToLowerInvariant() == \u0026#34;post\u0026#34;) { if (!Request.ContentType.ToLowerInvariant().Contains(\u0026#34;xml\u0026#34;)) { List\u0026lt;string\u0026gt; segments = Request.Url.Segments.ToList(); Context.RewritePath(string.Format(\u0026#34;/controllers/{0}\u0026#34;,segments[segments.Count()-1])); } } } ASMX and SOAP 1.1 - It was noticed that though ASMX supports SOAP 1.1, it doesn\u0026rsquo;t enforces it when it comes to \u0026ldquo;SOAPAction\u0026rdquo; Header. As per the SOAP 1.1 specification, \u0026ldquo;SOAPAction\u0026rdquo; Http Header is mandatory and is used to determineWebmethod to be invoked. Since WCF is compliant with SOAP 1.1 specification, it required additional step to infer Webmethod by means of parsing the body. Luckily, Microsoft has sample for Dispatch by Body Element and same can be readily used. Overall, WCF Samples is fantastic set of samples that covers wide variety of such scenarios. Do Check it out.\nUseful References Comparing ASMX web services to WCF APM Pattern using Tasks Async in WCF Comparing ASMX with WCF Discussion on ASMX to WCF Happy Coding !!\n","permalink":"http://localhost:1313/posts/apiupgrade/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eOne of the design considerations stressed upon by Jeffrey richter about APIs (Read more \u003ca href=/posts/restapiversioning/\n    \n    \n\u003ehere\u003c/a\u003e) is that \u0026ldquo;API is expected to be stable over long period of time\u0026rdquo;. Recently,for a .NET based project, we decided to upgrade some of the ASMX (legacy SOAP based approach) based APIs and were immediately reminded by Customer(s) to avoid any kind of impact on existing users.\u003c/p\u003e\n\u003cp\u003eThis means that upgrade must be done keeping in mind,\u003c/p\u003e","title":"Upgrading API: Learnings"},{"content":"Introduction In a company/enterprise, typically there are multiple sources of data. This could be result of M\u0026amp;A (where each of those add in a new data store) or result of multi year process of using data stores that are in vogue at that time. Result is combination of various types of relational databases, flat file systems, queues and so on. This results in Data Silos. This scenario is typically observed in companies who are running workloads On-prem (i.e. Pre-cloud, Companies who started on Cloud or have moved to it, typically tend to organize data platform better. This could be because of ease of migrating data on cloud. Typically, they centralize it around cheaper object storage (say AWS S3)).\nCompany will want to utilize this data, accumulated over the years, for business intelligence, machine learning purposes. Usually, it would require querying efficiently across these data sources or first collecting all the data in central location (say Data Lake or Operational Data store) and then querying on it.\nOverall, below are the widely adopted approaches,\nData warehouse with ETL Approach - This involves extracting data from Transactional systems (OLTP), ERP, Events store and so on. Transforming the same and then loading it into Data warehouse which is typically a store used for Analytics. Whole process is orchestrated as workflow using ETL Tools.\nLakehouse - Many companies have two different types of storate: Data Lake and Data warehouse. The data warehouse handles offline analytics, such as BI dashboards and reports, that describe what has or is happening in a business. The data lake is store for raw data (including unstructured). Instead of ETL (Extract - Transform - Load), ELT (Extract - Load - Transform) approach is followed where data from transactional system is loaded into Data Lake. Later, it is transformed/processed for analytics purposes and loaded in data warehouse. Alternatively, there is a trend where data lake itself is used for trend and/or predictive analytics. Data lake is usually based on cheaper, object storage with data stored using open formats (like Parquet , ORC etc.) favouring columnar approach. Columnar store is typically favoured for analytics over relational one.\nAs explained in Emerging Architecture for Data Infrastructure,\nData warehouse is used for analytics use cases i.e. help business make better decisions. Data lake is used for operational use cases. All the above approaches typically assume rather large volume of data being handled. Then what can be approach for companies who are having moderate amount of data (few terabytes) and still want to derive actionable insights from it. Such companies are unlikely to have big data systems like HDFC in place.\nFor these cases, One may consider Presto a.k.a. Trino. At it\u0026rsquo;s core, Presto translates SQL queries (it supports ANSI SQL) into whatever query language is necessary to access the underlying storage medium. Storage medium could be a Elasticsearch cluster, or a set of Parquet files on HDFS, or a relational database.\nPresto uses MPP (Massively parallel processing) architecture in which it has,\nCoordinator node - responsible for creating query plan and distributing the work among workers. Worker node(s) - they push down predicates to those data sources. Only the data necessary to compute join is retrieved. All workers operate in parallel mode. Presto provides many connectors like below (but not limited to),\nRelational Databases MySQL PostGres SQL Server Non-relational Databases Mongodb Redis Cassandra Columnar file formats like ORC, Parquet and Avro – stored on: Amazon S3 Google Cloud Store Azure Blog Store HDFS Clustered file systems It\u0026rsquo;s important to note that Presto does not write intermidiate results to disk, Hence worker nodes are expected to be optimized for processing and memory over storage. A Single Presto query can combine data from multiple sources. Most importantly, Presto can work without Hadoop. Presto has cost-based optimizer which means query plan takes into account the time cost associated with executing that plan and can therefore do various types of optimizations around join ordering and the sequence with which you execute that query plan to deliver the fastest level of performance.\nBelow is apt representation of how Presto works (Ref: prestodb.io)\nWhere Presto fits Typical Presto Deployment Typical use cases for Presto are,\nAd-hoc, Interactive Analytics Batch ETL processing. Centralized Data Access with Query Federation From the consumption perspective, Presto Offers CLI as well as JDBC Driver. However, there are many language specific clients available from Community.\nKey points to note while considering Presto,\nNo need for complex ETL/ELT processes and related Monitoring. No need to provision for specialized data store for Data Lake and/or Data warehouse. However, this may not hold true if Query results from Presto are required to persisted. Although, overall efforts and cost will much lower. This would also mean that existing data stores need to maintain historical data too Any specific use cases not suitable for Presto will have to be alternatively approached. Some of the points to explore further would be ,\nGiven that Presto does not use storage on its own, how can one perform Capacity planning given the expected workflow ? How are failures handled? Useful References/Interesting Links, Trino PostgreSQL protocol gateway for Presto distributed SQL query engine Happy Coding !!\n","permalink":"http://localhost:1313/posts/presto/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn a company/enterprise, typically there are multiple sources of data. This could be result of M\u0026amp;A (where each of those add in a new data store) or result of multi year process of using data stores that are in vogue at that time. Result is combination of various types of relational databases, flat file systems, queues and so on. This results in Data Silos. This scenario is typically observed in companies who are running workloads On-prem (i.e. Pre-cloud, Companies who started on Cloud or have moved to it, typically tend to organize data platform better. This could be because of ease of migrating data on cloud. Typically, they centralize it around cheaper object storage (say AWS S3)).\u003c/p\u003e","title":"Presto - A distributed SQL Engine for variety of data stores"},{"content":"Introduction While gathering data for Analytics, one often has to source data from multiple sources. Traditionally, the approach has been to do ETL (Extract-Transform-load) where,\nExtract - typically involves retrieving data from source. This could also be via streaming Transform - Apply transformation to the extracted data. Load - Loading the data in Operation Data store (ODS) or data warehouse Refer here for more details on ETL. ETL has been made easy by tools like Talend, SSIS and so on. However, there has been shift from above approach due to,\nNeed to handle different kinds of data (Structured and Unstructured) hugh volumes of data (IOT, Customer data management) Availability of cheaper storage and compute along with availability of internet scale cloud based data warehouses has recently caused wide adoption of ELT (Extract-transform-load) over ETL.\nELT offers an alternative to ETL in which data is loaded into the warehouse (sometimes in storage area called as data lake) before transforming it. It allows focussing on extraction and loading with heavy transformation offloaded to later stage. Since the transformation happens in the warehouse, it can potentially be defined using SQL (thus using same language across the pipeline). This allows more roles (say Data Analysts) to contribute to (or entirely own) the transformation logic. Data warehouse becomes single source of truth for data. Ref: ETL vs ELT\nTypically, Data flow pipeline consists of below phases (it also lists available tools for each phase),\nIngestion - Airbyte, Fivetran, Stitch Warehousing - Snowflake, BigQuery, Redshift, PostgreSQL Transformation - dbt Orchestration - Airflow, Prefect, Dagster BI - Superset, Metabase, Redash, Looker etc. I think the best way to understand the landscape is to use above tools. So i decided to implement below problem statement. The requirement is to run a weekly process that,\nDownloads list of CNX 500 companies from Exchange\u0026rsquo;s web site For each of the company , get Last traded price(ltp) and 52 week high price (yearlyhigh) Exclude companies having ltp \u0026lt; 20 or ltp \u0026gt; 50000 Rank companies by closeness of ltp to yearlyhigh Prepare buy list of up to 20 such companies. Earlier short listed stocks, which are not in top 20 this week or further than 5% from their yearlyhigh, should be marked for sell. Above is hypothetical example and using full fledged data stack may be overkill but should suffice the purpose of this article.\nE \u0026amp; L in ELT - Get the list of CNX 500 Companies and also get stock price for each of them Below are some of the options available for this task under extract and load category,\nUse Python to download list of stocks and then use yfinance to get the price and yearly high. Use tool like Airbyte which provides declarative way of importing the data via HTTP. I am planning to explore this option later. Use Go to perform the task. I decided to go with this one and code is available at here. It downloads CSV file from Exchange\u0026rsquo;s website (containing list of stocks in Index) and loads them to database. Since Yahoo finance no longer provides Free tier for API, It uses htmlquery library to parse HTML and retrieve stock price and yearly high value. T in ELT - Transform the company-wise data to arrive at weekly list of momentum stocks This is implemented using dbt. dbt (Data Build Tool) is a framework to facilitate transformations using SQL along with version control, automates tests, support for incremental load, snapshots and so on. It has notion of project or workspace that many developers are familiar with. It is offered as Command line interface (CLI) as well as on cloud which also provides web based UI. I have used CLI for this exercise. For a quick recap of dbt folder structure, refer [here]https://towardsdatascience.com/data-stacks-for-fun-nonprofit-part-ii-d375d824abf3).\nSource code of dbt project here. We will go through key part of this project which are Models that carry out the transformation. After the initial setup of dbt like configuring target (i.e. data source which in this case is a PostgreSQL database), below are Models used,\nSince Loading of company-wise data is already done in earlier step, next step is to rank the companies w.r.t. closeness to their yearly high. Below is dbt SQL which does it (At run time, dbt converts below SQL to the one understood by the Target database),\n``` {{ config( materialized='incremental', ) }} with cnxcompanies as ( select symbol, company, ltp, yearlyhigh, updatedat, rank() over (order by yearlyhigh-ltp) as diff_rank from {{ source('datastore', 'cnx500companies') }} where yearlyhigh::money::numeric::float8 - ltp::money::numeric::float8 \u0026gt; 0 and ltp::money::numeric::float8 \u0026gt; 20 and ltp::money::numeric::float8 \u0026lt; 50000 ), cnxtopstocks as ( select symbol, company, ltp, yearlyhigh, updatedat, diff_rank from cnxcompanies order by updatedat desc,diff_rank ) select * from cnxtopstocks ``` Above model creates corresponding table in database (as such dbt abstracts changes to database from developer and manages it on its own). Note that model is marked incremental so that it doesn\u0026rsquo;t overwrite the table on every run but rather incrementally applies changes.\nNext step is to arrive at Weekly list of stocks to buy and even sell those which are lacking momentum.\n``` {{ config( materialized='incremental', unique_key='concat(symbol,updatedat)' ) }} with currentlist as ( select distinct symbol, company, ltp, yearlyhigh, updatedat,diff_rank,'buy' as buyorsell from {{ref('rankstocks')}} where (yearlyhigh-ltp)/ltp*100 \u0026lt;= 5 order by updatedat desc, diff_rank limit 20 ), finallist as ( {% if is_incremental() %} select symbol, company, ltp, yearlyhigh, updatedat,diff_rank,'sell' as buyorsell from {{this}} as oldlist where not exists (select symbol from currentlist where symbol=oldlist.symbol and (yearlyhigh-ltp)/ltp*100 \u0026lt;= 5 ) union select symbol, company, ltp, yearlyhigh, updatedat,diff_rank,'buy' as buyorsell from currentlist where not exists (select symbol from {{this}} where symbol=currentlist.symbol and buyorsell='buy') {% else %} select * from currentlist {% endif %} ) select * from finallist ``` This model refers to earlier one using {{..}} jinja directive. It also refers to itself using {{this}} directive.\nAmong others, below are key feature of DBT that were observed,\nConcept of Project/Workspace which programmers are typically familiar with Using SQL for Data Transformation Support for Version control Support for testing Support for incremental load Support for snapshots Automatic schema updates Out of the box Documentation browser covering traceability across sources and models. Orchestration After completing ELT aspects, now it\u0026rsquo;s time to orchestrate this pipeline wherein the whole process will run every week. Typically, one can use task scheduler like Airflow or Prefect to do this. But for the purpose of this article, lets use at on windows (or cron if you are using Linux).\nso a simplest possible batch file (as below),\nset http_proxy= set https_proxy= .\\gover\\go run . .\\.venv\\scripts\\activate \u0026amp; .\\dbt\\dbt run will run the whole process and generate weekly list in weeklylist table in database. This batch file can be scheduled to run on weekly basis using command at 23:00 /every:F runscript.bat.\nThis is very basic approach to scheduling (with no error handling/retries or monitoring). Hopefully, i will be able to work on these part (something like this). Till then\u0026hellip;\nUseful References Reverse ETL Data stacks for Fun and Profit What warehouse to use Build Data Lake in PostgreSQL using FDW, Singer, Metabase Happy Coding !!\n","permalink":"http://localhost:1313/posts/elt/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWhile gathering data for Analytics, one often has to source data from multiple sources. Traditionally, the approach has been to do ETL (Extract-Transform-load) where,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eExtract\u003c/strong\u003e - typically involves retrieving data from source. This could also be via streaming\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTransform\u003c/strong\u003e - Apply transformation to the extracted data.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLoad\u003c/strong\u003e -  Loading the data in Operation Data store (ODS) or data warehouse\nRefer \u003ca href=https://www.sas.com/en_us/insights/data-management/what-is-etl.html#close\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehere\u003c/a\u003e for more details on ETL. ETL has been made easy by tools like \u003ca href=https://www.talend.com/products/talend-open-studio/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTalend\u003c/a\u003e, \u003ca href=https://docs.microsoft.com/en-us/sql/integration-services/sql-server-integration-services\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSSIS\u003c/a\u003e and so on.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHowever, there has been shift from above approach due to,\u003c/p\u003e","title":"ELT approach for Data Pipelines"},{"content":"Background Recently, i went through excellent video series on Designing \u0026amp; Versioning HTTP_REST APIs presented by Jeffrey Richter. It is available here. In the past, i had read Jeff\u0026rsquo;s books on CLR and found his writing to be very clear and understandable. So is my experience with this Video Series. Below is summary of learnings from this Video Series. I do not claim that every aspect is covered here so please do check out the videos.\nI have been developing REST APIs for many years but the video series opened up many new aspects that were previously unknown. Jeff starts with Need to Good API Design and related considerations, REST Fundamentals and then dives deeper into aspects like idempotent behavior, versioning, ETags and so on.\nJeff covers REST fundamentals, need for thoughtful API design as it might be difficult to amend it later followed by practices covering Naming,Need for Idempotency, Error Handling and so on. Below is an attempt to summarize aspects from these videos.\nREST Fundamentals REST is an architectural style with emphasis on,\nScalability Reduced latency via Caching Independent Deployment Encapsulating legacy Systems A REST service has resources where they represent state but not behavior. These behaviors are CRUD (Created, Read, Update and Delete). All operations of service must be idempotent.\nURL of the REST Service is expected to be stable over long period of time. URL (apart from HTTP scheme and host name:port), consists of\nDocument (eg. song-management) - sometimes omitted in which case the host determines document. Collection resource (users or playlists) - Hold items; use plural lowercase noun; avoid more than 2 collections. Item resource - Request/Response body holds the item\u0026rsquo;s state Method - Prefer \u0026lsquo;PATCH\u0026rsquo;, with JSON Merge Patch request body, over \u0026lsquo;PUT\u0026rsquo;. \u0026lsquo;PUT\u0026rsquo; for whole creation or replacement but may introduce issues between different versions of service. Avoid \u0026lsquo;POST\u0026rsquo; as it involves challenges in ensuring Idempotent behavior. The argument against \u0026lsquo;POST\u0026rsquo; is that it always creates resource and returns identifier which may get lost and client may retry. . Error Handling Videos contain tables explaining HTTP status code to be returned along with body in different conditions. below is quick summary,\nIf something unexpected happens return Status 500\nIf service is booting, too busy or shutting down then return Status 303\nIf HTTP Version not 1.1 then return status 505\nIf Authorization fails then return status 401\nIf Client makes too many requests/second then return status 429\nIf URL too long then return status 414\nIf HTTP Method not supported at all then return status 501\nIf resource not accessible to client then return status 403\nIf No support for HTTP Method not 1.1 then return status 405\nIf request not in acceptable format then return status 406\nIn case service returns non-success/error response for a request,\nIt is recommended to add header in response that indicates the same (that way client can inspect it before deserializing/inspecting the response).\nAlso if error is recoverable @ runtime then, string is specific else string is list of similar errors. Response body could be in JSON format as,\n{ \u0026#34;error\u0026#34;: { \u0026#34;code\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;message\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;target\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;innererror\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;minLength\u0026#34;: 6 } } } If server is overloaded then return 503\nIf tenant exceeds quota then return 429\nVersioning New version must be backward Compatible\nExamples of versioning in API,\nhttp://api.contoso.com/v1.0/products http://api.contoso.com/products?api-version=1.0 http://api.contoso.com/products?api-version=2021-01-01 Add new API when changing mandatory parameters, payload formats, error codes or behavior\nApproach to API Versioning should not be afterthought\nConsider embedding version number in the data structure\nChecklist for REST APIs Focus on great and consistent naming - This is very important because once in production, this is unlikely to change.\nEnsure that resource path make sense\nAlways try to simplify call to Service (by having fewer query parameters \u0026amp; JSON fields)\nUse\nPUT to Create/Replace whole resources. Last write wins. It should return 200-Ok, 201-Created.\nPATCH to Create/Modify resource with JSON Merge Patch. It should return 200-Ok, 201-Created.\nGET to Get the resource.It should return 200-Ok.\nDELETE to remove resource. It should return 200-Ok, 204-No content but 404-not found should be avoided.\nJeff recommends avoiding usage of POST unless request is idempotent (HTTP does not require it to be idempotent).For API having POST operation, below Idempotency Pattern can be considered,\nClient: Creates ID Client: sends request to server with generated ID (this can be retried) Server: If ID is not in log then, do operation \u0026amp; log ID (This should be part of transaction); respond with OK (Server periodically deletes old log to avoid unbounded growth) A URL should be stable/immutable\nUse proper response codes to enable customers to self-fix\nHave clear contracts for string values\nShare samples (Code) that really use your API\nUse Etag (Entity Tag) to identify the version of the resource,\nEtag is usually computed as checksum or as sequence value (which is incremented on every change) for single item response, it is set in header and for collections, it is added as field in body. Caching - Clients can use it for resource caching (send GET Request with ETag and server responds with 304-Not modified if resource hasn\u0026rsquo;t changed) Concurrent/Conditional Updates -Etag along with \u0026lsquo;if-none-match\u0026rsquo;/\u0026lsquo;if-match\u0026rsquo; headers allows conditional update/delete Services must fail fast if requests are greater than quota (requests/time)\nEvery request must be assigned unique ID for logging /tracing purposes. this ID can be returned in header of response.\nGenerate Telemetry for the Service. It should include User Agent information for diagnostic purposes. Also consider adding Distributed tracing (OpenTelemetry is standardization initiative in this regard).\nIn case of client retries, services must be idempotent (Idempotency indicates retrying a request has same intended effect, even if the original request succeeded, though response might differ)\nService must remain fault-tolerant in case of failures.\nTypically REST is meant for State transfer/CRUD Operations but many times the purpose of end point is to offer action. In such cases specify the action being performed at the end , i.e. after establishing the exact resource, of URL like, /user-management/users/{userid}/:send-sms. In this,\n\u0026lsquo;user-management\u0026rsquo; indicates host \u0026lsquo;users\u0026rsquo; indicates users collection \u0026lsquo;{userid}\u0026rsquo; is to identify user by ID \u0026lsquo;:send-sms\u0026rsquo; indicates action (prefixed with \u0026lsquo;:\u0026rsquo;) to be performed. Use tools like Swagger for API documentation and to create language-specific client libraries\nReviewing REST APIs While reviewing HTTP REST APis, below aspects should be evaluated,\nDoes the API Match Customer\u0026rsquo;s Expectation? Aspects to check are,\nURLs idempotency atomicity json casing status codes paging long running operations Consistency with other Services\nIs the Service/API sustainable over time i.e. API must be able to grow/version over time without breaking customer apps\nIn no way, the above covers everything available in the Video series. So do check it out here.\nUseful References Making retries safe with Idempotent APIs Happy API designing !!\n","permalink":"http://localhost:1313/posts/restapiversioning/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eRecently, i went through excellent video series on  \u003ccode\u003eDesigning \u0026amp; Versioning HTTP_REST APIs\u003c/code\u003e presented by \u003ca href=https://www.linkedin.com/in/jeffrichter/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJeffrey Richter\u003c/a\u003e. It is available \u003ca href=https://www.youtube.com/watch?v\u0026#61;9Ng00IlBCtw\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehere\u003c/a\u003e. In the past, i had read Jeff\u0026rsquo;s books on CLR and found his writing to be very clear and understandable. So is my experience with this Video Series. Below is summary of learnings from this Video Series. I do not claim that every aspect is covered here so please do check out the videos.\u003c/p\u003e","title":"Learnings from Jeff Richter's Designing and Versioning HTTP REST APIs Video Course"},{"content":"Background In a typical workflow of software development, Developer implements a Unit/component, tests it and pushes the changes to source control repository. It then goes through Continuous integration, automated testing, provisioning and deployment. Given High availability requirements expected (or should i say assumed) nowadays, As much as functional correctness of the Unit, it is also important to test how a Unit/Component handles failures, delays etc. in distributed environment. Often, such behavior is observed in production itself, unless project team is following practices of Chaos engineering.\nWouldn\u0026rsquo;t it be great if it is possible to start testing the resiliency features as part of development and during CI/CD pipeline execution itself ? Enter Toxiproxy\nToxiproxy is a TCP Proxy to simulate network and system conditions for chaos and resiliency Testing.\nToxiproxy essentially acts as middleman between your application and remote service/system being tested, allowing injection of delays, simulate Bandwidth restriction or turn interface off (down) etc.\nIt provides CLI as well as http API for applications to inject these behaviors or toxics. Refer here for various toxics supported.\nLets use Toxiproxy Lets see how one can use it in typical use case where Application uses PostgreSQL database and requirement is to benchmark it against database hosted remotely. Toxiproxy can help simulate production like behavior by means of introducing network delay.\nThe full source code of this application is available here. One can refer to Numbers (only as reference cause live conditions may widely vary) here while deciding on how much toxicity to introduce.\nApplication itself is a Web server in Go using excellent HTTPRouter, It does,\nprovision a table in Postgresql and load dummy data in it.\nExposes REST API that reads data from database and returns JSON\nSetup proxy between application and database either through Toxiproxy CLI (it can also be done programmatically using Toxiproxy-Go client),\n[ { \u0026#34;name\u0026#34;: \u0026#34;pgsql\u0026#34;, \u0026#34;listen\u0026#34; : \u0026#34;[::]:6000\u0026#34;, \u0026#34;upstream\u0026#34; : \u0026#34;127.0.0.1:5432\u0026#34;, \u0026#34;enabled\u0026#34;: true } ] or through Code like,\n// InjectLatency helper func InjectLatency(name string, delay int) *toxiproxy.Proxy { proxy, err := toxiClient.Proxy(name) if err != nil { panic(err) } proxy.AddToxic(\u0026#34;\u0026#34;, \u0026#34;latency\u0026#34;, \u0026#34;\u0026#34;, 1, toxiproxy.Attributes{ \u0026#34;latency\u0026#34;: delay, }) return proxy } Use hey or any other HTTP Benchmarking tool to test end points with and without toxicity\nor\nGo benchmark tests tests that are executed against HTTP end points. In my opinion, Toxiproxy allows us to embed aspect(s) of resiliency verification in the code itself so developer can test it before committing the code and it can be embedded in DevOps pipeline to get early feedback before facing the music in production environment.\nLike latency, one can easily introduce other Toxics like Bandwidth, Down and Timeout to check Application\u0026rsquo;s behavior when faced with such occurrences.\nUseful References, ToxiProxy - for all details on the tool like Clients available in various languages, server releases and so on. Happy Coding !!\n","permalink":"http://localhost:1313/posts/resiliencytoxiproxy/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eIn a typical workflow of software development, Developer implements a Unit/component, tests it and pushes  the changes to source control repository. It then goes through Continuous integration, automated testing, provisioning and deployment. Given High availability requirements expected (or should i say assumed) nowadays,  As much as functional correctness of the Unit, it is also important to test how a Unit/Component handles failures, delays etc. in distributed environment.  Often, such behavior is observed in production itself, unless project team is following practices of \u003ca href=https://netflixtechblog.com/tagged/chaos-engineering\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChaos engineering\u003c/a\u003e.\u003c/p\u003e","title":"Resiliency Testing with Toxiproxy"},{"content":"Background In a typical business Application, there are often requirements for,\nBatch processing - Often long running Tasks like data import/export, End of day processing etc. These tasks are often scheduled to be executed at pre-defined interval or on occurance of an Event. Asychronous processing - Tasks, often part of business process / workflow, that can be performed asychronously or offloaded. Such requirements are often fulfilled with custom approaches like batch processing frameworks, ETL Tools or using Queues or specific database features.\nI had been following how Uber fulfils these requirements using their Cadence platform. Cadence (now Temporal) is a distributed, scalable, durable, and highly available orchestration engine to execute asynchronous long-running business logic in a scalable and resilient way.\nTemporal defines workflow as any program which,\ngoes beyond single request-reply has multiple steps tied together with inherent state can be short or long lived. performs Event processing involves infrastructure automation This is interesting perspective that accommodates various use cases irrespective of architecture style (i.e. Monolith, Microservices) in use. In Temporal, one has to create workflow which in turn consists of one or more activities. Activities are functions containing actions to be taken on each step of the workflow. Temporal transparently preserves all the state associated with workflow and its activities.\nBelow is System architecture of Temporal, more details here,\nTemporal Architecture Overall, Temporal offers following features,\nWorkflow implemented as Application code - Basically it allows to implement Workflow as code, just like rest of the codebase of the application. Thus allowing one to concentrate on business logic and reduces complexity about authoring workflow as DSL, JSON etc. Retries and Timeouts - Nowadays, quite a few steps in workflow involve remote service invocation and whenever one crosses boundary of the application, it is important to have retries and timeouts in place. Reliability - Robustness against failure Scalability - Horizontally Scalable Support for SAGAs - If a Workflow calls multiple external/remote services and if one of them fails then, compensation call to other services will have to be made to complete rollback. Distributed Cron - Scheduled processing of workflow or steps in workflow. Persistent Storage in MySQL, Cassandra among others Frontend for tracking and diagnostics Monitoring using Prometheus or other backends. It is very easy to get basic \u0026ldquo;Helloworld\u0026rdquo; workflow up and running using detailed instructions on setup provided here provided docker desktop or such environment is easily available. Temporal documentation does a great job on this.\nTo evaluate Temporal further, we will orchestrate below,\nList of users are imported/received (say from a file or provided as input) These users are verified/validated by Admin through some Frontend (to simulate a maker/checker process). This may not resemble real world scenario but it will help evaluate features of Temporal like Signals - Waiting on Events (such as human intervention).\nWe will have below activities in our workflow,\nImport users - This activity will import list of users from file/stream. For the sake of simplicity, we will just pass it as string. func ImportUsers(ctx context.Context, userdata string, DbConnectionString string) (int, error) { logger := activity.GetLogger(ctx) logger.Info(\u0026#34;ImportUsers activity started.\u0026#34;, zap.String(\u0026#34;Dbconn\u0026#34;, DbConnectionString)) // Open connection to database db, close, err := GetSQLXConnection(context.Background(), DbConnectionString) if err != nil { logger.Error(\u0026#34;Cant open connection to database\u0026#34;, zap.Error(err)) return 0, err } defer close() if _, err := db.Exec(DBSchema); err != nil { logger.Error(\u0026#34;Error while executing Schema\u0026#34;, zap.Error(err)) return 0, err } logger.Info(\u0026#34;Database connection opened, now parsing user data\u0026#34;) sqlStmt := \u0026#34;insert into users(name,dob,city) values(?,?,?)\u0026#34; tx := db.MustBegin() defer func() { if err != nil { tx.Rollback() } tx.Commit() }() r := csv.NewReader(strings.NewReader(string(userdata))) r.Comma = \u0026#39;,\u0026#39; r.Comment = \u0026#39;#\u0026#39; records, err := r.ReadAll() if err != nil { logger.Error(\u0026#34;Error while reading\u0026#34;, zap.Error(err)) return 0, err } i := 0 for i, record := range records { if i == 0 { continue } logger.Info(\u0026#34;Record read is -\u0026gt;\u0026#34;, record[0]) if _, err := tx.Exec(sqlStmt, record[0], record[1], record[2]); err != nil { logger.Error(\u0026#34;Error while writing user record\u0026#34;, zap.Error(err)) return 0, err } } return i, nil } Approve users - This activity will mark all those users, Approved by Admininstrator via Service, as approved. func ApproveUsers(ctx context.Context, DbConnectionString string, Users string) (int, error) { logger := activity.GetLogger(ctx) logger.Info(\u0026#34;ApprovedUsers called\u0026#34;, zap.String(\u0026#34;Dbconn\u0026#34;, DbConnectionString), zap.String(\u0026#34;Userlist\u0026#34;, Users)) db, close, err := GetSQLXConnection(context.Background(), DbConnectionString) if err != nil { logger.Error(\u0026#34;Cant open connection to database\u0026#34;, zap.Error(err)) return 0, err } defer close() if _, err := db.Exec(DBSchema); err != nil { logger.Error(\u0026#34;Error while executing Schema\u0026#34;, zap.Error(err)) return 0, err } r := csv.NewReader(strings.NewReader(Users)) tx := db.MustBegin() defer func() { if err != nil { tx.Rollback() } tx.Commit() }() sqlStmt := \u0026#34;update users set isapproved =1 where id =:1\u0026#34; i := 0 for { record, err := r.Read() if err == io.EOF { break } if err != nil { logger.Error(\u0026#34;Error while reading from file\u0026#34;, zap.Error(err)) return 0, err } if i == 0 { continue } i++ if _, err := tx.Exec(sqlStmt, record[0]); err != nil { logger.Error(\u0026#34;Error while writing user record\u0026#34;, zap.Error(err)) return 0, err } } return i, nil } HTTP Service - This service will receive list of approved users and send it over to workflow via Signal, func (s *server) UpdateUsers(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { creader := csv.NewReader(r.Body) records, err := creader.ReadAll() if err != nil { log.Fatal(err.Error()) http.Error(w, err.Error(), http.StatusBadRequest) return } // Create the client object just once per process c, err := client.NewClient(client.Options{}) if err != nil { log.Fatalln(\u0026#34;unable to create Temporal client\u0026#34;, err) http.Error(w, \u0026#34;Internal Error :Temporal\u0026#34;, http.StatusInternalServerError) return } defer c.Close() workflowOptions := client.StartWorkflowOptions{ ID: app.UserApprovalWorkflow, TaskQueue: app.UserApprovalTaskQueue, RetryPolicy: \u0026amp;temporal.RetryPolicy{ InitialInterval: time.Second, BackoffCoefficient: 2.0, MaximumInterval: time.Minute, MaximumAttempts: 5, }, } _, err = c.SignalWithStartWorkflow(r.Context(), app.UserApprovalWorkflow, app.ApprovalSignalName, records, workflowOptions, app.OnboardUsers, app.Userdata, s.DBConnection) if err != nil { log.Fatal(err.Error()) http.Error(w, \u0026#34;Internal Error: Workflow\u0026#34;, http.StatusInternalServerError) return } fmt.Fprint(w, \u0026#34;Success\u0026#34;) } HTTP service uses workflow.SignalWithStartWorkflow function. This function sends the signal to running instance of workflow or starts new if none is in progress. Full source code is available here\nTemporal documentation has reference to Helm charts for deploying temporal in clustered configuration, for organization who is managing own data center it would be interesting to know if it also supports bare metal based deployment in addition to Kubernetes. Will update this post as and when details are available on this.\nOverall, Temporal provides a different approach to workflow orchestration. Its been battle tested at Uber and host of other companies. Temporal Community is a very active one with founders actively participating in discussions.\nCollection of Temporal related stuff Happy Coding !!\n","permalink":"http://localhost:1313/posts/temporalworkflow/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eIn a typical business Application, there are often requirements for,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBatch processing - Often long running Tasks like data import/export, End of day processing etc. These tasks are often scheduled to be executed at pre-defined interval or on occurance of an Event.\u003c/li\u003e\n\u003cli\u003eAsychronous processing - Tasks, often part of business process / workflow, that can be performed asychronously or offloaded.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSuch requirements are often fulfilled with custom approaches like batch processing frameworks, ETL Tools or using Queues or specific database features.\u003c/p\u003e","title":"Using Temporal.io to build Long running Workflows"},{"content":"Background How many times have we landed up in a meeting staring at random slowness or such production issues in a distributed Application ? only to experience helplessness with limited (or often times no) visibility available about the runtime behavior of the Application. It often ends up in manually correlating whatever diagnostic data available from Application and combining it with trace/logs that are available from O/S, databases etc. and trying to figure out \u0026ldquo;Root cause\u0026rdquo; of the issue.\nToday’s mission critical, distributed applications and systems make it even more important to observe them, be it serving web requests, processing stream of data or handling events. The scale at which these applications/systems operate at, often hundreds or thousands of requests, requires watching how well system is working, instead of waiting for failure or doing analysis post failure.\nIn distributed systems, telemetry can be divided into three overarching flavors:\n(Distributed) Traces: detailed records of the paths that distinct requests take as they propagate across an entire system (including across service boundaries) Metrics: aggregate statistics (mostly counters and gauges) about processes and infrastructure, typically with key:value tags attached to disaggregate patterns Logs: timestamped messages – sometimes structured – emitted by services or other components (though, unlike traces, not necessarily associated with any particular user request or transaction) To this effect, Cloud Native Computing Foundation (CNCF) has been working on Opentelemetry.\nWhat is OpenTelemetry? OpenTelemetry is a vendor-neutral standard for collecting telemetry data for applications, their supporting infrastructures, and services.\nFor deep dive, history etc., refer to Overview here.\nSo is this standard already available? As of this writing, it is about to go GA soon. This makes it more important to be aware of its scope (subjected to change). Let\u0026rsquo;s see how it is proposing to address/implement Observability.\nBelow diagram depicts what OpenTelemetry does in Nutshell (Source: Opentelemetry.io),\nOpenTelemetry in Nutshell The general process of using OpenTelemetry is,\nInstrumentation of Application Code (including libraries) Validate Instrumentation by sending it to Collector like Jaeger (For simplicity, we will only be using Console exporter) Learn how Instrumentation helps in correlating, watching runtime behavior While vendors, having back-end systems, are providing or working on integrations with OpenTelemetry. The OpenTelemetry team has provided client libraries for Instrumentation in Go, .NET, Java,JavaScript, Python (and more coming). So lets us see what these libraries offer as of today by implementing .NET library.\nIn this post, We will look at how Opentelemetry helps us with \u0026ldquo;Distributed tracing\u0026rdquo;.\nOpenTelemetry for .NET .NET client of OpenTelemetry supports both .NET Framework as well as .NET Core.\nFor list of available instrumentation libraries and exporters, refer here\nIn the below sections, We will try to simulate a scenario, which is typical in Microservices style of Architecture, where service invokes another service using HTTP. Now, aim is to verify how using OpenTelemetry will help in watching traffic between these two services.\nSample Scenario Lets start,\nCreate Web Service (I am using .NET Core SDK 3.1.300 on Windows)\nUse dotnet new webapi to scaffold a REST API\nAdd references to below packages using Nuget,\nOpenTelemetry.Exporter.Console - Exporter package to output telemetry to Console OpenTelemetry.Instrumentation.AspNetCore - Package that transparently instruments ASP.NET Core request processing pipeline OpenTelemetry.Instrumentation.Http - Package that transparently instruments HTTP Communication. Startup.cs - It configures OpenTelemetry instrumentation with Console Exporter and instrumentation for HTTP requests. Below is ConfigServices function of Startup class.\npublic void ConfigureServices(IServiceCollection services) { services.AddOpenTelemetryTracing( (builder) =\u0026gt; builder.AddAspNetCoreInstrumentation(opt =\u0026gt; opt.Enrich = (activity, eventName, rawObject) =\u0026gt; { if (eventName.Equals(\u0026quot;OnStartActivity\u0026quot;)) { if (rawObject is HttpRequest httpRequest) { activity.SetTag(\u0026quot;requestProtocol\u0026quot;, httpRequest.Protocol); } } else if (eventName.Equals(\u0026quot;OnStopActivity\u0026quot;)) { if (rawObject is HttpResponse httpResponse) { activity.SetTag(\u0026quot;responseLength\u0026quot;, httpResponse.ContentLength); } } }) .AddHttpClientInstrumentation() .AddConsoleExporter() //opt =\u0026gt; opt.DisplayAsJson = true) ); } WeatherForecastController.cs - This is default controller added by dotnet new webapi command. We will add GET endpoint to simulate a dummy HTTP Request. This is to verify telemetry produced for the same.\n[HttpGet(\u0026#34;{key}\u0026#34;)] public async Task\u0026lt;IEnumerable\u0026lt;WeatherForecast\u0026gt;\u0026gt; Get(string key) { // Making an http call here to serve as an example of // how dependency calls will be captured and treated // automatically as child of incoming request. var res = await httpClient.GetStringAsync(string.Format(\u0026#34;https://www.google.com/search?q={0}\u0026#34;, key)); var rng = new Random(); return Enumerable.Range(1, 5).Select(index =\u0026gt; new WeatherForecast { Date = DateTime.Now.AddDays(index), TemperatureC = rng.Next(-20, 55), Summary = Summaries[rng.Next(Summaries.Length)], }) .ToArray(); } Lets create a Service 1 For the sake of simplicity, we will have \u0026ldquo;Service 1\u0026rdquo; implemented as Console Application,\nUse dotnet new console to create new App.\nAdd reference to \u0026ldquo;OpenTelemetry.Exporter.Console\u0026rdquo; using dotnet add OpenTelemetry.Exporter.Console -version 0.7.0-beta.1. This package is specifically meant for exporting telemetry to Console. There are other exporters available to export to Jaegar, Zipkin etc. but this is simplest one to setup.\nAdd reference to \u0026ldquo;OpenTelemetry.Instrumentation.Http\u0026rdquo; using dotnet add OpenTelemetry.Instrumentation.Http -version 0.7.0-beta.1. This package helps in instrumenting HTTP requests.\nAdd below code to program.cs,\nstatic async Task Main(string[] args) { // Configure OpenTelemetry Tracer with Console exported and initiate it Sdk.CreateTracerProviderBuilder() .AddHttpClientInstrumentation() .AddConsoleExporter() .Build();\ntry { // Simulate HTTP Request to our service string responseBody = await client.GetStringAsync(\u0026quot;https://localhost:5001/weatherforecast/abc\u0026quot;); Console.WriteLine(responseBody); } catch (HttpRequestException e) { Console.WriteLine(\u0026quot;\\nException Caught!\u0026quot;); Console.WriteLine(\u0026quot;Message :{0} \u0026quot;, e.Message); } Console.WriteLine(\u0026quot;Done!\u0026quot;); } In this class, we have configured OpenTelemetry tracer with Console Exported and intialized it. Further, HTTP requests are automatically instrumented since we have added OpenTelemetry.Instrumentation.Http package.\nObserve the Telemetry,\nStart the Web Service. Check that it is listening on port 8080 by visiting https://localhost:8080. Note: you may have to install Client certificate to enable SSL. Start the Console Application. This application will send HTTP request to the service. Observe the telemetry produced by, Console Application,\nDefault Telemetry generated Activity Id (GUID) is generated for a Span (Refer here for details on what span means) It also records start and end time Web Service, Default Telemetry Observations\nCheck Activity ID being shown is same as one reported by Console Application. So correlation has been established across process boundaries. This is important when tracing end to end across processes. This is achieved by means of passing Activity ID as HTTP Header. In a Visualization tool, this correlation is used to depict end to end flow with time at each step. By default, it logs start and end time. For any HTTP request, it generates additional telemetry covering URL to which request was sent and start and end time. In Summary, this default telemetry can obviously be enhanced by adding Tags. When coupled with additional telemetry in the form of metering (to statistically observe behavior of high traffic, large scale system) and telemetry from Infrastructure (i.e. OS) and other Systems (e.g. Databases), it truly provides complete view of proceedings end to end.\nHope this provides overview of instrumentation as provided by OpenTelemetry. Let me know if you have any questions or suggestions in Comments section below.\nInstrumenting .NET framework based Apps for same scenario is similar to above, refer folder Opentelemetry in repository here\nUseful References, OpenTelemetry in 2023 OpenTelemetry in .NET Short course on OpenTelemetry) Happy Coding !!\n","permalink":"http://localhost:1313/posts/opentelemetry/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eHow many times have we landed up in a meeting staring at random slowness or such production issues in a distributed Application ? only to experience helplessness with limited (or often times no) visibility available about the runtime behavior of the Application. It often ends up in manually correlating whatever diagnostic data available from Application and combining it with  trace/logs that are available from O/S, databases etc. and trying to figure out \u0026ldquo;Root cause\u0026rdquo; of the issue.\u003c/p\u003e","title":"Getting Started with OpenTelemetry"},{"content":"Background I primarily work on Windows for development purposes. Whenever its about writing code in Golang, invariably one comes across usage of Make. A quick check on popular Go projects on Github will show Makefile being used to automate tasks like linting, build, testing and deployment.\nBeing on Windows, i have been looking for alternative build tool that is easy to setup (i.e. doesn\u0026rsquo;t require mingw and such environments) and use compared to Make (which is primarily targetted at Unix and Unix like Operating Systems).\nFollowing a wonderful post by Julia Evans (read here) on Ninja. I decided to give it a try for a Golang Application.\nJulia, in her post, has covered important aspects of Ninja but to summarize, Ninja is,\nA build automation tool Lightweight, with focus on speed Easy to configure Cross platform (Easy to setup across Windows and Linux) With this, lets give it a try,\nTo start with, lets create a simple go \u0026lsquo;Hello World\u0026rsquo; project,\nInitiate Go Module (in a Empty folder), go mod init github.com/sachinsu/ninjabuild\nCreate a \u0026lsquo;main.go\u0026rsquo; that prints \u0026lsquo;Hello World\u0026rsquo;,\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;hello world\u0026#34;) } Now setup Ninja, It is as easy as downloading binary for your Platform. It is also possible to build it locally, if you prefer it that way. For details, refer here\nOnce ninja is setup, lets create build configuration file (i.e. build.ninja),\nGOARCH = amd64 GOOS = linux rule lint command = go vet -mod=vendor ./... build lintoutput: lint rule unit command = go test -mod=vendor -cover -v -short ./... build utest: unit rule compile command = cmd /c go mod tidy \u0026amp;\u0026amp; go mod vendor \u0026amp;\u0026amp; go build -o $out $in \u0026amp;\u0026amp; echo \u0026#34;build done.\u0026#34; description = compile $in build ninjabuild.exe: compile . lets go through the contents of this file,\nOne can define variables GOARCH = amd64 and refer them as $GOARCH\nNinja configuration is combination of build step and associated rule, for e.g.\nrule compile command = cmd /c go mod tidy \u0026amp;\u0026amp; go mod vendor \u0026amp;\u0026amp; go build -o $out $in \u0026amp;\u0026amp; echo \u0026#34;build done.\u0026#34; description = compile $in build ninjabuild.exe: compile . Above snippet, defines rule compile with associated command that builds the code. Being on Windows, i have used cmd /c to start a new shell and concatenate multiple commands as part of compile rule using \u0026amp;\u0026amp; which chains the commands and executes next one only if current one succeeds. As demonstrated in above file, Ninja can be used to automate wide variety of tasks like build, tests, deployment and so on.\nMany of you using Make will find the approach similar to it. In contrast to Make, Ninja lacks features such as string manipulation, as Ninja build files are not meant to be written by hand. Instead, a \u0026ldquo;build generator\u0026rdquo; should be used to generate Ninja build files.\nI found simplicity (of installation and configuration) and easy of use to be key aspects of this tool.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/ninjabuildsystem/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI primarily work on Windows for development purposes. Whenever its about writing code in Golang, invariably one comes across usage of Make. A quick check on popular Go projects on Github will show Makefile being used to automate tasks like linting, build, testing and deployment.\u003c/p\u003e\n\u003cp\u003eBeing on Windows, i have been looking for alternative build tool that is easy to setup (i.e. doesn\u0026rsquo;t require mingw and such environments) and use compared to Make (which is primarily targetted at Unix and Unix like Operating Systems).\u003c/p\u003e","title":"Ninja - Using lightweight build system for Go projects "},{"content":"Background I started this blog, https://sachinsu.github.io few months back .\nIn this relatively short period of time, Blog has sizeable number of useful links across various categories in addition to the detailed blog post like this one.\nAs an ongoing activity, I think that it is necessary to verify links mentioned on this blog.\nSo how can it be done ? obviously one way is to do it manually by visiting each link and updating/removing those that are no longer available. but there is always of better way of doing things.\nThe requirement is to,\nParse all the files to links (being in Markdown links will be enclosed in brackets) Send request to each link and verify if its active using HTTP Status (say 200 or 302) Approach Enter Automation !!\nIt is possible to write a utility/tool (or it might be already available) or can good old command line utlities be used for this task?\nI decided to go for dos / shell script way and surprisingly all the necessary tools are already available.\nBelow is single command line that fulfils the requirement,\ngrep -E -i -w \u0026quot;http|https\u0026quot; *.md | sed 's/](http/\\nhttp/g' | sed 's/)/\\n/g' | grep ^http | xargs curl -s -I -w 'URL:%{url_effective} - %{http_code}\\n' | grep ^URL:\nIn above chain,\nI am using excellent Cmder console emulator, which also makes above nice tools (grep, sed etc.) available on Windows.\ngrep -E -i -w \u0026ldquo;http|https\u0026rdquo; *.md - this command extracts all the lines containing http(s) from all the markdown (.md) files\nPipe | - Pipe command streams output of command to the next one.\nsed \u0026rsquo;s/](http/\\nhttp/g\u0026rsquo; - this sed (stream editor) command adds line break before http for better extraction.\nsed \u0026rsquo;s/)/\\n/g\u0026rsquo; - this sed (stream editor) command removes trailing ) bracket.\ngrep ^http - this command removes all lines not containing http.\nxargs - xargs is a command on Unix and most Unix-like operating systems used to build and execute commands from standard input.\ncurl -s -I -w \u0026lsquo;URL:%{url_effective} \u0026mdash;\u0026gt; %{http_code}\u0026rsquo;\u0026rsquo; - previously used xargs command feeds each line (url) to this command as last argument. This command sends tcp request to the URL and prints out http status code along with URL.\ngrep ^URL: - For some reason, CURL outputs content even if -s (silent) parameter is passed. Hence, this grep command is used to ignore all lines not containing URL and HTTP Status.\nThe output is as below,\nList of URLs with HTTP Status code So, It is possible to quickly come up with this using built-in tools if writing a program is not an option or cumbersome for task at hand.\nAs a next step, Plan is to automatically run this script as part of Github Build and notify in case of any URL is failing so that appropriate action can be taken.\nHat Tip Suppose the requirement is to extract a particular text by recursively searching through files(for e.g. extract Target .NET Framework version across each of the project in a folder) then grep can be used as below,\ngrep -r --include \u0026quot;*.csproj\u0026quot; -oP \u0026quot;\u0026lt;TargetFrameworkVersion(?:\\s[^\u0026gt;]*)?\u0026gt;\\K.*?(?=\u0026lt;/TargetFrameworkVersion\u0026gt;)\u0026quot; .\nThis command will recursively search through all folders and print names of all those .csproj files containg \u0026lt;TargetFrameworkVersion\u0026gt; tag.\nLet me know (in comments) if you are aware of any alternate better way of achieving this.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/urlhealthchecks/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI started this blog, \u003ca href=https://sachinsu.github.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehttps://sachinsu.github.io\u003c/a\u003e few months back .\u003c/p\u003e\n\u003cp\u003eIn this relatively short period of time, Blog has sizeable number of useful links across various categories in addition to the detailed blog post like this one.\u003c/p\u003e\n\u003cp\u003eAs an ongoing activity, I think that it is necessary to verify links mentioned on this blog.\u003c/p\u003e\n\u003cp\u003eSo how can it be done ? obviously one way is to do it manually by visiting each link and updating/removing those that are no longer available. but there is always of better way of doing things.\u003c/p\u003e","title":"Validating urls from 'Useful Links' section using bash / command line tools"},{"content":"Background I recently had opportunity to support team who has been battling with Intermittent (scary i know :)) issues with TCP connectivity in Production.\nSimplified deployment Architecture is as below,\nHigh Level Architecture Technology Stack used is Microsoft .NET Framework 4.8 using ODP.NET for Oracle Connectivity (Oracle Server is 8 CPU box). Each of Web Servers in cluster have IIS hosted on it with multiple Applications (Application domains) serving HTTP(s) based traffic. These applications connect to Oracle Database.\nTeam is experienced in developing and running .NET Apps, but they needed help to diagnose and fix \u0026ldquo;Connection request timed out\u0026rdquo; exceptions being thrown while connecting to backend database.\nProblem Statement Host of .NET Applications (Web Applications, Web APIs) connect to Oracle Database. Each of them use ODP.NET. ODP.NET maintains connection pool per Application domain (Database resident Connection pool is not used). Some of these applications receive high number of requests per second compared to others.\nOracle.ManagedDataAccess.Client.OracleException (0x80004005): Connection request timed out.... has been reported randomly which results in failure of business transactions. ODP.NET provides extensive trace and along with above trace also contains OracleInternal.Network.NetworkException (0x80004005): Network Transport: TCP transport address connect failure ---\u0026gt; System.Net.Sockets.SocketException (0x80004005): A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\nSpecifically, Applications, receiving less traffic, were reporting it often compared to those with high traffic.\nApproach Simulate the Exception in Test Environment - We decided to try and simulate this exception in a Test Environment. Test environment is scaled down (50%) compared to production. Random Exceptions in production could not be simulated due to lack of Test Automation. for example, In Production, each server receives traffic for multiple HTTP End points whereas in Test environment, load testing was being done only against Single Application. This was like a end of the road since simulation would have greatly helped in diagnosing the issue. However, the show must go on so we decided to,\nCheck online documentation regarding this exception,\n\u0026ldquo;Pooled\u0026rdquo; or \u0026ldquo;Non-pooled\u0026rdquo; Connection - Whenever, ODP.NET raises \u0026ldquo;..timed out\u0026rdquo; error, it diffrentiates the same to indicate whether error is due to delay in retrieving connection from pool or if it is due to delay from the database server (Ref: Here). From this, it was clear that issue is clearly due to delay in obtaining response from database server.While this was happening , Database server (8 CPU Core box) was reporting less than 50% CPU Usage but it still had large number of inactive sessions originated from IIS Servers.\nSince the exception was reported frequently in low traffic applications, it was decided to track and verify the same on firewall and database server,\nFirewall - Firewall had TCP Timeout of 30 minutes and maintains detailed log of sessions. Quick analysis of it revealed that,\nProduction Environment - Unusually high number of sessions were being destroyed due to \u0026ldquo;Age out\u0026rdquo; (i.e. time out) Test Environment - No abnormal activity was reported. Most probably because of differences in traffic. Database Server - Listener Log on Oracle Database server did not had any log entry for request at the precise time when Application(s) had reported Exception.\nNext is to check settings in Application for connectivity with Oracle. Though ODP.NET does not have any direct \u0026ldquo;Time out\u0026rdquo; or \u0026ldquo;Time to live\u0026rdquo; settings, it does provide few parameters that can influence it,\n\u0026ldquo;Connection Lifetime\u0026rdquo; - ODP.NET uses this whenever Connection is closed and disposed by the Application. It will be destroyed (after maintaining number of connections as per \u0026ldquo;Min Pool Size\u0026rdquo;) if it has exceeded life time. For whatever reasons, this was set to unusually high duration (i.e. 90000 seconds). \u0026ldquo;Connection Timeout\u0026rdquo; - Period for which ODP.NET waits for the connection to be made available. This was set to 60 Seconds. Oracle has articles titled \u0026ldquo;ODP-1000 \u0026ldquo;Connection Request Timed Out\u0026rdquo; Explained\u0026rdquo; and \u0026ldquo;Resolving Problems with Connection Idle Timeout With Firewall (Doc ID 257650.1)\u0026rdquo; where it primarily recommends measures for tuning Application as well as database.\nOn the basis of above, it was decided to modify the code for below,\nThorough code review to verify that every ODP.NET Project is closed/disposed. Upgrade ODP.NET to latest version (v19.8.0 as of this writing) Turn \u0026ldquo;KeepAlive\u0026rdquo; while connecting to database Leverage ODP.NET tracing in case of exception Modify the connection lifetime to be less than time out at firewall and increase the \u0026ldquo;Time out\u0026rdquo; period. Introduce Retry functionality using Excellent Polly library with exponential back-off. These changes have been deployed to production and so far % of \u0026ldquo;Connection Request Timed out\u0026rdquo; errors have gone down significantly.\nWrap up Some key areas of focus are,\nFor a distributed system, Always validate assumptions by dignosing end to end. Plan to have test automation readyness to simulate production like load. Monitoring the behavior end to end using logs. Currently, Pool settings across applications is not optimal going by Oracle Real world Guidelines, also be mindful of Connection Storms Happy Troubleshooting !!\n","permalink":"http://localhost:1313/posts/connectiontimeouts/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI recently had opportunity to support team who has been battling with Intermittent (scary i know :)) issues with TCP connectivity in Production.\u003c/p\u003e\n\u003cp\u003eSimplified deployment Architecture is as below,\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/conntimeoutarch.png\"/\u003e \u003cfigcaption\u003e\n            High Level Architecture\n        \u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eTechnology Stack used is Microsoft .NET Framework 4.8 using ODP.NET for Oracle Connectivity (Oracle Server is 8 CPU box). Each of Web Servers in cluster have IIS hosted on it with multiple Applications (Application domains) serving HTTP(s) based traffic. These applications connect to Oracle Database.\u003c/p\u003e","title":"Trobleshooting TCP Connection request time outs"},{"content":"Background I recently came across bounty by Balaji Srinivasan to send Direct Message to all twitter followers. Currently, i do not intend to participate in bounty and this is mere exercise.\nThis is an attempt to write CLI tool in Golang in response to it.\nFor detailed requirements, refer here\nApproach In Brief,\nCLI should,\naccept arguments like Twitter API Key,Auth token, DM Message Download all followers (with profile details) Rank them by Criteria (e.g. Location) Send each follower a DM with provided message (upto daily DM Limit) be easy to use and maintain Notes,\nDue to Daily DM Limit, Follower details will have to be persisted alongside flag indicating if DM has been sent. SQLIte is used from simplicity perspective. There should be a scheduled job that will send the DM upto daily DM Limit. At the same time, it needs to refetch any new followers and push them in the flow (reconcile). Potentially, this could be extended to other social media providers other than twitter. Milestones, Create code structure Plan is to have separation between CLI \u0026amp; have twitter as go package Accept Arguments and Connect to Twitter Study and complete follower retrieval Ranking of followers Persisting followers Sending DM upto Daily limit Rules, Use golang\u0026rsquo;s in-built packages as much as possible Every milestone to have associated Unit test cases Current Status The code is ready and functionality to retrieve followers and saving in local DB is tested. Code to send DM is not yet tested as it will require setting up dummy twitter account.\nRoadmap In addition to CLI, Expose the utility as responsive Web Application Possibly extend this to social media platforms other than Twitter Have a look at code on Github and let me know what you think.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/massdmgolang/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI recently came across bounty by \u003ca href=https://twitter.com/balajis/status/1271945241881268224?s\u0026#61;20\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBalaji Srinivasan\u003c/a\u003e to send Direct Message to all twitter followers. \u003cem\u003eCurrently, i do not intend to participate in bounty and this is mere exercise.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThis is an attempt to write CLI tool in \u003ca href=https://golang.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGolang\u003c/a\u003e in response to it.\u003c/p\u003e\n\u003cp\u003eFor detailed requirements, refer \u003ca href=https://github.com/balajis/twitter-export\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cp\u003eIn Brief,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eCLI should,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eaccept arguments like Twitter API Key,Auth token, DM Message\u003c/li\u003e\n\u003cli\u003eDownload all followers (with profile details)\u003c/li\u003e\n\u003cli\u003eRank them by Criteria (e.g. Location)\u003c/li\u003e\n\u003cli\u003eSend each follower a DM with provided message (upto daily DM Limit)\u003c/li\u003e\n\u003cli\u003ebe easy to use and maintain\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNotes,\u003c/p\u003e","title":"Tool to mass DM followers on Twitter in Go"},{"content":"Section covering resources for Online learning etc.\nExploring basics of Computer Science, bit by bit Exploring basics of Distributed Systems Awesome List of Free Learning Resources Collection of online learning resources Complete intro to Linux and CLI Linux System Administration - Skill challenge ","permalink":"http://localhost:1313/links/onlearn/","summary":"\u003cp\u003eSection covering resources for  Online learning etc.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://medium.com/basecs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExploring basics of Computer Science, bit by bit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/baseds\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExploring basics of Distributed Systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ebookfoundation.github.io/free-programming-books/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome List of Free Learning Resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stackoverflow.blog/2020/04/27/build-your-technical-skills-at-home-with-online-learning/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of online learning resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://btholt.github.io/complete-intro-to-linux-and-the-cli/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComplete intro to Linux and CLI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/snori74/upskillchallenge\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLinux System Administration - Skill challenge\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Resources for Online Learning"},{"content":"Python has become pervasive all throught Data Science be it Machine learning, Deep learning, Data Processing and general purpose tasks like Web Development.\nCourses, Trainings Python Tutorials Python for Beginners from MSDN Nice Collection of trainings per level of complexity Python Programming And Numerical Methods: A Guide For Engineers And Scientists Practical Python Projects Articles Getting machine learning to production A quick-and-dirty guide on how to install packages for Python What to do when data doesn’t fit in memory DataSette - Architecture Notes Packages EasyOCR - supports 40\u0026#43; languages Simplified Static file serving for Python Static Site generator (with Markdown support) JupyterLab Desktop App Python helper library for ETL between databases Podcasts Talkpython ","permalink":"http://localhost:1313/links/python/","summary":"\u003cp\u003ePython has become pervasive all throught Data Science be it Machine learning, Deep learning, Data Processing and general purpose tasks like Web Development.\u003c/p\u003e\n\u003ch2 id=\"courses-trainings\"\u003eCourses, Trainings\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/norvig/pytudes\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePython Tutorials\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://channel9.msdn.com/Series/Intro-to-Python-Development/Python-for-Beginners-1-of-44-Programming-with-Python#comments\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePython for Beginners from MSDN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://forums.fast.ai/t/recommended-python-learning-resources/26888\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNice Collection of trainings per level of complexity\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pythonnumericalmethods.berkeley.edu/notebooks/Index.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePython Programming And Numerical Methods: A Guide For Engineers And Scientists\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://practicalpython.yasoob.me/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePractical Python Projects\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"articles\"\u003eArticles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=http://veekaybee.github.io/2020/06/09/ml-in-prod/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGetting machine learning to production\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://snarky.ca/a-quick-and-dirty-guide-on-how-to-install-packages-for-python/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA quick-and-dirty guide on how to install packages for Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pythonspeed.com/articles/data-doesnt-fit-in-memory/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat to do when data doesn’t fit in memory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://architecturenotes.co/datasette-simon-willison/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDataSette - Architecture Notes\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"packages\"\u003ePackages\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/JaidedAI/EasyOCR\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEasyOCR - supports 40\u0026#43; languages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://whitenoise.evans.io/en/stable/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSimplified Static file serving for Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/getpelican/pelican\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStatic Site generator (with Markdown support)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jupyterlab/jupyterlab_app#download\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJupyterLab Desktop App\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/BritishGeologicalSurvey/etlhelper\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePython helper library for ETL between databases\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"podcasts\"\u003ePodcasts\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://talkpython.fm/episodes/all\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTalkpython\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages - Python"},{"content":"At my current workplace, All Applications are expected to adhere to PCI DSS standards meant for Data protection, Access Regulation and so on. Dedicated SOC Team,consisting of Security analyst who are continously on the prawl to identify breach, conduct periodic auditing of Applications, hardening of Servers.\nWhile all our .NET applications adhere to below guidelines,\nASP.NET Security Overview Secure Coding Guidelines Security Guidelines by OWASP We also use tools like Snyk to perform code vulnerability analysis as part of Jenkins driven CI/CD pipeline. In spite of above, we do come across vulnerabilities identified by SOC Team which we needs to be addressed quickly. SOC team uses tools such as Burp Suite.\nThis post is going to summarize such incidents reported so far (and will keep updating it). In most of these cases, These issues required additional efforts over and above those provided by library or framework. Hopefully, it will be helpful to anyone trying address such vulnerabilities.\nCookie Path Every cookie being sent by the Web application has attributes like,\nHTTPOnly - Indicates whether a cookie is accessible by client-side script Domain - Indicates the domain to associate the cookie with Path - the virtual path to transmit with the current cookie Secure - Indicates whether cookie is sent only on Secure (HTTPS) Connections. OWASP has nice primer on Cookie Security.\nOf the above, Path attribute limits the scope of a cookie to a specific path on the server and can therefore be used to prevent unauthorized access to it from other applications on the same host. Accordingly, SOC Team had recommended that all cookies issued by application must have path attribute set.\nIn case of typical ASP.NET Application, there are cookies generated by .NET framework (like for Session, Anti XSRF Token and son on) and custom ones which are issued and used by Application itself.\nWhile it is fairly easy to set path for custom ones, we had to make code changes for cookies issued by .NET framework libraries. Lets take case of Session ID cookie, by default, this cookie always has root / as path. So how can this be changed as per the application\u0026rsquo;s deployment settings (i.e. specific virtual directory in IIS)?\nWe tried below,\nStep 1, try using httpcookies section in web.config like, \u0026lt;httpCookies requireSSL=\u0026#34;false\u0026#34; httpOnlyCookies=\u0026#34;true\u0026#34; domain=\u0026#34;site.com/myapp\u0026#34;/\u0026gt; First of all, this configuration element does not allow setting Path property and even during runtime, only the Domain property is populated while issuing the cookie. So this definitely does not help address the issue.\nSo other way is to programmatically set the path for Session Cookie. This can be done by providing custom implementation of SessionIDManager class like below,\npublic class MySessionIDManager : SessionIDManager, ISessionIDManager { void ISessionIDManager.SaveSessionID(HttpContext context, string id, out bool redirected, out bool cookieAdded) { base.SaveSessionID(context, id, out redirected, out cookieAdded); if (cookieAdded) { var name = \u0026#34;ASP.NET_SessionId\u0026#34;; var cookie = context.Response.Cookies[name]; // this will be possibly read from configuration cookie.Path = \u0026#34;/myapp\u0026#34;; } } } Thanks to this Stackoverflow thread for listing this approach. Application under consideration only had this particular cookie however, for all other .NET framework issued cookies, similar technique will have to be used.\nSameSite Cookie This is already detailed here\nMasking of Sensitive Data This typically involves masking the sensitive data like\nE-mail id Phone Number Credit/Debit Card Number It could well be used in Web Application or be received or sent as part of HTTP API.\nThe best bet in this case is to mask it on the server side itself before sending/rendering the data in browser. Note that, in some cases, above fields are used for data binding purposes. The approach we followed in such scenario was to use Hash value of it instead of merely masking the data. We have always used SHA256 or above for hashing.\nSummary Addressing security vulnerabilities is continuous process as hackers keep on inventing new ways for breaching and exploiting weak spots. As Application Architect/Developers, we need to brace ourselves for the same.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/websecurity/","summary":"\u003cp\u003eAt my current workplace, All Applications are expected to adhere to  \u003ca href=https://en.wikipedia.org/wiki/Payment_Card_Industry_Data_Security_Standard\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePCI DSS standards\u003c/a\u003e meant for Data protection, Access Regulation and so on.  Dedicated \u003ca href=https://en.wikipedia.org/wiki/Information_security_operations_center\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSOC\u003c/a\u003e Team,consisting of Security analyst who are continously on the prawl to identify breach, conduct periodic auditing of Applications, hardening of Servers.\u003c/p\u003e\n\u003cp\u003eWhile all our .NET applications adhere to below guidelines,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://support.microsoft.com/en-in/help/891028/asp-net-security-overview\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eASP.NET Security Overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/security/secure-coding-guidelines\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSecure Coding Guidelines\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cheatsheetseries.owasp.org/cheatsheets/DotNet_Security_Cheat_Sheet.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSecurity Guidelines by OWASP\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe also use tools like \u003ca href=https://www.snyk.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSnyk\u003c/a\u003e to perform code vulnerability analysis as part of Jenkins driven CI/CD pipeline. In spite of above, we do come across  vulnerabilities identified by SOC Team which we needs to be addressed quickly. SOC team uses tools such as \u003ca href=https://portswigger.net/burp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBurp Suite\u003c/a\u003e.\u003c/p\u003e","title":"Web Security Measures in ASP.NET Applications"},{"content":"Over the last many years, de-facto language of the Web (specifically front-end) has been Javascript (and variants like Typescript, ECMAScript versions and so on). The Web development has been revolving around HTML+CSS+Javascript trio. It all started with support for Javascript in browsers, followed by addition of XMLHTTP API, Rich DOM Manipulation Support in Javascript. To induce order and apply patterns to Javascript\u0026rsquo;s usage in browsers, numerous frameworks and libraries were introduced like React and Vue among others. To begin with, The target used to be browsers on Large Devices like Desktop \u0026amp; Laptops. However, soon all sorts of devices were targetted with advent of Responsive and Progressive CSS+Javascript libraries eg. Bootstrap. Offline Support soon came in ref: Electron and Progressive Web Applications.\nAs a result, Javascript has become lingua franca of Web Development and is being used on server side development (Nodejs).\nThe reason for this whole rant on history (which you are most likely to be aware of) is that latest kid on the Block could possibly challenge Monopoly of Javascript (and its ilk) at far as browsers are concerned.\nEnter WebAssembly (A.K.A. WASM)\nWebAssembly As per Wikipedia,\nWebAssembly (often shortened to Wasm) is an open standard that defines a portable binary-code format for executable programs, and a corresponding textual assembly language, as well as interfaces for facilitating interactions between such programs and their host environment.\nWebAssembly or wasm is a low-level bytecode format for in-browser client-side scripting, evolved from JavaScript. It is intermidiate representation(IR) where IR is transformed into machine instructions for the client architecture by browser.\nWebAssembly executables are precompiled, hence it is possible to use a variety of programming languages to make them. This essentially means that one can use same language for Server Side as well as Client side (i.e. in browser) development like (C# or Golang).\nWebAssembly was announced in 2015 and has since being supported by prominent browser(s) like Chrome and Firefox.\nAlong side browsers, many Vendors and open source communities/contributors have released libraries to make development of WebAssembly easy. We will look at how a WebAssembly can be developed in C# and Golang.\nNote: All major languages now support WebAssembly.\nC# During Microsoft Build 2020 1 event, Steve Sanderson had very good session on building WebAssembly using Blazor framework in .NET. Highly recommended to watch it.\nBlazor scaffolding provided with .NET core allows,\nBlazor Server App - A Template that runs server-side inside an ASP.NET Core app and handles user interactions over a SignalR connection.\nBlazor WebAssembly App - A Template for creating a Blazor app that runs on WebAssembly.\nChoosing Blazor WebAssembly App project type generates a project that has sample WebAssembly running. Overall, it makes development easy for any .NET developer easy since, it usesRazor syntax to add C# code along with HTML. During Build, it generates assembly for C# Code. When Accessed via browser, it downloads .NET runtime for WebAssembly (~ 621 KB) and the project assembly itself apart from static content (i.e. HTML files, images etc). The default scafolding includes Bootstrap CSS and prepares the UI to be responsive.\nThe repository referenced by Steve during presentation is available here.\nGolang Go has got clean, fast tooling. it produces static binaries and has superb concurrency primitives.\nVugu is an open source library that allows building a Web front-end in Go using WebAssembly. Generally static binaries are bulky and Vugu has addressed it using TinyGo compiler. Vugu is still work in progress but does work great in its current form. Check out their getting started page.\nInteresting take on Journey of JavaScript and what lies ahead for it, read it here.\nSummary In nutshell, Concept of WebAssembly provides compelling way to have full stack development in a language of your choice. It remains to be seen how and whether it provides viable alternative to current Javascript driven ecosystem.\nUseful References, Happy Coding !!\nModern Web UI with Blazor\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/webassembly/","summary":"\u003cp\u003eOver the last many years, de-facto language of the Web (specifically front-end) has been Javascript (and variants like Typescript, ECMAScript versions and so on). The Web development has been revolving around HTML+CSS+Javascript trio. It all started with support for Javascript in browsers, followed by addition of XMLHTTP API, Rich DOM Manipulation Support in Javascript. To induce order and apply patterns to Javascript\u0026rsquo;s usage in browsers, numerous frameworks and libraries were introduced like \u003ca href=https://reactjs.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReact\u003c/a\u003e and \u003ca href=https://vuejs.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVue\u003c/a\u003e among others. To begin with, The target used to be browsers on Large Devices like Desktop \u0026amp; Laptops. However, soon all sorts of devices were targetted with advent of Responsive and Progressive CSS+Javascript libraries eg. \u003ca href=https://getbootstrap.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBootstrap\u003c/a\u003e. Offline Support soon came in ref: \u003ca href=https://electronjs.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eElectron\u003c/a\u003e and \u003ca href=https://web.dev/progressive-web-apps/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProgressive Web Applications\u003c/a\u003e.\u003c/p\u003e","title":"Is WebAssembly future of Web Development"},{"content":"Background The source code of tracfee.com is hosted on Github Private.\nAt a High level, Tracfee\u0026rsquo;s Architecture involves,\nSingle Page Application using VueJS, deployed on Netlify API in Go, deployed on Oracle Cloud So far, API testing has been automated and we were looking at ways to automate deployment of both UI and API. Steps required to deploy API are less since we are using Docker to run it on VM. However, in case of Netlify, it is required to build and then upload the output folder on Netlify.\nAccordingly, it was decided to explore Github actions to automate deployment.\nUsing Github actions As per Github,\nGitHub Actions makes it easy to automate all your software workflows, now with world-class CI/CD. Build, test, and deploy your code right from GitHub. Make code reviews, branch management, and issue triaging work the way you want. GitHub actions work by provisioning Virtual machine to run an Event based workflow. It provides option to provision Linux/MacOS/Windows based Virtual machines. Steps in Workflow will have to be configured in YAML file. Trigger for Workflow can be (but not limited to) wide variety of events like on Push or commit on branch and so on.\nPost trigger, set of action(s) can be configured like,\nCheckout the branch Setup environment (Install Node.JS) Perform build Deployment Github has Marketplace which has many pre-built actions available. My requirement was to,\nProvision Linux (i.e. ubuntu-latest) Virtual Machine Checkout the code (using actions/checkout@v2) Setup Node.js (using actions/setup-node) perform Build and test using NPM Deploy to Netlify using netlify/actions/cli@master Any secrets required as part of Workflow can be maintained using Github secrets Above workflow needs to be maintained in .github\\workflows folder in the repository.\nbuild.yml for tracfee.com looks like,\nRefer Gist here.\nTesting the Build Workflow After configuring the workflow steps, next question is to check whether it is possible to test it locally? Luckily, there is tool available to do this. Enter Act , which is a tool to Run your GitHub Actions locally . Local testing is useful for Faster feedback. In Nutshell, Act uses local docker setup to provision container and then runs workflow steps in it. Give it a try !!\nAs a next step, Plan is to automate deployment of API on Oracle Cloud using OCI CLI interface.\nUseful References, Build with GitHub Actions, host on Netlify Adventures in CI/CD [#4]: Deploying A Microservice To The Oracle Cloud With GitHub Actions [OCI CLI Edition] Happy Coding !!\n","permalink":"http://localhost:1313/posts/usinggithubactions/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eThe source code of \u003ca href=https://tracfee.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003etracfee.com\u003c/a\u003e is hosted on Github Private.\u003c/p\u003e\n\u003cp\u003eAt a High level, Tracfee\u0026rsquo;s Architecture involves,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSingle Page Application using VueJS, deployed on \u003ca href=https://netlify.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNetlify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eAPI in \u003ca href=https://golang.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo\u003c/a\u003e, deployed on \u003ca href=https://www.oracle.com/in/cloud/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle Cloud\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSo far, API testing has been automated and we were looking at ways to automate deployment of both UI and API. Steps required to deploy API are less since we are using Docker to run it on VM. However, in case of Netlify, it is required to build and then upload the output folder on Netlify.\u003c/p\u003e","title":"Using Github Actions for Automated Testing and Deployment"},{"content":"Useful links for deep diving in various Cloud Ecosystems\nArticles Cost of Cloud - Paradox Cloud vs. On-premise Computing Zero dollar Infrastructure stack Cloud Server Performance, Prices, Specs and Features The Cost of Cloud, a Trillion Dollar Paradox Why we are leaving cloud General Guidelines when working as Cloud Engineer Articles (GCP) 13 sample architectures to kickstart your Google Cloud journey Using Google Cloud Spanner locally …using Emulator Articles (AWS) Serverless - Event driven Architecture Preparation Guidelines and courses for AWS Certification Saving egress costs on AWS using S3 Reducing AWS Costs Choosing between EC2 and RDS What a typical 100% Serverless Architecture looks like in AWS! Automating safe, hands-off deployments Containerizing legacy ASP.NET applications using AWS App2Container (A2C) Replacing web server functionality with serverless services AWS Lambda vs Cloudflare Workers Unbound One line Explaination for each of AWS Services Building a Multiplayer Game with API Gateway\u0026#43;Websockets, Go and DynamoDB Best Practices To Handle Lambda Timeout Errors Save 99.93% for Lambda with Init time Architecture of SAAS on Cloud managed by One man Team AWS Costs that every programmer should know You should not be probably using AWS Videos, Talks (AWS) DynamoDB - Advanced Design Patterns DynamoDB - Deep Dive Migration from Postgres to DynamoDB Tools Checkov-Prevent cloud misconfigurations during build-time Infracost - Open Source tool that shows Cloud cost estimates for Terraform in pull requests About Infrastructure as a Code Cloud Native Wiki - Cloud native Architectures, DevSecOps etc. Mock AWS Infrastructure ","permalink":"http://localhost:1313/links/cloud/","summary":"\u003cp\u003eUseful links for deep diving in various Cloud Ecosystems\u003c/p\u003e\n\u003ch3 id=\"articles\"\u003eArticles\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/the-cost-of-cloud-a-trillion-dollar-paradox/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCost of Cloud - Paradox\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.scirp.org/journal/paperinfexormation.aspx?paperid\u0026#61;87661\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCloud vs. On-premise Computing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/better-programming/the-zero-dollar-infrastructure-stack-7c840a8b555b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZero dollar Infrastructure stack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.vpsbenchmarks.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCloud Server Performance, Prices, Specs and Features\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/2021/05/27/cost-of-cloud-paradox-market-cap-cloud-lifecycle-scale-growth-repatriation-optimization/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Cost of Cloud, a Trillion Dollar Paradox\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://world.hey.com/dhh/why-we-re-leaving-the-cloud-654b47e0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy we are leaving cloud\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.lockedinspace.com/posts/001.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGeneral Guidelines when working as Cloud Engineer\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"articles-gcp\"\u003eArticles (GCP)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://cloud.google.com/blog/products/application-development/13-popular-application-architectures-for-google-cloud\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e13 sample architectures to kickstart your Google Cloud journey\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cloud.google.com/spanner/docs/emulator\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Google Cloud Spanner locally …using Emulator\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"articles-aws\"\u003eArticles (AWS)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://serverlessland.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eServerless - Event driven Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/training-and-certification/prepare-simultaneously-for-aws-certified-cloud-practitioner-and-aws-certified-solutions-architect-associate/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePreparation Guidelines and courses for AWS Certification\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.bitsand.cloud/posts/slashing-data-transfer-costs/?utm_source\u0026#61;hackernewsletter\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_term\u0026#61;data\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSaving egress costs on AWS using S3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.maxcountryman.com/articles/taming-aws-costs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReducing AWS Costs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.aws.amazon.com/prescriptive-guidance/latest/migration-sql-server/comparison.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChoosing between EC2 and RDS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/serverless-transformation/what-a-typical-100-serverless-architecture-looks-like-in-aws-40f252cd0ecb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat a typical 100% Serverless Architecture looks like in AWS!\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/builders-library/automating-safe-hands-off-deployments/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAutomating safe, hands-off deployments\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/modernizing-with-aws/containerizing-legacy-asp-net-applications-using-aws-app2container-a2c/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContainerizing legacy ASP.NET applications using AWS App2Container (A2C)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/compute/replacing-web-server-functionality-with-serverless-services/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReplacing web server functionality with serverless services\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.cloudflare.com/introducing-workers-unbound/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAWS Lambda vs Cloudflare Workers Unbound\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://adayinthelifeof.nl/2020/05/20/aws.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOne line Explaination for each of AWS Services\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://serialized.net/2020/09/multiplayer/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBuilding a Multiplayer Game with API Gateway\u0026#43;Websockets, Go and DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lumigo.io/learn/aws-lambda-timeout-best-practices/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Practices To Handle Lambda Timeout Errors\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@hichaelmart/shave-99-93-off-your-lambda-bill-with-this-one-weird-trick-33c0acebb2ea\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSave 99.93% for Lambda with Init time\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://anthonynsimon.com/blog/one-man-saas-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArchitecture of SAAS on Cloud managed by One man Team\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://david-codes.hatanian.com/2019/06/09/aws-costs-every-programmer-should-now.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAWS Costs that every programmer should know\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.karlsutt.com/articles/you-should-not-be-using-aws/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou should not be probably using AWS\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"videos-talks-aws\"\u003eVideos, Talks (AWS)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;6yqfmXiZTlM\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDynamoDB - Advanced Design Patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/AWSAktuell/deep-dive-into-dynamodb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDynamoDB - Deep Dive\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.instacart.com/company/how-its-made/from-postgres-to-amazon-dynamodb-%EF%BF%BC/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMigration from Postgres to DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"tools\"\u003eTools\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/bridgecrewio/checkov\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCheckov-Prevent cloud misconfigurations during build-time\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.infracost.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInfracost - Open Source tool that shows Cloud cost estimates for Terraform in pull requests\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://unzip.dev/0x004-infrastructure-as-code/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Infrastructure as a Code\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.aquasec.com/cloud-native-academy/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCloud Native Wiki - Cloud native Architectures, DevSecOps etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/spulec/moto\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMock AWS Infrastructure\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Cloud Tech"},{"content":"Useful links related from Generative AI, ML space\nCollections Gen AI- Collection of Articles on AI Code Generation and its pros and cons AI Guide by Mozilla Collection of resources related to Applied ML List of for MLOps Prompt Engineering Playbook for Programmers Free courses Fast AI by Jeremy Howard AI Canon - List of resources around GPT Free Deep learning course Articles AI native software Engineer in 2025 My LLM codegen workflow atm How to build your own perplexity for any dataset How a Machine Learns Machine learning is still too hard - Year 2022 Neural Networks from Scratch History of AI Machine Learning Algorithms: What is a Neural Network? What is Benford’s Law and why is it important for data science? Benford’s Law and Financial Statements Data Scientists Should Be More End-to-End Team Data science process (Microsoft) Traits of Good Data Scientist The First Rule of Machine Learning: Start without Machine Learning Deep learning is hitting wall Real world Recommendation System Videos Neural Networks Demystified Deep Learning: A Crash course Vector Embeddings, Vector Databases Storing OpenAI embeddings in Postgres with pgvector ChatGPT, LLMs A practical guide to building successful LLM products. Emerging Architecture for LLM Applications LocalGPT - Chat with your documents on your local device using GPT models Run LLMs from command line Resources on LLMs AI based Translation Lokalize - AI based translation of file Vibery - Semantic Search using embeddings and KNN Tools Markitdown - Convert PDF and Office documents to markdown to feed into LLM Aider - AI pair programming in your terminal An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with LlamaIndex, Langchain, OpenAI SDK, LiteLLM, and more. Vespa is an open-source search engine and big data processing platform. It’s particularly well[1]suited for applications that require low latency and high throughput. Our teams like Vespa’s ability to implement hybrid search using multiple retrieval techniques, to efficiently filter and sort many types of metadata, to implement multi-phased ranking, to index multiple vectors (e.g., for each chunk) per document without duplicating all the metadata into separately indexed documents and to retrieve data from multiple indexed fields at once. Kotaemon - An open-source RAG-based tool for chatting with your documents. ","permalink":"http://localhost:1313/links/aiml/","summary":"\u003cp\u003eUseful links related from Generative AI, ML space\u003c/p\u003e\n\u003ch2 id=\"collections\"\u003eCollections\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://addyo.substack.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGen AI- Collection of Articles on AI Code Generation and its pros and cons\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ai-guide.future.mozilla.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAI Guide by Mozilla\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/eugeneyan/applied-ml\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of resources related to Applied ML\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.google.com/spreadsheets/d/1i8BzE4puGQ3dmQueu4LQCcwaqrulgK1Vb-xeFwhy6gY/edit#gid\u0026#61;0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of  for MLOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://addyo.substack.com/p/the-prompt-engineering-playbook-for\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrompt Engineering Playbook for Programmers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"free-courses\"\u003eFree courses\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.fast.ai/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFast AI by Jeremy Howard\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/2023/05/25/ai-canon/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAI Canon - List of resources around GPT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fleuret.org/dlc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFree Deep learning course\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"articles\"\u003eArticles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://addyo.substack.com/p/tbe-ai-native-software-engineer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAI native software Engineer in 2025\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMy LLM codegen workflow atm\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jnnnthnn.com/how-to-build-your-own-perplexity-for-any-dataset\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to build your own perplexity for any dataset\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://janav.wordpress.com/2023/10/10/how-a-machine-learns/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow a Machine Learns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.nyckel.com/blog/ml-too-hard-for-software-developers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMachine learning is still too hard - Year 2022\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sirupsen.com/napkin/neural-net\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNeural Networks from Scratch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://spectrum.ieee.org/history-of-ai\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHistory of AI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.verypossible.com/insights/machine-learning-algorithms-what-is-a-neural-network\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMachine Learning Algorithms: What is a Neural Network?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/what-is-benfords-law-and-why-is-it-important-for-data-science-312cb8b61048\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat is Benford’s Law and why is it important for data science?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.auditanalytics.com/benfords-law-and-financial-statements/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenford’s Law and Financial Statements\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eugeneyan.com/writing/end-to-end-data-science/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Scientists Should Be More End-to-End\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTeam Data science process (Microsoft)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ianwhitestone.work/good-ds-bad-ds/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTraits of Good Data Scientist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eugeneyan.com/writing/first-rule-of-ml/?utm_source\u0026#61;hackernewsletter\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_term\u0026#61;fav\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe First Rule of Machine Learning: Start without Machine Learning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://nautil.us/deep-learning-is-hitting-a-wall-14467/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDeep learning is hitting wall\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.fennel.ai/p/real-world-recommendation-system?s\u0026#61;r\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReal world Recommendation System\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"videos\"\u003eVideos\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/playlist?list\u0026#61;PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNeural Networks Demystified\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;r0Ogt-q956I\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDeep Learning: A Crash course\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"vector-embeddings-vector-databases\"\u003eVector Embeddings, Vector Databases\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://supabase.com/blog/openai-embeddings-postgres-vector\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStoring OpenAI embeddings in Postgres with pgvector\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"chatgpt-llms\"\u003eChatGPT, LLMs\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://applied-llms.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA practical guide to building successful LLM products.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEmerging Architecture for LLM Applications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/PromtEngineer/localGPT\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLocalGPT - Chat with your documents on your local device using GPT models\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/simonw/llm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRun LLMs from command line\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://parlance-labs.com/education/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eResources on LLMs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"ai-based-translation\"\u003eAI based Translation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://lokalise.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLokalize - AI based translation of file\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/veekaybee/viberary/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVibery - Semantic Search using embeddings and KNN\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"tools\"\u003eTools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/markitdown\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMarkitdown - Convert PDF and Office documents to markdown to feed into LLM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/paul-gauthier/aider\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAider - AI pair programming in your terminal \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/lm-sys/FastChat\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAn open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/langfuse/langfuse\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with LlamaIndex, Langchain, OpenAI SDK, LiteLLM, and more.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/vespa-engine/vespa\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVespa is an open-source search engine and big data processing platform. It’s particularly well[1]suited for applications that require low latency and high throughput. Our teams like Vespa’s ability to implement hybrid search using multiple retrieval techniques, to efficiently filter and sort many types  of metadata, to implement multi-phased ranking, to index multiple vectors (e.g., for each chunk) per document without duplicating all the metadata into separately indexed documents and to retrieve data from multiple indexed fields at once.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Cinnamon/kotaemon\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eKotaemon - An open-source RAG-based tool for chatting with your documents. \u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Generative AI, Machine Learning"},{"content":"User Interface / User Experience Design Approach Modern Web - Guides, tools and libraries for modern web development. How Stripe Designs Beautiful Websites Tools for non artistic developers Principles of Design Micro frontends - Techniques, strategies and recipes for building a modern web app with multiple teams that can ship features independently. Thoughts on SPAs 33 JavaScript concepts every Developer should know Server side Events for Real-time streaming Updates Four ways to build Web Apps Parallel Data Fetching in SPA…has Good Primer on React Articles guideline on implementing auth in web applications Examples to manipulate HTML-DOM Comparing Polling vs WebSockets vs SSE A simple, choice-driven chatbot framework with Vanilla Javascript Centering in CSS: A Complete Guide Centering in CSS Full-bleed layout using CSS Grid Blog on HTML,fonts, Asynchronous JavaScript How to pick beautiful colors You dont need Javascript Sign in form Best practices How HTTP Range Requests work (for large file downloads etc.) Beginner’s guide to Next.js Data Model behind Notion’s flexibility How TCP Communication works between Client \u0026amp;amp; Server Practical Frontend Architecture using React,GraphQL, Next.JS and Typescript The baseline for Web development in 2022 Web UI Patterns by Addy Osmani The Web’s Next Transition Everything about HTMX Testing OSS Load and Functional testing tool Puppeteer - Testing using Headless Chrome Nodejs API Playwright - Nodejs library to automate Chromium, WebKit and Firefox Platforms Medusa - Flexible ECommerce Platform Libraries and Tools Bootstrap based Admin theme - Volt RsPack - Fast web bundler like webpack Dash - Python based framework for Visualization with no javascript ObservablePlot T3 - full-stack, typesafe Next.js app Perspective.js - A data visualization and analytics component, especially well-suited for large and/or streaming datasets. Observable - A static site generator for data apps, dashboards, reports Nginx Unit - Web Server with Native support for Languages GoatCounter - Open source Web site Analytics RedwoodJS - App framework Gatsby - React based fast framework Remix - Modern SPA framework Blitz - Modern SPA framework based on React Polaris design system by shopify Qiankun - Complete solution for Micro front-ends Astro - a website build tool Single SPA - Router for Micro front-ends HTMX -access AJAX, CSS Transitions, WebSockets and Server Sent Events directly in HTML, using attributes Bulletproof React - Opinionated React starter kit Javascript based Query/filter creator React based Sci-fi style UI Library with Animation and Sound Javascript libraries for Date and Time (Alternative to Moment.js) Zod - Schema validation in Typescript One line CSS Layouts by Google G9 - Interactive Graphs Interactive CSS Grid generator Msw - Mock Service Worker for REST \u0026amp;amp; GraphQL API Mocking Modern JavaScript Tutorial Web Vitals- Essential metrics for a healthy site. Clerk - User Management as Service Go based Fast Javascript bundler and minifier Finite State Machine in JS/Typescript Observable Plot - Data Visualization Library Shared data types for building collaborative software NoSQL-database for JavaScript Applications like Websites, hybrid Apps, Electron-Apps, Progressive Web Apps and NodeJs RemixIcon - Open Source Icons Repository Mermaid - Generate Diagrams from Markdown AutoMerge - Network agnostic library for JSON-like data structure (a CRDT) that can be modified concurrently by different users, and merged again automatically. Text (DSL) to diagrams Interactive guide to Flexbox End to end encryption in browser Collection of SVG logos Desktop App frameworks Tauri - smaller, faster, and more secure desktop applications with a web frontend (Native Webviews and no chromium) PWA PWABuilder - Publish Progressive Web App as Mobile App What a PWA can do today Step by Step using PWABuilder Mobile App Development Expo - universal native apps with React ","permalink":"http://localhost:1313/links/uiux/","summary":"\u003ch1 id=\"user-interface--user-experience\"\u003eUser Interface / User Experience\u003c/h1\u003e\n\u003ch2 id=\"design-approach\"\u003eDesign Approach\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://modern-web.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModern Web - Guides, tools and libraries for modern web development.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://leerob.io/blog/how-stripe-designs-beautiful-websites\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Stripe Designs Beautiful Websites\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://nodesign.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTools for non artistic developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://principles.design/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrinciples of Design\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://micro-frontends.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicro frontends - Techniques, strategies and recipes for building a modern web app with multiple teams that can ship features independently.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://nolanlawson.com/2022/05/25/more-thoughts-on-spas/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThoughts on SPAs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/leonardomso/33-js-concepts#8-iife-modules-and-namespaces\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e33 JavaScript concepts every Developer should know\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://shopifyengineering.myshopify.com/blogs/engineering/server-sent-events-data-streaming\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eServer side Events for Real-time streaming Updates\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tomhummel.com/posts/four-web-apps/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFour ways to build Web Apps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.martinfowler.com/articles/data-fetch-spa.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eParallel Data Fetching in SPA…has Good Primer on React\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"articles\"\u003eArticles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/pilcrowonpaper/copenhagen\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eguideline on implementing auth in web applications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://phuoc.ng/collection/html-dom/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExamples to manipulate HTML-DOM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://codeburst.io/polling-vs-sse-vs-websocket-how-to-choose-the-right-one-1859e4e13bd9\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComparing Polling vs WebSockets vs SSE\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/peekobot/peekobot\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA simple, choice-driven chatbot framework with Vanilla Javascript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://css-tricks.com/centering-css-complete-guide/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCentering in CSS: A Complete Guide\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ishadeed.com/article/learn-css-centering/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCentering in CSS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://joshwcomeau.com/css/full-bleed/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFull-bleed layout using CSS Grid\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://whistlr.info/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBlog on HTML,fonts, Asynchronous JavaScript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.datawrapper.de/beautifulcolors/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to pick beautiful colors\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/you-dont-need/You-Dont-Need-JavaScript\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou dont need Javascript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://web.dev/sign-in-form-best-practices/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSign in form Best practices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://developer.mozilla.org/en-US/docs/Web/HTTP/Range_requests\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow HTTP Range Requests work (for large file downloads etc.)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://welearncode.com/beginners-guide-nextjs/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBeginner’s guide to Next.js\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.notion.so/blog/data-model-behind-notion\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Model behind Notion’s flexibility\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sirupsen.com/napkin/problem-15/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow TCP Communication works between Client \u0026amp;amp; Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jaredgorski.org/writing/14-practical-frontend-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePractical Frontend Architecture using React,GraphQL, Next.JS and Typescript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.linecorp.com/en/blog/the-baseline-for-web-development-in-2022/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe baseline for Web development in 2022\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.patterns.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb UI Patterns by Addy Osmani\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.epicweb.dev/the-webs-next-transition\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Web’s Next Transition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hypermedia.systems\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEverything about HTMX\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"testing\"\u003eTesting\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://artillery.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOSS Load and Functional testing tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pptr.dev\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePuppeteer - Testing using Headless Chrome Nodejs API\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://playwright.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePlaywright - Nodejs library to automate Chromium, WebKit and Firefox\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"platforms\"\u003ePlatforms\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/medusajs/medusa\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMedusa - Flexible ECommerce Platform\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"libraries-and-tools\"\u003eLibraries and Tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/themesberg/volt-bootstrap-5-dashboard\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBootstrap based Admin theme - Volt\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/web-infra-dev/rspack\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRsPack - Fast web bundler like webpack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/plotly/dash\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDash - Python based framework for Visualization with no javascript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/observablehq/plot\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eObservablePlot\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/t3-oss/create-t3-app\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eT3 - full-stack, typesafe Next.js app\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/finos/perspective?tab\u0026#61;readme-ov-file\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePerspective.js - A data visualization and analytics component, especially well-suited for large and/or streaming datasets.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/observablehq/framework\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eObservable - A static site generator for data apps, dashboards, reports\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nginx/unit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNginx Unit - Web Server with Native support for Languages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/arp242/goatcounter\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoatCounter - Open source Web site Analytics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/redwoodjs/redwood\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedwoodJS - App framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.gatsbyjs.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGatsby - React based fast framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/remix-run/remix\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRemix - Modern SPA framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/blitz-js/blitz\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBlitz - Modern SPA framework based on React\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://polaris.shopify.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePolaris design system by shopify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/umijs/qiankun\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQiankun - Complete solution for Micro front-ends\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/withastro/astro\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAstro - a website build tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://single-spa.js.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSingle SPA - Router for Micro front-ends\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://htmx.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHTMX -access AJAX, CSS Transitions, WebSockets and Server Sent Events directly in HTML, using attributes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/alan2207/bulletproof-react\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBulletproof React - Opinionated React starter kit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://querybuilder.js.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJavascript based Query/filter creator\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://arwes.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReact based Sci-fi style UI Library with Animation and Sound\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dockyard.com/blog/2020/02/14/you-probably-don-t-need-moment-js-anymore\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJavascript libraries for Date and Time (Alternative to Moment.js)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/colinhacks/zod\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZod - Schema validation in Typescript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://1linelayouts.glitch.me/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOne line CSS Layouts by Google\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://omrelli.ug/g9/gallery/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eG9 - Interactive Graphs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://grid.layoutit.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteractive CSS Grid generator\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mswjs.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMsw - Mock Service Worker for REST \u0026amp;amp; GraphQL API Mocking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://javascript.info/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModern JavaScript Tutorial\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://web.dev/vitals\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb Vitals- Essential metrics for a healthy site.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=hthttps://tomhummel.com/posts/four-web-apps/tps://clerk.dev\n    \n    \n\u003eClerk - User Management as Service\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://esbuild.github.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo based Fast Javascript bundler and minifier\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://xstate.js.org/docs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFinite State Machine in JS/Typescript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/observablehq/plot\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eObservable Plot - Data Visualization Library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/yjs/yjs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eShared data types for building collaborative software\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rxdb.info\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNoSQL-database for JavaScript Applications like Websites, hybrid Apps, Electron-Apps, Progressive Web Apps and NodeJs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://remixicon.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRemixIcon - Open Source Icons Repository\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mermaid-js/mermaid\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMermaid - Generate Diagrams from Markdown\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/automerge/automerge\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAutoMerge - Network agnostic library for JSON-like data structure (a CRDT) that can be modified concurrently by different users, and merged again automatically.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://d2lang.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eText (DSL) to diagrams\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.joshwcomeau.com/css/interactive-guide-to-flexbox/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteractive guide to Flexbox\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.excalidraw.com/end-to-end-encryption/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEnd to end encryption in browser\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://svgl.vercel.app/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of SVG logos\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"desktop-app-frameworks\"\u003eDesktop App frameworks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/tauri-apps/tauri\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTauri - smaller, faster, and more secure desktop applications with a web frontend (Native Webviews and no chromium)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"pwa\"\u003ePWA\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.pwabuilder.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePWABuilder - Publish Progressive Web App as Mobile App\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://whatpwacando.today/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat a PWA can do today\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/ifdef-windows/get-started-building-a-progressive-web-app/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStep by Step using PWABuilder\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"mobile-app-development\"\u003eMobile App Development\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://GitHub.com/expo/expo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExpo - universal native apps with React\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"UI/UX"},{"content":"Background Recently, we had requirement wherein a process should,\nPeriodically (Poll) or Asynchronously (Pub-sub) listen on incoming requests/messages. The whole process is expected to be long running. Should also implement clean disposal of in-flight requests and subsequent cleanup using something similar to Cancelble Context in Go The first of the objective is somewhat dependent on mechanism (Pub/sub, Listener), protocol (TCP, HTTP etc.). For the second one, .NET framework (and .NET Core) offers CancellationToken. It is maint for co-operative cancellation between threads and Task Objects. So Armed with this, is it possible to come up with a template that allows cancellation of long running task while also being deployed as Windows Service (or using systemd in Linux) ?\nLets get Started,\nApproach We can use below to construct service,\nTopshelf - Allows Hosting services in-process as console apps or Windows services. NLog - For Logging Accordingly, we will have below Components,\nListener.cs - It wraps the long running process in a C# Task. It exposes Start and Stop functions which are essentially event handlers awaiting for Signal from the service. Refer Gist here\nProgram.cs - It configures the startup parameters for the service and initializes it. Using Topshelf, one can easily debug it as Console Application before deploying it as Service. Refer Gist here\nAbove Code was targetted at .NET Framework but the same can potentially be used on .NET Core thus targetting both Windows and Linux.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/windowsservicecancellabletask/","summary":"\u003ch3 id=\"background\"\u003eBackground\u003c/h3\u003e\n\u003cp\u003eRecently, we had requirement wherein a process should,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePeriodically (Poll) or Asynchronously (Pub-sub) listen on incoming requests/messages. The whole process is expected to be long running.\u003c/li\u003e\n\u003cli\u003eShould also implement clean disposal of in-flight requests and subsequent cleanup using something similar to Cancelble \u003ca href=https://golang.org/pkg/context/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContext\u003c/a\u003e in Go\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe first of the objective is somewhat dependent on mechanism (Pub/sub, Listener), protocol (TCP, HTTP etc.). For the second one, .NET framework (and .NET Core) offers \u003ca href=https://docs.microsoft.com/en-us/dotnet/api/system.threading.cancellationtoken?view\u0026#61;netcore-3.1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCancellationToken\u003c/a\u003e. It is maint for co-operative cancellation between threads and Task Objects. So Armed with this, is it possible to come up with a template that allows cancellation of long running task while also being deployed as Windows Service (or using systemd in Linux) ?\u003c/p\u003e","title":"Windows Service with Cancelable Task"},{"content":"Background Oftentimes, we come across situation where code does not perform as per expectation. What is typically approch to address it,\nPerformance Testing - Visual Studio Load Tests or Third party tools like Locust, Vegeta, Gatling etc. Visual Studio Diagnostics Tools Or Use tools like Perfview/dotTrace/dotMemory to diagnose bottlenecks What if it is possible to Benchmark code for,\nSet of varying parameter(s) Different runtimes (.NET Framework versions, .NET core, Mono etc.) with option to Benchmark it Observe Memory Allocations for diagnostics Get Detailed report on execution timeline Have it as part of test suite so that it can be easily executed with every iteration involving optimized code to get immediate feedback Enter BenchmarkDotNet, a Powerful .NET library for benchmarking. It is used by DotNET Team, Roslyn, ASP.NET Core and many other projects.\nThough Benchmarkdotnet.org has nice documentation with detailed examples, Below we will look at how to benchmark a code which is aimed at dumping in-memory list of objects to a delimited file. In real-world scenario, the list of objects could be retrieved from external data store.\nSo Lets Start.\nApproach We will have below before we proceed with using BenchmarkDotNet\nDummy class that represents Data Structure to be dumped to a file, Refer Gist here\nClass CardWriter.cs that generates file using,\nUsing StreamWriter with Buffer Using Stringbuilder and StreamWriter Using Open source CSVHelper library Refer Gist here\nNow, let us write code to benchmark above functions with Memory Diagnostics, Refer Gist here\nAbove code,\nClass FileGeneratorBenchmark - This class uses BenchmarkDotNET attributes to decorate set of functions which in turn call functions from CardWriter.cs class. Class Program - General purpose class with static main function that invokes BenchmarkRunner to execute benchmarks. It is required to run these benchmarks in Release mode or else BenchmarkDotNet will alert about the same. After running the benchmark, It will generate detailed report like below,\nReport shows Memory Allocation as well as Execution time lines across Platform (.NET Framework Vesions) and parameters.\nReferences:\nBenchmarkDotNet Introduction to Benchmarking C# Code with Benchmark .NET Happy Coding !!\n","permalink":"http://localhost:1313/posts/usingbenchmarkdotnet/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eOftentimes, we come across situation where code does not perform as per expectation. What is typically approch to address it,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePerformance Testing - Visual Studio Load Tests or Third party tools like  \u003ca href=https://locust.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLocust\u003c/a\u003e, \u003ca href=https://github.com/tsenart/vegeta\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVegeta\u003c/a\u003e, \u003ca href=https://gatling.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGatling\u003c/a\u003e etc.\u003c/li\u003e\n\u003cli\u003eVisual Studio Diagnostics Tools Or\u003c/li\u003e\n\u003cli\u003eUse tools like Perfview/dotTrace/dotMemory to diagnose bottlenecks\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhat if it is possible to Benchmark code for,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSet of varying parameter(s)\u003c/li\u003e\n\u003cli\u003eDifferent runtimes (.NET Framework versions, .NET core, Mono etc.) with option to Benchmark it\u003c/li\u003e\n\u003cli\u003eObserve Memory Allocations for diagnostics\u003c/li\u003e\n\u003cli\u003eGet Detailed report on execution timeline\u003c/li\u003e\n\u003cli\u003eHave it as part of test suite so that it can be easily executed with every iteration involving optimized code to get immediate feedback\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEnter \u003ca href=https://benchmarkdotnet.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenchmarkDotNet\u003c/a\u003e, a Powerful .NET library for benchmarking. It is used by \u003ca href=https://github.com/dotnet/performance\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDotNET\u003c/a\u003e Team, Roslyn, ASP.NET Core and many other projects.\u003c/p\u003e","title":"Optimizing  .NET Code using Benchmarks"},{"content":"Background A Web Application, developed in ASP.NET Core (Runtime Version 3.1.100) using Razor Pages and Web API, is expected to be launched from within third-party Web Application in iframe, with complete HTML being rendered.\nDuring the Development, a mock HTML Page was developed to simulate launching of ASP.NET core based Web Application in iframe. Note that this page as well as Application was hosted on same IIS Server and it worked fine. Subsequently, Web Application was deployed on Test Server and URL was shared for integration with third party Application and then it happened Boom\u0026hellip;. i.e. Application when launched in iframe rendered HTML but none of the post request would work (returning HTTP Error 400). Careful inspection showed that,\nBrowser\u0026rsquo;s Dev tools showed HTTP 400\nThere were no entries in Application\u0026rsquo;s Log File which indicates that Request was rejected either by IIS or ASP.NET Core\u0026rsquo;s chain of filters i.e. even before it reaches handler.\nIIS Log depicted that Request was rejected but had no additional details. May be some of the log settings were missing.\nNext up is to carefully look at Request sent by browser in \u0026lsquo;Network\u0026rsquo; tab of Dev tools. It showed that none of the cookies required by Application (i.e. for Session, CSRF token etc.) were present.\nEnter SameSite\nSameSite SameSite is a standard designed to provide some protection against cross-site request forgery (CSRF) attacks. Support for Samesite was added from .NET Core 2.2 and onwards. It is expected that developer will control the value of SameSite attribute using HttpCookie.SameSite property.Setting the SameSite property to Strict, Lax, or None results in those values being written on the network with the cookie.\nCookies without SameSite header are treated as SameSite=Lax by default. SameSite=None must be used to allow cross-site cookie use. Cookies that assert SameSite=None must also be marked as Secure. Applications that use \u0026lt;iframe\u0026gt; may experience issues with sameSite=Lax or sameSite=Strict cookies because \u0026lt;iframe\u0026gt; is treated as cross-site scenarios. The value SameSite=None is not allowed by the 2016 standard and causes some implementations to treat such cookies as SameSite=Strict. The SameSite=Lax setting works for most application cookies.\nAccordingly, below settings were made in startup.cs of the ASP.NET Core Application.\nservices.AddSession(options =\u0026gt; { options.IdleTimeout = TimeSpan.FromMinutes(30); options.Cookie.HttpOnly = true; // Samesite Settings. options.Cookie.SameSite = SameSiteMode.Lax; options.Cookie.IsEssential = true; }); services.AddAntiforgery(options =\u0026gt; { options.Cookie.SameSite = SameSiteMode.Lax; }); References SameSite cookie updates in ASP.net, or how the .Net Framework from December changed my cookie usage. Changes in SameSite Cookie in ASP.NET/Core and How it Impacts the Browser (Specifically Chrome) HTTP 203 Podcast covering CORS,CORB, Samesite Happy Coding !!\n","permalink":"http://localhost:1313/posts/samesitecookies/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eA Web Application, developed in ASP.NET Core (Runtime Version 3.1.100) using Razor Pages and Web API, is expected to be launched from within third-party Web Application in iframe, with complete HTML being rendered.\u003c/p\u003e\n\u003cp\u003eDuring the Development, a mock HTML Page was developed to simulate launching of ASP.NET core based Web Application in iframe. Note that this page as well as Application was hosted on same IIS Server and it worked fine. Subsequently, Web Application was deployed on Test Server and URL was shared for integration with third party Application and then it happened Boom\u0026hellip;. i.e. Application when launched in iframe rendered HTML but none of the post request would work (returning HTTP Error 400). Careful inspection showed that,\u003c/p\u003e","title":"ASP.NET Core - Mind the SameSite HTTP Cookie settings"},{"content":"Perspectives Section covering Business, project/programming perspectives\nLaws of Frugal Architecture Cognitive load is all that matters Stick to boring Architecture Your tech stack is not the product Architecture anti-patterns Don’t call yourself a programmer Grasp Responsibility Patterns Things every programmer should know Guiding principles after 20 years of programming Programmers: Before you turn 40, get a plan B The New Business of AI (and How It’s Different From Traditional Software) Hype driven Development Momentum vs Urgency in Software Project Management Data Science: Reality Doesn’t Meet Expectations Quantum computing for the very curious How to Speak (MIT) How Software Groups Rot: Legacy of the Expert Beginner What questions should systems architects ask before creating anything Basecamp for Personal Project Management Marketing for Engineers - Resources Approach to Exception Handling PRESALES (SE) LEADER? 10 THINGS YOU MUST BE DOING The Tail at Scale Long tail (99th percentile) latency Models for integrating data science teams within organizations Techniques and numbers for estimating system’s performance from first-principles The Amazon Builder’s library System Design Primer Telemetry Collection - Corelation in Latency Analysis Advice to Young kids by Stephen O’Grady Distributed Systems Reading List Awesome cold showers Behaviors to avoid in Software Architecture Role App Maintenance Cost Can Be Three Times Higher than Development Cost Foundational papers on distributed systems Dont end week with nothing Awesome Scalability - Collection of Articles around Performance, Scalability etc. Ego is the Enemy How to remember what you read? First Principles You are not Google 42 Lessons Learned in building production database Data structures implemented in JavaScript - I Data driven enterprises of 2025 Some Benefits of Simple Software Architecture Determining how Architectural decisions impact business via Value Use just one big Server When are Microservices a bad idea? The best engineers think like Investors not Builders CUPID principles Links for Aspiring CTO First principles thinking How Computer CPUs work A Distributed Systems Reading List 97 things, Pearls of wisdom for programmers collected from leading practitioners Evolutionary Architecture by Example Domain driven design - tools IO Devices and latency Legacy Modernization Patterns of Legacy Modernization Documenting the Architecture Arc42 - Open source Template for documenting the Software Architecture Arc42 \u0026#43; C4 - Example Structurizr - C4 Diagrams as Code Strategic Approach How to build an effective technical strategy Writing an Engineering Strategy A curated and opinionated list of resources for Chief Technology Officers, with the emphasis on startups Best Websites for Programmers Fintech Accounting for Computer Geeks Mifos X - Open source Financial Inclusion platform Moov.io - Tools/Libraries to integrate bank processing into their own software products like ISO8583 Awesome Fintech Resources Scheduling Evidence based scheduling Capacity planning, Database scalability Capacity planning for Web Application Scaling MySQL Web Hosting How i run my Servers? Career Checklist for Senior Engineer Power of Negative Thinking How to negotiate your salary package and much more Curated Lists Awesome Software Architecture Learning resources for curious programmer Documentation Adopting Doc as Code ","permalink":"http://localhost:1313/links/perspectives/","summary":"\u003ch1 id=\"perspectives\"\u003ePerspectives\u003c/h1\u003e\n\u003cp\u003eSection covering Business, project/programming perspectives\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://thefrugalarchitect.com/laws/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLaws of Frugal Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://minds.md/zakirullin/cognitive\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCognitive load is all that matters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://addyosmani.com/blog/boring-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStick to boring Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hoho.com/posts/your-stack-is-not-the-product/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYour tech stack is not the product\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://charity.wtf/2023/03/09/architects-anti-patterns-and-organizational-fuckery/?ref\u0026#61;architecturenotes.co\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArchitecture anti-patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDon’t call yourself a programmer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://en.wikipedia.org/wiki/GRASP_%28object-oriented_design%29\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGrasp Responsibility Patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mtdvio/every-programmer-should-know\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThings every programmer should know\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alexewerlof.medium.com/my-guiding-principles-after-20-years-of-programming-a087dc55596c\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuiding principles after 20 years of programming\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://improvingsoftware.com/2009/05/19/programmers-before-you-turn-40-get-a-plan-b/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProgrammers: Before you turn 40, get a plan B\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe New Business of AI (and How It’s Different From Traditional Software)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.daftcode.pl/hype-driven-development-3469fc2e9b22\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHype driven Development\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://testobsessed.com/2020/02/momentum-urgency/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMomentum vs Urgency in Software Project Management\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dfrieds.com/articles/data-science-reality-vs-expectations.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Science: Reality Doesn’t Meet Expectations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://quantum.country/qcvc#part-I\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuantum computing for the very curious\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ocw.mit.edu/resources/res-tll-005-how-to-speak-january-iap-2018/how-to-speak/index.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to Speak (MIT)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://daedtech.com/how-software-groups-rot-legacy-of-the-expert-beginner/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Software Groups Rot: Legacy of the Expert Beginner\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@budilov/what-questions-should-systems-architects-ask-before-creating-anything-6cd92a01e71b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat questions should systems architects ask before creating anything\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://basecamp.com/personal\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBasecamp for Personal Project Management\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/LisaDziuba/Marketing-for-Engineers\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMarketing for Engineers - Resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://particular.net/blog/but-all-my-errors-are-severe\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproach to Exception Handling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.linkedin.com/pulse/presales-se-leader-10-things-you-must-doing-jon-upton?articleId\u0026#61;6685231165948932097#comments-6685231165948932097\u0026amp;trk\u0026#61;public_profile_article_view\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePRESALES (SE) LEADER? 10 THINGS YOU MUST BE DOING\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/fulltext\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Tail at Scale\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.linkedin.com/performance/who-moved-my-99th-percentile-latency\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLong tail (99th percentile) latency\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@djpardis/models-for-integrating-data-science-teams-within-organizations-7c5afa032ebd\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModels for integrating data science teams within organizations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sirupsen/napkin-math\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTechniques and numbers for estimating system’s performance from first-principles\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/builders-library/?cards-body.sort-by\u0026#61;item.additionalFields.customSort\u0026amp;cards-body.sort-order\u0026#61;asc\u0026amp;awsf.filter-content-type\u0026#61;*all\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Amazon Builder’s library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/donnemartin/system-design-primer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSystem Design Primer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rakyll.medium.com/correlation-in-latency-analysis-419357b93287\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTelemetry Collection - Corelation in Latency Analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://thisistheway.us/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAdvice to Young kids by Stephen O’Grady\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dancres.github.io/Pages/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed Systems Reading List\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/hwayne/awesome-cold-showers\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome cold showers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.danielwatts.info/post/7-behaviours-to-avoid-software-architect/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBehaviors to avoid in Software Architecture Role\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.econnectivity.se/app-maintenance-cost-can-be-three-times-higher-than-development-cost/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApp Maintenance Cost Can Be Three Times Higher than Development Cost\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://muratbuffalo.blogspot.com/2021/02/foundational-distributed-systems-papers.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFoundational papers on distributed systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://training.kalzumeus.com/newsletters/archive/do-not-end-the-week-with-nothing\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDont end week with nothing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/binhnguyennus/awesome-scalability\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Scalability - Collection of Articles around Performance, Scalability etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fs.blog/2016/06/ego-is-the-enemy-genghis-khan/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEgo is the Enemy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fs.blog/2021/08/remember-books/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to remember what you read?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fs.blog/first-principles/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFirst Principles\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.bradfieldcs.com/you-are-not-google-84912cf44afb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou are not Google\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://maheshba.bitbucket.io/blog/2021/10/19/42Things.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e42 Lessons Learned in building production database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/trekhleb/javascript-algorithms\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData structures implemented in JavaScript - I\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/the-data-driven-enterprise-of-2025\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData driven enterprises of 2025\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.wave.com/en/blog/simple-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSome Benefits of Simple Software Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://martinfowler.com/articles/value-architectural-attribute.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDetermining how Architectural decisions impact business via Value\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.specbranch.com/posts/one-big-server/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse just one big Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://semaphoreci.com/blog/bad-microservices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhen are Microservices a bad idea?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://levelup.gitconnected.com/the-best-engineers-think-like-investors-not-builders-cf005e75ab80\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe best engineers think like Investors not Builders\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dannorth.net/2022/02/10/cupid-for-joyful-coding/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCUPID principles\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/kuchin/awesome-cto\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLinks for Aspiring CTO\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://addyosmani.com/blog/first-principles-thinking-software-engineers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFirst principles thinking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cpu.land/editions/one-pager\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Computer CPUs work\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dancres.github.io/Pages/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Distributed Systems Reading List\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/97-things/97-things-every-programmer-should-know\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e97 things, Pearls of wisdom for programmers collected from leading practitioners\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/evolutionary-architecture/evolutionary-architecture-by-example\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvolutionary Architecture by Example\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ddd-crew\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDomain driven design - tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://planetscale.com/blog/io-devices-and-latency\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIO Devices and latency\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"legacy-modernization\"\u003eLegacy Modernization\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://martinfowler.com/articles/patterns-legacy-displacement/#WeWantToBeLikeNetflix\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePatterns of Legacy Modernization\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"documenting-the-architecture\"\u003eDocumenting the Architecture\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://arc42.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArc42 - Open source Template for documenting the Software Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://githdub.com/bitsmuggler/arc42-c4-software-architecture-documentation-example\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArc42 \u0026#43; C4 - Example\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://structurizr.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStructurizr - C4 Diagrams as Code\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"strategic-approach\"\u003eStrategic Approach\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://leaddev.com/tech/how-build-effective-technical-strategy\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to build an effective technical strategy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lethain.com/eng-strategies/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWriting an Engineering Strategy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/kuchin/awesome-cto\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA curated and opinionated list of resources for Chief Technology Officers, with the emphasis on startups\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sdmg15/Best-websites-a-programmer-should-visit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Websites for Programmers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"fintech\"\u003eFintech\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://martin.kleppmann.com/2011/03/07/accounting-for-computer-scientists.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAccounting for Computer Geeks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mifos.org/mifos-x/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMifos X - Open source Financial Inclusion platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/moov-io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMoov.io - Tools/Libraries to integrate bank processing into their own software products like ISO8583\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/moov-io/awesome-fintech\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Fintech Resources\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"scheduling\"\u003eScheduling\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.joelonsoftware.com/2007/10/26/evidence-based-scheduling/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvidence based scheduling\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"capacity-planning-database-scalability\"\u003eCapacity planning, Database scalability\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://kirshatrov.com/posts/capacity-planning-for-web-apps/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCapacity planning for Web Application\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://kirshatrov.com/posts/scaling-mysql-stack-part-1-timeouts/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling MySQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"web-hosting\"\u003eWeb Hosting\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://blog.wesleyac.com/posts/how-i-run-my-servers\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow i run my Servers?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"career\"\u003eCareer\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://littleblah.com/post/2019-09-01-senior-engineer-checklist/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChecklist for Senior Engineer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://archive.is/O5Xcn\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePower of Negative Thinking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.complexsystemspodcast.com/episodes/how-to-negotiate-your-salary-package/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to negotiate your salary package and much more\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"curated-lists\"\u003eCurated Lists\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/mehdihadeli/awesome-software-architecture\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Software Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/charlax/professional-programming\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearning resources for curious programmer\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"documentation\"\u003eDocumentation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://medium.com/pinterest-engineering/adopting-docs-as-code-at-pinterest-4f18ad1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAdopting Doc as Code\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Perspectives"},{"content":"General Purpose tools Section covering useful tools for every day activities, Online learning etc.\nPlane - Open source alternative to JIRA ShareX - Screen capture, file sharing and productivity tools (Windows only) Dark Lang - Declarative platform to build serverless backend OBS Studio - Free and open source software for video recording and live streaming. Open source Wiki platform Open source 3D parametric modeler Backstage - an open platform for building developer portals Zoomit - screen zoom and annotation tool for technical presentations that include application demonstrations revealjs - HTML Presentation framework List of Self hosted software Open source Alternative to Heroku/Netlify for Self hosting A book of Secret knowledge - Collection of Useful tools Parsr - Transform PDF,Image into Structured data SOPS - Tool to secure secrets (JSON,YAML, INI etc.) via Command line and as GO library Windows Powertools for greater productivity Ex-googler’s list similar tools/techniques Recoll - Desktop full search tool Take potentially dangerous PDFs, office documents, or images and convert them to safe PDFs Briar - Secure peer to peer messaging on Android Open source alternative to Jira, slack,notion Useful Command line tools iperf -A TCP, UDP, and SCTP network bandwidth measurement tool Mise - version manager for multiple languages Guide to Linux Bash script Devbox - Quick shell with runtime environment without polluting laptop/desktop Shellcheck- a static analysis tool for shell scripts Useful online playgrounds by Julia Evans New list of useful Command line tools dsq- run sql queries against CSV,JSON,TSV, Web server logs exa - colorful alternative to ls duf - better disk usage/free utility Zmap - collection of open source tools for performing large-scale studies of the hosts and services that compose the public Internet. ripgrep - Recursively search directories for regex ripgrep-all - rigrep \u0026#43; PDFs, E-books, Office documents gron - Make JSON greppable xsv - fast command line CSV toolkit App that corrects previous Console command hstr - view bash shell history Lightening fast Code searching made easy Rewritten in Rust: Modern Alternatives of Command-Line Tools Broot - A better way to navigate directories fd - Alternative to Find bat - cat clone with wings Handy Linux networking tools rclone - manage files on cloud storage, Rsync for Cloud CPU-Z is a freeware system profiling and monitoring application for Microsoft Windows and Android Fselect - Find files with SQL-like queries HTTPie - Command line HTTP Client Visidata - A terminal spreadsheet multitool for discovering and arranging data Nginx - Tips for Sys Admins Avoiding the Top 10 NGINX Configuration Mistakes Listmonk - Open source newsletter and mailing list manager ATOP - Performance monitor for Linux (Better than htop) Below - Analyze Historical performance data for Linux Hyperfine - Generic Benchmarking tool Gmail backup tool gmvault - gmail backup tool Age - Simple File Encryption tool (Go) Encryption with Pass but Age as backend Yark - Archive youtube channels Linux related References Linux Network level performance Parameters Understand grep, awk and sed Awk in 20 minutes Understandin Awk Visual guide to SSH Tunnels Web based interface for Servers Structured data tools Structured data tools Hardware 10 Best Lightweight Operating System for old Laptop How and why I stopped buying new laptops Useful spreadsheet formulas Formulas for Personal finance Search tools Grep app- Search across Git Repos Blogging platforms, RSS etc Writefreely Yarr - Yet another feed aggregator Book of secret knowledge Book of Secret Knowledge Guidance and Templates for Resume Building Harward Uni. guidance on Resume building OpenResume - Professional, Free resume builder ","permalink":"http://localhost:1313/links/tools/","summary":"\u003ch1 id=\"general-purpose-tools\"\u003eGeneral Purpose tools\u003c/h1\u003e\n\u003cp\u003eSection covering useful tools for every day activities, Online learning etc.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/makeplane/plane\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePlane - Open source alternative to JIRA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://getsharex.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eShareX - Screen capture, file sharing and productivity tools (Windows only)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://darklang.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDark Lang - Declarative platform to build serverless backend\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://obsproject.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOBS Studio - Free and open source software for video recording and live streaming.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/BookStackApp/BookStack\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source Wiki platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/FreeCAD/FreeCAD\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source  3D parametric modeler\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://backstage.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBackstage - an open platform for building developer portals\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/sysinternals/downloads/zoomit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZoomit - screen zoom and annotation tool for technical presentations that include application demonstrations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://revealjs.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003erevealjs - HTML Presentation framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/awesome-selfhosted/awesome-selfhosted\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Self hosted software\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/coollabsio/coolify\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source Alternative to Heroku/Netlify for Self hosting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/trimstray/the-book-of-secret-knowledge\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA book of Secret knowledge - Collection of Useful tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/axa-group/parsr\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eParsr - Transform PDF,Image into Structured data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mozilla/sops\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSOPS - Tool to secure  secrets (JSON,YAML, INI etc.) via Command line and as GO library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/PowerToys\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWindows Powertools for greater productivity\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jhuangtw/xg2xg\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEx-googler’s list similar tools/techniques\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.lesbonscomptes.com/recoll/index.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRecoll - Desktop full search tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/freedomofpress/dangerzone\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTake potentially dangerous PDFs, office documents, or images and convert them to safe PDFs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://briarproject.org/quick-start/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBriar - Secure peer to peer messaging on Android\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/hcengineering/platform\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source alternative to Jira, slack,notion\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"useful-command-line-tools\"\u003eUseful Command line tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/esnet/iperf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eiperf -A TCP, UDP, and SCTP network bandwidth measurement tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jdx/mise\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMise - version manager for multiple languages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mywiki.wooledge.org/BashGuide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuide to Linux Bash script\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jetpack-io/devbox\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDevbox - Quick  shell with runtime environment without polluting laptop/desktop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.shellcheck.net/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eShellcheck- a static analysis tool for shell scripts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jvns.ca/blog/2021/09/24/new-tool--an-nginx-playground/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUseful online playgrounds by Julia Evans\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jvns.ca/blog/2022/04/12/a-list-of-new-ish--command-line-tools/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNew list of useful Command line tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/multiprocessio/dsq\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003edsq- run sql queries against CSV,JSON,TSV, Web server logs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ogham/exa\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eexa - colorful alternative to ls\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/muesli/duf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eduf - better disk usage/free utility\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/zmap\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZmap - collection of open source tools for performing large-scale studies of the hosts and services that compose the public Internet.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/BurntSushi/ripgrep\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eripgrep - Recursively search directories for regex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/phiresky/ripgrep-all\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eripgrep-all - rigrep \u0026#43; PDFs, E-books, Office documents\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tomnomnom/gron\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003egron - Make JSON greppable\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/BurntSushi/xsv\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003exsv - fast command line CSV toolkit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nvbn/thefuck\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApp that corrects previous Console command\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dvorka/hstr\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehstr - view bash shell history\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/hound-search/hound\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLightening fast Code searching made easy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://zaiste.net/posts/shell-commands-rust/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRewritten in Rust: Modern Alternatives of Command-Line Tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Canop/broot\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBroot - A better way to navigate directories\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sharkdp/fd\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003efd - Alternative to Find\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sharkdp/bat\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ebat - cat clone with wings\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.google.com/presentation/d/1PZ-bp-a00KKjE9bqKOd17ZoroyXHJkm70aXcFBqwXAQ/edit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHandy Linux networking tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rclone.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003erclone - manage files on cloud storage, Rsync for Cloud\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cpuid.com/softwares/cpu-z.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCPU-Z is a freeware system profiling and monitoring application for Microsoft Windows and Android\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jhspetersson/fselect\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFselect - Find files with SQL-like queries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://httpie.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHTTPie - Command line HTTP Client\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/saulpw/visidata\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisidata - A terminal spreadsheet multitool for discovering and arranging data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alex.dzyoba.com/blog/nginx-features-for-operators/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNginx - Tips for Sys Admins\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.nginx.com/blog/avoiding-top-10-nginx-configuration-mistakes\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAvoiding the Top 10 NGINX Configuration Mistakes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://listmonk.app\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eListmonk - Open source newsletter and mailing list manager\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.atoptool.nl/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eATOP - Performance monitor for Linux (Better than htop)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/facebookincubator/below\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBelow - Analyze Historical performance data for Linux\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sharkdp/hyperfine\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHyperfine - Generic Benchmarking tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jay0lee/got-your-back\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGmail backup tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/gaubert/gmvaulthttps://github.com/gaubert/gmvault\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003egmvault - gmail backup tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/filosottile/age\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAge - Simple File Encryption tool (Go)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://words.filippo.io/dispatches/passage/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEncryption with Pass but Age as backend\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Owez/yark\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYark - Archive youtube channels\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"linux-related-references\"\u003eLinux related References\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/leandromoreira/linux-network-performance-parameters\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLinux Network level performance Parameters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www-users.york.ac.uk/~mijp1/teaching/2nd_year_Comp_Lab/guides/grep_awk_sed.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstand grep, awk and sed\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ferd.ca/awk-in-20-minutes.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwk in 20 minutes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://earthly.dev/blog/awk-examples/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstandin Awk\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://robotmoon.com/ssh-tunnels/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisual guide to SSH Tunnels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cockpit-project.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb based interface for Servers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"structured-data-tools\"\u003eStructured data tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/dbohdan/structured-text-tools\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStructured data tools\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"hardware\"\u003eHardware\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://lotoftech.com/10-best-lightweight-operating-system-for-old-computers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 Best Lightweight Operating System for old Laptop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://solar.lowtechmagazine.com/2020/12/how-and-why-i-stopped-buying-new-laptops.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow and why I stopped buying new laptops\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"useful-spreadsheet-formulas\"\u003eUseful spreadsheet formulas\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://bou.ke/blog/formulas/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFormulas for Personal finance\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"search-tools\"\u003eSearch tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://grep.app/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGrep app- Search across Git Repos\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"blogging-platforms-rss-etc\"\u003eBlogging platforms, RSS etc\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/writefreely/writefreely\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWritefreely\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nkanaev/yarr\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYarr - Yet another feed aggregator\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"book-of-secret-knowledge\"\u003eBook of secret knowledge\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/trimstray/the-book-of-secret-knowledge\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBook of Secret Knowledge\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"guidance-and-templates-for-resume-building\"\u003eGuidance and Templates for Resume Building\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://hwpi.harvard.edu/files/ocs/files/undergrad_resumes_and_cover_letters.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHarward Uni. guidance on Resume building\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/xitanggg/open-resume\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpenResume - Professional, Free resume builder \u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Tools"},{"content":"Background Recently, i got involved in assignment where in an application was facing issues with throughput. Expectation is to support more than 500 transactions per second while load testing results were indicating system was experiencing high latency beyond 100+ transactions per second.\nThis application is developed in .NET Framework + .NET Core and primarily uses Relational Database for persistence and has point to point integration (mainly over HTTP) with internal \u0026amp; external application(s).\nApproach The high level approach decided to perform diagnostics and subsequent corrective action(s) were,\nBenchmark code that involves Database and take corrective action Identify tasks in hot code path that could potentially be decoupled or done in fire-n-forget mode. For point 2 from above, some of the tasks identified were,\nSending Email/SMS on myriad of events Integration with External Applications over HTTP Next task was to arrive at approach on how to perform them effectively outside of hot code path without incurring need of any additional resources (hardware or software)as far as possible. Accordingly, we had two options,\nPolling - Periodically polling database to check for occurance of event and then performing the action. Event Driven - Using Event notification feature of database (e.g. Listen/Notify in PostgreSQL or Change Notification/Advanced Queuing in Oracle). We decided to go with Event driven as,\nCleaner approach that doesn\u0026rsquo;t require perodically checking for events thus consuming a database connection and more code. We may have to have more than one such daemons to cater to different events in application. Post finalizing on event driven approach for gathering events, next task was to determine how to effectively send email/sms or any other HTTP requests considering that rate of arrival of events will not be matching rate of processing them. Also these\nSo what are the options available in .NET Ecosystem, Below are the ones i am aware of,\nChannels - High performance implementation of In-memory producer/consumer pattern. TPL Dataflow - Super set of Channels Library. Aimed at use cases where blocks of logic are to be linked together to same or different consumers and so on. Also all these features come with additional overheads. For the task at hand, functionality offered by Channels is sufficient to implement in-memory producer consumer pattern.\nSo we wrapped above event processing in a Windows service implemented as .NET Core Worker Service\nGeneric Implementation is as follows,\nEvent Generator - In practice, this class will be responsible for wiring up to receive events from database\nEvent Consumer which uses channels to process events in parallel\nRefer Gist here\nAdditionally, one may want to process requests out of order or asynchronously without using message queues. One such use case could be service to send Notifications where this service is exposed as Web API and it uses external service to dispatch notifications. For such scenarios, one can use back ground job in conjunction with Channels to process requests.\nBelow code shows a Web API that handles HTTP Requests and delegates actual task to background worker which is deployed as hosted service.\nRefer Gist here\nHowever, note that there are trade-offs vis-a-vis message queues with this approach. Notably, in case of Web server crash, the pending jobs in queue will be lost.\nSummary Other languages (notably Channels in Go) have been providing out of the box implementation for in-memory producer with concurrent, parallel consumers. With Channels, .NET Ecosystem finally has construct that can be effectively put to use for high performance, concurrent use cases.\nUseful References, Event Pattern in C# Gist on using Channels Happy Coding !!\n","permalink":"http://localhost:1313/posts/channelsforproducerconsumer/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eRecently, i got involved in assignment where in  an application was facing issues with throughput. Expectation is to support more than 500 transactions per second while load testing results were indicating system was experiencing high latency beyond 100+ transactions per second.\u003c/p\u003e\n\u003cp\u003eThis application is developed in .NET Framework + .NET Core and primarily uses Relational Database for persistence and has point to point integration (mainly over HTTP) with internal \u0026amp; external application(s).\u003c/p\u003e","title":"Using Channels for High performance Producer consumer implementation"},{"content":"Oracle Database Performance, Best Practices Connection Strategies for Database Applications Using High-Speed Data Loading and Rolling Window Operations with Partitioning Designing Applications for Oracle Real-World Performance Best Practices for Extreme Performance with Oracle Data Warehousing Blog on Oracle Performance troubleshooting Using PL/SQL Bulk processing features Auditing tables using Oracle Flashback data archive instead of triggers Flashback Data Archive to record changes to Table Bulk processing with PL/SQL Bulk Processing with BULK COLLECT and FORALL Primer on Oracle Partitioning Database Core performance principles - Deck Database insert \u0026amp;amp; referential integrity - Performance On Connection Pools, Cursor Differentiation, and Optimal Ordering Analytical Functions Overview About Materialized Views How to find Slow SQL Using External Tables and Table Clusters in Oracle Oracle DBA - Application Tuning Replacing Kafka use cases with Oracle Advanced queues in modern applications SQL Tips you can’t do without Change Data Capture Nice writeup on options to do CDC in Oracle Database Integrating Oracle and Kafka Videos Real world performance video series Oracle LiveLabs How to:Analyze AWR Report 5 Minutes Demo: Using Liquibase in SQLcl to version Oracle Database Analytic SQL for Developers - Free course Connection Pooling and SmartDB Oracle Database for Developers - Training How to Create an Execution plan? Machine learning in Autonomous Database Utilities, Tools OraTOTP, Free tool to enable 2 factor authentication Audit table Generator for Oracle Tables Swingbench, free load generator (and benchmarks) designed to stress test an Oracle database (12c, 18c, 19c). Create Excel file PL/SQL ","permalink":"http://localhost:1313/links/oracle/","summary":"\u003ch2 id=\"oracle-database\"\u003eOracle Database\u003c/h2\u003e\n\u003ch3 id=\"performance-best-practices\"\u003ePerformance, Best Practices\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://docs.oracle.com/en/database/oracle/oracle-database/12.2/adfns/connection_strategies.html##GUID-25F85237-702B-4609-ACE2-1454EBC8284B\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection Strategies for Database Applications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.oracle.com/webfolder/technetwork/tutorials/obe/db/11g/r2/prod/bidw/etl/etl.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing High-Speed Data Loading and Rolling Window Operations with Partitioning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.oracle.com/en/database/oracle/oracle-database/12.2/adfns/rwp.html##GUID-754328E1-2203-4B03-A21B-A91C3E548233\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesigning Applications for Oracle Real-World Performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.oracle.com/technetwork/database/bi-datawarehousing/pres-best-practices-for-extreme-per-130805.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Practices for Extreme Performance with Oracle Data Warehousing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://savvinov.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBlog on Oracle Performance troubleshooting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/solving-the-row-by-row-problem\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing PL/SQL Bulk processing features\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/a-fresh-look-at-auditing-row-changes\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAuditing tables using Oracle Flashback data archive instead of triggers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;FpRAc-FEWbE\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFlashback Data Archive to record changes to Table\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://livesql.oracle.com/apex/livesql/file/tutorial_IEHP37S6LTWIIDQIR436SJ59L.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBulk processing with PL/SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/bulk-processing-with-bulk-collect-and-forall\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBulk Processing with BULK COLLECT and FORALL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://asktom.oracle.com/partitioning-for-developers.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrimer on Oracle Partitioning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/koppelaars/database-core-performance-principles\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase Core performance principles - Deck\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dev.to/gvenzl/comment/12137\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase insert \u0026amp;amp; referential integrity - Performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/on-connection-pools-cursor-differentiation-and-optimal-ordering\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOn Connection Pools, Cursor Differentiation, and Optimal Ordering\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/a-window-into-the-world-of-analytic-functions\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAnalytical Functions Overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://livesql.oracle.com/apex/livesql/file/tutorial_JN0Y98523UQ6VVZRREWOVZUT9.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Materialized Views\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://livesql.oracle.com/apex/livesql/file/tutorial_JN0XQTKBU5D2JMNDVMTRQCFIE.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to find Slow SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/sql/how-to-create-alter-and-drop-tables-in-sql#create-external\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing External Tables and Table Clusters in Oracle\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://videohub.oracle.com/media/1_57pd28lv?elq_mid\u0026#61;174954\u0026amp;sh\u0026#61;082624191813080613161522312216341235\u0026amp;cmid\u0026#61;WWMK200518P00173\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle DBA - Application Tuning \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;kFQqS9Ry-jI\u0026amp;list\u0026#61;WL\u0026amp;index\u0026#61;9\u0026amp;ab_channel\u0026#61;OracleMania\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReplacing Kafka use cases with Oracle Advanced queues in modern applications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://speakerdeck.com/sqlmaria/sql-tuning-tips-you-cant-do-withou\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Tips you can’t do without\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"change-data-capture\"\u003eChange Data Capture\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://rmoff.net/2018/12/12/streaming-data-from-oracle-into-kafka/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNice writeup on options to do CDC in Oracle Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://talks.rmoff.net/ixPL5r/integrating-oracle-and-kafka\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIntegrating Oracle and Kafka\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"videos\"\u003eVideos\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/playlist?list\u0026#61;PLKCk3OyNwIzvwEXdaubc6PQXwnQOAE9h2\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReal world performance video series\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://apexapps.oracle.com/pls/apex/dbpm/r/livelabs/livelabs-workshop-cards?p100_focus_area\u0026#61;141\u0026amp;me\u0026#61;110\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle LiveLabs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;xSXQ3EwU8t0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to:Analyze AWR Report\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.thatjeffsmith.com/archive/2020/02/5-minutes-demo-using-liquibase-in-sqlcl-to-version-oracle-database/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e5 Minutes Demo: Using Liquibase in SQLcl to version Oracle Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devgym.oracle.com/pls/apex/dg/class/analytic-sql-for-developers.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAnalytic SQL for Developers - Free course\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;eiydITTdDAQ\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection Pooling and SmartDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://asktom.oracle.com/databases-for-developers.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle Database for Developers - Training\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/sql/how-to-create-an-execution-plan\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to Create an Execution plan?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/SandeshRao4/machine-learning-in-autonomous-data-warehouse\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMachine learning in Autonomous Database\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"utilities-tools\"\u003eUtilities, Tools\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.dbarj.com.br/en/oratotp-oracle-time-based-one-time-password/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOraTOTP, Free tool to enable 2 factor authentication\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/connormcd/audit_utility\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAudit table Generator for Oracle Tables\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://www.dominicgiles.com/swingbench.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSwingbench,  free load generator (and benchmarks) designed to stress test an Oracle database (12c, 18c, 19c).\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://technology.amis.nl/languages/oracle-plsql/create-an-excel-file-with-plsql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCreate Excel file PL/SQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Oracle"},{"content":"NOSQL Databases MongoDB FerretDB - MongoDB Interface with underlying PostgreSQL as database engine Amazon DynamoDB Data Modelling in DynamoDB Must follow Twitter handle of Rick Houlihan Best Practices for Secondary Indexes with DynamoDB Apache Cassandra 7 mistakes when using Apache Cassandra Apache Geode How Mastercard fights fraud with Apache Geode Apache Pinot Pinot- Enabling Real-time Analytics @ linkedin Redis About Redis DragonflyDB - Alternative to Redis Redis High Availability Redis Cluster KeyDB is a high performance fork of Redis with a focus on multithreading, memory efficiency, and high throughput. In addition to multithreading RediSQL, fastest, simplest, in-memory SQL Redisearch - Redis powered Search Engine JuiceFS - POSIX File System with Redis or S3 as backend SSDB - A fast NoSQL database, an alternative to Redis Comparing REDIS and Memcached Oracle Coherence Oracle Coherence Community Edition Full text Search Engines Deep Dive into Querying Elasticsearch. Filter vs Query. Full-text search Engine for Low-latency Computation over large data sets Open source Full text Search Engine Sonic - Fast, lightweight \u0026amp;amp; schema-less search backend ","permalink":"http://localhost:1313/links/nosql/","summary":"\u003ch1 id=\"nosql-databases\"\u003eNOSQL Databases\u003c/h1\u003e\n\u003ch2 id=\"mongodb\"\u003eMongoDB\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/FerretDB/FerretDB\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFerretDB - MongoDB Interface with underlying PostgreSQL as database engine\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"amazon-dynamodb\"\u003eAmazon DynamoDB\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;6yqfmXiZTlM\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Modelling in DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://twitter.com/houlihan_rick?lang\u0026#61;en\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMust follow Twitter handle of Rick Houlihan\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.trek10.com/blog/best-practices-for-secondary-indexes-with-dynamodb/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Practices for Secondary Indexes with DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"apache-cassandra\"\u003eApache Cassandra\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://blog.softwaremill.com/7-mistakes-when-using-apache-cassandra-51d2cf6df519\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e7 mistakes when using Apache Cassandra\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"apache-geode\"\u003eApache Geode\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://content.pivotal.io/blog/how-mastercard-fights-fraud-with-apache-geode\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Mastercard fights fraud with Apache Geode\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"apache-pinot\"\u003eApache Pinot\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/seunghyunlee1460/pinot-enabling-realtime-analytics-applications-linkedins-scale\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePinot- Enabling Real-time Analytics @ linkedin\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"redis\"\u003eRedis\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://architecturenotes.co/redis/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Redis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dragonflydb.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDragonflyDB - Alternative to Redis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alex.dzyoba.com/blog/redis-ha/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedis High Availability\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alex.dzyoba.com/blog/redis-cluster/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedis Cluster\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://keydb.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eKeyDB is a high performance fork of Redis with a focus on multithreading, memory efficiency, and high throughput. In addition to multithreading\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://redisql.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRediSQL, fastest, simplest, in-memory SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://oss.redislabs.com/redisearch/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedisearch - Redis powered Search Engine\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/juicedata/juicefs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJuiceFS - POSIX File System with Redis or S3 as backend\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ssdb.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSSDB - A fast NoSQL database, an alternative to Redis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.kablamo.com.au/posts/2021/memcached-vs-redis-whats-the-difference\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComparing REDIS and Memcached\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"oracle-coherence\"\u003eOracle Coherence\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/oracle/coherence\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle Coherence Community Edition\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"full-text-search-engines\"\u003eFull text Search Engines\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/deep-dive-into-querying-elasticsearch-filter-vs-query-full-text-search-b861b06bd4c0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDeep Dive into Querying Elasticsearch. Filter vs Query. Full-text search\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/vespa-engine/vespa\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEngine for Low-latency Computation over large data sets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.meilisearch.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source Full text Search Engine\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/valeriansaliou/sonic\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSonic -  Fast, lightweight \u0026amp;amp; schema-less search backend\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"NOSQL"},{"content":"MySQL Links Query analytics for the day-to-day developer with MySQL 8.0 Schema Change Management for MySQL Temporal Data tables in MariaDB MySQL 8.0 Indexes, Histograms, and Other Ways to Speed Up Your Queries Maxwell - MySQL to Kafka change data capture LetsEncrypt setup for MariaDB How LetsEncrypt has built Next Gen Database Servers 18 things you can do to remove mysql Bottlenecks due to High traffic MySQL from Developer’s perspective Replication in MySQL Interesting libraries, extensions Distributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres Orchestrator - Replication topology and high availability Vitess,a Distributed MySQL Massively scaling MySQL database How Slack uses Vitess ","permalink":"http://localhost:1313/links/mysql/","summary":"\u003ch1 id=\"mysql\"\u003eMySQL\u003c/h1\u003e\n\u003ch2 id=\"links\"\u003eLinks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/gabidavila/query-analytics-for-the-day-today-developer-with-my-sql-80\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuery analytics for the day-to-day developer with MySQL 8.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/skeema/skeema\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSchema Change Management for MySQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mariadb.com/kb/en/temporal-data-tables/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTemporal Data tables in MariaDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/davestokes/mysql-80-indexes-histograms-and-other-ways-to-speed-up-your-queries\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMySQL 8.0 Indexes, Histograms, and Other Ways to Speed Up Your Queries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/zendesk/maxwell\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMaxwell - MySQL to Kafka change data capture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/letsencrypt/openzfs-nvme-databases\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLetsEncrypt setup for MariaDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://letsencrypt.org/2021/01/21/next-gen-database-servers.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow LetsEncrypt has built Next Gen Database Servers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2020/04/03/18-things-you-can-do-to-remove-mysql-bottlenecks-caused-by-high-traffic-part-one/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e18 things you can do to remove mysql Bottlenecks due to High traffic\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.koehntopp.info/2020/09/07/mysql-from-a-developers-perspective.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMySQL from Developer’s perspective\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/JeanFranoisGagn/mysql-scalability-and-reliability-for-replicated-environment\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReplication in MySQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"interesting-libraries-extensions\"\u003eInteresting libraries, extensions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/knadh/sql-jobber\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/openark/orchestrator\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOrchestrator - Replication topology and high availability\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"vitessa-distributed-mysql\"\u003eVitess,a Distributed MySQL\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.infoq.com/presentations/vitess\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMassively scaling MySQL database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://slack.engineering/scaling-datastores-at-slack-with-vitess/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Slack uses Vitess\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"MySQL"},{"content":"Database Knowledge base around general database related topics.\nGeneral Links Which Data Architecture to choose Prisma’s Data Guide - A growing library of articles focused on making databases more approachable. Query optimization guide Database performance for Developers Heimdall data -Database scale-out without Application changes Database of databases Modern SQL in databases Eventual consistency by Werner Vogels Amazon Aurora ascendant: How we designed a cloud-native relational database - All Things Distributed Options for scaling from 1 to 100,000 tenants Amazon Aurora: design considerations for high throughput cloud-native relational databases | the morning paper NOSQL - Key Points Criteria for Choosing Data store Building Real Time Analytics APIs at Scale Streaming Database Changes with Debezium Why you should pick strong consistency, whenever possible Change Data Capture, Outbox and Event Sourcing Debezium Engine - setup without Apache Kafka Debezium without kafka connect Using Streamsets for CDC From Oracle to Other destinations Transactions in Google Spanner Things I Wished More Developers Knew About Databases Interactive Book about SQL SQL Interview Questions Hadoop or Laptop The lightweight, distributed relational database built on SQLite Optimizing SQL Queries, Regardless of Platform How to do Data Modelling the right way Primer on Database Replication Connection pool sizing for databases Some SQL tricks from Application DBA Best Practices while writing SQL Using checksums to verify syncing 100M database records How to populate a table with 1 million records using single query How databases optimize Sub-queries Approaches to database migration Tigetbeetle - Fast financial accounting database Opinionated thoughts on SQL Databases Tools Collection DBMS Tools OctoSQL - Query, Join CSV with Postgresql/mysql from Command line TSBS - tool to benchmark bulk load performance and query execution performance. Goose - Database schema migrations HammerDB - Benchmarking Suite for databases Sysbench - Scriptable database and system performance benchmark Soda core - Data schema checks, for Quality, as code Readyset - MySQL and Postgres wire-compatible caching layer that sits in front of existing databases to speed up queries and horizontally scale read throughput. Data Analytics Understanding avro, parquet and ORC Guidance on Data Visualizations Simple data pipeline Powertools Cube.dev - Open source Headless BI platform Evidence.dev - BI as Code - SQL \u0026#43; Markdown to generate Reports Apache spark defined Getting started with Spark in Python About Data Mesh Architecture Data mesh vs. Data Fabric Emerging Architectures for Modern Data Infrastructure Data Visualization/Exploration platforms Comparion Matrix Supercharging Apache Superset Snowplow - Cloud Native Behavioral data engine (e.g. User Analytics) Redash - Collaboration, dashboards Why data culture matters Designing a data transformation that delivers value right from the beginning List of Computational Data Analysis Workflow Systems Data Visualization framework for Python Analytics Academy by Segment Analytics Whitepapers by Sisense SQL Analytics Training A Beginner’s Guide to Data Engineering - 3-part series Chart types and its usage Rudder - Open source Customer Data Infrastructure Catalog of Widgets for Data Visualization Open source OLAP Database Modern Data stack guide by Castor Data Stack of 1mg A Unified Data Infrastructure Architecture Data and AI Product Landscape Transformations for DWH using DBT Awesome list of Business Intelligence Tools Article Series on Open source Data Analytics Stack (Postgres,Meltano, Airflow, dbt and Superset) Posthog - open source product analytics platform Typical Analytics Stack Flat Data - Scheduled Data Download on GitHub Actions in Repository and visualization Nocodb - Turn *MySQL/PostgreSQL data in smart Spreadsheet Real time data analysis with Apache Pinot and kafka UUIds are bad for performance Noria - Caching and updating Relational query results Differential Datalog - Language for incremental computation Using NanoIDs (not longer UUID) for public APis In-memory Databases Dragonfly - Compatible with REDIS Duck DB DuckDB - Embeddable OLAP DBMS SQL Workbench - run Duckdb on WASM DuckDB - Connect and join on external databases Using duckdb and postgres together ETL,ELT, Database-as-a-queue, Evolutionary Practices All about ETL Airbyte-Open source ELT Database CI/CD practices using Redshift Awesome Apache Airflow A Python library for building data applications: ETL, ML, Data Pipelines, and more. A modern data workflow platform Databus - Change Data capture System from Linkedin Dolt - Git for Data GridDB - next generation database for IoT \u0026amp;amp; big data with both NoSQL interface \u0026amp;amp; SQL Interface. Compressing data with Parquet Lance - alternate columnar, compressed format for ML Mara pipelines - Opinionated ETL framework Enso - Interactive Data Workflow builder with no coding Database for Event Sourcing What are Data Contracts Centrifuge - Database as a Queue Database scaling Database Hardware Selection Scaling TIDB to 1 million QPS Sharding a database MySQL Sharding at Quora CUID-Collision-resistant ids optimized for horizontal scaling and performance. Data Discovery OpenMetadata - Data Discovery, Lineage, Data Quality Evaluation of Data Discovery Platforms Data Discovery at Shopify Great Expectations - Data Documentation and Profiling tool Database Migration Practices Zero downtime database migrations Stripe - Database Online migration at scale using dual writes How big companies migrate from one database to another without losing data i.e database independent? Efficiently diff rows across two different databases. Metadata Management Growing importance of Metadata Management Systems SQLite Query against multiple SQLite databases using ATTACH Command Online SQLite Fiddle Why you should be using SQLITE(2023) Performance tuning settings Pocketbase - SQlite database with Go-based Wrapper to expose API Scaling SQLITE to 4M QPS on Single Server Streaming S3 Replication for SQLite lightweight, distributed relational database built on SQLite Interesting use cases for SQLITE Hosting SQLite databases on Github Pages Joining CSV and JSON data with an in-memory SQLite database Baked Data Architecture Pattern -DB side by side Web App Cron based backups for SQLITE Data Security, GDPR Tool for Sensitive Data Detection from Capital one Data bunker - Secure storage for personal records built to comply with GDPR Search Google Code Search using Inverted Index Open source Google Code Search tool in Go Manticore Search - easy to use open source fast database for search ZincSearch - lightweight alternative to ElasticSearch Why OpenSearch, fork of ElasticSearch Peer to peer web search and Intranet Search Appliance Get Started with Opensearch Capacity Planning About Oracle Capacity Planning Guidelines for SQL Server Capacity Planning Database Documentation [Schema spy - ER Diagram, Metadata Reports][https://github.com/schemaspy/schemaspy] Data Engineering Concepts Choosing a Data Catalog Awesome Data Catalog Create a Serverless Data Lake on AWS and Migrate your On-Prem Data to it Data Engineering How tos- List of Curated Articles/Videos Guide to Data lake, Data lake house Data Lake - Solution Patterns What is delta lake house? Poor man’s Data lake with Duckdb Data Model for Managing Collaborative Editing of Data Data platform playbook Dictionary of databases Database of Databases ","permalink":"http://localhost:1313/links/databases/","summary":"\u003ch1 id=\"database\"\u003eDatabase\u003c/h1\u003e\n\u003cp\u003eKnowledge base around general database related topics.\u003c/p\u003e\n\u003ch2 id=\"general-links\"\u003eGeneral Links\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://medium.com/academy-team/which-data-architecture-should-i-choose-for-my-workplace-a-data-engineers-approach-f913b71d8ee6\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhich Data Architecture to choose\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/prisma/dataguide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrisma’s Data Guide - A growing library of articles focused on making databases more approachable. \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aiven.co/developers/sql-query-optimization-guide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuery optimization guide\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/blog/demystifying-database-performance-for-developers\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase performance for Developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.heimdalldata.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHeimdall data -Database scale-out without Application changes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dbdb.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase of databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://use-the-index-luke.com/blog/2015-02/modern-sql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModern SQL in databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://use-the-index-luke.com/blog/2015-02/modern-sql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEventual consistency by Werner Vogels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.allthingsdistributed.com/2019/03/Amazon-Aurora-design-cloud-native-relational-database.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAmazon Aurora ascendant: How we designed a cloud-native relational database - All Things Distributed\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2018/06/28/scaling-from-one-to-one-hundred-thousand-tenants/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOptions for scaling from 1 to 100,000 tenants\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.acolyer.org/2019/03/25/amazon-aurora-design-considerations-for-high-throughput-cloud-native-relational-databases/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAmazon Aurora: design considerations for high throughput cloud-native relational databases | the morning paper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://martinfowler.com/articles/nosqlKeyPoints.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNOSQL - Key Points\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/data-store-comparison\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCriteria for Choosing Data store\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.algolia.com/building-real-time-analytics-apis/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBuilding Real Time Analytics APIs at Scale\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;Qvrhh0sHCrc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStreaming Database Changes with Debezium\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cloud.google.com/blog/products/gcp/why-you-should-pick-strong-consistency-whenever-possible\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy you should pick strong consistency, whenever possible\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://debezium.io/blog/2020/02/10/event-sourcing-vs-cdc/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChange Data Capture, Outbox and Event Sourcing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://debezium.io/documentation/reference/stable/development/engine.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDebezium Engine - setup without Apache Kafka\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@kestra-io/debezium-change-data-capture-without-kafka-connect-18f43cf095d2\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDebezium without kafka connect\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://streamsets.com/blog/replicating-oracle-to-mysql-and-json/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Streamsets for CDC From Oracle to Other destinations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://spanner.fyi/transactions/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTransactions in Google Spanner\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThings I Wished More Developers Knew About Databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://selectstarsql.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteractive Book about SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://quip.com/2gwZArKuWk7W\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Interview Questions\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://veekaybee.github.io/2017/03/20/hadoop-or-laptop/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHadoop or Laptop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=www.rqlite.com\n    \n    \n\u003eThe lightweight, distributed relational database built on SQLite\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/learning-sql-201-optimizing-queries-regardless-of-platform-918a3af9c8b1#635a\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOptimizing SQL Queries, Regardless of Platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://erwin.com/blog/how-to-do-data-modeling-the-right-way/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to do Data Modelling the right way\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.brianstorti.com/replication/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrimer on Database Replication\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection pool sizing for databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hakibenita.com/sql-tricks-application-dba\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSome SQL tricks from Application DBA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.metabase.com/learn/building-analytics/sql-templates/sql-best-practices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Practices while writing SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing checksums to verify syncing 100M database records\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://antonz.org/random-table/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to populate a  table with 1 million records using single query\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://scattered-thoughts.net/writing/materialize-decorrelation\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow databases optimize Sub-queries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.wix.engineering/post/wix-inbox-journey-3-approaches-for-zero-downtime-database-migration\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproaches to database migration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tigerbeetle.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTigetbeetle - Fast financial accounting database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.nelhage.com/post/some-opinionated-sql-takes/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpinionated thoughts on SQL Databases\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"tools-collection\"\u003eTools Collection\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://dbmstools.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDBMS Tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/cube2222/octosql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOctoSQL - Query, Join CSV with Postgresql/mysql from Command line\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/timescale/tsbs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTSBS - tool to benchmark bulk load performance and query execution performance.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pressly.github.io/goose/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoose - Database schema migrations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hammerdb.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHammerDB - Benchmarking Suite for databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/akopytov/sysbench\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSysbench - Scriptable database and system performance benchmark\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.soda.io/core\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSoda core - Data schema checks, for Quality, as code\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/readysettech/readyset\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReadyset -  MySQL and Postgres wire-compatible caching layer that sits in front of existing databases to speed up queries and horizontally scale read throughput.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-analytics\"\u003eData Analytics\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.vladsiv.com/big-data-file-formats/?ref\u0026#61;davidgomes.com#final-words\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstanding avro, parquet and ORC\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/cxli233/FriendsDontLetFriends\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuidance on Data Visualizations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://csvbase.com/blog/5\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSimple data pipeline Powertools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cube.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCube.dev - Open source Headless BI platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://evidence.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvidence.dev - BI as Code - SQL \u0026#43; Markdown to generate Reports\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.infoworld.com/article/3236869/what-is-apache-spark-the-big-data-platform-that-crushed-hadoop.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApache spark defined\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGetting started with Spark in Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.datamesh-architecture.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Data Mesh Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.datanami.com/2021/10/25/data-mesh-vs-data-fabric-understanding-the-differences/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData mesh vs. Data Fabric\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://future.a16z.com/emerging-architectures-modern-data-infrastructure/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEmerging Architectures for Modern Data Infrastructure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dropbox.tech/application/why-we-chose-apache-superset-as-our-data-exploration-platform\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Visualization/Exploration platforms Comparion Matrix\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSupercharging Apache Superset\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/snowplow/snowplow\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSnowplow - Cloud Native Behavioral data engine (e.g. User Analytics)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://redash.io/help/open-source/setup#other\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedash - Collaboration, dashboards\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/why-data-culture-matters#\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy data culture matters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.mckinsey.com/industries/financial-services/our-insights/designing-a-data-transformation-that-delivers-value-right-from-the-start#\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesigning a data transformation that delivers value right from the beginning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/common-workflow-language/common-workflow-language/wiki/Existing-Workflow-systems\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Computational Data Analysis Workflow Systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dash.plotly.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Visualization framework for Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://segment.com/academy/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAnalytics Academy by Segment\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.sisense.com/whitepapers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAnalytics Whitepapers by Sisense\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mode.com/sql-tutorial/sql-business-analytics-training/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Analytics Training\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Beginner’s Guide to Data Engineering - 3-part series\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://looker.com/blog/different-types-graphs-charts-uses\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChart types and its usage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rudderstack.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRudder - Open source Customer Data Infrastructure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://datavizcatalogue.com/search/time.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCatalog of Widgets for Data Visualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://clickhouse.tech/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source OLAP Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://notion.castordoc.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModern Data stack guide by Castor\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rudderstack.com/blog/1mgs-data-stack-explained-how-they-harness-and-activate-unlimited-real-time-data/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Stack of 1mg\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://7a9z42689xx35658r1hutm8n-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/Data-Report-Martin-Inline-Graphics-R7.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Unified Data Infrastructure Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://mattturck.com/wp-content/uploads/2020/09/2020-Data-and-AI-Landscape-Matt-Turck-at-FirstMark-v1.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData and AI Product Landscape\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/fishtown-analytics/dbt\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTransformations for DWH using DBT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/thenaturalist/awesome-business-intelligence\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome list of Business Intelligence Tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/data-stacks-for-fun-nonprofit-part-iii-dcfd46da9f9f\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArticle Series on Open source Data Analytics Stack (Postgres,Meltano, Airflow, dbt and Superset) \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://posthog.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePosthog - open source product analytics platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://technically.dev/posts/what-your-data-team-is-using\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTypical Analytics Stack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://octo.github.com/projects/flat-data\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFlat Data - Scheduled Data Download on GitHub Actions in Repository and visualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nocodb/nocodb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNocodb - Turn *MySQL/PostgreSQL data in smart Spreadsheet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.confluent.io/blog/real-time-analytics-with-kafka-and-pinot/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReal time data analysis with Apache Pinot and kafka\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2019/11/22/uuids-are-popular-but-bad-for-performance-lets-discuss/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUUIds are bad for performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mit-pdos/noria\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNoria - Caching and updating Relational query results\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/vmware/differential-datalog\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDifferential Datalog - Language for incremental computation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://planetscale.com/blog/why-we-chose-nanoids-for-planetscales-api\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing NanoIDs (not longer UUID) for public APis\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"in-memory-databases\"\u003eIn-memory Databases\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/dragonflydb/dragonfly\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDragonfly - Compatible with REDIS\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"duck-db\"\u003eDuck DB\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://duckdb.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDuckDB - Embeddable OLAP DBMS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sql-workbench.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Workbench - run Duckdb on WASM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDuckDB - Connect and join on external databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://motherduck.com/blog/postgres-duckdb-options\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing duckdb and postgres together\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"etlelt-database-as-a-queue-evolutionary-practices\"\u003eETL,ELT, Database-as-a-queue, Evolutionary Practices\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.sas.com/en_us/insights/data-management/what-is-etl.html#:~:text\u0026#61;ETL%20is%20a%20type%20of,to%20build%20a%20data%20warehouse.\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAll about ETL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/airbytehq/airbyte\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAirbyte-Open source ELT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/big-data-engineering/redshift-cicd-how-we-did-it-and-why-you-should-do-it-to-e46ecf734eab\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase CI/CD practices using Redshift\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jghoman/awesome-apache-airflow\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Apache Airflow\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dagster-io/dagster\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Python library for building data applications: ETL, ML, Data Pipelines, and more. \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/prefecthq/prefect\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA modern data workflow platform \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/linkedin/databus\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabus - Change Data capture System from Linkedin\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/liquidata-inc/dolt\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDolt - Git for Data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://griddb.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGridDB - next generation database for IoT \u0026amp;amp; big data with both NoSQL interface \u0026amp;amp; SQL Interface.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dev.l1x.be/posts/2021/03/08/compressing-data-with-parquet/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCompressing data with Parquet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/lancedb/lance\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLance - alternate columnar, compressed format for ML\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mara/mara-pipelines\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMara pipelines - Opinionated ETL framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/enso-org/enso\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEnso - Interactive Data Workflow builder with no coding\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.eventstore.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase for Event Sourcing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mlops.community/an-engineers-guide-to-data-contracts-pt-1/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat are Data Contracts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://segment.com/blog/introducing-centrifuge/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCentrifuge - Database as a Queue\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"database-scaling\"\u003eDatabase scaling\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://momjian.us/main/writings/pgsql/hw_selection.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase Hardware Selection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.flipkart.tech/scaling-tidb-to-1-million-qps-d556aa6a16ef\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling TIDB to 1 million QPS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stackoverflow.blog/2022/03/14/how-sharding-a-database-can-make-it-faster/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSharding a database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.quora.com/q/quoraengineering/MySQL-sharding-at-Quora?share\u0026#61;1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMySQL Sharding at Quora\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ericelliott/cuid\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCUID-Collision-resistant ids optimized for horizontal scaling and performance.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-discovery\"\u003eData Discovery\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://open-metadata.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpenMetadata - Data Discovery, Lineage, Data Quality\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eugeneyan.com/writing/data-discovery-platforms/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvaluation of Data Discovery Platforms\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.shopify.com/blogs/engineering/solving-data-discovery-challenges-shopify\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Discovery at Shopify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/great-expectations/great_expectations\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGreat Expectations - Data Documentation and Profiling tool\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"database-migration-practices\"\u003eDatabase Migration Practices\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.rainforestqa.com/blog/2014-06-27-zero-downtime-database-migrations\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZero downtime database migrations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stripe.com/blog/online-migrations\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStripe - Database Online migration at scale using dual writes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.quora.com/How-big-companies-migrate-from-one-database-to-another-without-losing-data-i-e-database-independent/answer/Siddharth-Anand\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow big companies migrate from one database to another without losing data i.e database independent?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/datafold/data-diff\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEfficiently diff rows across two different databases.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"metadata-management\"\u003eMetadata Management\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://gradientflow.com/the-growing-importance-of-metadata-management-systems/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGrowing importance of Metadata Management Systems\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"sqlite\"\u003eSQLite\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://simonwillison.net/2021/Feb/21/cross-database-queries/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuery against multiple SQLite databases using ATTACH Command\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sqlite.org/fiddle/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOnline SQLite Fiddle\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.epicweb.dev/why-you-should-probably-be-using-sqlite\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy you should be using SQLITE(2023)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://phiresky.github.io/blog/2020/sqlite-performance-tuning\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePerformance tuning settings\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pocketbase.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePocketbase - SQlite database with Go-based Wrapper to expose API\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.expensify.com/2018/01/08/scaling-sqlite-to-4m-qps-on-a-single-server/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling SQLITE to 4M QPS on Single Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://litestream.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStreaming S3 Replication for SQLite\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rqlite/rqlite\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003elightweight, distributed relational database built on SQLite\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://antonz.org/sqlite-is-not-a-toy-database/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteresting use cases for SQLITE\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://phiresky.github.io/blog/2021/hosting-sqlite-databases-on-github-pages/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHosting SQLite databases on Github Pages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://simonwillison.net/2021/Jun/19/sqlite-utils-memory/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJoining CSV and JSON data with an in-memory SQLite database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://simonwillison.net/2021/Jul/28/baked-data/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBaked Data Architecture Pattern -DB side by side Web App\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://litestream.io/alternatives/cron/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCron based backups for SQLITE\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-security-gdpr\"\u003eData Security, GDPR\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://capitalone.github.io/DataProfiler/docs/0.4.5/html/index.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTool for Sensitive Data Detection from Capital one\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://databunker.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData bunker - Secure storage for personal records built to comply with GDPR\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"search\"\u003eSearch\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://swtch.com/~rsc/regexp/regexp4.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoogle Code Search using Inverted Index\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/google/codesearch\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source Google Code Search tool in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/manticoresoftware/manticoresearch/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eManticore Search -  easy to use open source fast database for search\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://zincsearch.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZincSearch - lightweight alternative to ElasticSearch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://logz.io/learn/opensearch-faq-what-is-opensearch/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy OpenSearch, fork of ElasticSearch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/yacy/yacy_search_server\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePeer to peer web search and Intranet Search Appliance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://amulyasharma.medium.com/opensearch-up-and-running-in-10-mins-49e05689087e\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGet Started with Opensearch\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"capacity-planning\"\u003eCapacity Planning\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=http://www.dba-oracle.com/concepts/database_administration.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Oracle Capacity Planning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/sharepoint/administration/storage-and-sql-server-capacity-planning-and-configuration\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuidelines for SQL Server Capacity Planning\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"database-documentation\"\u003eDatabase Documentation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e[Schema spy - ER Diagram, Metadata Reports][https://github.com/schemaspy/schemaspy]\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-engineering\"\u003eData Engineering\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://glossary.airbyte.com/term/data-engineering-concepts/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConcepts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sarahsnewsletter.substack.com/p/choosing-a-data-catalog\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChoosing a Data Catalog\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/opendatadiscovery/awesome-data-catalogs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Data Catalog\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@budilov/create-a-serverless-data-lake-on-aws-and-migrate-your-on-prem-data-to-it-80dad09e23cb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCreate a Serverless Data Lake on AWS and Migrate your On-Prem Data to it\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/adilkhash/Data-Engineering-HowTo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Engineering How tos- List of Curated Articles/Videos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuide to Data lake, Data lake house\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/bigdata/data-lake-solution-patterns-use-cases\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Lake - Solution Patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat is delta lake house?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dagster.io/blog/duckdb-data-lake\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePoor man’s Data lake with Duckdb\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hytradboi.com/2022/viewing-collaborative-editing-through-a-databases-lens\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Model for Managing Collaborative Editing of Data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://playbook.hackney.gov.uk/Data-Platform-Playbook/architecture-decisions\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData platform playbook\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dictionary-of-databases\"\u003eDictionary of databases\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://dbdb.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase of Databases\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Databases"},{"content":"Below are some of my project(s),\nTracfee, One stop for Tutors to manage students, track fees. Developed as SPA in VueJS + Quasar using API in Golang, Oracle Database and hosted on Netlify.\nRSS APP RSS Reader app, to be used in lieu of Google Reader. Developed in Python with MongoDB as database.\n","permalink":"http://localhost:1313/projects/","summary":"\u003cp\u003eBelow are some of my project(s),\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=https://tracfee.netlify.app\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTracfee\u003c/a\u003e, One stop for Tutors to manage students, track fees. Developed as SPA in VueJS + Quasar using API in \u003ca href=https://golang.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGolang\u003c/a\u003e, Oracle Database and hosted on \u003ca href=https://netlify.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNetlify\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=https://github.com/sachinsu/rssapp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRSS APP\u003c/a\u003e RSS Reader app, to be used in lieu of Google Reader. Developed in Python with MongoDB as database.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"About"},{"content":"I am a software developer, currently working at @worldlineglobal. This is my personal site where i share helpful content (gathered or authored) on Technology (and other topics).\nI appreciate any ideas/suggestions you have on how I can improve this site.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a software developer, currently working at \u003ca href=https://twitter.com/WorldlineGlobal\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e@worldlineglobal\u003c/a\u003e. This is my personal site where i share helpful content (gathered or authored) on Technology (and other topics).\u003c/p\u003e\n\u003cp\u003eI appreciate any \u003ca href=https://github.com/sachinsu/sachinsu.github.io/issues/new\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eideas/suggestions you have\u003c/a\u003e on how I can improve this site.\u003c/p\u003e","title":"About"},{"content":"Microsoft .NET Platform where i have spent most time till now.\nGeneral Links What is .NET? by Scott Hanselman Async in Depth Using Async/Await in WCF or ASMX with AsyncEx Comparing Async/Await with GoRoutines .NET Presentations - Events in a Box Building Microservices in .NET Materialized View Pattern for Cross Service Queries Oracle DB and .NET - Optimizing Real-World Performance with Static Connection Pools Clean Code concepts and tools adapted for .NET Multiple ways how to limit parallel tasks processing Parallel programming in .NET Clean Architecture in .NET You’re (probably still) using HttpClient wrong and it is destabilizing your software Async/Await - Guidance \u0026amp;amp; Best Practices in Asynchronous Programming Async/Await - Deep dive for Windows based Async I/O One more look at why Async/Await, what happens underneath Implement a producer-consumer dataflow pattern Use Arrays of Blocking Collections in a Pipeline Performance related Web forms, Asynchronous operations and its performance impact List of Awesome Resources Using System.Diagnostics.StopWatch.GetTimeStamp for accurate duration C# Job Queues with TPL Dataflow and Failure Handling Know about Threadpool, types of Threads in CLR and changing them to improve performance Work flow of diagnosing memory performance issues ***Contention, poor performance, and deadlocks when you make calls to Web services from an ASP.NET application .NET GC - Memory fundamentals Debug high CPU usage in .NET Core Measure performance of High frequency events in .NET Core App .NET Core debug memory leak, High CPU Usaege, Deadlock TCP Connection Pool and how it works in .NET Framework/.NET Core Using max number of worker threads using Semaphore Performance tuning for .NET Core API A light-weight REST API development framework for ASP.NET 6 and newer. Starter kit .NET Core Starter kit ASP.NET Web forms What not to do in ASP.NET, and what to do instead Use Task.Run at the invocation, not in the implementation Take Advantage of ASP.NET Built-in Features to Fend Off Web Attacks Blazor for Web Form Developers Windows Forms Task.run vs. BackgroundWorker Tools, Libraries Coravel - In-memory Task Scheduling , Queueing Library Generate PDF using Scriban and Playwright .NET Playground RestSharp - REST HTTP Client Ocelot - API Gateway AsyncAwaitBestPractices Flurl Distributed transaction solution in micro-service base on eventually consistency, also an eventbus with Outbox pattern Simple Swiss Army knife for http/https troubleshooting and profiling Event sourcing using variety of stores like AMQP, database Feature Management library for ASP.NET Core General Checklist for Projects Open Source ing tool for .NET Core/.NET Framework that helps your application generate document-like reports Open source database, Optimized for Event sourcing bflat - No-frills, standalone compiler for .net Hashids.NET - Generate Youtube-like hashes (short codes) from one or more numbers Rate Limiting Library from Microsoft Task Queue/Scheduling tools Hangfire Tempus Background tasks with hosted services in ASP.NET Core Rebus - Smart end-points, dumb pipes service bus for .net Rules, workflow Workflow-core-Lightweight workflow engine for .NET Standard Rules Engine - A Json based Rules Engine with extensive Dynamic expression support from Microsoft .NET Core Approach for Incremental Migration from ASP.NET to ASP.NET Core .NET Portability Analyzer ASP.NET Core Architecture Overview ASP.NET Core Performance Best Practices Diagnosing Issues Under Load Of WebAPI App Migrated To ASP.NET Core On Linux Model binding in ASP.NET core HttpClient Connection Pooling in .NET Core An Introduction to System.Threading.Channels Working with Channels With Stephen Toub BackgroundService Gotcha: Application Lifetime AWS Porting Assistant for .NET Sample of Micro services in .NET Core CoreWCF (SOAP,TCP, WS-HTTP support) on .NET Core ASP.NET Web API Versioning Samples of ASP.NET Core you can use Step by Step OpenTelemetry in .NET Core Techempower performance benchmarks Security OWASP - Top Ten Vulnerabilities Microsoft RESTler-Security testing using Automated Fuzzing Security Code Scan in .NET Networking .NET 5 Networking Improvements Understanding WebRequest Problems and Exceptions Twitter Handles Scott Hanselman General .NET Conf 2021 Videos, Slides etc. Nuke - Alternate (to MSBUILD) Build system for .NET Design patterns implementations in C# ","permalink":"http://localhost:1313/links/dotnet/","summary":"\u003ch1 id=\"microsoft-net\"\u003eMicrosoft .NET\u003c/h1\u003e\n\u003cp\u003ePlatform where i have spent most time till now.\u003c/p\u003e\n\u003ch2 id=\"general-links\"\u003eGeneral Links\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?time_continue\u0026#61;1\u0026amp;v\u0026#61;bEfBfBQq7EE\u0026amp;feature\u0026#61;emb_logo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat is .NET? by Scott Hanselman\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/async-in-depth\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsync in Depth\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.stephencleary.com/2012/08/async-wcf-today-and-tomorrow.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Async/Await in WCF or ASMX with AsyncEx\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alexyakunin.medium.com/go-vs-c-part-1-goroutines-vs-async-await-ac909c651c11\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComparing Async/Await with GoRoutines\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://presentations.dotnetfoundation.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Presentations - Events in a Box\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://altkomsoftware.pl/en/blog/building-microservices-on-net-core-1/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBuilding Microservices in .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/architecture/patterns/materialized-view\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMaterialized View Pattern for Cross Service Queries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.oracle.com/en/database/oracle/oracle-database/12.2/jjucp/optimizing-real-world-performance.html#GUID-BC09F045-5D80-4AF5-93F5-FEF0531E0E1D\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle DB and .NET - Optimizing Real-World Performance with Static Connection Pools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/thangchung/clean-code-dotnet\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eClean Code concepts and tools adapted for .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/archive/blogs/fkaduk/multiple-ways-how-to-limit-parallel-tasks-processing\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMultiple ways how to limit parallel tasks processing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eParallel programming in .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ardalis/CleanArchitecture\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eClean Architecture in .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://josefottosson.se/you-are-probably-still-using-httpclient-wrong-and-it-is-destabilizing-your-software/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou’re (probably still) using HttpClient wrong and it is destabilizing your software\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/davidfowl/AspNetCoreDiagnosticScenarios/blob/master/AsyncGuidance.md#asynchronous-programming\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsync/Await - Guidance \u0026amp;amp; Best Practices in Asynchronous Programming\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tooslowexception.com/net-asyncawait-in-a-single-picture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsync/Await - Deep dive for Windows based Async I/O\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.scooletz.com/2018/05/14/task-async-await-valuetask-ivaluetasksource-and-how-to-keep-your-sanity-in-modern-net-world/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOne more look at why Async/Await, what happens underneath\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/how-to-implement-a-producer-consumer-dataflow-pattern\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eImplement a producer-consumer dataflow pattern\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/collections/thread-safe/how-to-use-arrays-of-blockingcollections\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse Arrays of Blocking Collections in a Pipeline\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"performance-related\"\u003ePerformance related\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/web-forms/overview/performance-and-caching/using-asynchronous-methods-in-aspnet-45\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb forms, Asynchronous operations and its performance impact\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/adamsitnik/awesome-dot-net-performance\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Awesome Resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.stopwatch.gettimestamp?view\u0026#61;net-5.0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing System.Diagnostics.StopWatch.GetTimeStamp for accurate duration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://michaelscodingspot.com/c-job-queues-part-3-with-tpl-dataflow-and-failure-handling/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eC# Job Queues with TPL Dataflow and Failure Handling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gist.github.com/JonCole/e65411214030f0d823cb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eKnow about Threadpool, types of Threads in CLR and changing them to improve performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-0/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWork flow of diagnosing memory performance issues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://support.microsoft.com/en-us/help/821268/contention-poor-performance-and-deadlocks-when-you-make-calls-to-web-s\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e***Contention, poor performance, and deadlocks when you make calls to Web services from an ASP.NET application\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Maoni0/mem-doc/blob/master/doc/.NETMemoryPerformanceAnalysis.md#Memory-Fundamentals\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET GC - Memory fundamentals\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/core/diagnostics/debug-highcpu?WT.mc_id\u0026#61;-blog-scottha\u0026amp;tabs\u0026#61;windows\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDebug high CPU usage in .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/core/diagnostics/event-counter-perf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMeasure performance of High frequency events in .NET Core App\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/core/diagnostics/debug-highcpu?tabs\u0026#61;windows\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Core debug memory leak, High CPU Usaege, Deadlock\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/azure-sdk/net-framework-connection-pool-limits/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTCP Connection Pool and how it works in .NET Framework/.NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.codeproject.com/Articles/859108/Writing-a-Web-Server-from-Scratch\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing max number of worker threads using Semaphore\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://reubenbond.github.io/posts/dotnet-perf-tuning\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePerformance tuning for .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"api\"\u003eAPI\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/FastEndpoints/FastEndpoints\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA light-weight REST API development framework for ASP.NET 6 and newer. \u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"starter-kit\"\u003eStarter kit\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/fullstackhero/dotnet-starter-kit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Core Starter kit\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"aspnet-web-forms\"\u003eASP.NET Web forms\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/aspnet/overview/web-development-best-practices/what-not-to-do-in-aspnet-and-what-to-do-instead#standards\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat not to do in ASP.NET, and what to do instead\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.stephencleary.com/2013/11/taskrun-etiquette-examples-dont-use.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse Task.Run at the invocation, not in the implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/previous-versions/dotnet/articles/ms972969%28v\u0026#61;msdn.10%29?redirectedfrom\u0026#61;MSDN\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTake Advantage of ASP.NET Built-in Features to Fend Off Web Attacks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dotnet.microsoft.com/en-us/learn/aspnet/architecture#ebook-blazor-for-web-forms-devs-swimlane\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBlazor for Web Form Developers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"windows-forms\"\u003eWindows Forms\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://blog.stephencleary.com/2013/09/taskrun-vs-backgroundworker-conclusion.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTask.run vs. BackgroundWorker\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"tools-libraries\"\u003eTools, Libraries\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/jamesmh/coravel\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCoravel - In-memory Task Scheduling , Queueing Library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.meziantou.net/generate-pdf-files-using-an-html-template-and-playwright.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGenerate PDF using Scriban and Playwright\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sharplab.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Playground\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/restsharp/RestSharp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRestSharp - REST HTTP Client\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ocelot.readthedocs.io/en/latest/features/configuration.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOcelot - API Gateway\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/brminnick/AsyncAwaitBestPractices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsyncAwaitBestPractices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://flurl.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFlurl\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://cap.dotnetcore.xyz/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed transaction solution in micro-service base on eventually consistency, also an eventbus with Outbox pattern\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/trimstray/htrace.sh\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSimple Swiss Army knife for http/https troubleshooting and profiling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/eventflow/EventFlow\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvent sourcing using variety of stores like AMQP, database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Unleash/unleash\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/FeatureManagement-Dotnet\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFeature Management library for ASP.NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/StephenCleary/Docs/blob/master/libraries/README.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGeneral Checklist for Projects\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.fast-report.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen Source ing tool for .NET Core/.NET Framework that helps your application generate document-like reports\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/eventstore/eventstore\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source database, Optimized for Event sourcing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/MichalStrehovsky/bflat\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ebflat - No-frills, standalone compiler for .net\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ullmark/hashids.net\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHashids.NET - Generate Youtube-like hashes (short codes) from one or more numbers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/announcing-rate-limiting-for-dotnet/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRate Limiting Library from Microsoft\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"task-queuescheduling-tools\"\u003eTask Queue/Scheduling tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.hangfire.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHangfire\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Workshell/tempus\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTempus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view\u0026#61;aspnetcore-5.0\u0026amp;tabs\u0026#61;visual-studio\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBackground tasks with hosted services in ASP.NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rebus-org/Rebus/wiki\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRebus - Smart end-points, dumb pipes service bus for .net\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"rules-workflow\"\u003eRules, workflow\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/danielgerlag/workflow-core\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWorkflow-core-Lightweight workflow engine for .NET Standard\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/RulesEngine\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRules Engine - A Json based Rules Engine with extensive Dynamic expression support from Microsoft\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"net-core\"\u003e.NET Core\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/incremental-asp-net-to-asp-net-core-migration/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproach for Incremental Migration from ASP.NET to ASP.NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/dotnet-apiport/blob/dev/docs/Console/README.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Portability Analyzer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://speakerdeck.com/davidfowl/asp-dot-net-core-architecture-overview\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eASP.NET Core Architecture Overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/core/performance/performance-best-practices?WT.mc_id\u0026#61;ondotnet-channel9-cephilli\u0026amp;view\u0026#61;aspnetcore-2.2\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eASP.NET Core Performance Best Practices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hanselman.com/blog/CustomerNotesDiagnosingIssuesUnderLoadOfWebAPIAppMigratedToASPNETCoreOnLinux.aspx\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDiagnosing Issues Under Load Of WebAPI App Migrated To ASP.NET Core On Linux\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/core/mvc/models/model-binding?view\u0026#61;aspnetcore-3.1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModel binding in ASP.NET core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.stevejgordon.co.uk/httpclient-connection-pooling-in-dotnet-core\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHttpClient Connection Pooling in .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/an-introduction-to-system-threading-channels/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAn Introduction to System.Threading.Channels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://channel9.msdn.com/Shows/On-NET/Working-with-Channels-in-NET?WT.mc_id\u0026#61;ondotnet-c9-cephilli\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWorking with Channels With Stephen Toub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.stephencleary.com/2020/06/backgroundservice-gotcha-application-lifetime.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBackgroundService Gotcha: Application Lifetime\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/aws/announcing-the-porting-assistant-for-net/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAWS Porting Assistant for .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/madslundt/NetCoreMicroservicesSample\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSample of Micro services in .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://corewcf.github.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCoreWCF (SOAP,TCP, WS-HTTP support) on .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dotnet/aspnet-api-versioning\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eASP.NET Web API Versioning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dodyg/practical-aspnetcore\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSamples of ASP.NET Core you can use\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://logz.io/blog/csharp-dotnet-opentelemetry-instrumentation/#conc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStep by Step OpenTelemetry in .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.techempower.com/benchmarks/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTechempower performance benchmarks\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"security\"\u003eSecurity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://owasp.org/www-project-top-ten/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOWASP - Top Ten Vulnerabilities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.microsoft.com/en-us/research/blog/restler-finds-security-and-reliability-bugs-through-automated-fuzzing/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicrosoft RESTler-Security testing using Automated Fuzzing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://security-code-scan.github.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSecurity Code Scan in .NET\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"networking\"\u003eNetworking\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/net-5-new-networking-improvements/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET 5 Networking Improvements\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/framework/network-programming/understanding-webrequest-problems-and-exceptions\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstanding WebRequest Problems and Exceptions\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"twitter-handles\"\u003eTwitter Handles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://twitter.com/shanselman\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScott Hanselman\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"general\"\u003eGeneral\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/dotnet-presentations/dotNETConf/tree/master/2021/MainEvent/Technical\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Conf 2021 Videos, Slides etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://nuke.build/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNuke - Alternate (to MSBUILD) Build system for .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/skimedic/presentations/tree/main/Patterns\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesign patterns implementations in C#\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages - .NET"},{"content":"Go Language My current Favorite Language\nArticles, E-books About Go - Compiler, packaging etc. When (and when not to) to use Generics in Go Ver. 1.8 High performance GO Workshop Learnings from Production usage of Go Thoughts on Go performance optimization Effective Go Handling 1M websockets connections in Go Notes on Go language Standard Go Project Layout 10 things you (probably) don’t know about Go Useful patterns in Go Interesting ways of using Go channels How i writer web services in Go Embed static file(s) in Go Executable and expose over HTTP Using go:embed in Go 1.16 Go Useful patterns by Roberto Clapis Strategies for Working with Message Queues Continuous build \u0026amp;amp; Testing using Go Convey Why American Express chose Go Thoughts on Performance Optimizations in Go by Damian Gryski Quick list of performance improvement targets in Go 10 things you probably don’t know about Go Learn Go with test-driven development Cancellable Pipelines in Go Running Go binary in Docker Go for Cloud - Tips and Techniques Why and what to instrument in Go Web Apps Continuous Profiling of Go programs How I write HTTP services in 2024 Go Concurrency - Singleflight, Bounded concurrency, Weighted bounded concurrency Why you should be using errgroup withcontext in Golang WebAssembly in Go gRPC in Go Go: Discovery of the Trace Package Tracing in production for Latency Rust for Go Developers Rust vs Go - When to use which Example of how to let only one Goroutine do the task while letting others wait for it useful in case of reading data from DB to be cached How to leverage AWS Lambda timeouts with Go context cancellation Design philosophy TLS and Go Effectively using Systemd for setting up HTTP Server Useful Code patterns Streams onboarding plan for using Go in 10 weeks Libraries, Tools HTMX \u0026#43; Go in single binary Staticcheck - The advaned Go linter Scripting with Go Right way to check weather Generate Go Code for Database / SQL for Mysql and PostgreSQL Why SQLc is better approach than ORM Golang style guide by Uber ORM to Model and Traversal of Data as a Graph structure Gops-A tool to list and diagnose Go processes currently running on your system Pocketbase - SQlite database with Go-based Wrapper to expose API Wails - Electron like environment in Go Visualize call graph of a Go program using dot (Graphviz) Semgrep - Lightweight static code analysis focussed on Security Draw Application diagrams using Go A Go metrics interface with fast buffered metrics and third party reporters Hey - HTTP load generator, ApacheBench (ab) replacement Go-metrics - library for exporting performance and runtime metrics to external metrics systems (i.e. statsite, statsd) Progressive Web App (PWA) with WebAssembly in Go GoPlus - The Go\u0026#43; language for data science Notes on Profiling in Go Go-Micro - Web and RPC Framework for Microservices in Go Approach on project Structure in Go Zero Allocation JSON logger Use Makefile with Go Review of HTTP Routers Library over Financial Markets i.e. Yahoo Finance etc. Excelsize - pure Go library providing a set of functions that allow you to write to and read from XLSX / XLSM / XLTM / XLTX files Benthos - Simplified stream processing with built-in connectors Service weaver - Write Modular Monolith Apps Xo - Tool to Generate DB Specific Go Code Learning Learn go with tests Task queues Queueing with Update..skip locked Machinery - Asynchronous task queue/job queue Bleve - Full text Search Engine Event Sourcing, pub/sub using AMQP/SQL/Channels Hydra - OAuth 2.0 Server Temporal - Scalable orchestration platform Distributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres. Tunny - Library to manage pool of goroutines to limit incoming work Scheduler library for Go Web scraping, downloader Elegant Scraper and Crawler Framework for Golang Fast, simple and clean video downloader Videos, Talks Best practices for Industrial Programming - by Peter Bourgon Profiling \u0026amp;amp; Optimizing in Go Rethinking classical Concurrency patterns Justforfunc: Programming in Go A Channel Compendium Visualize Concurrency in Go Real-world systems in Go Host Free Go Web app on Netlify Zen of Go - Ten engineering values for writing simple, readable, maintainable Go code [Ultimate Go Study Guide](https://githu b.com/hoanhan101/ultimate-go) Code snippets Web Service in Go - Code with Best practices Remote service with Retries Curated list of design patterns implemented in Go Gophercises - Exercises for Go Developers Practical concurrency guide in Go, communication by channels, patterns Sample DDD Project with Code Podcasts Go Time Performance Analysis Example of Performance analysis of Go Program using benchmarks ","permalink":"http://localhost:1313/links/go/","summary":"\u003ch2 id=\"go-language\"\u003eGo Language\u003c/h2\u003e\n\u003cp\u003eMy current Favorite Language\u003c/p\u003e\n\u003ch3 id=\"articles-e-books\"\u003eArticles, E-books\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://christine.website/blog/we-have-go-2\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Go - Compiler, packaging etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://planetscale.com/blog/generics-can-make-your-go-code-slower\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhen (and when not to) to use Generics in Go Ver. 1.8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dave.cheney.net/high-performance-go-workshop/gophercon-2019.html#welcome\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHigh performance GO Workshop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rytisbiel.com/2021/03/06/darker-corners-of-go/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearnings from Production usage of Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dgryski/go-perfbook\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThoughts on Go performance optimization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://golang.org/doc/effective_go.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEffective Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/eranyanay/1m-go-websockets\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHandling 1M websockets connections in Go \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://notes.shichao.io/gopl/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNotes on Go language\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/golang-standards/project-layout\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStandard Go Project Layout\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://talks.golang.org/2012/10things.slide#1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 things you (probably) don’t know about Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogtitle.github.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUseful patterns in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nomad-software/go-channel-compendium\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteresting ways of using Go channels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;rWBSMsLG8po\u0026amp;feature\u0026#61;emb_logo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow i writer web services in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rakyll/statik\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEmbed static file(s) in Go Executable and expose over HTTP\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.carlmjohnson.net/post/2021/how-to-use-go-embed/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing go:embed in Go 1.16\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogtitle.github.io/some-useful-patterns/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo Useful patterns by Roberto Clapis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://www.doxsey.net/blog/strategies-for-working-with-message-queues\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStrategies for Working with Message Queues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://goconvey.co/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContinuous build \u0026amp;amp; Testing using Go Convey\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://americanexpress.io/choosing-go/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy American Express chose Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dgryski/go-perfbook\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThoughts on Performance Optimizations in Go by Damian Gryski\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stephen.sh/posts/quick-go-performance-improvements\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuick list of performance improvement targets in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://talks.golang.org/2012/10things.slide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 things you probably don’t know about Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/quii/learn-go-with-tests\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearn Go with test-driven development\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.golang.org/pipelines\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCancellable Pipelines in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jpetazzo.github.io/2016/09/09/go-docker/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRunning Go binary in Docker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rakyll.org/go-cloud/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo for Cloud - Tips and Techniques\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alex.dzyoba.com/blog/go-prometheus-service/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy and what to instrument in Go Web Apps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/google-cloud/continuous-profiling-of-go-programs-96d4416af77b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContinuous Profiling of Go programs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://grafana.com/blog/2024/02/09/how-i-write-http-services-in-go-after-13-years/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow I write HTTP services in 2024\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://encore.dev/blog/advanced-go-concurrency\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo Concurrency - Singleflight, Bounded concurrency, Weighted bounded concurrency\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://bionic.fullstory.com/why-you-should-be-using-errgroup-withcontext-in-golang-server-handlers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy you should be using errgroup withcontext in Golang\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dstoiko.github.io/posts/go-pong-wasm/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWebAssembly in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://talks.golang.org/2015/gotham-grpc.slide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003egRPC in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/a-journey-with-go/go-discovery-of-the-trace-package-e5a821743c3c\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo: Discovery of the Trace Package\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://speakerdeck.com/rakyll/tracing-for-granularity\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTracing in production for Latency\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://christine.website/blog/TLDR-rust-2020-09-19\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRust for Go Developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://thenewstack.io/rust-vs-go-why-theyre-better-together/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRust vs Go - When to use which\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lakefs.io/2020/09/23/in-process-caching-in-go-scaling-lakefs-to-100k-requests-second/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExample of how to let only one Goroutine do the task while letting others wait for it useful in case of reading data from DB to be cached\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@filiplubniewski/how-to-leverage-aws-lambda-timeouts-with-go-context-cancellation-7dacde656540\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to leverage AWS Lambda timeouts with Go context cancellation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ardanlabs/gotraining/blob/master/topics/go/README.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesign philosophy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eli.thegreenplace.net/2021/go-https-servers-with-tls/#id8\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTLS and Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mgdm.net/weblog/systemd/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEffectively using Systemd for setting up HTTP Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://betterprogramming.pub/7-code-patterns-in-go-i-cant-live-without-f46f72f58c4b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUseful Code patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stream-wiki.notion.site/Stream-Go-10-Week-Backend-Eng-Onboarding-625363c8c3684753b7f2b7d829bcd67a\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStreams onboarding plan for using Go in 10 weeks\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"libraries-tools\"\u003eLibraries, Tools\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/maddalax/htmgo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHTMX \u0026#43; Go in single binary\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dominikh/go-tools\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStaticcheck - The advaned Go linter\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://bitfieldconsulting.com/golang/scripting\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScripting with Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/chubin/wttr.in\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRight way to check weather\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sqlc.dev\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGenerate Go Code for Database / SQL for Mysql and PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://brandur.org/sqlc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy SQLc is better approach than ORM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/uber-go/guide/blob/master/style.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGolang style guide by Uber\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://entgo.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eORM to Model and Traversal of Data as a Graph structure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/google/gops\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGops-A tool to list and diagnose Go processes currently running on your system\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pocketbase.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePocketbase - SQlite database with Go-based Wrapper to expose API\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/wailsapp/wails\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWails - Electron like environment in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ofabry.github.io/go-callvis/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisualize call graph of a Go program using dot (Graphviz)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://semgrep.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSemgrep - Lightweight static code analysis focussed on Security\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/blushft/go-diagrams\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDraw Application diagrams using Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/uber-go/tally\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Go metrics interface with fast buffered metrics and third party reporters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rakyll/hey\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHey - HTTP load generator, ApacheBench (ab) replacement\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/armon/go-metrics\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo-metrics - library for exporting performance and runtime metrics to external metrics systems (i.e. statsite, statsd)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://go-app.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProgressive Web App (PWA) with WebAssembly in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://goplus.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoPlus - The Go\u0026#43; language for data science\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/DataDog/go-profiler-notes\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNotes on Profiling in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://go-micro.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo-Micro - Web and RPC Framework for Microservices in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/benbjohnson/wtf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproach on project Structure in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rs/zerolog\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZero Allocation JSON logger\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://earthly.dev/blog/golang-makefile/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse Makefile with Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.alexedwards.net/blog/which-go-router-should-i-use\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReview of HTTP Routers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/piquette/finance-go\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLibrary over Financial Markets i.e. Yahoo Finance etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/qax-os/excelize\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExcelsize - pure Go library providing a set of functions that allow you to write to and read from XLSX / XLSM / XLTM / XLTX files\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Jeffail/benthos\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenthos - Simplified stream processing with built-in connectors\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ServiceWeaver/weaver\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eService weaver - Write Modular Monolith Apps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/xo/xo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eXo - Tool to Generate DB Specific Go Code\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"learning\"\u003eLearning\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/quii/learn-go-with-tests\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearn go with tests\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"task-queues\"\u003eTask queues\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://ente.io/blog/tech/postgres-queue/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQueueing with Update..skip locked\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/RichardKnop/machinery\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMachinery - Asynchronous task queue/job queue\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://blevesearch.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBleve - Full text Search Engine\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ThreeDotsLabs/watermill\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvent Sourcing, pub/sub using AMQP/SQL/Channels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ory.sh/hydra\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHydra - OAuth 2.0 Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://temporal.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTemporal - Scalable orchestration platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/knadh/sql-jobber\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Jeffail/tunny\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTunny - Library to manage pool of goroutines to limit incoming work\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/reugn/go-quartz\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScheduler library for Go\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"web-scraping-downloader\"\u003eWeb scraping, downloader\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/gocolly/colly\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eElegant Scraper and Crawler Framework for Golang\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/iawia002/annie\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFast, simple and clean video downloader \u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"videos-talks\"\u003eVideos, Talks\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;PTE4VJIdHPg\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest practices for Industrial Programming - by Peter Bourgon\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/bradfitz/talk-yapc-asia-2015/blob/master/talk.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProfiling \u0026amp;amp; Optimizing in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;5zXAHh5tJqQ\u0026amp;feature\u0026#61;emb_logo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRethinking classical Concurrency patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/channel/UC_BzFbxG2za3bp5NRRRXJSw\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJustforfunc: Programming in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;SmoM1InWXr0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Channel Compendium\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://divan.dev/posts/go_concurrency_visualize/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisualize Concurrency in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;_YK0viplIl4\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReal-world systems in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.carlmjohnson.net/post/2020/how-to-host-golang-on-netlify-for-free/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHost Free Go Web app on Netlify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://the-zen-of-go.netlify.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZen of Go - Ten engineering values for writing simple, readable, maintainable Go code\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e[Ultimate Go Study Guide](https://githu\nb.com/hoanhan101/ultimate-go)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"code-snippets\"\u003eCode snippets\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/ardanlabs/service/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb Service in Go - Code with Best practices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://play.golang.org/p/3mNhCTl01bX\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRemote service with Retries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tmrts/go-patterns\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCurated list of design patterns implemented in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gophercises.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGophercises - Exercises for Go Developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/luk4z7/go-concurrency-guide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePractical concurrency guide in Go, communication by channels, patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ThreeDotsLabs/wild-workouts-go-ddd-example\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSample DDD Project with Code\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"podcasts\"\u003ePodcasts\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://changelog.com/gotime\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo Time\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"performance-analysis\"\u003ePerformance Analysis\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://f4t.dev/software/go-performance-memory/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExample of Performance analysis of Go Program using benchmarks\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages - Go"},{"content":"Testing Links Testing in 2021 How different software companies do testing HTTP(S) benchmark tools, testing/debugging, \u0026amp;amp; restAPI (RESTful) Toxiproxy - A TCP proxy to simulate network and system conditions for chaos and resiliency testing Papercut SMTP - Test Email delivery during development Malabi -Trace based testing in JavaScript AB Testing 101 API Test Client Bruno Load Testing K6 - Load testing tool Vegeta - HTTP load testing tool and library. Bombardier - Fast cross-platform HTTP benchmarking tool written in Go Plow - A high-performance HTTP benchmarking tool with real-time web UI Hey - HTTP load generator, ApacheBench (ab) replacement Collection of HTTP(S) benchmark tools, testing/debugging, \u0026amp;amp; restAPI (RESTful) Light weight cross-platform test automation ","permalink":"http://localhost:1313/links/testing/","summary":"\u003ch1 id=\"testing\"\u003eTesting\u003c/h1\u003e\n\u003ch2 id=\"links\"\u003eLinks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.tbray.org/ongoing/When/202x/2021/05/15/Testing-in-2021\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTesting in 2021\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/abhivaikar/howtheytest\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow different software companies do testing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/denji/awesome-http-benchmark\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHTTP(S) benchmark tools, testing/debugging, \u0026amp;amp; restAPI (RESTful)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://toxiproxy.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eToxiproxy - A TCP proxy to simulate network and system conditions for chaos and resiliency testing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ChangemakerStudios/Papercut-SMTP\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePapercut SMTP - Test Email delivery during development\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/aspecto-io/malabi\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMalabi -Trace based testing in JavaScript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/jonathans-musings/ab-testing-101-5576de6466b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAB Testing 101\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"api-test-client\"\u003eAPI Test Client\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/usebruno/bruno\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBruno\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"load-testing\"\u003eLoad Testing\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://k6.io/open-source/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eK6 - Load testing tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tsenart/vegeta\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVegeta - HTTP load testing tool and library.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/codesenberg/bombardier\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBombardier - Fast cross-platform HTTP benchmarking tool written in Go \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/six-ddc/plow\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePlow - A high-performance HTTP benchmarking tool with real-time web UI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rakyll/hey\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHey - HTTP load generator, ApacheBench (ab) replacement\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/denji/awesome-http-benchmark\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of HTTP(S) benchmark tools, testing/debugging, \u0026amp;amp; restAPI (RESTful) \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gauge.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLight weight cross-platform test automation\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming - Testing"},{"content":"Programming Languages Links Hello world in every Programming Language General You are not Google Production Launch Checklist Things I Learnt The Hard Way in 30 Years of Software Development A collection of (mostly) technical things every software developer should know Startup idea Checklist System Design Primer Developer Roadmaps Why our team cancelled our move to microservices How Does HTTPS Work? RSA Encryption Explained How do you cut a monolith in half? Containers Awesome Collection of Docker Compose Recipes Podman Desktop - Alternative to Docker Desktop ","permalink":"http://localhost:1313/links/planguages/","summary":"\u003ch1 id=\"programming-languages\"\u003eProgramming Languages\u003c/h1\u003e\n\u003ch2 id=\"links\"\u003eLinks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/leachim6/hello-world\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHello world in every Programming Language\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"general\"\u003eGeneral\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://blog.bradfieldcs.com/you-are-not-google-84912cf44afb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou are not Google\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devchecklists.com/production-launch-checklist/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProduction Launch Checklist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.juliobiason.me/thoughts/things-i-learnt-the-hard-way/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThings I Learnt The Hard Way in 30 Years of Software Development\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mtdvio/every-programmer-should-know\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA collection of (mostly) technical things every software developer should know \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.defmacro.org/2019/03/26/startup-checklist.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStartup idea Checklist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/donnemartin/system-design-primer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSystem Design Primer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://roadmap.sh/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDeveloper Roadmaps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@steven.lemon182/why-our-team-cancelled-our-move-to-microservices-8fd87898d952\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy our team cancelled our move to microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tiptopsecurity.com/how-does-https-work-rsa-encryption-explained/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Does HTTPS Work? RSA Encryption Explained\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://programmingisterrible.com/post/162346490883/how-do-you-cut-a-monolith-in-half\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow do you cut a monolith in half?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"containers\"\u003eContainers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/docker/awesome-compose\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Collection of Docker Compose Recipes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/containers/podman-desktop\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePodman Desktop - Alternative to Docker Desktop\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages"},{"content":"System Design, Architecture Links covering concepts and approaches around Distributed Systems, DevOps, Observability etc.\nArchitectural Case studies Temenos Serverless banking at Scale @ AWS using CQRS leveraging RDS and DynamoDB Temenos @ AWS Architecture Diagrams Architecture for Generations Ubers Domain-Oriented Microservice Architecture Books on Architecture,Design Software Architecture Patterns by Mark Richards A comprehensive list of books on Software Architecture. Introduction to architecting systems for scale. Strategies/Approaches Serving a billion web requests with boring code Professional programming resources Rob Pikes 5 Rules of Programming Modules, monoliths, and microservices The macro problem with Microservices Break Monolith into Microservices Steps to migrate from Monolith to Microservices Distributed architecture concepts I learned while building a large payments system Video: Developing Asynchronous Microservices • Chris Richardson Collection of Software development Videos Slides Managing Data Consistency in Microservices Architecture Reliable Microservices Data Exchange With the Outbox Pattern Scaling to 100k Users Monolith - Modular Approach You dont need Microservices Event Modelling - Approach Ready for changes with Hexagonal Architecture How to fix Overloaded Web server How gov.uk reliably sends SMS messages using multiple providers Rule of thumbs for Architecture Scalability About Structure of Design document Important Aspects about Circuit breaker from Shopify CRDTs for Synchronization Asynchronous transaction processing @ Facebook Evolutionary Database Design Scaling with Common Sense by Zerodha Guidelines for Command line interface Azure Well-Architected Framework Change Data Capture, Strangler fig and Saga Patterns Gateway pattern to encapsulate integration with external systems Why refactoring? OpenFeature - Standardizing Feature Flagging for Everyone featbit: Enterprise-level feature flag platform that you can self-host. Get started - free. Unleash - Open-source feature management platform API Development, Security, Cryptography The Web API Checklist** Mockoon - Run Mock APIs locally Bruno - Opensource IDE For Exploring and Testing Api’s REST API Guidelines from Microsoft Open Source Vulnerability Management Equinors API Strategy and Guidelines Checklist of Web APIs Guidelines for designing better APIs API Security Checklist Googles API Design Guidelines API Design for Serverless Apps OWASP - Top Ten Vulnerabilities API Security Checklist libsodium - Easy to use cryptography Schannel in Windows for Strong Ciphers/Cryptography Training Teach yourself Computer Science Collection of Video Courses on Computer Science Learn by doing - You dont need another MOOC Distributed Systems Build your own (insert technology here) Kubernetes for Everyone The Service Mesh: What Every Software Engineer Needs to Know about the Worlds Most Over-Hyped Technology Very Brief intro to Container Orchestrators E-book kubernetes Up \u0026amp;amp; Running Class materials for a distributed systems lecture series Containers - Training resources Distributed Systems Cheat Sheet Microservices — architecture nihilism in minimalisms clothes Microservices, pl. dont Disasters from Microservices world Saga: How to implement complex business transactions without two phase commit. Sagas by clement Vasters Ref. implementation of cloud design patterns Automation Microsoft Power Automate Desktop - Free Windows 10 Desktop Automation Automate the Boring Stuff with Python Four bad ways to use RPA Data Science at the Command line RobotFramework - Open source Test Automation and RPA WASP - Windows Automation Snapin for PowerShell Web API rate limiting Tools, Libraries (\nCollection of TILs (Today I learned) Miller - awk, sed, cut, join, and sort for name-indexed data such as CSV, TSV, and tabular JSON Digital services offerings from within European union Six things I wish we had known about scaling Awesome Design tools Regex Repository SpiderFoot, the most complete OSINT collection and reconnaissance tool Analyze TCP Connections by proxy TCP/IP -Why your websites should be 14KB in size Cloud Architecture Diagrams Free Online Cloud Architecture Diagram Tool Online Flowcharts, UML diagrams Embeddable charts using DataWrapper Figma - Design and prototype builder Open source Voice chat Zulip - Open source alternative to Slack Open source Video Conferencing Open network for secure, decentralized communication Alternatives for Local Kubernetes development Jami - tool for Encrypted Audio/Video calls Keycloak - Open source Identity and Access Management Ory - Next Gen Identity Management Diagram as Code (Python) Virtual whiteboard for sketching hand-drawn like diagrams with Collaboration*** Syncthing - Free, OSS, File synchronization across devices Library for Code Scanning Across GO, C#, Java etc. Open source Project Management Software Blueboat - Serverless infrastructure for On-premise deployment Text to Timeline (Gantt) chart Open source Pipelining, workflows Pipelines/workflow frameworks Workflow Engines List of ETL frameworks Streaming frameworks Extendable Workflow Automation tool in NodeJS Nodered - Low code event driven pipelines Security Definitive guide to key management7 A deep dive in CyberSecurity OWASP ZAP- Free Security Testing for Web Application Web Application Security Testing Understanding OAuth and OpenID Connect OWASP Cheat Sheet Series Microsoft App Inspector Open Policy Agent - General purpose Policy Engine Teler - Tool for Real time HTTP Intrusion detection Joern - platform for analyzing source code, bytecode, and binary executables Syft - Software Bill of Materials (SBOM) generator for vulnerability scanning Devops/Monitoring Open source Alerts Management Trivy - Scanner for vulnerabilities in container images, file systems, and Git repositories, as well as for configuration issues and hard-coded secrets Impact of Architecture on DevOps Run CI/CD pipeline locally with Dagger List of how organizations do SRE (Publicly available) Open source API Designer with CI/CD Workflow Microsoft Azure - DevOps Checklist Hashicorp Waypoint - easy way to build, deploy and release applications Zabbix, Time Series Data and TimescaleDB – Zabbix Blog PromScale - Observability backend powered by Timescaledb \u0026amp;amp; PostgreSQL How to Create and Manage CRON Jobs lazydocker - Docker mgmt tool for linux What’s in a CI pipeline Repository of DevOps Questions n Answers Google Incident Response Framework Dockerfile Best Practices Github Workflow - Test them locally using Act Code coverage best practices from Google A terminal UI for tshark, inspired by Wireshark Developer playbook approach by Hackney council Nice content on Ansible Performance profiling using Open source Pyroscope Server Act - Run Github Actions locally Approach to Uptime Guarantees Observability OpenObserve - Elasticsearch/Splunk/Datadog alternative for logs, metrics, traces Ntfy - OSS Server \u0026#43; Android App to send \u0026amp;amp; receive notification on Desktop/Android App Tips for Analyzing logs Decision guide on Tooling Prometheus and Cardinality of Metric All about Log Aggregation Observability in 2022 Observability @ Cloudflare What to Monitor and Metrics to collect for Web App with Background Jobs What was observability again? Dashboard design best practices Infrastructure Monitoring with Postgres Tracing, Fast and Slow – roguelynn OpenTelemetry in 2023 Course on using Opentelemetry Opentelemetry Overview Techniques for Monitoring Web services OpenTelemetry, Distributed Tracing, W3c Trace Context Tracing at Slack using Kafka Distributed tracing covering Client (Mobile App) tracing at slack Metrics, tracing, and logging Open source infrastructure and application Monitoring Opstrace - OSS alternative to Datadog,SignalFX Monitoring your own infrastructure using Grafana, InfluxDB, and CollectD Tool to extract whitebox monitoring data from application logs for collection in a timeseries database Percona Monitoring \u0026amp;amp; Mgmt - Open Source Software for MySQL/MongoDB/PostgreSQL Monitoring Monitoring and Observability With USE and RED Horizontally scalable storage for Prometheus Thanos - Highly available Prometheus setup with long term storage capabilities. Monitoring with VictoriaMetrics Healthchecks.io -Simple and Effective Cron Job Monitoring Decks on Prometheus deep dive, OpenMetrics Improving Observability with AWS App Mesh Metrics to track for your API Details about Cortex vs Thanos, Grafana Loki and Tempo Get started with Prometheus, Grafana and loki How to build a scalable prometheus architecture Introduction to FluentBit - Logs n Metrics Processor Distributed tracing vs. Logging Identifying disk i/o bottlenecks in Linux Signoz - Open Source Opentelemetry based Observability platform Centralized logging with Signoz What is eBPF \u0026amp;amp; its application in Observability Database Reliability Engineering(ebook) Distributed tracing using Tempo, OpenTelemetry and Grafana Cloud Skywalking - Open source Application Performance Monitoring tool HTTP Toolkit - Freemium HTTP Interceptor toolkit Comparing Open source log collectors Fluentd, Logstash, Fluentbit Observing Network Traffic with Open source tools Distributed messaging, Streams Iggy-persistent message streaming platform written in Rust, supporting QUIC, TCP and HTTP transport protocols, capable of processing millions of messages per second. SmoothMQ - Drop-in replacement for SQS With SQlite backend Comparison - BlazingMQ, RabbitMQ and Kafka Redpanda - Alternative to Kafka, Streaming Platform VerneMQ - A distributed MQTT message broker based on Erlang/OTP Kafka - Capacity Planning Why Kafka Is so Fast RabbitMQ vs Kafka - architec tural perspsective RabbitMQ vs Kafka A comparison between RabbitMQ and Apache Kafka Comparing RabbitMQ and Kafka Strategies for Working with Message Queues All about Queues Benefits of Message Queues Reasons to use Message Queues NSQ - a realtime distributed messaging platform designed to operate at scale Kafka Without Zookeeper - A Sneak peak Oracle Advanced Queues Instrumenting distributed systems for operational visibility Microservices Antipattern - Queue Explosion Trying out durable, replicated quorum queues in RabbitMQ ZeroMQ - Universal Messaging Library Comparing Techniques for Communicating Between HTTP Services Coding Style Guide Google Code Style Guide Rust Getting started with Rust A half-hour to learn Rust Tour of Rust PHP PHP: The Right way Email Server Setup Email server using Docker mailserver Networking All about Load Balancers Nerdy Videos Contalks Real world Architectures Deployment @ Wikimedia Interview Questions System Design 101 through Diagrams 10 API Product Manager Interview Questions API REST API Best practices Comparing API Architectural Styles Eventcatalog - Open source tool to document event driven Architectures Interesting free services Grist spreadsheets - alternative to Airtable Penpot - prototyping tool C, C++ Learnings from C Lang ","permalink":"http://localhost:1313/links/programming/","summary":"\u003ch1 id=\"system-design-architecture\"\u003eSystem Design, Architecture\u003c/h1\u003e\n\u003cp\u003eLinks covering concepts and approaches around Distributed Systems, DevOps, Observability etc.\u003c/p\u003e\n\u003ch2 id=\"architectural-case-studies\"\u003eArchitectural Case studies\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;mtZvA7ARepM\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTemenos Serverless banking at Scale @ AWS using CQRS leveraging RDS and DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://d1.awsstatic.com/architecture-diagrams/ArchitectureDiagrams/Temenos-on-aws.pdf?did\u0026#61;wp_card\u0026amp;trk\u0026#61;wp_card\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTemenos @ AWS Architecture Diagrams\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://increment.com/software-architecture/architecture-for-generations/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArchitecture for Generations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eng.uber.com/microservice-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUbers Domain-Oriented Microservice Architecture\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"books-on-architecturedesign\"\u003eBooks on Architecture,Design\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.oreilly.com/content/software-architecture-patterns/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSoftware Architecture Patterns by Mark Richards\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mhadidg/software-architecture-books\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA comprehensive list of books on Software Architecture.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIntroduction to architecting systems for scale.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"strategiesapproaches\"\u003eStrategies/Approaches\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://notes.billmill.org/blog/2024/06/Serving_a_billion_web_requests_with_boring_code.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eServing a billion web requests with boring code\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/charlax/professional-programming\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProfessional programming resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://users.ece.utexas.edu/~adnan/pike.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRob Pikes 5 Rules of Programming\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tailscale.com/blog/modules-monoliths-and-microservices/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModules, monoliths, and microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stackoverflow.blog/2020/11/23/the-macro-problem-with-microservices/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe macro problem with Microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://programmingisterrible.com/post/162346490883/how-do-you-cut-a-monolith-in-half\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBreak Monolith into Microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://semaphoreci.com/blog/monolith-microservices#modularize\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSteps to migrate from Monolith to Microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.pragmaticengineer.com/distributed-architecture-concepts-i-have-learned-while-building-payments-systems/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed architecture concepts I learned while building a large payments system\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;kyNL7yCvQQc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVideo: Developing Asynchronous Microservices • Chris Richardson\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dev.tube/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of Software development Videos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/chris.e.richardson/saturn-2018-managing-data-consistency-in-a-microservice-architecture-using-sagas\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSlides Managing Data Consistency in Microservices Architecture \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReliable Microservices Data Exchange With the Outbox Pattern\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alexpareto.com/scalability/systems/2020/02/03/scaling-100k.html#fnref:1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling to 100k Users\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://speakerd.s3.amazonaws.com/presentations/7590b86ae80649c19cbbbb27ad89d798/2018-02-22_Microservices_Meetup_Munich_-_Monoliths.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMonolith - Modular Approach\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/swlh/stop-you-dont-need-microservices-dc732d70b3e0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou dont need Microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eventmodeling.org/posts/what-is-event-modeling/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvent Modelling - Approach\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReady for changes with Hexagonal Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://web.dev/overloaded-server/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to fix Overloaded Web server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gds.blog.gov.uk/2020/04/03/how-gov-uk-notify-reliably-sends-text-messages-to-users/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow gov.uk reliably sends SMS messages using multiple providers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@i.gorton/six-rules-of-thumb-for-scaling-software-architectures-a831960414f9\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRule of thumbs for Architecture Scalability\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.industrialempathy.com/posts/design-docs-at-google/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Structure of Design document\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.shopify.com/blogs/engineering/circuit-breaker-misconfigured\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eImportant Aspects about Circuit breaker from Shopify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jlongster/crdt-example-app\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCRDTs for Synchronization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.fb.com/production-engineering/async/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsynchronous transaction processing @ Facebook\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.martinfowler.com/articles/evodb.html#AllDatabaseArtifactsAreVersionControlledWithApplicationCode\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvolutionary Database Design\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://zerodha.tech/blog/scaling-with-common-sense/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling with Common Sense by Zerodha\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://clig.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuidelines for Command line interface\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/architecture/framework/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAzure Well-Architected Framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/slideshow/embed_code/key/d5w2hZIBJeFfu0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChange Data Capture, Strangler fig and Saga Patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://martinfowler.com/articles/refactoring-external-service.html#SeparatingTheRemoteCallIntoAConnectionObject\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGateway pattern to encapsulate integration with external systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://xp123.com/articles/refactoring-whole-team-guide/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy refactoring?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://openfeature.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpenFeature - Standardizing Feature Flagging for Everyone\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/featbit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003efeatbit: Enterprise-level feature flag platform that you can self-host. Get started - free.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gUnleash/unleash\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnleash - Open-source feature management platform\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"api-development-security-cryptography\"\u003eAPI Development, Security, Cryptography\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://mathieu.fenniak.net/the-api-checklist/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Web API Checklist**\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mockoon/mockoon\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMockoon - Run Mock APIs locally\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/usebruno/bruno\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBruno - Opensource IDE For Exploring and Testing Api’s \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Microsoft/api-guidelines/blob/master/Guidelines.md#12-versioning\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eREST API Guidelines from Microsoft\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fossa.com/product/open-source-vulnerability-management?ref\u0026#61;unzip.dev\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen Source Vulnerability Management\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/equinor/api-strategy/blob/master/docs/strategy.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEquinors API Strategy and Guidelines\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mathieu.fenniak.net/the-api-checklist/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChecklist of Web APIs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://r.bluethl.net/how-to-design-better-apis\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuidelines for designing better APIs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/shieldfy/API-Security-Checklist\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAPI Security Checklist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://google.aip.dev/100\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoogles API Design Guidelines\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.readysetcloud.io/blog/allen.helton/the-importance-of-proper-serverless-api-design/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAPI Design for Serverless Apps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://owasp.org/www-project-top-ten/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOWASP - Top Ten Vulnerabilities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://curity.medium.com/api-security-checklist-a-guide-to-protecting-your-apis-c8fb5d385605\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAPI Security Checklist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jedisct1/libsodium\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003elibsodium - Easy to use cryptography\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/core-infrastructure-and-security/demystifying-schannel/ba-p/259233\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSchannel in Windows for Strong Ciphers/Cryptography\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"training\"\u003eTraining\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://teachyourselfcs.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTeach yourself Computer Science\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Developer-Y/cs-video-courses\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of Video Courses on Computer Science\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eugeneyan.com/writing/you-dont-need-another-mooc/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearn by doing - You dont need another MOOC\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"distributed-systems\"\u003eDistributed Systems\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/danistefanovic/build-your-own-x#build-your-own-network-stack\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBuild your own (insert technology here)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.google.com/document/d/1p4ZYQYM2VrMCR8K3T68JOMzWHlV-C8Jogrl9Ces77OA/edit?utm_sq\u0026#61;gjkgbut0r7\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eKubernetes for Everyone\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://servicemesh.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Service Mesh: What Every Software Engineer Needs to Know about the Worlds Most Over-Hyped Technology\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lwn.net/SubscriberLink/905164/e1f4d4c1ce35f8b9/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVery Brief intro to Container Orchestrators\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://azure.microsoft.com/en-us/resources/kubernetes-up-and-running/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eE-book kubernetes Up \u0026amp;amp; Running\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/aphyr/distsys-class\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eClass materials for a distributed systems lecture series\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://container.training/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContainers - Training resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://dimafeng.com/2016/12/04/distributed-systems/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed Systems Cheat Sheet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://vlfig.me/posts/microservices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicroservices — architecture nihilism in minimalisms clothes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://riak.com/posts/technical/microservices-please-dont/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicroservices, pl. dont\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://world.hey.com/joaoqalves/disasters-i-ve-seen-in-a-microservices-world-a9137a51\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDisasters from Microservices world\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.bernd-ruecker.com/saga-how-to-implement-complex-business-transactions-without-two-phase-commit-e00aa41a1b1b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSaga: How to implement complex business transactions without two phase commit.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://vasters.com/archive/Sagas.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSagas by clement Vasters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mspnp/cloud-design-patterns\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRef. implementation of cloud design patterns\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"automation\"\u003eAutomation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://flow.microsoft.com/en-us/blog/automate-tasks-with-power-automate-desktop-for-windows-10-no-additional-cost/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicrosoft Power Automate Desktop - Free Windows 10 Desktop Automation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://automatetheboringstuff.com/2e/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAutomate the Boring Stuff with Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.thoughtworks.com/insights/articles/four-bad-ways-use-rpa?utm_campaign\u0026#61;ping-jun19\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_source\u0026#61;marketo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFour bad ways to use RPA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.datascienceatthecommandline.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Science at the Command line\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://robotframework.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRobotFramework - Open source Test Automation and RPA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mavaddat/wasp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWASP - Windows Automation Snapin for PowerShell\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/stefanprodan/WebApiThrottle\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb API rate limiting\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"tools-libraries\"\u003eTools, Libraries\u003c/h2\u003e\n\u003cp\u003e(\u003c/p\u003e","title":"Programming"},{"content":"Below is list of curated links for various technical topics, Awesome - de-facto repository covering wide range of technical topics. Awesome list of self hosted software List of Open source Alternatives to SASS Online Learning Perspectives Distributed Systems Design, Architecture Testing UI/UX Languages Go .NET/C# Python Databases MySQL Oracle PostgreSQL NoSQL Cloud Tech AI/Machine Learning Generative AI General Purpose tools Must follow Community Sites Hacker news Lobsters A list of SaaS, PaaS and IaaS offerings that have free tiers of interest to devops and infradev Miscellaneous OSS alternatives to Popular tools/Systems Open Source alternative tools Attention is all Manager need - Techniques and processes Gokey - Derived random passwords based on Master password Useful tools for Windows by Scott Hanselman Library of Free music Ergonomic Home office setup Consider upgrading a few PC/laptop Components like SSD How to use Google like a pro Pick Parts.Build Your PC.Compare And Share Privacy - Nice Overview and content Privacy tools for everyday user Hackers Diet Beam - Blog for a Project or Organization List of Greatest Novels of all time Cryptonomics by Tyler Cowen All About Public key Infrastructure(PKI) Most data work seems fundamentally Worthless 100 tips for Better Life ","permalink":"http://localhost:1313/links/home/","summary":"\u003ch4 id=\"below-is-list-of-curated-links-for-various-technical-topics\"\u003eBelow is list of curated links for various technical topics,\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=http://awesome.re/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome\u003c/a\u003e - de-facto repository covering wide range of technical topics.\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/awesome-selfhosted/awesome-selfhosted\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome list of self hosted software\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Runacapital/awesome-oss-alternatives\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Open source Alternatives to SASS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/onlearn/\n    \n    \n\u003eOnline Learning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/perspectives/\n    \n    \n\u003ePerspectives\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/programming/\n    \n    \n\u003eDistributed Systems Design, Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/testing/\n    \n    \n\u003eTesting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/uiux\n    \n    \n\u003eUI/UX\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/planguages/\n    \n    \n\u003eLanguages\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=/links/go/\n    \n    \n\u003eGo\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/dotnet/\n    \n    \n\u003e.NET/C#\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/python\n    \n    \n\u003ePython\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/databases/\n    \n    \n\u003eDatabases\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=/links/mysql/\n    \n    \n\u003eMySQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/oracle/\n    \n    \n\u003eOracle\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/postgresql/\n    \n    \n\u003ePostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/nosql/\n    \n    \n\u003eNoSQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/cloud/\n    \n    \n\u003eCloud Tech\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eAI/Machine Learning\n\u003cul\u003e\n\u003cli\u003e\u003ca href=/links/aiml/\n    \n    \n\u003eGenerative AI\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/tools/\n    \n    \n\u003eGeneral Purpose tools\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"must-follow-community-sites\"\u003eMust follow Community Sites\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://news.ycombinator.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHacker news\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lobste.rs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLobsters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://free-for.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA list of SaaS, PaaS and IaaS offerings that have free tiers of interest to devops and infradev\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"miscellaneous\"\u003eMiscellaneous\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/Runacapital/awesome-oss-alternatives\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOSS alternatives to Popular tools/Systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://degoogle.jmoore.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen Source alternative tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://philcalcado.com/2023/07/21/attention_is_all_a_manager_needs.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAttention is all Manager need  - Techniques and processes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/cloudflare/gokey\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGokey - Derived random passwords based on Master password\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hanselman.com/blog/scott-hanselmans-2021-ultimate-developer-and-power-users-tool-list-for-windows\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUseful tools for Windows by Scott Hanselman\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cchound.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLibrary of Free music\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.amirathi.com/2019/08/18/ergonomic-office-setup/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eErgonomic Home office setup\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hanselman.com/blog/consider-upgrading-a-few-pc-components-a-good-ssd-is-so-fast-its-not-even-funny\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConsider upgrading a few PC/laptop Components like SSD\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://markodenic.com/use-google-like-a-pro/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to use Google like a pro\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pcpartpicker.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePick Parts.Build Your PC.Compare And Share\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.eff.org/pages/tools\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrivacy - Nice Overview and content\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.privacytools.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrivacy tools for everyday user\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.fourmilab.ch/hackdiet/www/tableofcontents1_6.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHackers Diet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/planetscale/beam\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBeam - Blog for a Project or Organization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://editoreric.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Greatest Novels of all time\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://marginalrevolution.com/wp-content/uploads/2022/05/Cryptoeconomics-Modern-Principles.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCryptonomics by Tyler Cowen\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://smallstep.com/blog/everything-pki/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAll About Public key Infrastructure(PKI)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ludic.mataroa.blog/blog/most-data-work-seems-fundamentally-worthless\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMost data work seems fundamentally Worthless\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.lesswrong.com/posts/7hFeMWC6Y5eaSixbD/100-tips-for-a-better-life\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e100 tips for Better Life\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Useful Links"},{"content":"Background One of the key project(s) at my current organization is developed on .NET 4.6.1. It is developed as Modular Monolith. As part of it\u0026rsquo;s functionality, it supports different channels like Mobiles, Terminals and Web. For the Web channel, there was need to develop a Web application with,\nHigh availability Lightweight, High throughput (Need to support few thousand(s) active users) Accordingly, we have been exploring developing this Web Application in .NET core 3.1. However, it also means that we will have to use class libraries, targeted at .NET framework 4.6.1, in .NET core and vice-versa. How can this be done?\n.NET Standard to the rescue !!\n.Net Standard is a standard that enabled development of portable libraries usable across .NET versions.\nBelow is approach adopted to create usable libraries across .NET framework \u0026amp; .NET Core.\n.NET \u0026amp; IDE versions used are,\n.Net Framework 4.6.1 .Net core 3.1 Visual Studio 2015 - for .NET Framework 4.6.1 development Visual Studio Code - For .NET core development Step 1 -\nCreate a library that targets .NET Standard. Refer to Table on Implementation Support to decide on version that can be targetted at. In my case, it was 2.0 (Remember that higher the version, more APIs will be available to use). Do check .NET API browser, which lists API available with each version.\nUsing .NET core, use below command, dotnet new classlib \u0026lt;name\u0026gt;\nNote that, by default csproj file generated targets .NET Standard, but do confirm by checking in \u0026lt;name\u0026gt;.csproj file, It should have entry like,\n\u0026lt;PropertyGroup\u0026gt; \u0026lt;TargetFramework\u0026gt;netstandard2.0\u0026lt;/TargetFramework\u0026gt; \u0026lt;/PropertyGroup\u0026gt; Change the version of .NET Standard if required.\nAdd necessary code to the library and build it using, dotnet build\nCreate a Nuget Package using, dotnet pack This will generate \u0026lt;name\u0026gt;1.0.0.nupkg package in bin\\debug folder (assuming that you are using Debug mode)\nStep 2 -\nLets consume this library from console Application, using .NET Framework 4.6.1, in Visual Studio 2015.\nCreate New Console Application and ensure that it is targeted at .NET Framework 4.6.1 or Higher.\nBefore consuming .NET standard library, few steps are needed since VS 2015 only has legacy support for consuming .NET core artifacts also it does not have latest version of Nuget, so lets do below,\nInstall NuGet 3.6.0 or higher for VS 2015 from NuGet’s download site Install the \u0026ldquo;.NET Standard Support for Visual Studio 2015\u0026rdquo; from here Open the csproj file in Text Editor and add \u0026lt;ImplicitlyExpandDesignTimeFacades\u0026gt; tag as shown in below example, \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;Project ToolsVersion=\u0026#34;12.0\u0026#34; DefaultTargets=\u0026#34;Build\u0026#34; xmlns=\u0026#34;http://schemas.microsoft.com/developer/msbuild/2003\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;Configuration Condition=\u0026#34; \u0026#39;$(Configuration)\u0026#39; == \u0026#39;\u0026#39; \u0026#34;\u0026gt;Debug\u0026lt;/Configuration\u0026gt; \u0026lt;Platform Condition=\u0026#34; \u0026#39;$(Platform)\u0026#39; == \u0026#39;\u0026#39; \u0026#34;\u0026gt;AnyCPU\u0026lt;/Platform\u0026gt; \u0026lt;ProjectGuid\u0026gt;{75678902-8224-4222-BB33-756784B2FA29}\u0026lt;/ProjectGuid\u0026gt; \u0026lt;OutputType\u0026gt;Library\u0026lt;/OutputType\u0026gt; \u0026lt;RootNamespace\u0026gt;FooBar\u0026lt;/RootNamespace\u0026gt; \u0026lt;AssemblyName\u0026gt;FooBar\u0026lt;/AssemblyName\u0026gt; \u0026lt;TargetFrameworkVersion\u0026gt;v4.6.1\u0026lt;/TargetFrameworkVersion\u0026gt; ... \u0026lt;ImplicitlyExpandDesignTimeFacades\u0026gt;false\u0026lt;/ImplicitlyExpandDesignTimeFacades\u0026gt; \u0026lt;/PropertyGroup\u0026gt; Post update to file, VS 2015 will prompt to reload the project.\nNow we are set to consume .NET standard library, authored in .NET Core, in this project.\nStep 3 -\nWithin VS 2015, Goto Nuget Console and install the package created earlier. This link has steps to consume local nuget package(s). Happy Coding !!\n","permalink":"http://localhost:1313/posts/dotnetstandard/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eOne of the key project(s) at my current organization is developed on .NET 4.6.1. It is developed as \u003ca href=https://www.youtube.com/watch?v\u0026#61;5OjqD-ow8GE\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModular Monolith\u003c/a\u003e. As part of it\u0026rsquo;s functionality, it supports different channels like Mobiles, Terminals and Web. For the \u003cem\u003eWeb\u003c/em\u003e channel, there was need to develop a Web application with,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHigh availability\u003c/li\u003e\n\u003cli\u003eLightweight, High throughput (Need to support few thousand(s) active users)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAccordingly, we have been exploring developing this Web Application in .NET core 3.1. However, it also means that we will have to use class libraries, targeted at .NET framework 4.6.1, in .NET core and vice-versa. How can this be done?\u003c/p\u003e","title":"Using .NET standard Assembly in .NET core and .NET Framework"},{"content":"Even Eric Evans explicitly states that DDD isn\u0026rsquo;t suitable for problems when there\u0026rsquo;s substantial technical complexity, but little business domain complexity. Using DDD is most beneficial when the complexity of the domain makes it challenging for the domain experts to communicate their needs to the software developers. By investing your time and effort into modeling the domain and coming up with a set of terminology that\u0026rsquo;s understood for each subdomain, the process of understanding and solving the problem becomes much simpler and smoother\nModeling is an intense examination of the problem space. Key to this is working together with the subject matter experts to identify the core domain and other subdomains that you\u0026rsquo;ll be tackling. Another important aspect of modeling is identifying what\u0026rsquo;s called bounded contexts. And within each of these bounded contexts, you focus on modeling a particular subdomain. As a result of modeling a bounded context, you\u0026rsquo;ll identify entities, value objects, aggregates, domain events, repositories, and more and how they interact with each other.\nthe ubiquitous language. A simple definition of a ubiquitous language is to come up with terms that\u0026rsquo;ll be commonly used when discussing a particular subdomain. And they will most likely be terms that come from the problem space, not the software world, but they have to be agreed upon so that as discussions move forward, there is no confusion or misunderstanding created by the terminology used by various members of the team\nProjects,\nFrontdesk.core - contains domain model Frontdesk.infrastructure - integration with database and rabbitmq Frontdesk.API - API Endpoints bounded contexts maintain their separation by giving each context its own team, codebase, and database schema.\nsubdomain is a view on the problem space, how you\u0026rsquo;ve chosen to break down the business or domain activity, whereas a bounded context represents the solution space, how the software and the development of that software has been organized. Quite often, these will match up perfectly, but not always.\nSame Entity can appear in more than one bounded context\nThe Domain Layer is responsible for representing concepts of the business, information about the business situation, and business rules. State that reflects the business situation is controlled and used here, even though the technical details of storing it are delegated to the infrastructure. This layer of the domain is the heart of business software.\nValue object is an object that is used to measure, quantify, or describe something in your domain. Rather than having an identity key, its identity is based on the composition of the values of all of its properties. Because the property values define a value object, it should be immutable. In other words, you shouldn\u0026rsquo;t be able to change any of the properties once you\u0026rsquo;ve created one of these objects. Instead, you would simply create another instance with the new values. If you need to compare two value objects to determine if they are equal, you should do so by comparing all of the values. Value objects may have methods and behavior, but they should never have side effects. Any methods on the value objects should only compute things; they shouldn\u0026rsquo;t change the state of the value object, since it\u0026rsquo;s immutable, or the system. If a new value is needed, a new value object should be returned. In DDD, both entities and value objects are typically defined as classes. Classes have advantages over structs when it comes to encapsulation and support for inheritance‑based extension and reuse.Value objects typically don\u0026rsquo;t exist alone, they\u0026rsquo;re usually applied to an entity to describe something about it.\ndomain services give you a place to put logic and behavior that you can\u0026rsquo;t find a home for in the entities and value objects in your domain.domain services should generally only be used if you don\u0026rsquo;t have an entity or value object where the behavior makes sense.domain services should be stateless, though they may have side effects. What this means is we should always be able to simply create a new instance of a service to perform an operation, rather than having to rely on any previous history that might have occurred within a particular service instance. But of course, the result of calling a method on a service might result in changes to the state of the system itself. These rules apply specifically to domain services which belong in the core of our application.\nSide effects are changes that occur in your application or any kind of interaction with the outside world.\nAggregates consist of one or more entities and value objects that change together. We need to treat them as a unit for data changes, and we need to consider the entire aggregate\u0026rsquo;s consistency before we apply changes.an aggregate is a cluster of associated objects that we treat as a unit for the purpose of data changes.\nA bidirectional association means that both objects can be understood only together. When application requirements do not call for traversal in both directions, adding a traversal direction reduces interdependence and simplifies the design.\nAn aggregate is a group of related objects that work together in a transaction. The root becomes the entry point through which you do any work with the aggregate, and the root also is what\u0026rsquo;s in charge of making sure that all of the rules that apply to that graph of objects are met. ‑Each of the rules that describes the state that the system must be in in order to be valid is called an invariant. Within our aggregates, we have objects that are related to one another. In DDD, we refer to these relationships as associations. If you use an ORM, you may hear the term navigation properties, which refers to those properties that reference the related objects in the model. And we talked about the importance of defaulting to one‑way relationships, which we also refer to as unidirectional relationships. ‑In addition to these important terms, Steve and I shared a lot of guidance around creating aggregates and roots in your domain models. Nobody wants to work with a big ball of mud. We use aggregates to organize our model. An aggregate is a set of related objects that live in a single transaction while encapsulating the rules and enforcing invariance of that transaction, making sure that the system is in a consistent state. When designing how related objects work together, your job will be easier with one‑way relationships. Use those as a default, and only introduce bidirectional navigation if you really need to. ‑And most importantly, don\u0026rsquo;t resist updating your model as you and your team of domain experts learn more about the domain. Hopefully, most of this will happen early on, and then just once in a while you might have a big breakthrough, like we did when we realized that the schedule made more sense as an aggregate root than trying to have each appointment be its own aggregate.\nbe sure to provide repositories only for aggregate roots that require direct access. And next, keep the clients focused on the model, while delegating all of the object storage and access concerns to the repositories.\neach domain event should be its own class\nDomain events are a type of object that actually represents something that occurred within the domain that other parts of the system may find interesting and want to tie their behavior to.\nanti‑corruption layers, which use a variety of design patterns to insulate our model from the design choices of other applications or bounded contexts.\n","permalink":"http://localhost:1313/posts/dddnotes/","summary":"\u003cp\u003eEven Eric Evans explicitly states that DDD isn\u0026rsquo;t suitable for problems when there\u0026rsquo;s substantial technical complexity, but little business domain complexity. Using DDD is most beneficial when the complexity of the domain makes it challenging for the domain experts to communicate their needs to the software developers. By investing your time and effort into modeling the domain and coming up with a set of terminology that\u0026rsquo;s understood for each subdomain, the process of understanding and solving the problem becomes much simpler and smoother\u003c/p\u003e","title":""},{"content":"Introduction Architecture plays a pivotal role in the delivery of software in terms of achieving business goals set forth for the software like maintainability, availability, performance and many more. It helps introduce structured approach to development by means of having appropriate abstractions. Typical driving forces for a software are,\nFunctional requirements Quality attributes (performance, scalability, availability etc.) Agility (Need to respond fluently to changes) Constraints (Deployment platform) Principles (Automated testing, Automated deployment etc.) In this pursuit, there are alternate styles to structure software. Lets look at below ones which are dominant,\nMonolith - Traditional approach involving tiering or layering by means of separation of concerns like UI, business logic and Data into layers/tiers. Each layer is \u0026ldquo;horizontally\u0026rdquo; sliced (Packaged by Layer). Promotes rules like UI/Controller must talk to Service which should only talk to Repository/Data Access layer. Typical observation is that changes to any one of the layers usually results in changes across all layers. Any change typically involves re-deployment of entire or most parts of Application.\nMicroservices - an approach for developing a single application as a suite of small services, each running in it\u0026rsquo;s own processes and communicating with lightweight mechanisms like HTTP based APIs. Services are built around business capabilities and are independently deployable. Key objective is bare minimum of centralized management. Typically suitable for Large, complex software projects.\nAt a high level, Monolith approach has shown need for adaptation when it comes of agility expected from Software, while MicroServices provides agility , its often requires change in Organization\u0026rsquo;s approach and found to be suitable for large use cases where benefits outweigh related concerns like Eventual consistency, Operational Complexity and Distributed nature (Remote calls/(Fallacies of Distributed computing)[https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing]).\nGiven this, are their tailored approaches aimed at specific requirements ? Let\u0026rsquo;s look at them ,\nModular Monolith - Approach that tries to have golden mean between Monolith and Microservices by structuring the application into independent modules or components with well-defined boundaries with future possibilities of carving out microservices.\nVertical Slice Architecture (VSA)- Architecture is built around distinct requests, encapsulating and grouping all concerns from front-end to back-end.\nClean Architecture - Paradigm originally proposed by Robert Martin that isolates interfaces (user interfaces, databases, external systems, devices) from business logic.\nThis article aims to provide general context and aid in decision making about the above architecture styles. Please note Limitations of General Advice\nUnderstanding Each Architecture Individually: Modular Monolith Core Idea: is a way of organizing a software application into set of well defined, independent, extractable Modules.Modules have ‌specific functionality, which can be independently developed and tested, while the entire application is deployed as a single unit.\nKey Characteristics: Encapsulation, clear boundaries between modules, high cohesion within modules, low coupling between modules.\nBenefits: Easier to start, single deployment, can evolve towards microservices if needed, good for smaller to medium teams. Suitable to manage when significant domain-specific changes are expected.\nPotential Drawbacks/Concerns: Can become a \u0026ldquo;big ball of mud\u0026rdquo; if modularity isn\u0026rsquo;t strictly enforced, deployment unit size. These issues may be addressed using Fitness functions (e.g. Cyclomatic complexity, coupling) and static code analysis etc. Carries on with some monolith bottlenecks like fault tolerance, scalability, elasticity etc.\nModular Monolith Vertical Slice Architecture (VSA) Core Idea: This is in a way evolution of Modular Monolith where focus is on axes of expected change and modelling features end-to-end for it. For every individual request(s), all the code is co-located across layers. Organizing code around business capabilities or \u0026ldquo;verticals\u0026rdquo; (e.g., user management, order processing) rather than technical layers (UI, Business Logic, Data Access). A Module may have one or more features. Each feature is self-contained and can be developed/tested independently. Module boundaries are explicit. Aim is to Minimize coupling between slices and maximize within slice.\nKey Characteristics: Code organized by feature/capability, strong encapsulation within slices, minimal dependencies between slices, often involves defining clear boundaries.\nBenefits: High cohesion within slices, improved team autonomy, easier to understand and modify specific features, good for evolving complexity.\nPotential Drawbacks: Can lead to duplication if not managed carefully (e.g., common domain logic), requires a discipline of keeping slices truly independent.\nVertical Slice Architecture Vertical Slice Architecture Clean Architecture (or similar layered/hexagonal approaches): Core Idea: opinionated way to structure code and to separate the concerns of the application into layers. Core aim is to separate the business logic from infrastructure (i.e. data Access, external integrations etc.) and presentation layers. Originally popularized by Robert C Martin. Crux is to have business logic isolated from less stable external elements.\nKey Characteristics:\nDomain as the core, use of interfaces for external interactions. Aim is to achieve maintainability, testability, and extendability Ability to change infrastructure and presentation without affecting core business logic Ideal for complex, medium to large scale applications where maintainability and scalability are key objectives. Benefits: High testability, framework independence, maintainability, clear separation of concerns, easier to swap out external components.\nPotential Drawbacks: Can be perceived as overly complex for simple projects. Strict adhering to layering and use of interfaces often lead to lot of boilerplate code. Simple Applications may find it as overhead to implement.\nClean Architecture Comparative Analysis: Aspect Modular Monolith Vertical Slice Architecture Clean Architecture Application Size Suitable for small to medium Sized Applications. Easy to get started and is cost effective. Agnostic of Application size. But keep watch for refactoring opty. Larger initial codebase due to abstractions but clean separation helps irrespective of size Organization Modular approach per Domain functionalities By feature or use case, with each slice containing all relevant layers. by layers i.e. Presentation, Domain and Infrastructure Maintainability, Testability Individual slices/use cases can be tested Easier to maintain and test, as changes are localized to a single feature slice. Improved testability Flexibility Improved due to modularity but may require complete deployment High. Different features can use different technical implementations. High due to isolation of layers Scalability Useful when future scalability requirements are uncertain. Slices can be deployed independently Can be achieved by means of isolation of state management and ability to switch implementations Testability better than trad.Monolith High Each layer can be tested independently, Synergies and Overlaps: As one says there is no \u0026ldquo;one size fits all\u0026rdquo;, similarly there is no reason to constrain self to use a specific architectural style for Application and neither of the above styles are mutually exclusive. A Modular Monolith is where modules are structured but can use Vertical slice Architecture principles. A VSA based implementation can adopt clean Architecture principles with clean separation between domain logic and adapters (UI, Data stores, external integrations etc.) While VSA focuses on what to organize by, Clean Architecture focuses on how to organize within those boundaries.\nConclusion: The Architecture styles evolve as they are tested against real-time requirements in terms of flexibility, maintainability, scalability and so on. There is no one architecture style that fits many situation but each of the style provides path way to think and analyze fitment for the actual use case. As the First Law of Software Architecture states that everything in software is a trade-off, key is to evaluate these styles against requirements and arrive at tradeoffs and decide based on it.\nUseful References Modular Monolith 1 Modular Monolith 2 Modular Monolith 3 Vertical Slice Architecture 1 Clean Architecture from Robert Martin Clean Architecture 1 Clean Architecture 2 Clean Architecture 3 Cognitive load is all that matters Happy Coding !!\n","permalink":"http://localhost:1313/posts/comparearchitecturestyles/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eArchitecture plays a pivotal role in the delivery of software in terms of achieving business goals set forth for the software like maintainability, availability, performance and many more. It helps introduce structured approach to development by means of having appropriate abstractions. Typical driving forces for a software are,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFunctional requirements\u003c/li\u003e\n\u003cli\u003eQuality attributes (performance, scalability, availability etc.)\u003c/li\u003e\n\u003cli\u003eAgility (Need to respond fluently to changes)\u003c/li\u003e\n\u003cli\u003eConstraints (Deployment platform)\u003c/li\u003e\n\u003cli\u003ePrinciples (Automated testing, Automated deployment etc.)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this pursuit, there are alternate styles to structure software. Lets look at below ones which are dominant,\u003c/p\u003e","title":"Clean Architecture, Modular Monolith and Vertical Slice Architecture "},{"content":"Introduction A Software Bill of Materials (SBOM) is a list of all the components, libraries, and modules that make up a software, providing transparency into its composition. It describes various packages and dependencies that go into creating a software artifact.\nWhy ? Software products are composed of many different components, some of which might come from third party sources. These third-party components and dependencies can have vulnerabilities, which attackers can exploit, leading to security incident or breaches. Key threats include attackers inserting malicious code, vulnerabilities in outdated components, and breaches by compromised suppliers. These issues can lead to data breaches, operational disruptions, and reputational damage. SBOM can help improve software security and protect against potential threats.\nEffective Incident Response - SBOM can assist in speeding up by providing detailed information on dependencies.\nVulnerabilities identification and patch management - Using SBOM, organizations can quickly spot and address known vulnerabilities in the software by patching them.\nCompliance - SBOM helps organizations to streamline adherence to security regulations, guidelines and best practices on software security by providing required transparency in software composition.\nMany Governments around that world are now recommending SBOM like,\nNIST CERT-IN Tools and Processes Lets look at ways to generate SBOM.\nThere are standards/specifications available to represent bills of material including SBOM. Important ones are,\nSPDX - An open standard capable of representing systems with software components in as SBOMs (Software Bill of Materials) and other AI, data and security references supporting a range of risk management use cases. CycloneDX - is a full-stack Bill of Materials (BOM) standard that provides advanced supply chain capabilities for cyber risk reduction. CycloneDX is an Ecma International standard published as ECMA-424. Various tools and libraries typically scan the container images, file systems and generate a Software Bill of Materials as per above specifications. Each tool supports parsing of files for various languages/platforms to extract details on dependencies.\nBelow are some of the open source tools available,\nCycloneDX has repository that contains various tools like, Cyclonedx-CLI - Cli for conversion, analysis, merging cyclonedx-dotnet - for .NET projects cyclonedx-gomod - for Go Modules cyclonedx-core-java - For Core Java Syft - Supports C/C++/Dotnet/Java/JavaScript and many more. Refer here.It can generate BOM in either SPDX or CycloneDX specification. Microsoft SBOM tool - Generates SPDX 2.2 compatible SBOM. The above tools are typically integrated in Build (CI/CD) pipeline for automated SBOM Generation.\nHigh level Adoption approach could be,\nInitiation Identify Critical Assets and Develop a Project Plan. Determine the SBOM format and minimum requirements. Identify security requirements,secure storage and tooling. Plan for Proof of Concept Progress Secure Installation and Operation Guidance Development. Preparation of SBOM Integrate SBOM in each phase of Secure Software Development Lifecycle. On going Analysis and review of existing SBOM periodically and any changes as needed Conclusion: Each of the above tool help generate SBOM for the platform in either the standard Specification format (SPDX/CycloneDX) or tool\u0026rsquo;s own proprietary format (e.g. syft has its own specification too.). Depending on the requirement, these tools can be effectively used for the projects.\nUseful References HBOM - Inventory hardware components for IoT, ICS, and other types of embedded and connected devices. OWASP AIBOM - AIBOM aims to provide transparency into how AI models are built, trained, and deployed. Happy Coding !!\n","permalink":"http://localhost:1313/posts/sbom/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA Software Bill of Materials (SBOM) is a list of all the components, libraries, and modules that make\nup a software, providing transparency into its composition. It describes various packages and dependencies that go into creating a software artifact.\u003c/p\u003e\n\u003ch3 id=\"why-\"\u003eWhy ?\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSoftware products are composed of many different components, some of which might come from\nthird party sources. These third-party components and dependencies can have vulnerabilities, which\nattackers can exploit, leading to security incident or breaches. Key threats include attackers inserting\nmalicious code, vulnerabilities in outdated components, and breaches by compromised suppliers. These issues can lead to data breaches, operational disruptions, and reputational damage. SBOM can help improve software security and protect against potential threats.\u003c/p\u003e","title":"What is Software Bill of Material (SBOM)"},{"content":"Introduction In the ever-evolving landscape of AI and machine learning, Google\u0026rsquo;s MCP Toolbox for Databases stands out. This open-source server enables developers to connect generative AI applications to enterprise databases, facilitating prompt-based querying and natural language processing (NLP). Whether you\u0026rsquo;re setting up your LLM on-premises using OLLAMA or leveraging providers like Gemini, Claude, or OpenAI, this toolbox offers a versatile and powerful solution. Lets explore it in detail.\nQuick Start Guide To get started with the Gen AI Toolbox for Databases, follow the official quick start guide. This guide provides detailed instructions on setting up your database and integrating it with the toolbox. While the guide focuses on using PostgreSQL, the principles can be applied to other supported databases as well.\nStep-by-Step Setup For a detailed walkthrough, refer here.\nSet Up Your Database: Ensure your database (PostgreSQL, in this case) is configured and running.\nInstall the Toolbox: Download and install the Gen AI Toolbox server.\nConfigure Your Connection: Set up the connection parameters to link your database with the toolbox.\nDeploy Your LLM: Choose your LLM provider (OLLAMA, Gemini, Claude, OpenAI) and configure it to work with the toolbox. I decided to try with Llama3.2 (Initially tried with Deepseek-r1 but it has some issues when used via Ollama w.r.t. tools usage) via Ollama.\nBelow are the additional steps,\nSet up additional libraries like,\nlangchain-ollama using pip install langchain-ollama\nollama using pip install ollama\nBelow are the changes to sample code.\nInclude package ref. at the top, from langchain_ollama import ChatOllama\nChange main functions code to use Ollama as,\ndef main(): # TODO(developer): replace this with another model if needed model = ChatOllama(model=\u0026#34;llama3.2:latest\u0026#34;) Ensure that\nOllama is running either as a Service or using ollama serve.\nRun toolbox, using ./toolbox --tools_file \u0026quot;tools.yml\u0026quot; . Note: Replace the name of configuration file as needed.\nMake any changes to yaml configuration for toolbox. This includes configuring Tools that are used by LLMs while inferencing. Each tool is mapped to specific Query and associated parameters.\nToolbox Configuration Run the code python \u0026lt;Name of file\u0026gt;.py\nIf all goes well, agent queries the database and one can confirm by the log generated by the toolbox and provides output.\nResponse to Prompt Key Use Cases The Gen AI Toolbox for Databases opens up a plethora of use cases, making it a valuable asset for enterprises:\n1. Prompt-Based Querying With the integration of LLMs, users can query databases using natural language prompts. This simplifies the process of data retrieval and analysis, making it accessible to non-technical users.\n2. Enhanced Data Insights By leveraging NLP, the toolbox can provide deeper insights into the data. It can identify patterns, trends, and anomalies that might be missed by traditional querying methods.\n3. Automated Reporting The toolbox can automate the generation of reports based on user queries. This not only saves time but also ensures that the reports are comprehensive and up-to-date.\n4. Real-Time Data Interaction Users can interact with the database in real-time, making it possible to get instant responses to their queries. This is particularly useful for applications that require up-to-the-minute data.\n5. Privacy and Security Users can only interact with the database via the queries specified in tools configuration for Toolbox. This is useful if database owner wants fine-grained control or restrict access to data. Use of local LLM for inference caters to cases where privacy is critical and expenses are sensitive topic and somewhat delayed response time is acceptable.\nConclusion Google\u0026rsquo;s Gen AI Toolbox for Databases is a game-changer in the realm of database management and AI integration. By enabling prompt-based querying and NLP, it democratizes access to data and enhances the capabilities of enterprise applications. Whether you\u0026rsquo;re working with on-premises setups or cloud providers, this toolbox offers a robust and flexible solution.\nFor more information, check out the official documentation and the GitHub repository.\nReferences: Google Cloud Blog\nGitHub Repository\nLangChain Announcement\nRunning Local LLMs\nMCP- What is it?\n","permalink":"http://localhost:1313/posts/genaidb/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn the ever-evolving landscape of AI and machine learning, Google\u0026rsquo;s \u003ca href=https://googleapis.github.io/genai-toolbox\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMCP Toolbox for Databases\u003c/a\u003e stands out. This open-source server enables developers to connect generative AI applications to enterprise databases, facilitating prompt-based querying and natural language processing (NLP). Whether you\u0026rsquo;re setting up your LLM on-premises using OLLAMA or leveraging providers like Gemini, Claude, or OpenAI, this toolbox offers a versatile and powerful solution. Lets explore it in detail.\u003c/p\u003e","title":"Exploring MCP Toolbox for Databases: A New Era of Database Querying"},{"content":"Summary Explore various approaches to handle out-of-order or delayed processing, addressing scenarios like bulk operations and long-running tasks. Learn about message queues, background workers, and other techniques to improve application responsiveness.\nIntroduction In the world of software development, we often encounter tasks that don\u0026rsquo;t need to or (should not) be completed immediately. Whether it\u0026rsquo;s sending mass emails, processing large datasets, or handling complex computations. Blocking the user\u0026rsquo;s main flow (Either on Web App or API) for these operations is rarely a good idea. That\u0026rsquo;s where out-of-order or delayed processing comes in.\nThis post will delve into different strategies for managing these asynchronous tasks, comparing their strengths and weaknesses, and providing practical examples.\nUse Cases Bulk Operations: Sending bulk emails, generating reports, or processing large files. Long-Running Tasks: Video transcoding, complex calculations, or data analysis. Non-Blocking User Interactions: Accepting user requests without waiting for completion, improving responsiveness Approaches Thread Pools (In-Process Concurrency)\nDescription: Using threads to execute tasks concurrently within the same application process. Pros: Simple to implement, low overhead for small tasks. Cons: Limited scalability, potential for resource contention, not suitable for distributed systems. Example (Go): package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func processTask(taskID int) { fmt.Printf(\u0026#34;Processing task %d\\n\u0026#34;, taskID) } func main() { tasks := []int{1, 2, 3, 4, 5} var wg sync.WaitGroup for _, task := range tasks { wg.Add(1) go func(id int) { defer wg.Done() processTask(id) }(task) } wg.Wait() } Example (C#): using System; using System.Threading.Tasks; public class Program { public static async Task ProcessTask(int taskID) { // Console.WriteLine($\u0026#34;Processing task {taskID}\u0026#34;); await Task.Delay(taskID); } public static async Task Main(string[] args) { int[] tasks = { 1, 2, 3, 4, 5 }; var taskList = new Task[tasks.Length]; for (int i = 0; i \u0026lt; tasks.Length; i++) { int taskID = tasks[i]; taskList[i] = ProcessTask(taskID); } await Task.WhenAll(taskList); Console.WriteLine(\u0026#34;All tasks completed.\u0026#34;); } } Background Workers (Dedicated Processes or as a sidekick)\nDescription: Running dedicated processes or services to handle background tasks. Pros: Good isolation, scalability, suitable for long-running tasks. Cons: Increased complexity, requires process management. Examples: Machinery (Go), Quartz.net (.NET), Hangfire (.NET). Often used with message queues. Go: Implementing a background worker involves creating a separate executable, or using a library that facilitates background task execution like Machinery. C# , Out-of-process approach can be implemented using Windows Service or Systemd on Linux. Alternatively, dedicated processes can be run as scoped service and process task(s) sequentially. Refer to \u0026ldquo;Queued Background tasks\u0026rdquo; example here. Scheduled Tasks (Cron Jobs/Task Schedulers)\nDescription: Executing tasks at specific intervals or times. Pros: Simple scheduling, suitable for recurring tasks. Cons: Less flexible than message queues, not ideal for event-driven tasks. Go: Using cron libraries like Gocron or Windows Task Scheduler. C#: Using Windows Task Scheduler, or libraries like Quartz.NET/hangfire. Message Queues (Asynchronous Communication)\nDescription: Using a message broker (e.g., RabbitMQ, Kafka, Redis Pub/Sub) to decouple task producers and consumers. Pros: Scalable, fault-tolerant, supports distributed systems, excellent for decoupling. Cons: Requires additional infrastructure, increased complexity. Example (Conceptual): Producer: Sends a message (task details) to a queue. Consumer (Worker): Retrieves the message from the queue and processes the task. Considerations: Message durability, delivery guarantees, message serialization. Go (using RabbitMQ): (Requires RabbitMQ client library) // Example using amqp library. Add error handling. // ... C# (using RabbitMQ): (Requires RabbitMQ client library) // Example using RabbitMQ.Client library. Add error handling. // ... Asynchronous APIs (Callbacks/Promises/Async-Await)\nDescription: Allowing client applications to initiate tasks and receive results later without blocking. Pros: Improves client-side responsiveness, good for web applications. Cons: Requires careful handling of asynchronous operations, potential for callback hell (older callback based approaches).d q Go: Using Goroutines and channels for asynchronous communication. C#: refer to implementation of Asynchronous (long-running) Apis here. Typical flow is as follow,\nAsync Request/Reply pattern Outbox Pattern\nDescription: The Outbox Pattern provides a reliable way to publish events or messages when database transactions are involved. Instead of directly publishing messages to a message queue, events are stored in an outbox table within the same database. This helps with consistency issues as updates can be part of same transaction context. A separate process then reads these events from the outbox table and publishes them to the message queue. This pattern is typically used alongside other patterns mentioned above.\nBenefits:\nAtomicity: Ensures that events are published only if the database transaction succeeds. Reliability: Prevents message loss in case of application crashes or network issues. Decoupling: Decouples the application from the message queue. Implementation: 1. Outbox Table: Typical outbox table to store events:\n```sql CREATE TABLE outbox ( id SERIAL PRIMARY KEY, payload JSONB NOT NULL, destination VARCHAR(255) NOT NULL, processed BOOLEAN NOT NULL DEFAULT FALSE, created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW() ); ``` Publishing Events: When an event occurs, insert a row into the outbox table within the same database transaction as the business logic. Background Processor: Create a background process that reads events from the outbox table, publishes them to the message queue, and updates the processed column. Idempotency: ensure that the message consumer is idempotent, to handle possible duplicate messages. Example (C# with PostgreSQL):\n```csharp using Npgsql; using System.Text; using System.Text.Json; using System.Threading; using System.Threading.Tasks; public class OutboxProcessor { private readonly string _connectionString; private readonly IConnection _rabbitConnection; public OutboxProcessor(string connectionString, IConnection rabbitConnection) { _connectionString = connectionString; _rabbitConnection = rabbitConnection; } public async Task ProcessOutbox(CancellationToken cancellationToken) { while (!cancellationToken.IsCancellationRequested) { try { using (var connection = new NpgsqlConnection(_connectionString)) { await connection.OpenAsync(cancellationToken); using (var transaction = connection.BeginTransaction()) { using (var command = new NpgsqlCommand( \u0026quot;SELECT id, payload, destination FROM outbox WHERE processed = FALSE FOR UPDATE SKIP LOCKED LIMIT 1\u0026quot;, connection, transaction)) { using (var reader = await command.ExecuteReaderAsync(cancellationToken)) { if (await reader.ReadAsync(cancellationToken)) { int id = reader.GetInt32(0); string payload = reader.GetString(1); string destination = reader.GetString(2); PublishToRabbitMQ(destination, payload); using (var updateCommand = new NpgsqlCommand( \u0026quot;UPDATE outbox SET processed = TRUE WHERE id = @id\u0026quot;, connection, transaction)) { updateCommand.Parameters.AddWithValue(\u0026quot;id\u0026quot;, id); await updateCommand.ExecuteNonQueryAsync(cancellationToken); } } } } await transaction.CommitAsync(cancellationToken); } } } catch (Exception ex) { Console.WriteLine($\u0026quot;Error processing outbox: {ex.Message}\u0026quot;); } await Task.Delay(1000, cancellationToken); } } private void PublishToRabbitMQ(string destination, string payload) { using (var channel = _rabbitConnection.CreateModel()) { channel.BasicPublish(exchange: \u0026quot;\u0026quot;, routingKey: destination, basicProperties: null, body: Encoding.UTF8.GetBytes(payload)); } } } ``` Notice the use of `SELECT .... FOR UPDATE ..... SKIP LOCKED`. This is useful in case outbox table will be accessed/read concurrently by multiple processes. This ensures read operation will skip (and not wait) records that have `read lock`. This feature is available in most of RDBMS. Comparison Table Approach Scalability Complexity Fault Tolerance Use Cases Thread Pools Low Low Low Simple, in-process tasks Message Queues High High High Distributed systems, decoupling, asynchronous communication Background Workers High Medium Medium Long-running tasks, dedicated processing Scheduled Tasks Medium Low Low Recurring tasks, scheduled operations Asynchronous APIs Medium Medium Medium Web applications, non-blocking client interactions, improved responsiveness \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; Conclusion Choosing the right approach depends on the specific requirements of your application. Message queues and background workers offer excellent scalability and fault tolerance for complex, distributed systems. Thread pools and scheduled tasks are suitable for simpler scenarios. Asynchronous APIs are crucial for improving client-side responsiveness in web applications.\nBy understanding these techniques, you can effectively manage out-of-order and delayed processing, enhancing the performance and user experience of your applications.\nUseful links (#usefullinks) Happy Coding !!\n","permalink":"http://localhost:1313/posts/outoforder/","summary":"\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eExplore various approaches to handle out-of-order or delayed processing, addressing scenarios like bulk operations and long-running tasks. Learn about message queues, background workers, and other techniques to improve application responsiveness.\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn the world of software development, we often encounter tasks that don\u0026rsquo;t need to or (should not) be completed immediately. Whether it\u0026rsquo;s sending mass emails, processing large datasets, or handling complex computations. Blocking the user\u0026rsquo;s main flow (Either on Web App or API) for these operations is rarely a good idea. That\u0026rsquo;s where out-of-order or delayed processing comes in.\u003c/p\u003e","title":"Taming Time: Strategies for Out-of-Order and Delayed Processing"},{"content":"Background There was a requirement to perform series of tasks, involving generation of output files, such that the required throughput is achieved. These tasks involve database read operation, external API invocation and file i/o. Generally, benchmarking showed that executing them in sequential way was not helpful. What if asynchronous programming be used to perform this task.\nSo Lets Start.\nApproach Lets assume that this typical use case requires,\nfetching data from database for the purpose of merging placeholders in a Template and perform mail merge\nGenerate PDF file from mail-merged output of last step (say HTML to PDF)\nsend notification to users via third party API.\nThe requirement is to perform these steps in such a way that 50 or more notifications (with file) are sent per minute.\nFor the purpose of simplicity, lets assume that,\nDatabase read operation and HTML generation basis template, takes upto 2 seconds per iteration We will use Puppeteer Sharp library for PDF Generation External API Integration takes up to 2 seconds per call Since current approach of sequential execution is not helpful, lets try below (both the methods process 5 requests[i.e. generate 5 pdf files] per iteration),\nUsing Task asynchronous programming model - This uses Task library to start tasks in parallel and subsequently process them as each completes. Using Task Async. Library Using Dataflow - Task Parallel Library - This uses Dataflow Library to orchestrate each step in the process and use parallelism for performance. Using DataFlow Library Below is the Report from Benchmarkdotnet for both the approaches.\nBenchmark Results As one can see, using above techniques, It is straightforward to write asynchronous code that performs parallel execution and achieves better performance compared to sequential alternate approach.\nReferences:\nBenchmarkDotNet Introduction to Benchmarking C# Code with Benchmark .NET Happy Coding !!\n","permalink":"http://localhost:1313/posts/parallelprocessing/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eThere was a requirement to perform series of tasks, involving generation of output files, such that the required throughput is achieved. These tasks involve database read operation, external API invocation and file i/o. Generally, benchmarking showed that executing them in sequential way was not helpful.  What if asynchronous programming be used to perform this task.\u003c/p\u003e\n\u003cp\u003eSo Lets Start.\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cp\u003eLets assume that this typical use case requires,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003efetching data from database for the purpose of merging placeholders in a Template and perform mail merge\u003c/p\u003e","title":"Using Asynchronous programming to manage parallel processing "},{"content":"Location Mumbai, Maharashtra, India\nProfessional Title Senior Technical Architect at Worldline India\nWhat do you do ? I write code. In my current role, I am responsible for Architecture for all the systems in Payments space covering Acquiring and Issuance of Cards, UPI (QR based payment system in India). I am involved in creating and maintaining the Architecture of various systems, integration between them, primarily focussing on non-functional (ilities) aspects.\nWhy ? I like building things and understanding patterns.\nWhat should we read? Poor Charlies Almanack by Charlie Munger\nURLS: Linkedin\nMy Blog\nI appreciate any ideas/suggestions you have on how I can improve this site.\n","permalink":"http://localhost:1313/now/","summary":"\u003ch2 id=\"location\"\u003eLocation\u003c/h2\u003e\n\u003cp\u003eMumbai, Maharashtra, India\u003c/p\u003e\n\u003ch2 id=\"professional-title\"\u003eProfessional Title\u003c/h2\u003e\n\u003cp\u003eSenior Technical Architect at Worldline India\u003c/p\u003e\n\u003ch2 id=\"what-do-you-do-\"\u003eWhat do you do ?\u003c/h2\u003e\n\u003cp\u003eI write code. In my current role, I am responsible for Architecture for all the systems in  Payments space covering Acquiring and Issuance of Cards, UPI (QR based payment system in India). I am involved in creating and maintaining the Architecture of various systems, integration between them, primarily focussing on non-functional (ilities) aspects.\u003c/p\u003e","title":"What am i doing *NOW*"},{"content":"Introduction Artificial Intelligence, especially Large language models (LLMs) are all in high demand. Since OpenAI released ChatGPT, interest has gone up multi-fold. Since 2023, Powerful LLMs can be run on local machines. Local Large Language Models offer advantages in terms of data privacy and security and can be enriched using enterprise-specific data using Retrieval augmentation generation (RAG).Several tools exist that make it relatively easy to obtain, run and manage such models locally on our machines. Few examples are Ollama, Langchain, LocalAI.\nSemantic Kernel is an SDK from Microsoft that integrates Large Language Models (LLMs) like OpenAI, Azure OpenAI, and Hugging Face with conventional programming languages like C#, Python, and Java. Semantic Kernel also has plugins that can be chained together to integrate with other tools like Ollama.\nThis post describes usage of Ollama to run model locally, communicate with it using REST API from Semantic kernel SDK.\nOllama To setup Ollama follow the installation and setup instructions from the Ollama website. Ollama runs as a service, exposing a REST API on a localhost port.Once installed, you can invoke ollama run to talk to this model; the model is downloaded, if not already and cached the first time it\u0026rsquo;s requested.\nFor the sake of this post, we can use Phi3 model, so run ollama run phi3. This will download phi3 model, if not already, and once done, it will present a prompt. Using this prompt, one can start chatting with the model.\nWhy SemanticKernel ? As such , Ollama can be integrated with from any application via REST API. Then why go for SemanticKernel SDK? It provides a simplified integration of AI capabilities into existing applications, lowering the barrier of entry for new developers and supporting the ability to fine-tune models. It supports multiple languages like C#, Python and Java.\nUsing Ollama Install Ollama by following instructions here.Ollama exposes set of REST APIs, check Documentation here. It provides range of functions like get response for Prompt, get Chat response. for Specific operations, it supports streaming and non-streaming response. First step is to download/pull using ollama run phi3. This will pull, if required, the model and set it up locally. In the end, it will show prompt where user can interact with model.\nNow Ollama API can be easily accessed. Below is the gateway class.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 ``` public class OllamaApiClient { private HttpClient _client = new(); public Configuration Config { get; } public interface IResponseStreamer\u0026lt;T\u0026gt; { void Stream(T stream); } public class ChatMessage { [JsonPropertyName(\u0026#34;role\u0026#34;)] public string Role { get; set;} [JsonPropertyName(\u0026#34;content\u0026#34;)] public string Content {get;set;} } public class ChatResponse { [JsonPropertyName(\u0026#34;model\u0026#34;)] public string Model { get; set; } [JsonPropertyName(\u0026#34;created_at\u0026#34;)] public string CreatedAt { get; set; } [JsonPropertyName(\u0026#34;response\u0026#34;)] public string Response { get; set; } [JsonPropertyName(\u0026#34;message\u0026#34;)] public ChatMessage? Message { get; set; } [JsonPropertyName(\u0026#34;messages\u0026#34;)] public List\u0026lt;ChatMessage\u0026gt; Messages { get; set; } [JsonPropertyName(\u0026#34;embedding\u0026#34;)] public List\u0026lt;Double\u0026gt; Embeddings { get; set; } [JsonPropertyName(\u0026#34;done\u0026#34;)] public bool Done { get; set; } } public class ChatRequest { [JsonPropertyName(\u0026#34;model\u0026#34;)] public string Model { get;set;} [JsonPropertyName(\u0026#34;prompt\u0026#34;)] [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)] public string Prompt {get; set;} [JsonPropertyName(\u0026#34;format\u0026#34;)] [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)] public string Format {get; set;} [JsonPropertyName(\u0026#34;messages\u0026#34;)] [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)] public IList\u0026lt;ChatMessage\u0026gt; Messages {get; set;} [JsonPropertyName(\u0026#34;stream\u0026#34;)] public bool Stream {get; set;} = false; } public class Configuration { public Uri Uri { get; set; } public string Model { get; set; } } public OllamaApiClient(string uriString, string defaultModel = \u0026#34;\u0026#34;) : this(new Uri(uriString), defaultModel) { } public OllamaApiClient(Uri uri, string defaultModel = \u0026#34;\u0026#34;) : this(new Configuration { Uri = uri, Model = defaultModel }) { } public OllamaApiClient(Configuration config) : this(new HttpClient() { BaseAddress = config.Uri }, config.Model) { Config = config; } public OllamaApiClient(HttpClient client, string defaultModel = \u0026#34;\u0026#34;) { _client = client ?? throw new ArgumentNullException(nameof(client)); _client.Timeout = TimeSpan.FromMinutes(10); (Config ??= new Configuration()).Model = defaultModel; } public async Task\u0026lt;ChatResponse\u0026gt; GetEmbeddingsAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; return await PostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/embeddings\u0026#34;,message,token); } public async Task\u0026lt;ChatResponse\u0026gt; GetResponseForChatAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; return await PostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/chat\u0026#34;,message,token); } public async Task\u0026lt;ChatResponse\u0026gt; GetResponseForPromptAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; return await PostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/generate\u0026#34;,message,token); } public async IAsyncEnumerable\u0026lt;ChatResponse\u0026gt; GetStreamForPromptAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; message.Stream = true; await foreach(ChatResponse resp in StreamPostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/generate\u0026#34;,message,token)) { yield return resp; } } public async IAsyncEnumerable\u0026lt;ChatResponse\u0026gt; GetStreamForChatAsync(ChatRequest message, CancellationToken token) { message.Model = this.Config.Model; message.Stream = true; await foreach(ChatResponse resp in StreamPostAsync\u0026lt;ChatRequest,ChatResponse\u0026gt;(\u0026#34;/api/chat\u0026#34;,message,token)) { yield return resp; } } private async Task\u0026lt;TResponse\u0026gt; GetAsync\u0026lt;TResponse\u0026gt;(string endpoint, CancellationToken cancellationToken) { var response = await _client.GetAsync(endpoint, cancellationToken); response.EnsureSuccessStatusCode(); var responseBody = await response.Content.ReadAsStringAsync(cancellationToken); return JsonSerializer.Deserialize\u0026lt;TResponse\u0026gt;(responseBody); } private async Task PostAsync\u0026lt;TRequest\u0026gt;(string endpoint, TRequest request, CancellationToken cancellationToken) { var content = new StringContent(JsonSerializer.Serialize(request), Encoding.UTF8, \u0026#34;application/json\u0026#34;); var response = await _client.PostAsync(endpoint, content, cancellationToken); response.EnsureSuccessStatusCode(); } private async IAsyncEnumerable\u0026lt;TResponse\u0026gt; StreamPostAsync\u0026lt;TRequest,TResponse\u0026gt;(string endpoint, TRequest request, CancellationToken cancellationToken) { var content = new StringContent(JsonSerializer.Serialize(request), Encoding.UTF8, \u0026#34;application/json\u0026#34;); var response = await _client.PostAsync(endpoint, content, cancellationToken); using Stream stream = await response.Content.ReadAsStreamAsync(); using StreamReader reader = new StreamReader(stream); while (!reader.EndOfStream) { var jsonString = await reader.ReadLineAsync(cancellationToken); TResponse result = JsonSerializer.Deserialize\u0026lt;TResponse\u0026gt;(jsonString); yield return result; } yield break; } private async Task\u0026lt;TResponse\u0026gt; PostAsync\u0026lt;TRequest, TResponse\u0026gt;(string endpoint, TRequest request, CancellationToken cancellationToken) { var content = new StringContent(JsonSerializer.Serialize(request), Encoding.UTF8, \u0026#34;application/json\u0026#34;); var response = await _client.PostAsync(endpoint, content, cancellationToken); response.EnsureSuccessStatusCode(); var responseBody = await response.Content.ReadAsStringAsync(cancellationToken); return JsonSerializer.Deserialize\u0026lt;TResponse\u0026gt;(responseBody); } } With this class in place, now it can be integrated with SemanticKernel.\nIntegrating with SemanticKernel Semantickernel SDK operates on a plug-in system, where developers can use pre-built plugins or create their own. These plugins consist of prompts that the AI model should respond to, as well as functions that can complete specialized tasks. Accordingly, it provides interfaces for (Chat completion)[https://learn.microsoft.com/en-us/dotnet/api/microsoft.semantickernel.chatcompletion.ichatcompletionservice?view=semantic-kernel-dotnet] and Text Generation tasks which can be use d to integrate with external implementation like Ollama.\nBelow are implementations of these interfaces that use Ollama API,\nText Generation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 public class TextGenerationService : ITextGenerationService { public string ModelApiEndPoint { get; set; } public string ModelName { get; set; } public IReadOnlyDictionary\u0026lt;string, object?\u0026gt; Attributes =\u0026gt; throw new NotImplementedException(); public async Task\u0026lt;IReadOnlyList\u0026lt;TextContent\u0026gt;\u0026gt; GetTextContentsAsync(string prompt, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, CancellationToken cancellationToken = default) { var client = new OllamaApiClient(ModelApiEndPoint, ModelName); OllamaApiClient.ChatRequest req = new OllamaApiClient.ChatRequest() { Model=ModelName, Prompt=prompt, }; OllamaApiClient.ChatResponse resp = await client.GetResponseForPromptAsync(req , cancellationToken); return new List\u0026lt;TextContent\u0026gt;() { new TextContent(resp.Response) }; } public async IAsyncEnumerable\u0026lt;StreamingTextContent\u0026gt; GetStreamingTextContentsAsync(string prompt, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, CancellationToken cancellationToken = default) { var ollama = new OllamaApiClient(ModelApiEndPoint, ModelName); OllamaApiClient.ChatRequest req = new OllamaApiClient.ChatRequest() { Prompt=prompt, Stream=true }; await foreach( OllamaApiClient.ChatResponse resp in ollama.GetStreamForPromptAsync(req, cancellationToken)) { yield return new StreamingTextContent( text: resp.Response) ; } } } Chat Completion 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 public class OllamaChatCompletionService : IChatCompletionService { public string ModelApiEndPoint { get; set; } public string ModelName { get; set; } public IReadOnlyDictionary\u0026lt;string, object?\u0026gt; Attributes =\u0026gt; throw new NotImplementedException(); public async Task\u0026lt;IReadOnlyList\u0026lt;ChatMessageContent\u0026gt;\u0026gt; GetChatMessageContentsAsync(ChatHistory chatHistory, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, CancellationToken cancellationToken = default) { var client = new OllamaApiClient(ModelApiEndPoint, ModelName); OllamaApiClient.ChatRequest req = new OllamaApiClient.ChatRequest() { Model=ModelName }; req.Messages = new List\u0026lt;OllamaApiClient.ChatMessage\u0026gt;(); // iterate though chatHistory Messages foreach (var history in chatHistory) { req.Messages.Add(new OllamaApiClient.ChatMessage{ Role=history.Role.ToString(), Content=history.Content }); } OllamaApiClient.ChatResponse resp = await client.GetResponseForChatAsync(req , cancellationToken); List\u0026lt;ChatMessageContent\u0026gt; content = new(); content.Add( new(role:resp.Message.Role.Equals(\u0026#34;system\u0026#34;,StringComparison.InvariantCultureIgnoreCase)?AuthorRole.System:AuthorRole.User,content:resp.Message.Content)); return content; } public async IAsyncEnumerable\u0026lt;StreamingChatMessageContent\u0026gt; GetStreamingChatMessageContentsAsync(ChatHistory chatHistory, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, CancellationToken cancellationToken = default) { var client = new OllamaApiClient(ModelApiEndPoint, ModelName); OllamaApiClient.ChatRequest req = new OllamaApiClient.ChatRequest() { Model=ModelName }; req.Messages = new List\u0026lt;OllamaApiClient.ChatMessage\u0026gt;(); // iterate though chatHistory Messages foreach (var history in chatHistory) { req.Messages.Add(new OllamaApiClient.ChatMessage{ Role=history.Role.ToString(), Content=history.Content }); } CancellationTokenSource source = new CancellationTokenSource(); CancellationToken token = source.Token; await foreach (OllamaApiClient.ChatResponse resp in client.GetStreamForChatAsync(req,token)) { yield return new(role:resp.Message.Role.Equals(\u0026#34;system\u0026#34;,StringComparison.InvariantCultureIgnoreCase)?AuthorRole.System:AuthorRole.User, content:resp.Message.Content ?? string.Empty); } } } Above implementation is for demonstration purposes only. I am sure further optimization is certainly possible.\nAfter this, it is time to use it as client of SemanticKernel SDK. Below is the test case for chat completion service,\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [Fact] public async void TestChatGenerationviaSK() { var ollamachat = ServiceProvider.GetChatCompletionService(); // semantic kernel builder var builder = Kernel.CreateBuilder(); builder.Services.AddKeyedSingleton\u0026lt;IChatCompletionService\u0026gt;(\u0026#34;ollamaChat\u0026#34;, ollamachat); // builder.Services.AddKeyedSingleton\u0026lt;ITextGenerationService\u0026gt;(\u0026#34;ollamaText\u0026#34;, ollamaText); var kernel = builder.Build(); // chat generation var chatGen = kernel.GetRequiredService\u0026lt;IChatCompletionService\u0026gt;(); ChatHistory chat = new(\u0026#34;You are an AI assistant that helps people find information.\u0026#34;); chat.AddUserMessage(\u0026#34;What is Sixth Sense?\u0026#34;); var answer = await chatGen.GetChatMessageContentAsync(chat); Assert.NotNull(answer); Assert.NotEmpty(answer.Content!); System.Diagnostics.Debug.WriteLine(answer.Content! } Full Source code of this post is available here.\nSummary Local AI combined with Retrieval Augmented Generation is powerful combination that any one get started with without need for subscriptions while conserving data privacy. Next step in this is to Use RAG for augmenting the results using enterprise/private data.\nHappy Coding !!\nHelpful Links Demystifying Retrieval Augmented Generation with .NET Gemma, ollama and Langchaingo ","permalink":"http://localhost:1313/posts/ollamasemantickernel/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eArtificial Intelligence, especially Large language models (LLMs) are all in high demand. Since OpenAI released ChatGPT, interest has gone up multi-fold. Since 2023, Powerful LLMs can be run on local machines. Local Large Language Models  offer advantages in terms of data privacy and security and can be enriched using enterprise-specific data using Retrieval augmentation generation (RAG).Several tools exist that make it relatively easy to obtain, run and manage such models locally on our machines. Few examples are \u003ca href=https://ollama.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOllama\u003c/a\u003e, \u003ca href=https://github.com/hwchase17/langchain\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLangchain\u003c/a\u003e,  \u003ca href=localai.io\n    \n    \n\u003eLocalAI\u003c/a\u003e.\u003c/p\u003e","title":"Using local LLM with Ollama and Semantic Kernel"},{"content":"Java Language Articles, E-books Getting Started with Java in 2023 Finding Java Thread Leaks With JDK Flight Recorder and a Bit Of SQL ","permalink":"http://localhost:1313/links/java/","summary":"\u003ch2 id=\"java-language\"\u003eJava Language\u003c/h2\u003e\n\u003ch3 id=\"articles-e-books\"\u003eArticles, E-books\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.morling.dev/blog/getting-started-with-java-development-2023/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGetting Started with Java in 2023\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.morling.dev/blog/finding-java-thread-leaks-with-jdk-flight-recorder-and-bit-of-sql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFinding Java Thread Leaks With JDK Flight Recorder and a Bit Of SQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages - Java"},{"content":"Background Ever encountered a scenario where REST API consumption works from tools like curl, Web Browser but not from Application. Lets dive in.\nThe requirement is as simple as consuming REST API from a Application over TLS.\nProblem Statement The REST API, to be consumed, is standard API interface which requires access over TLS. The client in this case is Windows 2016 server.\nDuring Development, Windows 10 is used to develop and test the code. Later, the same is tested on a Windows 2016 Server. It is at this stage, it fails with cryptic Error \u0026ldquo;The request was aborted: Could not create SSL/TLS secure channel\u0026rdquo;. But it works fine with other tools like curl, PostMan or even from a Web Browser.\nNetwork trace log from Application Causal Analysis Given that this error was related TLS/SSL and it is standard across platforms. What could be the reason for this behavior? With not much luck with Application level trace, its time to take help of Wireshark. If you are new to Wireshark then refer to this excellent write-up by Julia Evans.\nSo, i used wireshark during test from CURL as well as from the Application and below is what is shows,\nUsing CURL List of Ciphers Exchanged during \u0026#39;Client Hello\u0026#39; Cipher returned by Server during \u0026#39;Server Hello\u0026#39; With CURl, TLS handshare happens as intended and API works as expected.\nVia Application Below is list of ciphers exchanged and list is considerably short compared to earlier.\nList of Ciphers Exchanged during \u0026#39;Client Hello\u0026#39; Below is error logged\nTLS handshake Error To understand this behavior, Let\u0026rsquo;s do a quick primer.\nThere are many implementations of TLS/SSL (a.k.a. Security service providers) available across platforms. Notably,\nNetwork Security Services This is used by browsers like Firefox\nLibreSSL - Used by Chrome, curl (in ready-to-use build, refer here)\nRefer here for nice comparison of various implementations in summary format.\n`Microsoft Windows has its own Implementation called Windows SSPI (a.k.a. schannel SSPI). As per TLS/SSL Overview,\nSchannel is a Security Support Provider (SSP) that implements the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) Internet standard authentication protocols. Microsoft Windows and development platforms like .NET use this implementation by default. Via this provider it is possible for Administrators to enforce policies like restrict version of TLS, usage of ciphers and so on. Note that, as part of Security/Compliance requirements, It is often necessary to have these policies enforced and this is exactly what was done.\nBelow is Sample C# code using BouncyCastle (alternate library for cryptography)\nWrap up Hence, the resolution for this could be,\nMake sure that Server hosting the API complies with any of the ciphers allowed on the client. In case if this is not possible then , Cipher restrictions on the client will have to be modified (assuming its within the requirement for Compliance). Useful References, 1 - CURL using OpenSSL in default build\nHappy Troubleshooting !!\n","permalink":"http://localhost:1313/posts/tlshandsharefailure/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eEver encountered a scenario where REST API consumption works from tools like \u003ca href=https://github.com/jeroen/curl\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ecurl\u003c/a\u003e, Web Browser but not from Application. Lets dive in.\u003c/p\u003e\n\u003cp\u003eThe requirement is as simple as consuming REST API from a Application over TLS.\u003c/p\u003e\n\u003ch2 id=\"problem-statement\"\u003eProblem Statement\u003c/h2\u003e\n\u003cp\u003eThe REST API, to be consumed, is standard API interface which requires access over TLS. The client in this case is Windows 2016 server.\u003c/p\u003e\n\u003cp\u003eDuring Development, Windows 10 is used to develop and test the code. Later, the same is tested on a Windows 2016 Server. It is at this stage, it fails with cryptic Error \u0026ldquo;The request was aborted: Could not create SSL/TLS secure channel\u0026rdquo;. But it works fine with other tools like curl, PostMan or even from a Web Browser.\u003c/p\u003e","title":"Troubleshooting TLS handshake issue"},{"content":"Background A Client has E-commerce Application consisting of services aimed at specific domains of business functionality it serves. One of these services is responsible for accepting the order, authenticating it and forwarding it for further processing in terms of inventory checks, payment and so on. For Authentication, this service sends SMS to Customer\u0026rsquo;s Mobile number (and e-mail id) and customer is supposed to confirm this order placement by means of entering Code received in it. This code is valid for a short duration.\nThe requirement is to add a URL to this SMS which customer can use to view the order and confirm it on Mobile itself.\nFor above, there are constraints like,\nService is expected to trigger SMS, with required content like code, URL Etc., instantaneously. This is because time-bound action is expected from customer post receiving this SMS. SMS Message size restrictions to be taken into consideration while adding URL to it (since it already has other content in it). Implementation details Given the size restrictions on SMS, a URL need to be as short as possible. Hence, URL Shortener will have to be used which reduces length of overall URL. Additionally, very low latency is expected while preparing content of SMS and sending the same (by calling Telecom Service Provider\u0026rsquo;s API) hence external services like Bitly are most probably not useful. This is because the whole response time will then be tied to performance, up-time of this external service. Better alternative is to generate short / nano ID within Service itself. This will work assuming appropriate short domain (like t.me or youtu.be etc.) is available.\nBelow are the alternatives to generate short id within the Service,\nNanoid HashIds Base62 algorithm One can choose any of the above considering tolerance for Collision. With Nanoid, one can check extent to which length can be reduced while avoiding collision using this Calculator.\nThis approach helps with,\nEncapsulation - Keeping logic of short id generation, logging it in storage (ie. database), and responding to request for URL containing this short id within service itself. Keep external dependencies to minimum as much as possible so as to have better control over latency/throughput and easier monitoring. Useful References Why Nanoids by Planetscale Building highly reliable Web sites System Designer’s Interview - Insider’s Guide - Has Nice chapter on URL Shorteners Happy Coding !!\n","permalink":"http://localhost:1313/posts/shortidgeneration/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eA Client has E-commerce Application consisting of services aimed at specific domains of business functionality it serves. One of these services is responsible for accepting the order, authenticating it and forwarding it for further processing in terms of inventory checks, payment and so on. For  Authentication, this service sends \u003ca href=https://en.wikipedia.org/wiki/SMS\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSMS\u003c/a\u003e to Customer\u0026rsquo;s  Mobile number (and e-mail id) and customer is supposed to confirm this order placement by means of entering Code received in it. This code is valid for a short duration.\u003c/p\u003e","title":"URL Shortener in High Throughput Service"},{"content":"Background How Nuke Helps Summary Key Advantages of Nuke are,\nC# based DSL to compose build pipeline Build pipeline is part of solution (i.e. actual code) display a dependency graph logging support for lot of CI/CD helper tools Useful References, Nuke - Documentation Cake Fake Happy Code building !!\n","permalink":"http://localhost:1313/posts/nukebuildautomation/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003ch2 id=\"how-nuke-helps\"\u003eHow Nuke Helps\u003c/h2\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eKey Advantages of Nuke are,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eC# based DSL to compose build pipeline\u003c/li\u003e\n\u003cli\u003eBuild pipeline is part of solution (i.e. actual code)\u003c/li\u003e\n\u003cli\u003edisplay a dependency graph\u003c/li\u003e\n\u003cli\u003elogging\u003c/li\u003e\n\u003cli\u003esupport for lot of CI/CD helper tools\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"useful-references\"\u003eUseful References,\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.nuke.build/docs/getting-started/philosophy.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNuke - Documentation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/cake-build/cake\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCake\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fake.build/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFake\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHappy Code building !!\u003c/p\u003e\n\u003chr\u003e\n\u003cscript src=\"https://utteranc.es/client.js\" repo=\"sachinsu/sachinsu.github.io\" issue-term=\"title\" label=\"blogcomment\"\n    theme=\"github-light\" crossorigin=\"anonymous\" async\u003e\u003c/script\u003e","title":"Nuke as Build Automation tool for .NET projects"},{"content":"PostgreSQL General Articles Mistakes to avoid while using PostgreSQL Free Postgres database (or SQLite) from fly.io Using generate_series feature for reporting When Postgres blocks: 7 tips for dealing with locks PostgreSQL - Don’t do this Is PostgreSQL good enough? Online event processing by Martin Klepmann PostgreSQL rocks, except when it blocks: Understanding locks Connection handling best practice with PostgreSQL 10 Things I Hate About PostgreSQL PostgreSQL - Advanced Administration by Bruce Momjian Top Tools and Recommendations to Manage Postgres in an Enterprise: Administration, Performance, High Availability, and Migration Using PostgreSQL as Cache and Read Optimization tips Adyen’s Use of PostgreSQL PostgreSQL version Upgrade @ Gitlab Zombodb - PostgreSQL and ElasticSearch work together Using pg_timetable for job scheduling Using pg_cron to schedule background tasks Using pg_cron to roll up for Analytics PG Database Configuration Helper Full text search in PostgreSQL Postgres full text search capabilities Full text search (Crunchydata) PostgreSQL - Best practices(Azure) Designing high performance time series data table in (RDS) postgresql while using BRIN Index Informative blog on PostgreSQL Understanding GIN indexes PostgreSQL - Using SQL for Data Analysis Approach to Bulk Import in PostGreSQL Schema updates with zero downtime in PostgreSQL How to JSON in PostgreSQL Grouping, Rollups and Cubes Row level Security Just use postgres Performance tuning, configuration etc. pgassistant - insights into database behavior, identifies schema-related issues, and assists in correcting them Partitioning as Query Optimization Strategy Database Configuration Builder Configuration for Diagnosing Performance issues OrioleDB- Solving Wicked problems of PostgreSQL 5 Minutes in PostgreSQL - Videos PostgreSQL Tips Optimizing AutoVaccum in Postgresql 10 Things i hate about PostgreSQL Various index types and their usage Few gotchas for Application Developers Five tips for healthy PostgreSQL database Make PostgreSQL healthy and speedy Diagnose Linux related Disk \u0026amp;amp; RAM issues PostgreSQL database configuration tuning advicer Database configuration for Web Services Online explain analyzer \u0026amp;amp; Generally Good Blog on PostgreSQL Vertically scaling PostgreSQL How PostgreSQL Query Optimizer works A Performance Dashboard Simple script to analyse your PostgreSQL database configuration, and give tuning advice Tuning PostgreSQL for High Write Throughput Postgres is a great pub/sub \u0026amp;amp; job server PostgreSQL - Optimize Configuration Be careful with CTE in PostgreSQL Per core Connection limit guidance for EDB PostgreSQL - Claim unused Index size PgBadger - A fast PostgreSQL Log Analyzer Using CTE to perform binary search on table Top tools to manage PostgreSQL Performance Impact of idle Postgresql connections (usage of Pgbench) How to Manage Connections Efficiently in Postgres, or Any Database How to Audit PostgreSQL Database SQL Optimizations in PostgreSQL: IN vs EXISTS vs ANY/ALL vs JOIN PostgreSQL Scaling advice in 2021 Security Hardening for PostgreSQL Working with Postgres @ Zerodha Using PostgreSQL for Data warehouse Testing PG High availability with Patroni Comparison of PostgreSQL Monitoring tools Using Timeout feature of PostgreSQL Benchmarking bulk data ingestion in PostgreSQL All about indexes in PostgreSQL Use cases for Partitioning Asynchronous Commits for faster data loading Push style Notifications and Background Queue Processing using Listen/Notify and skiplocked Queues in PostgreSQL How postgresql stores data on disk Using Postgresql for job queueing and lessons learned Interesting Extensions/Products Using duckdb and postgres together Collection of Postgresql related tools PostgreSql based Message queue End-to-end machine learning solution Incrementally update Materialized Views in real-time using Materialize Artificial Intelligence with PostgreSQL Materialize - Incrementally-updated materialized views - in ANSI Standard SQL and in real time. pg_bulkload - pg_bulkload is a high speed data loading tool for PostgreSQL. pgcenter - Command-line admin tool for observing and troubleshooting Postgres. TOTP implementation in PLPGSQL Connection pooler - Odyssey Connection pooler - PGBouncer Setting up Multiple pgBouncer Instances Connection pooler and much more - Pgpool-II Change data capture in PostgreSQL Swarm64 DA -20x faster PostgreSQL query performance Greenplum - data warehouse, based on PostgreSQL Apache Age - graph database functionality for PostgreSQL Distributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres. Supabase -Listen to PG changes in real time without using Listen/Notify Job queues, Single reader and pub/sub Use cases for scaling out PostgreSQL - Citus Database lab Engine - Fast cloning of Database for dev/QA/staging PGSync - Sync data from one Postgres database to another Neon - Serverless Open source PostgreSQL Push PG Listen/Notify events over Websockets Generate ERD using D2 Diagrams Mathesar - Spreadsheet-like Web interface for PostgreSQL Migration to PostgreSQL Migration Guide from Oracle to PostgreSQL Lessons while migrating from Oracle to PostgreSQL Reshape - easy-to-use, zero-downtime schema migration tool Migra - diff tool for PostgreSQL Schema pgroll: PostgreSQL zero-downtime migrations made easy reshape: An easy-to-use, zero-downtime schema migration tool for Postgres High Availability Tools for Multi-Master Replication PostgreSQL Replication Distributed PostgreSQL Change Data Capture, Asynchronous change processing etc. Electric SQL - Mobile Local first sync layer with PostgreSQL PGQ - Queueing Solution PGQ - as used by Skype Bucardo - Asynchronous replication for PostgreSQL using Triggers Using Logical Decoding, Wal2json for CDC Webedia’s approach of using Customer processor (walparser) to read from Wal2JSON and CDC between PG and Elasticsearch Message queuing using native postgresql Queues in PostgreSQL Message queueing with native postgresql Using PGQ to invalidate caches pgstream- turns your database into an event stream Wal-listener CLI Postgres as Message Queue Data Privacy PgSodium - Interface to LibSodium from PostgreSQL including Server Key Management PostgreSQL Anonymizer - hides or replaces personally identifiable information (PII) Vector Embeddings Storing OpenAI embeddings in Postgres with pgvector Overview of pgVector Scalability and performance Scaling in PG Bulk import performance aspects Data Analysis Window functions for Data Analysis Data Synchronization, CDC Electric - Sync data from PostgreSQL Debezium - Stream changes from database ","permalink":"http://localhost:1313/links/postgresql/","summary":"\u003ch1 id=\"postgresql\"\u003ePostgreSQL\u003c/h1\u003e\n\u003ch2 id=\"general-articles\"\u003eGeneral Articles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://philbooth.me/blog/nine-ways-to-shoot-yourself-in-the-foot-with-postgresql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMistakes to avoid while using PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fly.io/blog/free-postgres/?utm_source\u0026#61;hackernewsletter\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_term\u0026#61;code\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFree Postgres database (or SQLite) from fly.io\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rob.conery.io/2018/08/01/simple-monthly-reports-in-postgresql-using-generate_series/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing generate_series feature for reporting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2018/02/22/seven-tips-for-dealing-with-postgres-locks/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhen Postgres blocks: 7 tips for dealing with locks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://wiki.postgresql.org/wiki/Don%27t_Do_This#Database_Encoding\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Don’t do this\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://renesd.blogspot.com/2017/02/is-postgresql-good-enough.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIs PostgreSQL good enough?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://queue.acm.org/detail.cfm?id\u0026#61;3321612\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOnline event processing by Martin Klepmann\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2018/02/15/when-postgresql-blocks/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL rocks, except when it blocks: Understanding locks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/connection-handling-best-practice-with-postgresql/ba-p/790883\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection handling best practice with PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@rbranson/10-things-i-hate-about-postgresql-20dbab8c2791\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 Things I Hate About PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://momjian.us/main/writings/pgsql/administration.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Advanced Administration by Bruce Momjian\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.enterprisedb.com/blog/top-tools-and-recommendations-manage-postgres-enterprise-administration-performance-high\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTop Tools and Recommendations to Manage Postgres in an Enterprise: Administration, Performance, High Availability, and Migration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://renesd.blogspot.com/2019/10/using-postgresql-as-cache.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing PostgreSQL as Cache and Read Optimization tips\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.adyen.com/blog/updating-a-50-terabyte-postgresql-database\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAdyen’s Use of PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://about.gitlab.com/blog/2020/09/11/gitlab-pg-upgrade/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL version Upgrade @ Gitlab\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.zombodb.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZombodb - PostgreSQL and ElasticSearch work together\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/products/pg_timetable/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing pg_timetable for job scheduling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/evolving-pg-cron-together-postgres-13-audit-log-background/ba-p/1829588\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing pg_cron to schedule background tasks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2017/12/27/real-time-analytics-dashboards-with-citus/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing pg_cron to roll up for Analytics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresqlco.nf/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePG Database Configuration Helper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://rachbelaid.com/postgres-full-text-search-is-good-enough/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFull text search in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://xata.io/blog/postgres-full-text-search-engine\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgres full text search capabilities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/postgres-full-text-search-a-search-engine-in-a-database\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFull text search (Crunchydata)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/postgresql/application-best-practices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Best practices(Azure)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/database/designing-high-performance-time-series-data-tables-on-amazon-rds-for-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesigning high performance time series data table in (RDS) postgresql while using BRIN Index\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://depesz.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInformative blog on PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pganalyze.com/blog/gin-index\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstanding GIN indexes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hakibenita.com/sql-for-data-analysis\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Using SQL for Data Analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/postgresql-bulk-loading-huge-amounts-of-data/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproach to Bulk Import in PostGreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fabianlindfors.se/blog/schema-migrations-in-postgres/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSchema updates with zero downtime in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ftisiot.net/postgresqljson/main/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to  JSON in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/postgresql-grouping-sets-rollup-cube/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGrouping, Rollups and Cubes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.tangramvision.com/blog/hands-on-with-postgresql-authorization-part-2-row-level-security\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRow level Security\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.amazingcto.com/postgres-for-everything/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJust use postgres\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"performance-tuning-configuration-etc\"\u003ePerformance tuning, configuration etc.\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/nexsol-technologies/pgassistant\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epgassistant - insights into database behavior, identifies schema-related issues, and assists in correcting them\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ashutoshpg.blogspot.com/2023/08/partitioning-as-query-optimization.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePartitioning as Query Optimization Strategy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgconfig.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase Configuration Builder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/blog/exposing-postgres-performance-secrets\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConfiguration for Diagnosing Performance issues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/AlexanderKorotkov/solving-postgresql-wicked-problems\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOrioleDB- Solving Wicked problems of PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/channel/UCDV_1Dz2Ixgl1nT_3DUZVFw/videos\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e5 Minutes in PostgreSQL - Videos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/postgres-tips\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL Tips\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2022/07/28/debugging-postgres-autovacuum-problems-13-tips/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOptimizing AutoVaccum in Postgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rbranson.medium.com/10-things-i-hate-about-postgresql-20dbab8c2791\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 Things i hate about PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/postgres-indexes-for-newbies?utm_source\u0026#61;hackernewsletter\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_term\u0026#61;data\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVarious index types and their usage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hagander.net/talks/PostgreSQL%20Gotchas%20for%20App%20Developers.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFew gotchas for Application Developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/five-tips-for-a-healthier-postgres-database-in-the-new-year\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFive tips for healthy PostgreSQL database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://info.crunchydata.com/blog/cleaning-up-your-postgres-database\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMake PostgreSQL healthy and speedy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.highgo.ca/2021/02/08/troubleshooting-performance-issues-due-to-disk-and-ram/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDiagnose Linux related Disk \u0026amp;amp; RAM issues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresqltuner.pl\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL database configuration tuning advicer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tightlycoupled.io/my-goto-postgres-configuration-for-web-services/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase configuration for Web Services\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://explain.depesz.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOnline explain analyzer \u0026amp;amp; Generally Good Blog on PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pgdash.io/blog/scaling-postgres.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVertically scaling PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/how-the-postgresql-query-optimizer-works/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow PostgreSQL Query Optimizer works\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ankane/pghero\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Performance Dashboard\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresqltuner.pl\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSimple script to analyse your PostgreSQL database configuration, and give tuning advice\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/GrantMcAlister/tuning-postgresql-for-high-write-throughput\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTuning PostgreSQL for High Write Throughput\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://webapp.io/blog/postgres-is-the-answer/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgres is a great pub/sub \u0026amp;amp; job server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresqlco.nf/en/doc/param/9275132/real-life-example-when-to-use-outer-cross-apply-in-sql/9275865#9275865\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Optimize Configuration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hakibenita.com/be-careful-with-cte-in-postgre-sql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBe careful with CTE in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://richyen.com/postgres/2021/09/03/less-is-more-max-connections.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePer core Connection limit guidance for EDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hakibenita.com/postgresql-unused-index-size\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL - Claim unused Index size\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/darold/pgbadger\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePgBadger - A fast PostgreSQL Log Analyzer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.endpoint.com/blog/2020/10/02/postgresql-binary-search-correlated-data-cte\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing CTE to perform binary search on table\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.enterprisedb.com/blog/top-tools-manage-postgres-enterprise-administration-performance-high-availability-and\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTop tools to manage PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/database/performance-impact-of-idle-postgresql-connections/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePerformance Impact of idle Postgresql connections (usage of Pgbench)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://brandur.org/postgres-connections\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to Manage Connections Efficiently in Postgres, or Any Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://severalnines.com/database-blog/how-to-audit-postgresql-database\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to Audit PostgreSQL Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2020/04/16/sql-optimizations-in-postgresql-in-vs-exists-vs-any-all-vs-join/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Optimizations in PostgreSQL: IN vs EXISTS vs ANY/ALL vs JOIN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/postgres-scaling-advice-for-2021/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL Scaling advice in 2021\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://goteleport.com/blog/securing-postgres-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSecurity Hardening for PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://zerodha.tech/blog/working-with-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWorking with Postgres @ Zerodha\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.narrator.ai/blog/using-postgresql-as-a-data-warehouse/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing PostgreSQL for Data warehouse\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2021/06/11/postgresql-ha-with-patroni-your-turn-to-test-failure-scenarios/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTesting PG High availability with Patroni\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sematext.com/blog/postgresql-monitoring/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComparison of PostgreSQL Monitoring tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/control-runaway-postgres-queries-with-statement-timeout\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Timeout feature of PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/database/speed-up-time-series-data-ingestion-by-partitioning-tables-on-amazon-rds-for-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenchmarking bulk data ingestion in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pganalyze.com/blog/postgres-create-index\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAll about indexes in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.anayrat.info/en/2021/09/01/partitioning-use-cases-with-postgresql/#storage-tiering\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse cases for Partitioning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2020/08/21/postgresql-synchronous_commit-options-and-synchronous-standby-replication/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsynchronous Commits for faster data loading\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.enterprisedb.com/blog/listening-postgres-how-listen-and-notify-syntax-promote-high-availability-application-layer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePush style Notifications and Background Queue Processing using Listen/Notify and skiplocked\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;WIRy1Ws47ic\u0026amp;list\u0026#61;PLlrxD0HtieHjSzUZYCMvqffEU5jykfPTd\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQueues in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://drew.silcock.dev/blog/how-postgres-stores-data-on-disk/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow postgresql stores data on disk\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.rudderstack.com/blog/scaling-postgres-queue/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Postgresql for job queueing and lessons learned\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"interesting-extensionsproducts\"\u003eInteresting Extensions/Products\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://motherduck.com/blog/postgres-duckdb-options\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing duckdb and postgres together\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gist.github.com/cpursley/c8fb81fe8a7e5df038158bdfe0f06dbb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of Postgresql related tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tembo-io/pgmq\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSql based Message queue\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgresml.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEnd-to-end machine learning solution\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://materialize.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIncrementally update Materialized Views in real-time using Materialize\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://momjian.us/main/writings/pgsql/AI.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArtificial Intelligence with PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://materialize.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMaterialize - Incrementally-updated materialized views - in ANSI Standard SQL and in real time.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ossc-db/pg_bulkload\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epg_bulkload - pg_bulkload is a high speed data loading tool for PostgreSQL.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/lesovsky/pgcenter\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epgcenter - Command-line admin tool for observing and troubleshooting Postgres.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/pyramation/totp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTOTP implementation in PLPGSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/yandex/odyssey\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection pooler - Odyssey\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgbouncer.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection pooler - PGBouncer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.2ndquadrant.com/en/blog/running-multiple-pgbouncer-instances-with-systemd/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSetting up Multiple pgBouncer Instances\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgpool.net/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection pooler and much more - Pgpool-II\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/change-data-capture-in-postgres-how-to-use-logical-decoding-and/ba-p/1396421e\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChange data capture in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://swarm64.com/swarm64-da/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSwarm64 DA -20x faster PostgreSQL query performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/greenplum-db/gpdb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGreenplum - data warehouse, based on PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://age.apache.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApache Age - graph database functionality for PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/knadh/sql-jobber\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/supabase/realtime\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSupabase -Listen to PG changes in real time without using Listen/Notify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://spin.atomicobject.com/2021/02/04/redis-postgresql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJob queues, Single reader and pub/sub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/when-to-use-hyperscale-citus-to-scale-out-postgres/ba-p/1958269\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse cases for scaling out PostgreSQL - Citus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://postgres.ai/products/how-it-works\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase lab Engine - Fast cloning of Database for dev/QA/staging\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ankane/pgsync\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePGSync - Sync data from one Postgres database to another\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/neondatabase/neon\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNeon - Serverless Open source PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/CrunchyData/pg_eventserv\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePush PG Listen/Notify events over Websockets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/zekenie/d2-erd-from-postgres\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGenerate ERD using D2 Diagrams\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/centerofci/mathesar\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMathesar - Spreadsheet-like Web interface for PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"migration-to-postgresql\"\u003eMigration to PostgreSQL\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/new-oracle-to-postgres-migration-guide-for-azure/ba-p/2055303\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMigration Guide from Oracle to PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cybertec-postgresql.com/en/building-an-oracle-to-postgresql-migrator-lessons-learned/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLessons while migrating from Oracle to PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/fabianlindfors/reshape\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReshape - easy-to-use, zero-downtime schema migration tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/djrobstep/migra\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMigra - diff tool for PostgreSQL Schema\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/xataio/pgroll\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epgroll: PostgreSQL zero-downtime migrations made easy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/fabianlindfors/reshape\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ereshape: An easy-to-use, zero-downtime schema migration tool for Postgres\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"high-availability\"\u003eHigh Availability\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://wiki.postgresql.org/wiki/Replication,_Clustering,_and_Connection_Pooling\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTools for Multi-Master Replication\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;jPp4XIY4XRw\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL Replication\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/blog/an-overview-of-distributed-postgresql-architectures\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"change-data-capture-asynchronous-change-processing-etc\"\u003eChange Data Capture, Asynchronous change processing etc.\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://electric-sql.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eElectric SQL - Mobile Local first sync layer with PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://wiki.postgresql.org/wiki/PGQ_Tutorial\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePGQ - Queueing Solution\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgcon.org/2009/schedule/attachments/91_pgq.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePGQ - as used by Skype\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://bucardo.org/Bucardo/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBucardo - Asynchronous replication for PostgreSQL using Triggers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/azure-database-for-postgresql/change-data-capture-in-postgres-how-to-use-logical-decoding-and/ba-p/1396421\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Logical Decoding, Wal2json for CDC\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.postgresql.eu/events/pgconfeu2019/sessions/session/2651/slides/237/Deploy%20your%20own%20replication%20system%20with%20Wal2json.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWebedia’s approach of using Customer processor (walparser) to read from Wal2JSON and  CDC between PG and Elasticsearch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/message-queuing-using-native-postgresql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMessage queuing using native postgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.pgcon.org/2016/schedule/attachments/414_queues-pgcon-2016.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQueues in PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.crunchydata.com/blog/message-queuing-using-native-postgresql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMessage queueing with native postgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hagander.net/talks/cache_invalidation_2014.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing PGQ to invalidate caches\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tmc/pqstream\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003epgstream- turns your  database into an event stream\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ihippik/wal-listener\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWal-listener CLI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dagster.io/blog/skip-kafka-use-postgres-message-queue\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgres as Message Queue\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-privacy\"\u003eData Privacy\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/michelp/pgsodium\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePgSodium - Interface to LibSodium from PostgreSQL including Server Key Management\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.postgresql.org/about/news/postgresql-anonymizer-10-privacy-by-design-for-postgres-2452/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePostgreSQL Anonymizer -  hides or replaces personally identifiable information (PII)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"vector-embeddings\"\u003eVector Embeddings\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://supabase.com/blog/openai-embeddings-postgres-vector\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStoring OpenAI embeddings in Postgres with pgvector\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jkatz05.com/post/postgres/pgvector-overview-0.5.0/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOverview of pgVector\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"scalability-and-performance\"\u003eScalability and performance\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.postgresql.org/docs/current/populate.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling in PG\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.postgresql.org/docs/current/populate.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBulk import performance aspects\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-analysis\"\u003eData Analysis\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/blog/window-functions-for-data-analysis-with-postgres\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWindow functions for Data Analysis\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-synchronization-cdc\"\u003eData Synchronization, CDC\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://electric-sql.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eElectric - Sync data from PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://debezium.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDebezium - Stream changes from database\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"PostgreSQL"},{"content":"Introduction While embarking on building any new server application, one of the key requirement is whether it needs durable, persistent storage of data (and in most cases, it does). This is followed by evaluating suitable data store. Likely evaluation criteria is Application\u0026rsquo;s Requirement (Tolerance for eventual consistency, High Availability etc.), Team\u0026rsquo;s familiarity, Costs, Tech. support availability and so on. In case of choices in relational databases, typical go to options are MySQL, PostgreSQL or even proprietary databases like Oracle , SQL Server. Seldom one considers SQLite for this purpose.\nAt the outset, SQLite is well-known as file-based database used in specific use cases like software running on peripheral/low resource devices such as Mobiles, tablets or in browsers for intermediate storage.Recently, i came across session by Ben Johnson on using SQLite in production. In the Video, it is mentioned that SQLite can potentially be used for server applications having 100s of concurrent requests.\nIn SQLite, There can only be a single writer at a time. However, it supports concurrency by allowing multiple connections to be opened to database and it internally serializes the write requests. This limitation (of single writer) was addressed by means of implementing Write ahead log. In this, where transactions are first written to a separate file (called \u0026rsquo;log\u0026rsquo; file) and then moved to database on commit. When WAL Mode is used, it supports much better concurrent reads and writes to the database.\nLets check if SQLite can really be considered for non-trivial, server based applications.\nCode To have proof of concept (POC) to simulate typical real world use case, lets expose HTTP based API using Go as below,\nimport ( \u0026#34;database/sql\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/rs/xid\u0026#34; _ \u0026#34;modernc.org/sqlite\u0026#34; ) const dbfilepath string = \u0026#34;./foo.db\u0026#34; const params string = \u0026#34;?_pragma=busy_timeout%3d5000\u0026amp;_pragma=journal_mode%3dwal\u0026#34; // Open opens the database connection. func Open(dsn string) (*sql.DB, error) { db, err := sql.Open(\u0026#34;SQLite\u0026#34;, dsn) if err != nil { log.Fatal(err) return nil, err } // setting this to higher number (i.e.\u0026gt; 1) not only causes constraint violation (probably because the way isolation works in SQLite over same and diff. connections) and but also degrades performances db.SetMaxOpenConns(runtime.NumCPU()) return db, nil } We will use ModernC SQLite library which is CGO free port of SQLite. However, there are other libraries listed here\nNext,we have HTTP handler which exposes POST end point and writes data to SQLite database,\nfunc main() { err := setUpDB() if err != nil { log.Println(\u0026#34;Error while setting up database\u0026#34;) return } db, err := Open(dbfilepath + params) if err != nil { log.Printf(\u0026#34;%q: %s\\n\u0026#34;, err, dbfilepath+params) return } defer db.Close() mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/Addfoo\u0026#34;, FooHandler(db)) log.Println(\u0026#34;Listening on :3000...\u0026#34;) err = http.ListenAndServe(\u0026#34;:3000\u0026#34;, mux) log.Fatal(err) } func genXid() string { guid := xid.New() return guid.String() } func FooHandler(db *sql.DB) func(http.ResponseWriter, *http.Request) { return func(w http.ResponseWriter, r *http.Request) { if r.URL.Path != \u0026#34;/Addfoo\u0026#34; { http.NotFound(w, r) return } switch r.Method { case http.MethodGet: // Handle the GET request... http.Error(w, \u0026#34;method not allowed\u0026#34;, http.StatusMethodNotAllowed) case http.MethodPost: // Handle the POST request... tx, err := db.Begin() if err != nil { log.Printf(\u0026#34;begin. Exec error=%s\\n\u0026#34;, err) return } defer tx.Commit() // intVal := randomSeed.Int63() uid := genXid() _, err = tx.Exec(fmt.Sprintf(\u0026#34;insert into Foo(id, Name) values(\u0026#39;%s\u0026#39;,\u0026#39;name-%s\u0026#39;)\u0026#34;, uid, uid)) if err != nil { log.Printf(\u0026#34;Error inserting record -\u0026gt; %s\\t%s\\n\u0026#34;, err.Error(), strings.HasSuffix(err.Error(), \u0026#34;(SQLite_BUSY)\u0026#34;)) http.Error(w, \u0026#34;Internal Error\u0026#34;, http.StatusInternalServerError) return } w.WriteHeader(http.StatusCreated) case http.MethodOptions: w.Header().Set(\u0026#34;Allow\u0026#34;, \u0026#34;GET, POST, OPTIONS\u0026#34;) w.WriteHeader(http.StatusNoContent) default: w.Header().Set(\u0026#34;Allow\u0026#34;, \u0026#34;GET, POST, OPTIONS\u0026#34;) http.Error(w, \u0026#34;method not allowed\u0026#34;, http.StatusMethodNotAllowed) } } } Above is simple HTTP handler function which is invoked on call to /Addfoo endpoint and adds a record to a table in database.\nNext is to check throughput provided by this HTTP API. We can use benchmarking tool for this purpose. It generates a load against API and records the response times, errors and so on and presents analysis based on it. One such tool is Bombardier and there are others like wrk, wrk2 and so on. I used Bombardier primarily because it is cross-platform (Golang based) and works on Windows, which i am using to conduct this POC.\nFirst, application is started as go run . which starts the HTTP server, ready to receive requests.\nNext is to use Bombardier to assess throughput of the API,\nWith limit of 100 requests per second, result shows, average latency of 2.23ms with no errors thrown Database has around 1252 records. bombardier.exe -m POST -l -r 100 http://localhost:3000/Addfoo Bombarding http://localhost:3000/Addfoo for 10s using 125 connection(s) [===========================================================================================================================================================] 10s Done! Statistics Avg Stdev Max Reqs/sec 99.96 32.72 254.39 Latency 2.23ms 4.39ms 119.61ms Latency Distribution 50% 1.72ms 75% 2.32ms 90% 3.12ms 95% 3.31ms 99% 4.44ms HTTP codes: 1xx - 0, 2xx - 1001, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 21.20KB/s With limit of 100 requests per second, result shows, average latency of 2.23ms with no errors thrown Database has around 1252 records. bombardier.exe -m POST -l -r 100 http://localhost:3000/Addfoo Bombarding http://localhost:3000/Addfoo for 10s using 125 connection(s) [===========================================================================================================================================================] 10s Done! Statistics Avg Stdev Max Reqs/sec 99.96 32.72 254.39 Latency 2.23ms 4.39ms 119.61ms Latency Distribution 50% 1.72ms 75% 2.32ms 90% 3.12ms 95% 3.31ms 99% 4.44ms HTTP codes: 1xx - 0, 2xx - 1001, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 21.20KB/s With limit of 1000 requests per second, Latency has gone up 15x Still no error reported and database has additional records. bombardier.exe -m POST -l -r 1000 http://localhost:3000/Addfoo Bombarding http://localhost:3000/Addfoo for 10s using 125 connection(s) [===========================================================================================================================================================] 10s Done! Statistics Avg Stdev Max Reqs/sec 964.73 314.04 2149.94 Latency 30.05ms 80.20ms 1.48s Latency Distribution 50% 4.02ms 75% 16.00ms 90% 74.75ms 95% 155.30ms 99% 434.48ms HTTP codes: 1xx - 0, 2xx - 9670, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 202.72KB/s With limit of 4000 requests per second, it looks like below, bombardier.exe -m POST -l -r 4000 http://localhost:3000/Addfoo Bombarding http://localhost:3000/Addfoo for 10s using 125 connection(s) [===========================================================================================================================================================] 10s Done! Statistics Avg Stdev Max Reqs/sec 1304.49 688.92 2199.91 Latency 95.00ms 174.73ms 2.40s Latency Distribution 50% 35.00ms 75% 95.11ms 90% 228.16ms 95% 382.68ms 99% 1.02s HTTP codes: 1xx - 0, 2xx - 13186, 3xx - 0, 4xx - 0, 5xx - 0 others - 0 Throughput: 275.73KB/s Overall, above shows that,\nSQLite with WAL mode on and busy timeout set to 5 seconds can support high concurrency Above is very simplistic test, in real application it is likely going to be very different (i.e. most likely on the lower side of throughput) since there will be multiple connections reading and writing to not one but many tables concurrently. This is likely to impact throughput and latency. One of the factors on why better throughput is recorded could be because SQLite, being implemented as library, can be easily integrated with application and resides on same node/VM as application. This helps tremendously in avoiding network round trip and helps in much better performance. Refer to Martin Fowler\u0026rsquo;s First law Back to evaluating databases for a given use case and SQLite fits in ,\nCriteria Description SQLite ACID Guarantees Is Database expected to provide Strong Consistency guarantees? (this may not be required for every use case) Yes.Note that, there is no isolation between operations that occur within the same database connection. Data Durability Does Database maintain data in durable ,consistent way? Yes Reliability Does it provide reliable storage ? (Although storage reliability is not limited only to software and often depends on other factors like type of storage, associated hardware.) Yes Availability Is database highly available? SQLite being file based, availability is confined to the Node/VM on which it is running. It can be further enhanced using tools like, Litestream (which implements change data capture and syncs it with remote storage like AWS S3 or SFTP among others). rqlite is clustered database based on SQLite. network partition support Does database support partitioning of data? No. Being a file based data storage system, it is constrained on single node i.e. it can be scaled vertically. However, it can be setup in active + Stand-by backup mode using specific tools. Additionally, other databases (files on same node) can be attached to and accessed by application as one database. Tech. Support In case of FOSS software, is Community active in terms of releases/bug fixes as well as on discussion forums? Are their any providers who provide paid support? SQLite is mature database. Though, it is open source, it does not accept pull requests from anyone out side of core committers. Having said that, one has to check for availability of support in case things go north (corrupted database and so on.) Database features Support for Typical RDBMS features like Data types, User Management \u0026amp; Security, Stored procedures (but not triggers) etc. Refer here for detailed comparison of features across SQLite and populate RDBMSs. Hopefully, above provides good starting point in deciding database for your next application. As always, comments/suggestions are welcome.\nUseful References Limits in SQLite Consider SQLite SQLite has good support for JSON, read about it here SQLite as a document database, read about it here Interesting lists of extensions sqlite-utils - Collection of utilities including migration from MySQL/PostgreSQL Sqlite and Go by David Crawshaw Server side SQLite SQLite backup using Cron Happy Coding !!\n","permalink":"http://localhost:1313/posts/is_sqlite_production_ready/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWhile embarking on building any new server application, one of the key requirement is whether it needs durable, persistent storage of data (and in most cases, it does). This is followed by evaluating suitable data store. Likely evaluation criteria is Application\u0026rsquo;s Requirement (Tolerance for eventual consistency, High Availability etc.), Team\u0026rsquo;s familiarity, Costs, Tech. support availability and so on.\nIn case of choices in relational databases, typical go to options are MySQL, PostgreSQL or even proprietary databases like Oracle , SQL Server. Seldom one considers \u003ca href=https://SQLite.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQLite\u003c/a\u003e for this purpose.\u003c/p\u003e","title":"Can SQLite be considered for Server Applications?"},{"content":"Introduction We develop a piece of software with aim to fulfil specific business requirements in terms of resource usage, throughput, availability among others. Profiling and benchmarking are approaches that developer has in his/her arsenal to gain continuous feedback on whether a piece of code is behaving optimally and adhering to it\u0026rsquo;s objectives.\nLets look at what they mean,\nProfiling is defined as process aimed at understanding the behavior of a program. A profile result might be a table of time taken per function, as per this and this) Benchmarking measures the time for some whole operation. e.g. I/O operations per second under some workload. So the result is typically a single number, in either seconds or operations per second. Or a data set with results for different parameters, so you can graph it.. Refer this for more information. Also do check Benchmarking correctly is hard by Julia Evans. Typically, Profiling is supported by most of the environments (either via IDEs like Visual Studio or through language itself [Like Go] has buil-in provision for the same while Benchmarking is typically performed on dedicated testing infrastructure.\nIn this article, We will look at couple of tools in this space that can be easily integrated in developer\u0026rsquo;s workflow so as to get early feedback. Lets\u0026rsquo; go.\nProfiling Pyroscope is Open Source Application for profiling Application. It is a cross-language tool i.e. programs in variety of languages can be profiled using it. It works in client server model where in, - Client - Pyroscope executable runs the intended code (in languages like C#, Ruby) etc. (in case of Go, it is available as dependency) and collects instrumentation details to be sent to server. - Server - Runs as a separate process (on Linux [Works in WSL if using Windows] or Mac), collects the data from client processes and renders them as table and/or flame graph via Web UI.A flamegraph is a way to visualize resources used by a program, like CPU usage or memory allocations, and see which parts of your code were responsible.\nLets see how a function in C# can be instrumented using PyroScope.\nDevelop function to be profiled Lets have ASP.NET Core 5.0 based Web API as below, Simple Web API handler in C# Setup Pyroscope\nInstall Pyroscope Application by following instructions here for Windows. Note that, Pyroscope server component won\u0026rsquo;t run on Windows in which case either Windows Subsystem for Linux (WSL) or Docker can be used. In case of Linux, instructions provided here are sufficient for both client and server components.\nI have setup the application on Windows 10 while using WSL for Pyroscope Server.\nConfigure Pyroscope client and run the Application\nBuild the application using dotnet build\nConfigure below environment variables (below is powershell format or you can use SET ... commands on command prompt),\n``` $env:PYROSCOPE_SPY_NAME=\u0026quot;dotnetspy\u0026quot;; $env:PYROSCOPE_APPLICATION_NAME=\u0026quot;my.dotnet.app\u0026quot;; $env:PYROSCOPE_SERVER_ADDRESS=\u0026quot;http://localhost:4040\u0026quot;; ``` Update path to include pyroscope installation folder using $env:Path += \u0026quot;;C:\\Program Files\\Pyroscope\\Pyroscope Agent\\\u0026quot;\nRun the Application using pyroscope exec dotnet .\\bin\\Debug\\net5.0\\webapi.dll.\nRun Pyroscope Server\nStart Pyroscope server from WSL Linux prompt using, sudo pyroscope server. The output of this command should show Port on which server is running.\nEither use curl or hey tool to invoke the API. Below command shows how to generate load using hey, run .\\hey.exe -m GET -c 10 -q 2 http://localhost:5000/weatherforecast (Note: Modify the URL As appropriate) Observe the flame graph in Pyroscope Web UI.\nObserve the Table and/or flamegraph using Pyroscope Web interface. Below screenshot shows flamegraph for above code. Refer here and here for everything about flame graphs.\nTable and flamegraph for API Table and flamegraph for API Overall, Pyroscope provides easy way to observe Memory/CPU utilization as part of developer workflow on workstation itself. This is especially useful for development environments which do not provide profiling out of the box.\nBenchmarking Crank is tool used by Microsoft internally to benchmark applications. It is released as Nuget package and currently .NET based code or Docker Containers can be benchmarked using it. Lets see steps to benchmark .NET Application using Crank.\nWrite code, intended to be benchmarked. In this case, its very simple one as below,\nC# Code to be benchmarked Setup Crank\nFollow the instructions provided here to setup crank. Crank expects Configuration in YAML format which contains details like Job to be used. Crank has built-in jobs which are essentially wrappers around CLI load testing tools like bombardier and wrk and so on. Since i am using Windows to run crank, we will go with Bombardier which is cross platform. Below is how a basic configuration looks like,\nCrank YAML Configuration It allows for extensibility in terms of overriding the job configuration in terms of how load should be generated etc.\nRun Crank Agent - Next step is to run crank agent in a command prompt or powershell by simply running crank-agent\nRecord data for benchmarking using Crank CLI.\nNow run Crank from the application folder as crank --config crank.benchmarks.yml --scenario hello --profile local --application.options.displayOutput true\nThis command builds the code and launches job while recording the Utilization and other parameters and shows output like,\nApplication\u0026#39;s CPU Utilization Observations during executing load testing Overall, i found Crank helpful for following,\nit helps quickly test effect of any code changes by means of quickly benchmarking the application. The overall benchmarking might not be similar to end state ie. when the application will be deployed on target infrastructure. However, it still gives insights to developer about impact of code changes Crank can be easily used for local applications as well as for docker containers. It can either be used locally or in distributed manner. Useful References Pyroscope Crank Performance Anti-patterns Happy Profiling and Benchmarking !!\n","permalink":"http://localhost:1313/posts/profiling_n_benchmarking/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWe develop a piece of software with aim to fulfil specific business requirements in terms of resource usage, throughput, availability among others. Profiling and benchmarking are approaches that developer has in his/her arsenal to gain continuous feedback on whether a piece of code is behaving optimally and adhering to it\u0026rsquo;s objectives.\u003c/p\u003e\n\u003cp\u003eLets look at what they mean,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProfiling is defined as process \u003ccode\u003eaimed at  understanding the behavior of a program. A profile result might be a table of time taken per function,\u003c/code\u003e as per \u003ca href=https://stackoverflow.com/questions/34801622/difference-between-benchmarking-and-profiling\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ethis\u003c/a\u003e and \u003ca href=https://en.wikipedia.org/wiki/Profiling_%28computer_programming%29\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ethis\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eBenchmarking  \u003ccode\u003emeasures the time for some whole operation. e.g. I/O operations per second under some workload. So the result is typically a single number, in either seconds or operations per second. Or a data set with results for different parameters, so you can graph it.\u003c/code\u003e. Refer \u003ca href=https://en.wikipedia.org/wiki/Benchmark_%28computing%29\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ethis\u003c/a\u003e for more information. Also do check \u003ca href=https://jvns.ca/blog/2016/07/23/rigorous-benchmarking-in-reasonable-time/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenchmarking correctly is hard by Julia Evans\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTypically, Profiling is supported by most of the environments (either via IDEs like \u003ca href=https://docs.microsoft.com/en-us/visualstudio/profiling/profiling-feature-tour?view\u0026#61;vs-2022\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisual Studio\u003c/a\u003e or through language itself [Like \u003ca href=https://go.dev/blog/pprof\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo\u003c/a\u003e] has buil-in provision for the same while Benchmarking is typically performed on dedicated testing infrastructure.\u003c/p\u003e","title":"Profiling and benchmarking tools for Applications"},{"content":"Introduction I have been reading excellent Database Reliability Engineering book and below are my notes from it.\nKey Incentive(s) for Automation\nElimination of Toil - Toil is the kind of work tied to running a production service that tends to be manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly as a service grows. Important System Characteristics\nLatency, also known as response time, is a time-based measurement indicating how long it takes to receive a response from a request. It is best to measure this for end-to-end response from the customer rather than breaking it down component by component. This is customer-centric design and is crucial for any system that has customers, which is any system\nAvailability - This is generally expressed as a percentage of overall time the system is expected to be available. Availability is defined as the ability to return an expected response to the requesting client. Note that time is not considered here, which is why most SLOs include both response time and availability. After a certain latency point, the system can be considered unavailable even if the request is still completing. Availability is often denoted in percentages, such as 99.9% over a certain window. All samples within that window will be aggregated\nHigh availability - For any mission-critical data that you truly care about, you should avoid running with less than three live copies. That’s one primary and two-plus secondaries for leader-follower data stores like MySQL or MongoDB or a replication factor of three for distributed data stores like Cassandra or Hadoop. Because you never, ever want to find yourself in a situation in which you have a single copy of any data you care about, ever. This means that you need to be able to lose one instance while still maintaining redundancy, which is why three is a minimum number of copies, not two.\nInfrastructure engineering Virtualization * Hypervisor - A hypervisor or virtual machine monitor (VMM) can be software, firmware, or hardware. The hypervisor creates and runs VMs. A computer on which hypervisor runs one or more VMs is called a host machine, and each VM is called a guest machine. The hypervisor presents the guest operating systems with a virtual operating platform and manages the execution of the guest operating systems. Databases running within hypervisors show lower boundaries for concurrency than the same software on bare metal. When designing for these virtualized environments, the focus should be on a horizontally scaled approach, minimizing concurrency within nodes.\nStorage - Storage durability and performance are not what you would expect in the virtualized world. Between the page cache of your VM and the physical controller lies a virtual controller, the hypervisor, and the host’s page cache. This means increased latency for I/O. For writes, hypervisors do not honor calls in order to manage performance. This means that you cannot guarantee that your writes are flushed to disk when there is a crash.\nDatabase Servers\nPhysical servers - Recommended to have dedicated ones for database (and not shared) Why ? Much control with OS and more visibility May find redundant capacity on a dedicated hardware. Linux is not particularly optimized for database loads requiring low latency and high concurrency. The kernel is not predictable when it goes into reclaim mode, one of the best recommendations we can give is to simply ensure that you never fully use your physical memory by reserving it to avoid stalls and significant latency impacts. You can reserve this memory by not allocating it in configuration Storage\nCapacity - Single large disks are single points of failure, unless mirrored (RAID 1). RAID 0 will have its MTBF reduced by a factor of N, where N is the number of disks striped together.\nThroughput - When considering the needs, you must consider IOPS for the peak of a database’s workload rather than the average.\nLatency - Latency is the end-to-end client time of an I/O operation; in other words, the time elapsed between sending an I/O to storage and receiving an acknowledgement that the I/O read or write is complete.\nTransactional applications are sensitive to increased I/O latency and are good candidates for SSDs. You can maintain high IOPS while keeping latency down by maintaining a low queue length and a high number of IOPS available to the volume. Consistently driving more IOPS to a volume than it has available can cause increased I/O latency. Throughput-intensive applications like large MapReduce queries are less sensitive to increased I/O latency and are well-suited for HDD volumes. You can maintain high throughput to HDD-backed volumes by maintaining a high queue length when performing large, sequential I/O Availability - Plan for disk failures.\nDurability - When your database goes to commit data to physical disk with guarantees of durability, it issues an operating system call known as rather than relying on page cache flushing. An example of this is when a redo log or write-ahead log is being generated and must be truly written to disk to ensure recoverability of the database. Filesystem operations can also cause corruption and inconsistency during failure events, such as crashes. Journaling filesystems like XFS and EXT4 significantly reduce the possibility of such events, however.\nStorage Area Networks (SAN) vs. SSDs - Data snapshots and movement are some of the nicest features in modern infrastructures, where SSDs provide better IO than traditional SANs.\nRelational Database Internals\nIn Relational databases, data is stored in containers called blocks or pages that correspond to a specific number of bytes on disk. Different databases will use blocks or pages in their terminology. In this book, we use blocks to refer to both. Blocks are the finest level of granularity for storing records. Oracle Database stores data in data blocks. A page is a fixed size called a block, just like blocks on disks. Blocks are the smallest size that can be read or written to access data. This means that if a row is 1 K and the block size is 16 K, you will still incur a 16 K read operation. If a database block size is smaller than the filesystem block size, you will be wasting I/O for operations that require multiple pages. A block require some metadata to be stored, as well, usually in the form of a header and trailer or footer. This will include disk address information, information about the object the block belongs to, and information about the rows and activity that have occurred within that block.\nMost databases structure their data in a binary tree format, also known as B-tree. A B\u0002tree is a data structure that self-balances while keeping data sorted. The B-tree is optimized for the reading and writing of blocks of data, which is why B-trees are commonly found in databases and filesystems\nSummary of the attributes and benefits of B-trees: Excellent performance for range-based queries.\nNot the most ideal model for single-row lookups\nKeys exist in sorted order for efficient key lookups and range scans.\nStructure minimizes page reads for large datasets.\nBy not packing keys into each page, deletes and inserts are efficient, with only occasional splits and merges being needed.\nPerform much better if the entire structure can fit within memory.\nA crucial variable in configuring your databases for underlying storage is the database block size. We’ve discussed the importance of aligning database block sizes with the underlying disk block sizes, but that is not enough. If you are using Solid-State Drives (SSDs), for instance, you might find smaller block sizes provide much better performance while traversing B-trees. An SSD can experience a 30% to 40% latency penalty on larger blocks versus performance on Hard Disk Drives (HDDs). Because reads and writes are required in B-tree structures, this must be taken into account.\nNon-Relational Database Internals\nWhat is sorted-string tables (SST) storage engine? - It has a number of files, each with a set of sorted key–value pairs inside. Unlike in the block storage discussed earlier, there is no need for the metadata overhead at the block or row level. Keys and their values are opaque to the DBMS and stored as arbitrary binary large objects (BLOBs). Because they are stored in a sorted fashion, they can be read sequentially and treated as an index onthe key by which they are sorted.\nThere is an algorithm that combines in-memory tables, batch flushing, and periodic compaction in SST storage engines. This algorithm is referred to a log-structured merge (LSM) tree architecture\nA bloom filter is a data structure that you can use to evaluate whether a record key is present in a given set.\nDatabase Indexes\nHash indexes - A hash map is a collection of buckets that contain the results of a hash function applied to a key. That hash points to the location where the records can be found. A hash map is only viable for single-key lookups because a range scan would be prohibitively expensive. Bitmap Indexes - A bitmap index stores its data as bit arrays (bitmaps). When you traverse the index, it is done by performing bitwise logical operations on the bitmaps. In B-trees, the index performs the best on values that are not repeated often. This is also known as high cardinality. The bitmap index functions much better when there are a small number of values being indexed Replication\nTypes Synchronous - A transaction that is written to a log on the leader is shipped immediately over the network to the followers. The leader will not commit the transaction until the followers have confirmed that they have recorded the write. This ensures that every node in the cluster is at the same commit point. This means that reads will be consistent regardless of what node they come from, and any node can take over as a leader without risk of data loss if the current leader fails. On the other hand, network latency or degraded nodes can all cause write latency for the transaction on the leader.\nAsynchronous - A transaction is written to a log on the leader and then committed and flushed to disk. A separate process is responsible for shipping those logs to the followers, where they are applied as soon as possible. In asynchronous replication models, there is always some lag between what is committed on the leader and what is committed on the followers. Additionally, there is no guarantee that the commit point on one follower is the same as the others. In practice, the time gap between commit points might be too small to notice.\nSemi-synchronous - In this algorithm, only one node is required to confirm to the leader that they have recorded the write. This reduces the risk of latency impacts when one or more nodes are functioning in degraded states while guaranteeing that at least two nodes on the cluster are at the same commit point. In this mode, there is no longer a guarantee that all nodes in the cluster will return the same data if a read is issued on any reader.\nFormats used during Replication\nStatement based logs - the actual SQL or data write statement used to execute the write is recorded and shipped from the leader to followers. e.g. MySQL Write-ahead logs - A write-ahead log (WAL), also known as a redo log, contains a series of events, each event mapped to a transaction or write. In the log are all of the bytes required to apply a transaction to disk. In systems, such as PostgreSQL, that use this method, the same log is shipped directly to the followers for application to disk. Approaches\nRow based Replication - In row-based replication (also called logical), writes are written to replication logs on the leader as events indicating how individual table rows are changed. Columns with new data are indicated, columns with updated information show before/after images, and deletes of rows are indicated as well. Replicas use this data to directly modify the row rather than needing to execute the original statement.\nBlock level Replication - Block-level replication is synchronous and eliminates significant overhead in the replicated write. However, you cannot have a running database instance on the secon‐dary node. So, when a failover occurs, a database instance must be started. If the for‐mer master failed without a clean database shutdown, this instance will need to perform recovery just as if the instance had been restarted on the same node.\nMethods\nSingle Leader - (Simplest of replicated environments) All writes go to single leader and are replicated to other nodes. Advantages are that there will be no consistency conflicts. There are some variations like data getting replicated to only few followers which further replicate to remaining ones. By far the most common implementation of replication due to simplicity.\nMultiple Leaders - There are 2 approaches,\nThere are typically 2 leaders responsible for receiving writes and propagating them to replicas. each leader is located in different data centers/availability zones. Any node can take reads or writes at any time. More complex than Single Leader approach due to need for conflict resolution. Use cases,\nAvailability - In case of failover with Single Leader approach, impact may last from 30 seconds to minutes depending on how the system is designed. This is due to replication consistency checks, crash recovery and more such steps. This impact could be unacceptable. Locality - Application is requirement is such that it needs to cater to users in different regions with separate datacenters. This could be to for data protection purposes or to ensure low latency. Disaster Recovery - Highly critical application with need to have multiple data centers to ensure availability. Conflict resolution approaches,\nSharding - distribute range of primary keys across leaders Affinity - Specific users (by region, unique ID) are always redirected to specific leader Shard by Application layer ie. Application instance is deployed in each datacenter avoid need for active/active cross region replication Write anywhere- Any node can take read or write requests. Attributes typically associated with such systems are,\nEventual consistency - there is no guarantee that data is consistent across all nodes at any time, that data will eventually converge. Read \u0026amp; Write Quorum - It indicates minimum number of readers or writers necessary to guarantee consistency of data. Quorum of 2 in 3 node cluster means one node\u0026rsquo;s failure is tolerated. Formula: N is the number of nodes in a cluster.R is the number of read nodes available, and W is the number of write nodes. If R + W is greater than N, you have an effective quorum to guarantee at least one good read after a write. Sloppy quorums - Indicates situation when nodes are available but unable to meet quorum due to lack of data. Anti Entropy - Mechanism to keep data synchronized across nodes even in case of inactivity (i.e. no reads). Anti-entropy is critical for datastores that store a lot of cold, or infrequently accessed,data. Data governance is the management of the availability, integrity, and security of the data that an organization saves and uses. Intro‐duction of new data attributes is something that should be considered carefully and documented. The use of JSON for data storage allows new data attributes to be introduced too easily and even accidentally.\nImportant aspects in Infrastructure Architecture,\nRelaxed durability means data loss must be considered an inevitability. Instance instability means automation, failover, and recovery must be very reliable. Horizontal scale requires automation to manage significant numbers of servers. Applications must be able to tolerate latency instability. Infrastructure Management An immutable infrastructure is one that is not allowed to mutate, or change, after it has been deployed. If there are changes that must happen, they are done to the version controlled configuration definition, and the service is redeployed.In the interest of moderation and middle ground, there can be some mutations that are frequent, automated and predictable, and can be allowed in the environment. Manual changes are still prohibited, keeping a significant amount of the value of predictability and recoverability while minimizing operational overhead. , Packer allows you to create multiple images from the same configuration. This includes images for virtual machines on your workstation. Using a tool like Vagrant on your workstation allows you to download the latest images, build the VMs, and even run through a standard test suite to verify that everything works as expected.\nPacker is one such tool from Hashicorp that creates images. The interesting thing about Packer is that it can create images for different environments (such as Amazon EC2 or VMWare images) from the same configuration. Most configuration management utilities can create baked images as well. Service Discovery \u0026amp; Service catalog - Service discovery is an abstraction that maps specific designations and port numbers of your services and load balancers to semantic names. A service catalog can be very simple, storing service data to integrates services, or it can include numerous additional facilities, including health checks to ensure that data in the catalog provides working resources.\nIsolation of Network Traffic - Network traffic can be broken up in,\nInternode communications Application traffic Administrative traffic Backup and recovery traffic Isolation of traffic is one of the first steps to proper networking for your databases. You can do this via physical network interface cards (NICs), or by partitioning one NIC Data Security - Tracking every failed and successful SQL statement sent to database is critical for identifying SQL injection attacks. SQL syntax errors can be a leading indicator\nData Architecture\nFrontline Datastores - Historically, these systems have been referred to as OnLine Transactional Processing (OLTP) systems. They were characterized by a lot of quick transactions, and thus they were designed for very fast queries, data integrity in high concurrency, and scale based on the number of transactions they can handle concurrently. All data is expected to be real time with all of the necessary details to support the services using them. Each user or transaction is seeking a small subset of the data. This means query patterns tend to focus on finding and accessing a small, specific dataset within a large set. Effective indexing, isolation, and concurrency are critical for this, which is why it tends to be fulfilled by relational systems. Typical characteristics are, Low-latency writes and queries\nHigh availability\nLow Mean Time to Recover (MTTR)\nAbility to scale with application traffic\nEasy integration with application and operational services\nDatabase proxies - Sits between application and frontline datastores. It could be,\nLayer 4 (Networking transport layer) - Uses the information available at networking layer like destination IP Addresses to distribute the traffic. This type can not work with factors like load or replication lag while distributing traffic Layer 7 - Operates at higher level of networking transport layer. At this layer, proxy can include functionality like, Health checking and redirection to healthy servers Splitting of reads and writes to send reads to replicas Query rewriting to optimize queries that cannot be tuned in code Caching query results and returning them Redirecting traffic to replicas that are not lagged Generate metrics on queries Perform firewall filtering on query types or hosts Event and Messaging systems - Used for actions to be triggered after a transaction like,\nData must be put into downstream analytics and warehouses Orders must be fulfilled Fraud detection must review a transaction Data must be uploaded to caches or Content Delivery Networks (CDNs) Personalization options must be recalibrated and published Caches and Memory Store - Used to overcome slowness in Disk I/o. Approaches to putting data are,\nPutting data in cache after its been written to persistent data store Writing to cache and datastore at the same time (Fragile due to possibility of one of the store failing) Writing to cache first and then to datstore asynchronously (Write-through approach) Lambda Architecture - The Lambda architecture is designed to handle a significant volume of data that is processed rapidly to serve near-real-time requests, while also supporting long\u0002running computation. Lambda consists of three layers: batch processing, real-time processing, and a query layer.If data is written to a frontend datastore, you can use a distributed log such as Kafka to create a distributed and immutable log for the Lambda processing layers. Some data is written directly to log services rather than going through a datastore. The pro‐cessing layers ingest this data.\nKappa Architecture - Append only immutable log is used in this Architecture. Kappa architecture eliminates the batch processing system, with the expectation that the streaming system can handle all transformations and computations. One of the biggest values to Kappa is the reduction in complexity and operational expense of Lambda by eliminating the batch processing layer. It also aims to reduce the pain of migrations and reorganizations. When you want to reprocess data, you can start a reprocessing, test it, and switch over to it.\nApplication Architecture Patterns\nEvent sourcing pattern - Changes to entities are saved as sequence of state changes. When state changes, a new event is appended to the log. The datastore is called as event store. it maintains audit of life cycle of entity which helps in recreation or populating the tables in case of data loss. However, evolution of entity over period of time needs to be managed as it may invalidate previous events. It allows giving full historical access via API for auditing, reconstruction, and different transformations can provide significant benefits.\nCQRS - The driver for this is the idea that same data can be represented for consumption using multiple models or views. like Append only log for writes and read optimized data stores for queries.\nMonitoring and Observability Synthetic Monitoring - The case for synthetic monitoring is to provide coverage that is consistent and thorough. Users might come from different regions and be active at different times. This can cause blind spots if we are not monitoring all possible regions and code paths into our service. With synthetic monitoring, we are able to identify areas where availability or latency is proving to be unstable or degraded, and prepare or mitigate appropriately. Examples of such preparation/mitigation include adding extra capacity, performance tuning queries, or even moving traffic away from unstable region\nLatency SLO - Service Level Objective could be \u0026ldquo;Ninety-nine percent request latency over one minute must be between 25 and 100 ms\u0026rdquo;.\nWHY MTTR (Mean time to recover) Over MTBF (Mean time between failure)? When you create a system that rarely breaks, you create a system that is inherently fragile. Will your team be ready to do repairs when the system does fail? Will it even know what to do? Systems that have frequent failures that are controlled and mitigated such that their impact is negligible have teams that know what to do when things go sideways. Processes are well documented and honed, and automated remediation becomes actually useful rather than hiding in the dark corners of your system\nSome of the Important statistics (Metrics, Events, Logs\u0026hellip;.) to be observed from observability perspective are,\nMetrics\nLatency - How long are client calls to your service ? Availability - How many calls result in errors? Call Rates - How oftern are calls sent to service? Utilization - How critical resources are being utilized to ensure quality of service and capacity. Types of Metrics, Counters - These are cumulative metrics that represent how many times a specific occurrence of something has occurred. Gauges - These are metrics that change in any direction, and indicate a current value, such as temperature, jobs in queue, or active locks. Histograms - A number of events broken up into configured buckets to show distribution. Summaries - This is similar to histogram but focused on proving counts over sliding windows of time Events - An event is a discrete action that has occurred in the environment. A change to a config is an event. A code deployment is an event. A database master failover is an event. Each of these can be signals that are used to correlate symptoms to causes.\nAlerts \u0026amp; Notifications\nAlerts - An alert is an interrupt to a human that instructs him to drop what he’s doing and investigate a rules violation that caused the alert to be sent. This is an expensive operation and should be utilized only when SLOs are in imminent danger of violation.\nTickets/tasks - For work that must be done but there is o imminent disaster. The output of monitoring should be tickets/tasks for developers\nNotifications - Events like Code Deployment completed.\nAutomation - One example is Autoscaling basis outcome of monitoring.\nVisualization - GUI tool for visualizing outcome of monitoring.\nMinimum Viable monitoring set Databases Monitor if your databases are up or down (pull checks). Monitor overall latency/error metrics and end-to-end health checks (push checks).\nInstrument th application layer to measure latency/errors for every database call (push checks).\nGather as many metrics as possible about the system, storage, database, and app layers, regardless of whether you think they will be useful. Most operating systems, services, and databases will have plug-ins that are fairly comprehensive.\nCreate specific checks for known problems. For example, checks based on losing x percent of database nodes or a global lock percent that is too high\nHealth check at the application level that queries all frontend datastores\nQuery run against each partition in each datastore member, for each datastore\nImminent capacity issues\nDisk capacity Database connections Error log scraping\nDB restarts Corruption Database connection layer - A tracing system should be in place be able to break out time talking to a proxy and time from the proxy to the backend as well. You can capture this via tcpdump and Tshark/Wireshark for ad hoc sampling. This can be automated for occasional sampling.\nUtilization Connection upper bound and connection count (Tip: PostgreSQL uses one Unix process per connection. MySQL, Cassandra, and MongoDB use a thread per connection) Connection states (working, sleeping, aborted, and others) Kernel-level Open file utilization Kernel-level max processes utilization Memory utilization Thread pool metrics such as MySQL table cache or MongoDB thread pool utilization Network throughput utilization Measure Saturation using, TCP connection backlog Database-specific connection queuing, such as MySQL back_log Connection timeout errors Waiting on threads in the connection pools Memory swapping Database processes that are locked With utilization and saturation, you can determine whether capacity constraints and bottlenecks are affecting the latency of your database connection layer. Monitor Errors, Database logs will provide error codes when database-level failures occur. Sometimes you have configurations with various degrees of verbosity. Make sure you have logging verbose enough to identify connection errors, but do be careful about overhead, particularly if your logs are sharing storage and IO resources with your database. Application and proxy logs will also provide rich sources of errors. Host errors discussed in the previous section should also be utilized Internal Database Activity\nThroughput and latency metrics Reads Writes Inserts Updates Deletes Other Operations Commits Rollbacks DDL Statements Other admin. tasks Commits, redo, journaling Dirty buffers (MySQL) Checkpoint age (MySQL) Pending and completed compaction tasks (Cassandra) Tracked dirty bytes (MongoDB) (Un)Modified pages evicted (MongoDB) Memory structures A mutex (Mutually Exclusive Lock) is a locking mechanism used to synchronize access to a resource such as a cache entry. Only one task can acquire the mutex. This means that there is ownership associated with mutexes, and only the owner can release the lock (mutex). This protects from corruption. A semaphore restricts the number of simultaneous users of a shared resource up to a maximum number. Threads can request access to the resource (decrementing the semaphore) and can signal that they have finished using the resource (incrementing the semaphore). Application\nMeasuring and logging all requests and responses to pages or API endpoints. also external services, which includes databases, search indexes, 3rd party APIs and caches. Any jobs or independent workflows that should be monitored. Any independent, reusable code like a method or function that interacts with databases, caches, and other datastores should be instrumented. Monitor how many database calls are executed by each endpoint, page, or function/method When doing SQL tuning, a big challenge is mapping SQL running in the database to the specific place in the codebase from which it is being called. In many database engines, you can add comments for information. These comments will show up in the database query logs. This is a great place to insert the codebase location Logging - Logs should include stack traces Setting up an external check for each major product or service, as well as a health check on the monitoring service itself, is a good best practice Server (Metrics)\nCPU Memory Network interfaces Storage I/O Storage capacity Storage controllers Network controllers CPU interconnect Memory interconnect Storage interconnect Server (Logs) - should be sent to processors (e.g. Logstash, Loki)\nkernel, cron, authentication, mail, and general messages logs as well as process- or application-specific log to ingest, such as MySQL, or nginx Overall, this book is highly recommended for understanding the Observability landscape. Though focussed on databases, it covers lot of ground on other aspects involved in infrastructure.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/dbre/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eI have been reading excellent \u003ca href=https://www.oreilly.com/library/view/database-reliability-engineering/9781491925935/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase Reliability Engineering\u003c/a\u003e book and below are my notes from it.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eKey Incentive(s) for Automation\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eElimination of Toil - Toil is the kind of work tied to running a production service that tends to be manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly as a service grows.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eImportant System Characteristics\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eLatency\u003c/em\u003e, also known as response time, is a time-based measurement indicating how long it takes to receive a response from a request. It is best to measure this for end-to-end response from the customer rather than breaking it down component by component. This is customer-centric design and is crucial for any system that has customers, which is any system\u003c/p\u003e","title":"Database Reliability Engineering - My Notes"},{"content":"Introduction Suppose you have a distributed application running in production and it is based on Micro services/Service Oriented Architecture and have SLA of being \u0026ldquo;always on\u0026rdquo; (be available 24*7, barring deployments of course !!). In such cases, having proper monitoring of Application health in place is absolutely essential.\nWhat if Monitoring is an afterthought (i.e. application is already in production) ? and that there is little apetite for additional components like (Visualization tools, specialized storage for logs/metrics/traces) for monitoring?\nIs it even possible to have near real time Monitoring of Application\u0026rsquo;s behaviour using already-in-use technologies (like PostgreSQL) ?\nMonitoring and more generically, \u0026ldquo;Observability\u0026rdquo; has three pillars. They are Logs, Metrics and traces. Many of the existing applications are producing either (mostly logs or traces) but seldom all. Hence, it is necessary to use existing logs/traces as basis for Metrics generation.\nThere are on-going developments With standards like Opentelemetry in this field. Some have even suggested ( here \u0026amp; here) that traces (distributed) will eventually replace logging.\nApproach The high level architecture looks like below,\nHigh Level Architecture Considering as-is state of Application Architecture and given the constraints (mentioned earlier), this post covers approach that is based upon,\nPostgreSQL - Data store for Analytics and Reporting TimescaleDB - Timescale plugin for PostgreSQL FluentBit - Processing of Web Server logs \u0026amp; forwarding to database Grafana - Data Visualization and Monitoring platform. Lets see how to get this done step by step.\nData Collection and Storage TimescaleDB Timescale is a Postgresql Plugin for time-series data management.\nRationale\nThe reports and dashboards expected for near real time API monitoring are time intensive in nature. TimescaleDB is optimized for such time intensive reporting and suits well for this use case as it is a plugin over PostgreSQL, which is already being used for analytics/reporting. Installation of plugin is straightforward. Step by Step tutorial is very helpful.\nNext step is to create a database for the data to be used for Monitoring. Hyper table(s) in this database will contain Metrics data, collected from Application and web server (IIS).\nOne of the required dashboard/report was to monitor API request(s) in terms of success \u0026amp; failure (%), Response times (in buckets like 1-5 secs,5-10 secs and so on).\nFor each API request, application collects specific details and persists it in database. Currently below attributes are stored in database as part of each log entry,\nAttribute Description Time Timestamp of event Service Attribute indicating service name Operation Attribute indicating Operation of the service for which request was received Outcome Outcome of the API Invocation i.e. Success or Failure Timeout Timestamp of completion of API invocation The DDL command will look like,\ncreate table apilog (time timestamptz not null, service text not null, operation text, outcome text not null, timeout timestamptz ); After creating the table, it will have to be converted into Hypertable by using command,\nSELECT create_hypertable('apilog', 'time');\nNote: Timescale transparently manages storage for hyper table and PostgreSQL Developer can continue to use standard SQL/plpgsql with it.\nFor the sake of quick testing, One can add dummy data to this table using below SQL,\ninsert into apilog SELECT (current_timestamp - \u0026#39;0 day\u0026#39;::interval), (case when x = 1 then \u0026#39;finance\u0026#39; else \u0026#39;it\u0026#39; end),(case when x = 1 then \u0026#39;getPrices\u0026#39; else \u0026#39;getUptime\u0026#39; end), (case when x \u0026lt; 2 then \u0026#39;success\u0026#39; else \u0026#39;failure\u0026#39; end), (current_timestamp - \u0026#39;0 day\u0026#39;::interval) + trunc(random() * 20) * \u0026#39;1 second\u0026#39;::interval FROM generate_series(0, 5000, 5) AS t(x); Currently, Application generates log events in OLTP Database and data from this database is replicated to Reporting database. Since we have created new Hyper table to host this data,a simple approach of Trigger can be used to populate it from current table.\nIn real scenario, you may want to consider replicating the data directly to hyper table.\nFluentBit So far , we have collected Application logs in the database. There is one more source which is of importance in the context of Monitoring and that is infrastructure software. It could be Operating System, Web Servers and so on. They generate lot of logs and metrices that can be ingested and consumed in conjuction with Application log to get better picture. We will look at how Web server logs can be sourced in data source.\nThere are many monitoring tools (refer Useful links below for comparison) available with focus on IT and Network monitoring. Such tools readily include infrastructure software too. For the sake of this article, We can use Log collector tool for this purpose. As such there are many log collector tools available, we will use Fluentbit.At a very High level, It has concepts of,\nInput - Log sources Parsers - Plugins to parse \u0026amp; transform the logs Output - Log Destination like Prometheus, Kafka, PostgreSQL and so on. Some of the advantages of Fluentbit are,\nHigh log delivery performance with efficient resource utilization Robut and Lightweight approach Log enrichment at Node level itself than on the destination Simpler configuration format Setup FluentBit - Fluentbit provides binaries that are bundled with package managers in case of Linux and as installers for Windows.\nAs of writing of this post, Pre-built binaries do not include output plugin for PostgreSQL. So Fluentbit has to be built from source after modifying Cmakelist so,\nClone the github repository\nModify CMakeLists.txt file as below,\noption(FLB_OUT_PGSQL \u0026quot;Enable PostgreSQL output plugin\u0026quot; No)\nto\noption(FLB_OUT_PGSQL \u0026quot;Enable PostgreSQL output plugin\u0026quot; Yes)\nRefer to Compiling from Source for further details.\nConfiguration - Once fluentbit is installed, It needs to be configured to read Web server logs , parse them and push them to PostgreSQL.\nBelow is sample configuration to periodically read Web Server Logs (in w3c log format), parse and push them to PostgreSQL,\n[SERVICE] Flush 5 Daemon Off Log_Level debug Log_File d:\\monitoring\\fluentbit.log Parsers_File parsers.conf Parsers_File generated/parsers_generated.conf HTTP_Server On HTTP_Listen 0.0.0.0 HTTP_Port 2020 [INPUT] Name tail Tag format.iis Parser dips-w3c path d:\\temp\\iis.log DB d:\\temp\\raw.iis.db [OUTPUT] Name pgsql Match * Host 172.0.0.1 Port 5432 User fluentbit Password fluentbit Database timescalepoc Table iislogs Timestamp_Key time Configuration for Parser is as below,\n[PARSER] Name dips-w3c Format regex Regex ^(?\u0026lt;time\u0026gt;\\d{4}-\\d{2}-\\d{2} \\d{2}[\\:\\.]\\d{2}[\\:\\.]\\d{2}) (?\u0026lt;serverip\u0026gt;\\S+) (?\u0026lt;method\u0026gt;\\S+) (?\u0026lt;uristem\u0026gt;\\S+) (?\u0026lt;uriquery\u0026gt;\\S+) (?\u0026lt;serverport\u0026gt;\\S+) (?\u0026lt;username\u0026gt;\\S+) (?\u0026lt;clientip\u0026gt;\\S+) (?\u0026lt;userAgent\u0026gt;\\S+) (?\u0026lt;referrer\u0026gt;\\S+) (?\u0026lt;status\u0026gt;\\S+) (?\u0026lt;substatus\u0026gt;\\S+) (?\u0026lt;win32status\u0026gt;\\S+) (?\u0026lt;timetaken\u0026gt;\\S+) (?\u0026lt;useragent1\u0026gt;\\S+) (?\u0026lt;auth\u0026gt;\\S+) (?\u0026lt;contenttype\u0026gt;\\S+) Time_Key time Time_Format %F %T Time_Keep True types serverPort:integer httpStatus:integer httpSubStatus:integer win32Status:integer timetaken:integer This parser basically uses Regular Expression to parse each line in log file into key - value pairs with data points of interest.\nIn terms of output, Fluentbit\u0026rsquo;s Postgresql plugin provisions the table itself with a structure that stores entire JSON in field as part of row. Either this table can be used as is or use \u0026ldquo;Before insert\u0026rdquo; trigger as suggested by Fluentbit\u0026rsquo;s manual to parse the Json and populate separate table.\nFluentbit can be easily configured to run as daemon (on Linux) or Service (on windows).\nVisualization With data getting added to timescaledb Hyper table,Lets see how it can be visualized.\nTypically, there are 2 approaches to be considered for Visualization,\nCustom-built Web UI - This only makes sense if,\nThere is already a Reporting/Visualization Web UI in place and adding new dashboards/reports is not much pain Not much customization and/or slicing-dicing is expected. Limited Efforts available. Off the shelf Tools - This approach makes sense if,\nIt is expected that Monitoring dashboards should be flexible and provide ease of customization by business or power users.\nAdditional dashboards are expected or can be provisioned with minimal or no coding.\nThere are many paid and open source tools available. Notable OSS options are,\nGrafana - Tailor made for Monitoring and extensive analysis of Time series data. Apache Superset - open-source application for data exploration and data visualization able to handle data at petabyte scale. Lets see how Grafana can be used for visualization (Probably, i may evaluate superset some time and update this post.)\nGrafana Grafana has multiple offerings and one of them being Open source, Self-hosted Application. It has Go backend and is very easy to install. For Windows, Just follow the steps at Installation.\nOnce grafana is setup, one can quickly start it by running grafana-server. By default, it starts Web server at port 3000. With Grafana Web-based GUI up and running, lets perform below steps to get dashboard in place.\nConnectivity to PostgreSQL - One needs to add Data Source in Grafana which in this case is PostgreSQL Database. It can be added from sidebar on Grafana UI, by hovering over \u0026ldquo;Configuration\u0026rdquo; option. In below screenshot, it shows configuration. Grafana: Connect to PostgreSQL Add Dashboard - Once the Data source is setup, next step is to add a dashboard. Dashboard essentially is a visualization or a report. It has Query (in this case SQL Query) to fetch the data. Below screenshot shows configuration of simple query for Dashboard, Grafana: Query for Dashboard Grafana requires certain functions to be included (like $__time(..) and $__timeFilter(..)) in query so as to facilitate filtering/ordering by user through UI, like shown below,\nGrafana: View data and apply Filter Grafana provides extensive ways to transform on the data fetched by SQL Query. This feature is more aimed at business and power user who may want to perform additional analysis on it. Alternative is to provide desired SQL and get the visualization like Time series or Graph as shown below,\nGrafana: Complex SQL Query with minimal transformation Grafana: Time Series Visualization Note that there are many more features provided by Grafana (in terms of transformations, Visualization options, Access Control to UI itself and so on.\nKey points with this approach are,\nLeveraging tools/products currently in use. Greater Flexibility in Visualization over custom built tool containing canned reports/graphs Lesser learning curve than inducting new tools. This post barely touches surface of what each of the individual tools mentioned have on offer, one would do well to go through their documentation to derive most value out of it.\nUseful links (#usefullinks) Comparison of IT Monitoring tools Nice Introduction to Modern Observability Happy Coding !!\n","permalink":"http://localhost:1313/posts/nrtanalysispostgresql/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eSuppose you have a distributed application running in production and it is based on Micro services/Service Oriented Architecture and have SLA of being \u0026ldquo;always on\u0026rdquo; (be available 24*7, barring deployments of course !!). In such cases, having proper monitoring of Application health in place is absolutely essential.\u003c/p\u003e\n\u003cp\u003eWhat if Monitoring is an afterthought (i.e. application is already in production) ? and that there is little apetite for additional components like (Visualization tools, specialized storage for logs/metrics/traces) for monitoring?\u003c/p\u003e","title":"Near real time API Monitoring with Grafana and PostgreSQL"},{"content":"Course Overview Welcome to Pluralsight. My name is Julie Lerman, and this is Steve Smith. Together, we\u0026rsquo;d like to welcome you to our course, Domain‑Driven Design Fundamentals. Steve is a trainer and architect with NimblePros and spends a lot of time helping teams write better code, faster. And Julie is well known in the DDD community for helping reluctant teams embrace domain‑driven design. In this course, we give you a strong foundation for learning how to build applications and microservices using domain‑driven design. DDD has proven to be a very effective approach for managing complex requirements. The original version of this course has helped many thousands of learners leverage domain‑driven design, and they have shared amazing feedback. Now, we\u0026rsquo;ve updated the course and its sample application to reflect ideas and tools that have emerged since that first version. Some of the major topics that we\u0026rsquo;ll cover include what are the essential ideas of domain‑driven design? What are the main patterns used in domain models? We\u0026rsquo;ll also talk about how to break up concepts into smaller parts and how these smaller aggregates and contexts communicate with one another. By the end of this course, you\u0026rsquo;ll know how to break down customer requirements into a maintainable domain model and structure a solution using domain‑driven design. Before beginning the course, you should at least be familiar with software development, ideally using C#. From here, you should feel comfortable diving into DDD and design patterns with courses on the DDD learning path and the design patterns learning path. We hope you\u0026rsquo;ll join us on this journey to learn domain‑driven design with the Domain‑Driven Design Fundamentals course, at Pluralsight.\nIntroducing Domain-Driven Design Introduction and Overview Hi, this is Steve Smith ‑and this is Julie Lerman. Welcome to our course, Domain‑Driven Design Fundamentals. ‑We\u0026rsquo;re looking forward to sharing our experience with DDD and how it\u0026rsquo;s helped us and our clients. You\u0026rsquo;re welcome to reach out to us online. ‑You can find me online at thedatafarm.com or on Twitter @julielerman. ‑And I\u0026rsquo;m online at ardalis.com or on Twitter as @ardalis. ‑Eric Evans coined the term Domain‑Driven Design in his groundbreaking book with the same title published in 2004. Since then, other titles have followed, including great books expanding on the subject by Jimmy Nilsson and Vaughn Vernon and so many who are now also great experts at DDD. And there are also now a number of fantastic DDD conferences and even a well‑established virtual meetup. ‑There\u0026rsquo;s definitely continued and renewed interest in Domain‑Driven Design as both the demand for and complexity of software continues to grow. Domain‑Driven Design is commonly referred to as DDD and even has its own Twitter hashtag, dddesign. Although DDD has been around for so long, it continues to be a great approach to building software that we both enjoy employing and sharing with others. And as more minds have gotten involved in DDD, it continues to evolve.\nWhat to Expect from This Course and This Module Domain‑Driven Design is a huge topic. Our focus will be on the developer perspective and the technical and coding aspects of DDD more so than architectural concerns. We\u0026rsquo;ll start by talking about why we think you should even be watching this course. Next, we\u0026rsquo;ll jump right into an existing solution so you can get a concept of what the code and the architecture of an application written using DDD practices looks like. Then we\u0026rsquo;ll start digging into the big DDD concepts like modeling problems of the domain, what the various technical components of DDD are, and how you can use DDD to manage complex projects. Throughout the course, we\u0026rsquo;ll use the existing solution so you can see how some of this process works. ‑With this in hand, we\u0026rsquo;ll walk through extending the sample based on a new request from the client. Since this is a fundamentals course, we certainly don\u0026rsquo;t expect to turn you into an expert by the end of it; however, you should be well on your way to understanding the value behind Domain‑Driven Design and how some of the practices can be employed to improve your success with complex software projects. Right now, if you\u0026rsquo;re new to DDD, you don\u0026rsquo;t even know what you don\u0026rsquo;t know yet. However, once you\u0026rsquo;re done with this course, you\u0026rsquo;ll know more about DDD, but of course, you\u0026rsquo;ll also realize how much more there is to learn. That\u0026rsquo;s one of the great things about our industry. The more you know, the more you realize how much more there is you don\u0026rsquo;t know. ‑In this module, we\u0026rsquo;ll focus on the value of Domain‑Driven Design. You\u0026rsquo;ll learn what the term represents and what problems DDD can help you with in your software building process. ‑Not only will we share the benefits of DDD, but we will be sure to highlight some of the potential drawbacks. Finally, you\u0026rsquo;ll get a look at a small application that we\u0026rsquo;ll be using throughout the course as you learn DDD.\nUnderstanding the Value of Domain-Driven Design Domain‑Driven Design focuses on the problems of the business domain that you\u0026rsquo;re attempting to solve. Its a critical shift from decades of focusing on how to store your data and then letting that drive how the software is designed. But that workflow added a lot of unnecessary complexity to the task of building software. So why should you watch this course? Why should you care about learning Domain‑Driven Design. Steve and I have both been designing and developing software for a very long time. Without giving away our ages, we\u0026rsquo;ve got over 40 years of experience between the two of us, and we\u0026rsquo;ve both been very inspired by Domain‑Driven Design. In many ways, it aligns very naturally with ideas that we\u0026rsquo;ve each come to from our own experience. It also takes these ideas and lays them out in a way that\u0026rsquo;s not only illuminating, but it\u0026rsquo;s repeatable. When Eric Evans wrote his book, his goal was to understand what was behind the successes he had achieved with large‑scale, complex software projects and what were the patterns. That\u0026rsquo;s what he laid out in the book. ‑This is why we care about DDD, and we hope that you can gain from our experience, which is why we put together this course. DDD provides principles and patterns to help us tackle difficult software problems and even business problems. These are patterns that are being used successfully to solve very complex problems. The more we\u0026rsquo;ve learned about DDD, the more we found these ideas aligned with the approaches we\u0026rsquo;ve learned from our many combined years of experience. DDD provides us with a clean representation of the problem in code that we can readily understand and verify through tests. We developers live to code. When starting on a new project, we\u0026rsquo;re eager to jump in and start coding so that we can build some software. But you can\u0026rsquo;t build software unless you truly understand the client\u0026rsquo;s needs. DDD places as much emphasis on not only comprehending what your client wants, but working with them as full partners through a project. The ultimate goal isn\u0026rsquo;t to write code, not even to build software, but to solve problems. ‑You need to realize that nobody really wants your program. They want what it can give them. There\u0026rsquo;s a famous saying in sales. Buy a quarter‑inch drill, they want to buy quarter‑inch holes. Your client\u0026rsquo;s not interested in building software, but in being successful at their mission. Software provides a more efficient means to this end.\nGaining a High-Level Understanding of DDD Domain‑driven design is for solving complex problems. Evans put a lot of thought into the subtitle of his DDD book and came up with Tackling Complexity in the Heart of Software. But DDD itself is a complex topic. To start with, we think it\u0026rsquo;s helpful to look at it from a very high level. We call it the 10,000 foot view here in the US, but that\u0026rsquo;s probably 3,048 meters to the rest of you. ‑One of the critical pieces of DDD is to encourage better interaction with domain experts. These are the people who live and breed the business or process or whatever you are targeting with the software you\u0026rsquo;re planning to write. You may be thinking, but we already talked to them. Perhaps, but probably you\u0026rsquo;re using your terms, not theirs, and maybe talking in the language of tables in a database rather than domain concepts. Or you may presume that after some standard requirements gathering, you can infer enough about the problem at hand to design the solution on your own. After our own history in the business of developing software, we know that that rarely ends well. DDD guides us to engage with the domain experts at much greater length and through much more of the process than many software teams are used to doing. ‑When talking with Eric Evans about this, he told us that you really need to cultivate your ability to communicate with business people in order to free up their creative modeling. Another core theme in DDD is to focus on a single subdomain at a time. Say you\u0026rsquo;re asked to build software for a spaceship manufacturer. They describe their business tasks such as purchasing materials, engineering, managing employees, advertising their spaceships and share with you their dreams about mass producing spaceships when the market\u0026rsquo;s ready. Each one of these tasks are in themselves a complex subdomain filled with their own specific tasks, terminology, and challenges, and those subdomains may have only minimal interaction between them. Many applications just try to do too many things at once, then adding additional behavior gets more and more difficult and expensive. With DDD, you\u0026rsquo;ll divide and conquer. By separating the problem into separate subdomains, each problem can be tackled independently, making the problem much easier to solve. This lets us focus on the problem of employee management separately from the problem of sourcing materials for producing the spaceships. The term modeling is important in DDD and refers to how you decipher and design each subdomain. You\u0026rsquo;ll learn much more about this as you progress through the course. ‑The final theme in our high‑level perspective of DDD is writing the code to implement each subdomain. The principle of separation of concerns not only plays a critical role in identifying the subdomains, but within each subdomain, we use it as well. Many applications spread the domain logic between the persistence layer and the user interface, making it much more difficult to test and to keep all of the business logic consistent. DDD applies separation of concerns to help steer you clear of this problem by focusing on the domain and not on details like how to persist data into a database or how to connect to a service in the cloud. Those become implementation details that you can worry about separately. While implementing these subdomains, the focus is on the subdomain, the problems of the subdomain you are trying to solve with your software. You don\u0026rsquo;t get bogged down worrying about infrastructure concerns.\nExploring the Benefits and Potential Drawbacks of DDD Domain‑Driven Design is a big commitment. While Steve and I have both chosen to leverage pieces of DDD as we learn more about the wider scope, one thing we\u0026rsquo;re both confident about is that it\u0026rsquo;s providing a lot of benefits to our work. Because DDD guides us to focus on small, individual, nearly autonomous pieces of our domain, our process and the resulting software is more flexible. We can easily move or modify the small parts with little or no side effects. It even lets us be more flexible with our project resources as we\u0026rsquo;re building the software. ‑The resulting software also tends to be more closely mapped to the customer\u0026rsquo;s understanding of the problem. DDD gives you a clear and manageable path through a very complex problem. When you look at the code, you can see that it\u0026rsquo;s generally well organized and easily tested, and the business logic all lives in one place. Even if you don\u0026rsquo;t use full DDD for a project, there are many patterns and practices that you can use by themselves to benefit your application. So keep watching, even if you don\u0026rsquo;t think you\u0026rsquo;ll need all of it. ‑We often describe DDD as a way to take big, messy problems and transform them into small, contained, solvable problems. But DDD is not a path for every project. It\u0026rsquo;s real benefit is for complex domains. Even Eric Evans explicitly states that DDD isn\u0026rsquo;t suitable for problems when there\u0026rsquo;s substantial technical complexity, but little business domain complexity. Using DDD is most beneficial when the complexity of the domain makes it challenging for the domain experts to communicate their needs to the software developers. By investing your time and effort into modeling the domain and coming up with a set of terminology that\u0026rsquo;s understood for each subdomain, the process of understanding and solving the problem becomes much simpler and smoother. ‑But all this comes at a cost. You\u0026rsquo;ll spend a lot of time talking about the domain and the problems that need to be solved, and you\u0026rsquo;ll spend plenty of time sorting out what is truly domain logic and what is just infrastructure. The easy example there is data persistence, or for the sake of our spaceship manufacturer, maybe it\u0026rsquo;s how to communicate with an external service that helps to verify that potential buyers are properly vetted for space travel. ‑You\u0026rsquo;ll have a big learning curve as you learn new principles, patterns, and processes. There\u0026rsquo;s no question about that. DDD is a big topic and gaining expertise from end to end is a big commitment. This course doesn\u0026rsquo;t aim to make you an end‑to‑end expert in DDD, but to give you a big step forward that will allow you to not only comprehend the concepts, but you\u0026rsquo;ll gain a lot of new tools that you can use right away, whether or not you choose to dig further. And it\u0026rsquo;s worth restating that DDD is not always the correct path for your applications. And it\u0026rsquo;s helpful to keep in mind some of the scenarios where DDD is just going to be overkill. For example, if you have an application or a subdomain that\u0026rsquo;s just a data‑driven app and doesn\u0026rsquo;t need much more than a lot of CRUD logic, there\u0026rsquo;s really no need to use DDD. It would be a waste of time and effort. ‑And be clear about the difference between complexity in your business domain and technical complexity. DDD is designed to help with complex domains. If your domain is simple, even if you have a lot of technical challenges to overcome, DDD still may not be the right path. For example, if you are writing a tic‑tac‑toe game for a touch screen with a new complex API, the complexity lies in the touch interactions of the two players on the screen. The domain itself is well known and just comes down to Xs and Os. Getting others to follow the DDD approach can also be a drawback. There may be some politics involved in this decision. It really depends on your team and your organization. We hope that another takeaway from this course will be to help you understand the concrete benefits of DDD, which you can show to your coworkers to help convince them.\nInspecting a Mind Map of Domain-Driven Design In his DDD book, Evans included a really useful diagram of how many of the concepts and patterns of DDD are interrelated. Let\u0026rsquo;s take a look at that mind map. ‑Evans refers to this as a navigation map, and it lays out all of the pieces of Domain‑Driven Design and how they relate to one another. We want you to see it so that you have a concept of the big picture, even though in this course we\u0026rsquo;ll spend most of our time on a subset. We will be defining many of these terms later on in the course, so don\u0026rsquo;t panic. We\u0026rsquo;ve mentioned modeling the domain and subdomains a few times. Modeling is an intense examination of the problem space. Key to this is working together with the subject matter experts to identify the core domain and other subdomains that you\u0026rsquo;ll be tackling. Another important aspect of modeling is identifying what\u0026rsquo;s called bounded contexts. And within each of these bounded contexts, you focus on modeling a particular subdomain. As a result of modeling a bounded context, you\u0026rsquo;ll identify entities, value objects, aggregates, domain events, repositories, and more and how they interact with each other. ‑In the image, there\u0026rsquo;s more than just these subdomains, however. For example, there is a concept of an anti‑corruption layer, which allows subdomains to communicate with one another from behind their boundaries. The model also has notes for each element, such as free teams to go separate ways. This is something that can be accomplished once you\u0026rsquo;ve identified the boundaries of each subdomain. Or avoid overinvesting in generic subdomains. That could be something like a credit card verification service that you could choose to use rather than building yourself. As you begin focusing on specific subdomains, another very important DDD concept surfaces, driven by the need for clear, concise communication. It\u0026rsquo;s called the ubiquitous language. A simple definition of a ubiquitous language is to come up with terms that\u0026rsquo;ll be commonly used when discussing a particular subdomain. And they will most likely be terms that come from the problem space, not the software world, but they have to be agreed upon so that as discussions move forward, there is no confusion or misunderstanding created by the terminology used by various members of the team. ‑We invite you to pause this video to look over this map and read the notes associated with the various elements and contemplate what they might mean. We\u0026rsquo;ll revisit this throughout the course, and we hope that the map will make more and more sense as you work through the course.\nIntroducing Our Sample Application Now we want to switch over and show you a relatively small DDD‑based solution that we\u0026rsquo;ll be working on for the rest of the course. This app represents an appointment scheduling system for a veterinary clinic. It\u0026rsquo;s \u0026ldquo;small\u0026rdquo;, but since DDD requires a certain amount of complexity to warrant its use, it\u0026rsquo;s bigger than most demos you\u0026rsquo;ll see in other courses or presentations. For this course, we decided that we would use a veterinary clinic management system because it has a decent amount of complexity, and that means that we can apply some of the DDD principles, but it also gives us an excuse to show off pictures of our pets. ‑And our friends pets too. We\u0026rsquo;ve got a whole bunch of pet pictures from other Pluralsight authors in here, and they\u0026rsquo;re all so cute. ‑We\u0026rsquo;ve got Ben Franklin here from Michael Jenkins. We\u0026rsquo;ve got Patrick Neborg\u0026rsquo;s dog here, Sugar. Aren\u0026rsquo;t these guys cute? And, of course, Julie\u0026rsquo;s got Sampson. ‑Oh, my handsome boy. ‑And I\u0026rsquo;ve got Darwin, the silly poodle. He was just a puppy when we recorded the first version of this course, and he\u0026rsquo;s got a new friend, Rosie. Rosie is just a puppy. I guess every time I get a puppy we have to update this course. ‑So the idea behind this application is that if you\u0026rsquo;re working at the front desk of a vet clinic and someone walks in, maybe they want to schedule an appointment, or the phone rings with someone who wants to schedule an appointment for their pet, the first thing you\u0026rsquo;re going to do is look that client up, the person, in the system. ‑So the user starts by looking up the client, and from there, they can choose which of the clients, animals or patients, they\u0026rsquo;re going to schedule. So here\u0026rsquo;s Julie with Sampson. Here\u0026rsquo;s Kim with Roxy. Next, the user is just going to click on an open slot in the schedule, which opens up the create appointment window. ‑Oh, Roxy, you\u0026rsquo;re such a cutie. We can set up Roxy for a wellness exam with Dr. Smith. ‑Now notice before we save this appointment, it isn\u0026rsquo;t yet confirmed. We\u0026rsquo;ll get to that in a minute. So we save, and the appointment shows up. Now the complexity in this system comes into play when we have to do some checks for certain things. We want to make sure, for instance, that Roxy isn\u0026rsquo;t already scheduled in one of the other rooms at this exact time. We also want to send an email notification to Kim to let her know that Roxy has this appointment scheduled. We\u0026rsquo;ll add a link in the email the client can click to confirm. And in a real system, perhaps it would add it to their calendar of choice. The idea is to cut down on no‑show appointments for the clinic. ‑Of course, there are other features of this application. We\u0026rsquo;re focused on the schedule right now, but we do need to be able to manage client data and manage their pet data, the clinic\u0026rsquo;s patients, and things like that. Admins need to be able to manage doctors and rooms and appointment type since these all might change over time or from one clinic to another that uses the same software. But those are mostly CRUD tasks, which means we\u0026rsquo;re just talking about adding and removing records and maybe making some edits without a whole lot of complexity. We\u0026rsquo;ll talk about those tasks in a different compartment of the application than the schedule, which, of course, has a lot more complexity.\nExploring the Sample App\u0026rsquo;s High-level Structure So why don\u0026rsquo;t we take a look at the structure of our app? This is a distributed application built with ASP.NET Core on .NET 5. It\u0026rsquo;s running Blazor WebAssembly in the front end, which is talking to APIs running on ASP.NET Core. There are three different web apps that the system uses. Two are used internally by client staff, and then there\u0026rsquo;s the public‑facing website for the clinic, which is needed for the confirmation links that users will click. The two clinic apps, Front Desk and Clinic Management, each have their own database, and all three apps communicate with one another using messages transported by RabbitMQ. Like I said, it\u0026rsquo;s maybe a little more complicated than most demos. We want the sample app to be something you spend some time with and extend as part of your experience with this course, so please be sure to check it out and run it locally. It should just work if you have Docker installed. ‑Now let\u0026rsquo;s take a quick look at how the code is organized. The full solution is hosted on Steve\u0026rsquo;s GitHub account. Here\u0026rsquo;s the URL, but we\u0026rsquo;ll definitely also have that URL in the resources slides at the end of this module. PLURALSIGHT DDD FUNDAMENTALS is the name of the root of our GitHub repository. In here, you can see the three web apps, ClinicManagement, FrontDesk, and the public‑facing website, VetClinicPublic. ‑There\u0026rsquo;s also a folder for SharedKernel, which we\u0026rsquo;ll talk about a little bit later. The first app we\u0026rsquo;re going to focus on though is the FrontDesk app. ‑Our main focus for this course is going to be the front desk application and its scheduling functionality. Looking at the solution, you can see it\u0026rsquo;s broken up into seven projects, which seems like a lot, but three of them are just there to support Blazor The server‑side code, where our domain model resides, is just three projects. ‑The most important project is FrontDesk.Core. That\u0026rsquo;s where the domain model is defined. All of the app\u0026rsquo;s infrastructure needs, like how it talks to its database or RabbitMQ, are kept in the FrontDesk.Infrastructure project. In the front end, in this case, ASP.NET Core and its API endpoints, is in the FrontDesk.Api project. This is the front end from the server\u0026rsquo;s perspective. The system is using a clean architecture design which you may also hear referred to as onion architecture or ports and adapters. I cover this in my N‑Tier Applications in C# course, and I have a popular GitHub solution template you can use to set up a new project using this approach. ‑With clean architecture, the project dependencies all point towards the domain model in the core project, so both the API and infrastructure projects have a dependency on Core. Core should never depend on infrastructure concerns, but it can leverage NuGet packages that don\u0026rsquo;t couple it to infrastructure concerns. ‑In this case, it\u0026rsquo;s using a couple of utility packages, as well as the SharedKernel package that\u0026rsquo;s shared by other apps. We\u0026rsquo;ll talk more about SharedKernel later. The ClinicManagement app uses the same kind of structure and also has a Blazor front end because why not? It\u0026rsquo;s pretty much just CRUD, so we don\u0026rsquo;t focus too much on its domain model, but it is a distinct app with its own database, and we do need to build into our design a way to propagate changes from it to the FrontDesk app. ‑Finally, there\u0026rsquo;s the public web app. It\u0026rsquo;s just one project, and it\u0026rsquo;s pretty simple. This is responsible for sending emails, which this demonstration fakes using a tool called PaperCut, and it hosts the link that clients click to confirm appointments. The public web app also needs to communicate with the front desk, but it doesn\u0026rsquo;t have a database of its own, nor does it access any of the other app\u0026rsquo;s databases. ‑That\u0026rsquo;s it in a nutshell. We\u0026rsquo;ll demonstrate the confirmation emails and more complex use cases later in the course. But for now, that should give you an idea of how the ideas we\u0026rsquo;re sharing are put into practice.\nReview and Resources So, as we\u0026rsquo;ve talked about, creating applications is not about writing code, even though often that\u0026rsquo;s a really, really fun part for us developers, but it\u0026rsquo;s about solving problems. And the more complex the problems are, the more difficult the whole project becomes. So Domain‑Driven Design gives us some great patterns and practices for attacking these more complex problems, and they get us to really focus on interacting with the domain experts, breaking apart our domain, and working on things in smaller units and in a very organized fashion. And in the end, it gives us a much more efficient and effective path to success in creating our solutions. ‑Yeah, we talked about some of the benefits that Domain‑Driven Design provides, as well as some of the drawbacks. Specifically, your team just needs to know Domain‑Driven Design, and your domain experts need to be available to work with you on these systems. Domain‑Driven Design is a big topic. We looked at some of the different concepts that are involved in DDD, and we\u0026rsquo;re going to look at a lot more of them in depth through this course. But remember that this is just an introduction to Domain‑Driven Design, so some of these aspects that are a little more advanced, we\u0026rsquo;re not going to be able to cover with a great deal of depth. ‑In the next module, we\u0026rsquo;ll start exploring the process of discovering and modeling domains. Here are some links to resources that we mentioned this module and others that we find relevant. ‑This is Steve Smith ‑and this is Julie Lerman, and thanks for watching Domain‑Driven Design Fundamentals.\nModeling Problems in Software Introduction and Overview Hi. This is Steve Smith. ‑And this is Julie Lerman. Welcome back to our Domain‑Driven Design Fundamentals course. This module will focus on modeling problems in software, and you\u0026rsquo;re welcome to reach out to us online. You can find me online at thedatafarm.com or on Twitter @julielerman. ‑And I\u0026rsquo;m at ardalis.dot com or on Twitter as @ardalis. In this module, we\u0026rsquo;re going to take a look at how we decompose the model for the veterinary office domain. We\u0026rsquo;ll talk about the importance of domain experts in DDD. ‑We\u0026rsquo;ll drive this point home with a play in which we\u0026rsquo;ll consider a few different scenarios for how the project might have gone, which should provide you with examples of ways to involve the domain expert in the design of the system. ‑Next, we\u0026rsquo;ll talk about the domain model and some of the elements that typically are found in this part of the application. It\u0026rsquo;s important to separate the core domain model from related subdomains, and we\u0026rsquo;ll talk about how bounded contexts can help us accomplish this separation. ‑And then we\u0026rsquo;ll wrap things up by talking about ubiquitous language and how this seemingly small thing with a big name can have a large impact on your model, your design, and, of course, your application. So let\u0026rsquo;s get started.\nIntroducing Our Domain Steve and I both have a love for animals. In fact, Steve\u0026rsquo;s wife, Michelle, is a veterinarian. In thinking about a sample application we could use for this course, we wanted to use something complex enough to justify the use of DDD. The veterinary clinic management domain made a lot of sense, allowing us to leverage our own experience as pet owners, as well as having a domain expert available in the form of Michelle, or Dr. Smith as we\u0026rsquo;ll be referring to her in the course. ‑There are many different pieces involved in managing a typical veterinary clinic. The staff needs to be able to schedule appointments. They likely need to schedule their own working shifts as well. They need to be able to invoice for their services and collect payments and, in many cases, send out bills. They\u0026rsquo;ll also need to be able to store and retrieve medical records, as well as work with external labs and specialty clinics. Most veterinary practices also have products for sale and may need to track inventory, as well as sales. And there are often follow‑ups and reminders that may need to be sent by mail, phone, or perhaps email. There is certainly sufficient complexity in this domain to merit the use of domain‑driven design.\nPlanning Ahead to Learn About the Domain Of course, it\u0026rsquo;s a good idea to speak with a domain expert about the systems requirements before diving in and beginning to code a solution. Whether you\u0026rsquo;re tasked with building a full system or just adding a new feature, an overall understanding of the client\u0026rsquo;s business is a critical start. Of course, it\u0026rsquo;s just the beginning. It\u0026rsquo;s also important that you have a continuous conversation with the domain expert throughout the development of the system. The simple system we showed in the last module needs some updates. So we\u0026rsquo;re going to share some conversations we had with the domain expert to help validate our initial assumptions. ‑An important part of this conversation is going to be identifying the things that aren\u0026rsquo;t included in the scope of the project or feature. To that end, we\u0026rsquo;ll try to identify subdomains within the overall problem domain and then determine whether or not we need to concern ourselves with these subdomains at the moment. If not, we can consciously remove them from the scope with the customer\u0026rsquo;s approval and avoid confusion and possible missed expectations later. To get started though, we do want to know a little bit about the big picture.\nConversation with a Domain Expert: Exploring the Domain and Its Subdomains As Julie already mentioned, my wife, Michelle, is a veterinarian. In addition, she has a deep understanding of software development processes, having successfully managed software teams at NimblePros and Teller. She has graciously agreed to play the role of domain expert for our course. In real life, she knows quite a bit about software and technology, but for the purposes of this course, she\u0026rsquo;s playing the more traditional role of a veterinarian with little background in software development. Hi Dr. Smith. Thanks for your time today. Julie and I would like to learn more about what goes on in your veterinary clinic. Can you share some of the big picture processes involved in the day‑to‑day operation of a clinic? ‑So the biggest thing is probably scheduling patients and keeping track of them once they arrive. Clients will usually call ahead unless it\u0026rsquo;s an emergency, and then we need to get them entered into our system. Of course, surgical procedures need to be scheduled in advance. And when they\u0026rsquo;re here, we need to record information about the patient, our observations, notes, and diagnoses. ‑Wow, that\u0026rsquo;s quite a list. Probably not what you were dreaming about when you started vet school. So many of these are all secondary to the core reason for being a vet, keeping pets healthy. And, I think it sets you apart from other businesses that have to manage clients and schedule appointments. But, you can\u0026rsquo;t run a business without it. Is that all? ‑So when the appointment is over, they also have to pay. So most of the time that\u0026rsquo;s done immediately, but we do have some billing that\u0026rsquo;s done after the fact, and when they\u0026rsquo;re checking out, they may need to buy some things for their pets, toys or prescriptions, or maybe some prescription food as well, and we need to track all of that as well. For some of the lab work, we need to send that out and get the results back, and some prescriptions go out to outside pharmacies as well. So we need to manage all of those through the system. ‑Okay, so payments, billing, point of sale, labs, prescriptions, anything else? ‑I think that\u0026rsquo;s about it. Oh, we also use the system to note which staff members are working when, and right now our website isn\u0026rsquo;t integrated into the system at all, but we were thinking it would be great if clients could view information about their pets, maybe schedule appointments, look up prescriptions, and we can make updates to the site without having to go through our computer contractor. ‑Okay, great. So, we\u0026rsquo;ll add staff scheduling and content management to the list. I don\u0026rsquo;t want to assume you know what a content management system is. We also call it a CMS, you might have heard of that. It\u0026rsquo;s a type of software system that lets the owner, that\u0026rsquo;s you, be in charge of the information that\u0026rsquo;s displayed. A blog is a really good example of a CMS that can be managed by its owner. ‑I have a blog, so I understand exactly what you mean. Something like that would be really great for us to have so we can make updates right in‑house. But it\u0026rsquo;s kind of like a blog, especially something that\u0026rsquo;s more professional than my personal blog. ‑Cool. So I think that\u0026rsquo;s probably enough of a big picture view for us to consider at the moment. Now let\u0026rsquo;s try and think about which of these are connected to the others so we can determine which ones we need to worry about for our application\u0026rsquo;s needs. ‑We started with this fairly complicated view of the overall problem domain, but now we\u0026rsquo;ve segregated these into different areas and we know which ones we need to focus on right now and which ones we can treat as external collaborators. ‑Determining where we can safely draw the line between what problem our immediate application needs to solve and what is outside of its area is certainly helpful. It\u0026rsquo;s also important that this be well understood and communicated among everyone involved in the project.\nConversation with a Domain Expert: Exploring the Scheduling Subdomain Now that we have a better understanding of the domain and the other subdomains around the scheduling system, it\u0026rsquo;s time to focus more on understanding the scheduling subdomain. We had another meeting with Dr. Smith, and you can listen in. ‑Hi guys, welcome back to the clinic. How are things going with the computer system? ‑We\u0026rsquo;re making good progress, and now we\u0026rsquo;re ready to look at another more complex feature. ‑We know there\u0026rsquo;s a lot that goes on here, but today we want to focus on appointment scheduling because we realize we\u0026rsquo;re still a little confused about it. ‑Since we\u0026rsquo;ve both owned pets for a long time, we figure we probably have a rough idea of what\u0026rsquo;s needed, but it\u0026rsquo;ll be good to talk through it with you. Do your patients usually schedule their appointments over the phone? ‑Okay, so yeah our patients aren\u0026rsquo;t usually involved in the scheduling. Usually, it\u0026rsquo;s the clients that call in for appointments for their pets. And yeah, usually it\u0026rsquo;s on the phone or in person when they\u0026rsquo;re checking out after an office visit. Julie and I talked about that earlier. ‑Yeah, so Steve, the patients are the animals, and the clients are the people or the pet owners. ‑Right, right, of course, that\u0026rsquo;ll be important to get right. ‑Remember, we talked about that. So the client needs to make an appointment for their pet. They\u0026rsquo;ll talk to a staff member who will schedule the appointment. What kind of information do they need in order to do that? ‑So that really depends on the type of appointment. It could be an office visit, or it could be a surgery. Why don\u0026rsquo;t we talk about the office visits first. If it\u0026rsquo;s just for a wellness exam, that\u0026rsquo;s pretty standard. They just need to choose an available time slot with one of the doctors. Some of the visits can be scheduled with just a technician though, so if they need just their toenails trimmed, for example. ‑Or painted, like Samson. He gets his toenails painted. ‑Does he really? ‑No, I\u0026rsquo;m joking. I just want to, pink. ‑I\u0026rsquo;m sure he\u0026rsquo;d love that. Okay, so office visits might be an exam requiring the doctor or another kind of appointment that only requires a technician. ‑Right. We also have to worry about our rooms too. We only have five exam rooms available, and we try not to overbook. We don\u0026rsquo;t like for our clients to have to wait too long in the reception area, especially if we have a lot of cats and big dogs out there at the same time. It makes them all really nervous. ‑What about other staff? ‑So our technicians will float between the exam rooms and other areas of the clinic as needed, except, of course, for those scheduled technician visits. We do have a schedule for the staff, but it\u0026rsquo;s separate from how we schedule our appointments. ‑Okay, so what about the surgeries? ‑Well, if it\u0026rsquo;s a surgery, those are only scheduled on certain days, and they require that the operating room be available, as well as some recovery space in the kennel area. It also depends on what kind of surgery or procedure we\u0026rsquo;re going to be doing. Something simple like a dental cleaning takes less time and fewer people than a caesarean section for a bulldog. ‑Okay, so an appointment is either an office visit or a surgery. Office visits happen in the exam room; surgeries require the operating room and recovery space. Is that right? ‑Right. And depending on the reason for the visit or the surgery, different staff might need to be involved. ‑So we\u0026rsquo;ll probably want to have separate classes for appointments and surgeries. ‑Classes? No, we refer our clients to obedience and puppy preschool classes at other facilities. We don\u0026rsquo;t actually schedule any of those in the clinic themselves. ‑I\u0026rsquo;m sorry. That\u0026rsquo;s a software term. In software, we have different classifications of concepts in the program, which are called classes. I\u0026rsquo;m just getting ahead of myself here. Sorry. ‑Don\u0026rsquo;t worry. We\u0026rsquo;re not going to make you learn our software terms. Steve and I will try to have a little bit more self control with that. We do want to make sure we\u0026rsquo;re all speaking the same language when it comes to concepts in the application though. ‑Okay, so I have another quick question. Do we have to worry about multiple staff members scheduling appointments at the same time? ‑No, there should only ever be one person doing the scheduling at a time, although I could see if we grew in the future that could change. But I don\u0026rsquo;t think that\u0026rsquo;ll happen in the next couple of years. Okay, then we don\u0026rsquo;t have to worry about the rare occurrence of two people creating a conflict if they\u0026rsquo;re trying to schedule an appointment for different patients in the same room or with the same doctor. That\u0026rsquo;ll keep things a lot simpler. And we need to know before an appointment if certain resources are available, like rooms and doctors. And then if they are and we want to schedule the appointment, then we need to be able to book the doctor, the room, and any other resources. Hey, is it okay if we refer to doctors as resources? ‑Sure, that makes sense. You know, I think it makes sense to use the term resources to refer to the doctors, the rooms, and the technicians since those are all things that can affect whether or not an appointment can be scheduled. But remember, sometimes it\u0026rsquo;ll be just a vet tech in a room, and other times it might be the doctor in the room, but sometimes you might need the doctor, the technician, and a room. ‑Wow, this is a lot more complicated than we\u0026rsquo;d realized, but it\u0026rsquo;s interesting. This is going to be cool to model in the application.\nReviewing Key Takeaways from Meeting with Domain Expert(s) Some of the things we learned in that initial high‑level discussion with the domain expert included the fact that patients and clients are not the same thing to a veterinarian. ‑Yeah, that\u0026rsquo;s pretty obvious in hindsight. But in most other medical professions, it is the patients who make appointments and pay the bills. It\u0026rsquo;s good we were able to get on the same page with the customer on that early on in the process. ‑I think it helped Dr. Smith put some of the processes she uses into explicit terms that we could program against also. A lot of times just describing the process to someone who is unfamiliar with it can really help improve the understanding of it. It\u0026rsquo;s like that idea that when you have to teach something to someone else, it makes you learn it a lot better. Listen to what Dr. Smith had to say at the end of our conversation about this. ‑Yeah, I never really thought about the details of how we do some of these things since it\u0026rsquo;s just something we do, and we don\u0026rsquo;t really think about it. Being more explicit about what the rules are that determine how we do are scheduling could help us avoid some of the occasional scheduling problems we\u0026rsquo;ve had. This is going to be great. ‑We also need to remember not to use too much programmer jargon, especially when there are programming terms that might have a different meaning in the customer\u0026rsquo;s domain. ‑I agree. It\u0026rsquo;s a little early for us to be worrying about how things might end up looking in the code anyway. At this stage, the main focus is on understanding the domain. We\u0026rsquo;ll get to building the software soon enough. But first, we want to make sure we know what problem it\u0026rsquo;s going to be solving. One of the most important things we can do as we explore the problem with the domain expert is to try and make their implicit knowledge about the process they use now explicit. Once we\u0026rsquo;re able to capture the process and its rules and exceptions with some detail, we can start to work on modeling a solution using this information. Building software is hard. One of my favorite sayings is as software developers, we fail in two ways. We build the thing wrong, or we build the wrong thing. By making sure we understand what the customer needs and, of course, working closely with the customer throughout the development process, we can dramatically reduce the likelihood of the second kind of failure, which is much harder to fix typically. ‑Hey, Steve. I like the way you quote yourself here, but it really is a great quote.\nTaking a First Pass at Modeling our Subdomain After talking to Dr. Smith about how appointments work, we\u0026rsquo;ve identified a few high‑level elements of our model. The central concept in this application seems to be the appointment itself. Typically, an appointment is scheduled by a client for a patient. Booking an appointment often requires an exam room and a doctor, but may involve other resources. Appointments might be for office visits or vaccinations, or they might be surgeries, which are a separate kind of thing entirely with their own rules which involved different kinds of procedures. Surgeries require different resources too, like operating rooms and recovery rooms. ‑That\u0026rsquo;s a pretty good high‑level view of the model we have so far for the appointment management part of our application. I think it\u0026rsquo;s worth noting that some of the concerns of this application are going to also play a part in other subdomains. For instance, I\u0026rsquo;m pretty sure we\u0026rsquo;re also going to be working with clients and patients in a lot of the different parts of this application. ‑Yeah, I think it\u0026rsquo;s time we introduce the idea of bounded contexts.\nUsing Bounded Contexts to Untangle Concepts that Appear to Be Shared As you develop your model, remember to identify its bounded context. That is, where is this model valid? If you don\u0026rsquo;t put boundaries around your model, eventually, pieces of it will be used where they don\u0026rsquo;t fit. Concepts that make sense in one part of the application may not make sense in another, even if they have the same name and sometimes even if they literally refer to the same thing. ‑For example, as we built out the appointment scheduling portion of this system, we needed to know some very basic information about clients. But in the context of appointment scheduling, these are very simple concepts with little behavior beyond their names. However, in the billing context, we\u0026rsquo;ll want to include contact and payment information for clients, but that\u0026rsquo;s information we don\u0026rsquo;t care about back in the appointment scheduling context. If we try to reuse the same exact client model in multiple places, it\u0026rsquo;s likely to cause inconsistent behavior in our system. ‑That\u0026rsquo;s right. For instance, we might decide to include some form of validation on clients to ensure we have enough information to bill them. If we\u0026rsquo;re not careful, that validation might inadvertently prevent us from being able to use clients to schedule appointments, which certainly isn\u0026rsquo;t the desired behavior. Maybe the billing system requires that clients have a valid credit card in order to save changes for them, but it wouldn\u0026rsquo;t make sense for a lack of a credit card to prevent us from saving an appointment for a client in the appointment scheduling system. In this example, we have two contexts, but the boundaries between them are blurred and overlapping. Eric Evans notes that models are only valid within specific contexts. Therefore, it\u0026rsquo;s best to explicitly define the context within which a model applies. We should be able to avoid compromising the model within this context, keeping it strictly consistent within these bounds and avoiding distractions or confusion from outside issues. ‑Once we explicitly define our bounded contexts, we can easily see whether or not we have elements of our model that are trying to span multiple contexts. In this example, we\u0026rsquo;d want to keep a simple view of a client in the appointment scheduling up and a richer version of the client with contact and billing information in the billing context. We would define these two views of a client in two separate classes, and they will most likely live in separate applications. In fact, Evans recommends that bounded contexts maintain their separation by giving each context its own team, codebase, and database schema. ‑While this is ideal, in many real‑world apps, we need to work on systems where this level of separation is not present, usually due to resource constraints or for political reasons within the organization. Remember though, if you have multiple contexts, you\u0026rsquo;ll want to keep them bounded. And one way to maintain this separation is to keep their data, code, and team members distinct from one another, although in real world, I\u0026rsquo;ve never seen something with that level of separation. ‑Yeah, but I think even if it\u0026rsquo;s not possible to literally do that with your company and your team, just having that concept in mind really helps in your brain have that idea of separation. ‑I agree. I know that just thinking about the fact that these things ought to be separated and trying to figure out a way to do it means that even if you can\u0026rsquo;t get to the ultimate level where everything is is completely separate, you can still introduce separations through things like namespaces, separate folders, separate projects, anything you can do to make it clear that these are different contexts that shouldn\u0026rsquo;t be sharing too much information. ‑You know, I think that\u0026rsquo;s also really important point about this course in general and DDD in general. For me, it\u0026rsquo;s really hard to think of all of these things we\u0026rsquo;re learning as hard and fast rules, like you have to do it this way or you\u0026rsquo;re not doing it right. I like to see all of this as really good guidance. So, you know, it helps me keep my eye on the prize, and when there\u0026rsquo;s places where I can\u0026rsquo;t truly achieve exactly what DDD kind of directs me to do, you know, I\u0026rsquo;m using my own experience, my own intelligence to make decisions about how to do things, and I\u0026rsquo;m letting DDD guide me in a lot of scenarios. ‑Sure. And some of these ideals, I think of like 100% test coverage. It\u0026rsquo;s almost impossible in most real‑world applications to achieve 100% test coverage. But just because that ideal is not something you can ever achieve doesn\u0026rsquo;t mean that you shouldn\u0026rsquo;t strive for more test coverage. ‑Yeah, yeah, totally, totally agree with that.\nConversation with Eric Evans on Subdomains and Bounded Contexts When learning about DDD, most of us have a hard time understanding how subdomains and bounded contexts are different. We asked Eric Evans about this and got some great insight. He explained that a subdomain is a view on the problem space, how you\u0026rsquo;ve chosen to break down the business or domain activity, whereas a bounded context represents the solution space, how the software and the development of that software has been organized. Quite often, these will match up perfectly, but not always. ‑Eric helped us understand this further with the example of a room that you want to cover with carpeting. The room is the problem space, so it\u0026rsquo;s like a subdomain. You could install a wall‑to‑wall carpet that matches the shape of the room perfectly. This would be like when the subdomain and the bounded context encompass the same thing. But other times you might just use some area rugs to cover the floor, and the area rugs solve the problem. They cover the part of the floor where you walk, and you don\u0026rsquo;t have to worry about cold feet in the winter. And that\u0026rsquo;s a scenario where the area rugs are like bounded contexts that don\u0026rsquo;t match the subdomain, but they solve the problem even though they\u0026rsquo;re not an exact match to the shape of the room.\nIntroducing Context Maps If your organization has multiple bounded contexts, and ideally these are separated, there can be confusion when the different teams are talking to one another. Again, DDD focuses at least as much on effective communication as it does on anything specifically related to the code we produce. Evans recommends using context maps to visualize and demonstrate to all teams where the boundaries between their context lie. ‑Think about a complex topographical map. It will frequently include a legend, like the one shown here, in order to explain what each of the lines and symbols on the map mean. However, this legend is only valid within the context of the map with which it appears. Trying to use this legend on another map would be confusing at best. ‑A good first step for an existing application is to create a map that shows how things are. Remember that the names of your contexts are also important as you\u0026rsquo;ll refer to them frequently when discussing different parts of the application. It may be that things are not as separate as they should be, and that\u0026rsquo;s worth noting. If you have separate teams responsible for different contexts that share resources, it\u0026rsquo;s important that each team understands which aspects of the application they can change on their own and which are shared dependencies they\u0026rsquo;ll need to coordinate with other teams to avoid breaking things. If we look at these two sets of concepts, we can see some obvious overlap. For one thing, Client appears in both contexts, but we know that for appointment scheduling we really only care about the client\u0026rsquo;s name, whereas in the billing system they\u0026rsquo;ll want additional information like address and payment details. However, although the details involved vary, we know that Mr. Jones, the client on the left, is the same actual person as Mr. Jones, the client on the right. However, we also have a concept of notifications on both sides, and in this case, they\u0026rsquo;re referring to different things. On the left, we\u0026rsquo;re talking about sending a notification when an appointment is booked as a reminder, and on the right, we\u0026rsquo;re talking about notifying the client that their payment was received or perhaps that it\u0026rsquo;s past due. ‑Especially in smaller organizations, it\u0026rsquo;s common to have one team responsible for several contexts of the same overall application. In such cases, it\u0026rsquo;s also common for the team to use a single codebase for the bounded context that they\u0026rsquo;re working with and store it in a single repository, such as GitHub. Usually, there will also be a shared database. As we\u0026rsquo;ve already noted, this is not ideal since it makes it much more difficult to maintain the boundaries between the separate contexts. ‑Part of creating a context map involves explicitly identifying its boundaries. If we try to draw the boundaries around these two bounded contexts, we can see there are now several resources that belong to each bounded context. This isn\u0026rsquo;t ideal if the two contexts really are meant to be kept separate. ‑In the ideal case for a large complex system, we would have bounded contexts like these, with their own teams, codebases, and database. For instance, on the left, we have an appointment scheduler application. It\u0026rsquo;s being worked on by Team Awesome, and they\u0026rsquo;re storing all of their code in their own repository called vet‑app‑sched. And, of course, this application has its own database. This team is free to change anything they want with their model or any other part of their system without worrying about breaking anything outside the boundaries for the team on the right, which is working on a billing system, and their team has decided to call themselves Team Ultimate, store their code in a repository called vet‑billing, and, of course, using their own database. By having this separation, this can greatly increase team velocity and reduce integration bugs. ‑Of course, you\u0026rsquo;re probably wondering how the two systems will interoperate. There are a number of patterns that can be applied to enable this kind of integration. We won\u0026rsquo;t be covering all of them in this course, but one question that frequently comes up is how to share cross‑cutting concerns like blogging and shared abstractions such as people names that are used by multiple bounded contexts. For this scenario, a common approach is to designate these shared concepts or resources as what we call a shared kernel. Team Awesome and Team Ultimate agreed to share the subset of the domain model. Since they\u0026rsquo;re sharing it, they also agree not to change it without coordinating with the other team first. Frequently, the shared kernel will either be a part of the customer\u0026rsquo;s core domain, or some set of generic subdomains, or even both, though it could be any part of the model that both teams require. Using a shared kernel is a tradeoff between code reuse and consistency and the overhead involved in integrating changes to the shared kernel across multiple teams and bounded contexts. It works best when the shared model is relatively stable.\nAddressing the Question of Separate Databases per Bounded Context The concept of having separate databases for each bounded context often throws people for a loop. But with the advent of microservices, which also, by definition, each have their own database, teams are beginning to get more accustomed to the idea. Here\u0026rsquo;s what Eric Evans said to us when we talked with him about the problems created by trying to share a database across teams. \u0026ldquo;If you\u0026rsquo;re in a company where you share your database and it gets updated by hundreds of different processes, it\u0026rsquo;s very hard to create the kind of models that we\u0026rsquo;re talking about and then write software that does anything interesting with those models.\u0026rdquo; Given that sharing a database across bounded contexts is really not a great idea, then we have another important question. ‑Another question that comes up often is how to sync data between the individual databases that are tied to each of the bounded contexts. Some different patterns you can use are publisher/subscriber, commonly referred to as pub/sub, and two‑way synchronization. Pub/sub is definitely simpler and preferable when you can manage it. You can use different implementations like message queues, database processes, batch jobs, or synchronous API calls. It\u0026rsquo;s really up to you how you want to design your synchronization between bounded contexts. The point is just that you don\u0026rsquo;t get the integration for free from using a shared database.\nSpecifying Bounded Contexts in our Application We talked with Eric again to get his perspective on defining context boundaries. Some of the key points he shared were that first, it\u0026rsquo;s important to understand that it\u0026rsquo;s never a simple task whether you\u0026rsquo;re new to it or not. And he\u0026rsquo;s seen stumbling blocks of all sorts. The most common is not having a clear enough context boundary, so the effort of applying DDD isn\u0026rsquo;t clearly separated from other tasks related to building software. ‑He also reminded us that the bounded context is such an essential ingredient that is probably the biggest stumbling block. And it\u0026rsquo;s not often one that an individual on a project can usually addressed by themselves. It kind of has to be dealt with at the team level or even the organizational level. In our application, we\u0026rsquo;ve organized the solution to make it clear where the boundaries are between our contexts. The main area that we are currently focused on is the appointment scheduling bounded context. ‑We\u0026rsquo;ve identified two other bounded contexts that are involved in the overall application or will be eventually. For instance, it\u0026rsquo;ll be important for users to be able to manage clients and their patients. The staff of the clinic also needs a way to manage their schedules so they know who\u0026rsquo;s working on different days. We\u0026rsquo;re referring to these two bounded contexts as client patient management and resource scheduling. ‑We also have a few parts of the application that are common to several bounded contexts. These are cross‑cutting concerns that we have consciously chosen to share. In DDD, we isolate such code into its own package referred to as a shared kernel, and it\u0026rsquo;s worth noting that a bounded context does not always mean a separate application, even though we\u0026rsquo;ve identified several different bounded contexts. ‑It\u0026rsquo;s also a great opportunity to consider packaging logic up into microservices. Do keep in mind, however, that there\u0026rsquo;s not always a 1:1 alignment between bounded contexts and microservices or applications. Also, let\u0026rsquo;s not forget that our application will definitely need a front end.\nUnderstanding the Ubiquitous Language of a Bounded Context We\u0026rsquo;ve mentioned already that an important part of DDD is an emphasis on effective communication among the stakeholders in the project. And remember, if you\u0026rsquo;re a programmer, count yourself as one of the stakeholders in whatever you\u0026rsquo;re working on since you certainly have a stake in its success. The language we use to describe the problem and how we choose to model it is key to the shared understanding we want to have with our domain experts in order to be successful. Having a single, shared, ubiquitous language helps avoid unnecessary confusion and translation within the team building the software and is one of the fundamental practices of Domain‑Driven Design. And when I talk about the team building the software, I don\u0026rsquo;t just mean the programmers. I mean the whole team, including the business people that are deriving what the software should do. The discovery of the Rosetta Stone allowed us to unlock several different languages by showing the same message in three different texts. We don\u0026rsquo;t want to have to have a Rosetta Stone or any other sort of tool to help us translate between what the business is talking about and what the programmers are talking about. We want to make sure that everyone is speaking the same language the whole time so that translation is unnecessary. ‑Think about if you\u0026rsquo;ve ever used an online translation tool to round trip a sentence. You can run into similar communication issues in your application if you\u0026rsquo;re constantly having to translate to and from the domain expert terms or the programmer\u0026rsquo;s terms. Here\u0026rsquo;s an example of a user story for a sample system about creating appointments. ‑We have a lot of developer friends in Nigeria, so I thought it would be fun to try out Igbo for our translation. We used a website to translate between English and Igbo a few times, and in the end, the user story has changed just enough to create confusion. Translation software is pretty good these days, and we were hoping for a more humorous result, but according to animal experts, it\u0026rsquo;s close, but not the same as a veterinary technician. ‑But the point here, of course, isn\u0026rsquo;t just relating to different international languages, but to the different languages spoken by business experts and programmers. ‑Incidentally, a great practice when you\u0026rsquo;re discussing your system requirements with customers is to always try and explain back to them what you think it is they want the system to do so they have an opportunity to correct your understanding of what they think they just told you. ‑Definitely. Remember, one of the key benefits of using a ubiquitous language is that all parties can understand it without having to perform any translation. This means when you show a test or some code to a domain expert, you don\u0026rsquo;t have to explain that in the system you call something an animal when the domain expert calls it a patient. ‑Evans cautions that a project faces serious problems when it\u0026rsquo;s language is fractured. When domain experts stick to using their jargon while the technical team members have their own language tuned to discussing the domain terms in the design, translation errors will manifest as software bugs. Neither the customers nor the developer\u0026rsquo;s language is sufficient for all parties to discuss the application effectively. What is needed is a shared common language that incorporates and uses terms defined in the domain model. The use of this language must be ubiquitous, and the more the language is used, the more will force deficiencies in the model into the open. ‑And by ubiquitous, we mean it must be used everywhere within the bounded context. The vocabulary of the language includes the names of model classes and prominent operations. The team should use these common terms in code, in diagrams, on the whiteboard, in design documents, and especially when discussing the system. ‑Yeah, pretty much ubiquitous means everywhere, all the time. Even in that one email you\u0026rsquo;re sending off to another developer, stick to using the terms that you\u0026rsquo;ve agreed makes sense for this bounded context.\nConversation with a Domain Expert: Working on our Ubiquitous Language You\u0026rsquo;ve heard some of our conversations that helped lead to a ubiquitous language for the scheduling app. There was another important one that happened early on between Michelle and me that we want to share with you now. ‑Pay attention to not only the clarification of the terms, but also to the fact that Julie and Michelle are equal partners in this conversation. Although Julie is trying to lead the conversation towards the goal of identifying the correct terms, she\u0026rsquo;s careful not to make assumptions about Michelle\u0026rsquo;s domain. ‑So Michelle, last time you and Steve and I got together to talk, Steve and I have been working on just kind of fleshing things out and planning things, and I realized that we had some confusion over some of the common terms, like things that, as real pet owners, we would kind of assume the terms are, but then when we\u0026rsquo;re thinking about business and software, we\u0026rsquo;re thinking of the terms a little differently. So I was wondering if we could just sort that out with you so that we\u0026rsquo;re all on the same page and using the same terms and using terms that none of us have to stop and think about what we\u0026rsquo;re talking about. We\u0026rsquo;ll always know what they mean. ‑Sure. ‑The first thing is we have these clients, those are the people who own the pet. So when thinking about the software and business, we think of them as clients, but kind of in the real world, and me, I have a pet, I go to the vet all the time. I think of myself as a pet owner. So what do you refer to those people who bring the pets, pay their bills, call and make the appointments, etc? ‑Most of the time, I mean those would be listed as as clients. ‑Okay, so you do call them clients. You don\u0026rsquo;t worry about calling them owners, and of course, it sounds kind of weird to say I own a dog, right? ‑He kind of owns you. ‑Yeah, that\u0026rsquo;s more like it. You\u0026rsquo;re the pro you know. So then what about that dog, like are they patients, are they pets, are they clients? What do you refer to the pets as? ‑So for the purpose of the medical record, we refer to them as the patient. ‑Okay. So it would be client and patient. ‑Exactly. And actually in veterinary medicine they talk a lot about this triad, the veterinary client/patient relationship, where all three are really important in that. ‑Okay. So those are actually terms that are commonly used in your industry. Industry, that sounds so weird, but with that. Cool. Alright, so the next one we were also going back and forth on was an appointment or an office visit. When somebody is scheduling a visit, scheduling to come in, how do you refer to that? ‑So there would be two big subsets of what they might be scheduling to come in for. They might schedule a surgery, which is an easy one to define. They\u0026rsquo;re going to come in, we\u0026rsquo;re going to do some sort of a procedure. Usually, there is going to be some anesthetic involved. That would be a surgery and that would be outside of our normal office hours. ‑Oh, okay. So what about when they just come in for regular stuff? ‑So when they come in for regular appointments, you could call those office visits or appointments, and there are a few different subsets of those. You may have an appointment that\u0026rsquo;s a wellness exam, and in that exam, we would be doing, of course, a physical examination and generally wellness treatments like vaccination, some blood work, generally your healthy pet who is coming in for a routine checkup. ‑So that\u0026rsquo;s an office visit and there is a couple other things that come under the umbrella of office visit, but if I, I\u0026rsquo;m also thinking about scheduling because that\u0026rsquo;s the thing we\u0026rsquo;re really going to be focused on is the scheduling portion of the app. So we\u0026rsquo;re always scheduling an appointment, an appointment for a surgery, an appointment for an office visit, whatever type of office visit that is, so is using the term appointment, does that make sense? Would you, if if I said appointment would you think that could be a surgery, that could be a checkup, that could be whatever. This thing to be scheduled is what I want to define. ‑Yeah, I mean I think you could call them all appointments, but I would differentiate between the surgery and something that\u0026rsquo;s done in the office, but then I would further differentiate in the office between a wellness exam, an exam for somebody that\u0026rsquo;s coming in with a problem, or an exam that doesn\u0026rsquo;t need to see a doctor, but could just be done by a technician like a toenail trim. ‑Oh good. Yeah, we always need those, clickety‑clack on the floors. Alright, so I think then we\u0026rsquo;ll use just the overall umbrella of we\u0026rsquo;ll schedule an appointment and then we\u0026rsquo;ll be more explicit about what type of an appointment that\u0026rsquo;s going to be. Would that feel okay to you? ‑Yeah, that makes sense to me. ‑Great. Excellent. Alright, so I\u0026rsquo;ll get back to Steve and then we\u0026rsquo;ve got another meeting set up I think in a few days to just hash out some more details after Steve and I\u0026rsquo;ve gotten some more of our ducks in a row. ‑Sounds great! ‑Excellent. Thanks Michelle. Bye bye. ‑Thank you. Bye. ‑Now we have a stake in the ground for our ubiquitous language. As we continue working with Michelle, not only will we learn more items for the bounded context, but there is also a chance that the ubiquitous language will evolve. Eric Evans guides us to pay attention to those changes because a change in the ubiquitous language is also likely to mean a change in the domain model. We have to update our design to accommodate what we\u0026rsquo;ve learned.\nReviewing Important Concepts from This Module We\u0026rsquo;ve covered quite a few concepts in this module. One of the most important ones is just understanding the problem domain and the overall thing that your software is working within. ‑‑And breaking things apart. I know that when I started out, I had a really hard time really understanding differences between the core domain, the subdomains, and the bounded context, especially the subdomains and the bounded context because at first glance, they looked like the same thing to me. ‑‑Sure, it\u0026rsquo;s really easy to have an application where you have some kind of a concept, like a customer that you know is used by every system that your organization uses. And it ends up becoming this like God object in your database and in your different applications where any given application might only care about a tiny subset of that concept. ‑‑Yeah. So, for me, I think the most important thing is really focusing on the bounded context. Getting down to that and understanding about the boundaries. One thing that helps me a lot is just stating within the context of this and then suddenly like, oh right, that\u0026rsquo;s what a context is. It\u0026rsquo;s not like some mysterious new term that Eric Evans invented. He just is leveraging what makes sense. Within the context of appointment scheduling, this is what a client looks like. Within the context of billing, this is what a client looks like. ‑‑Sure, I think that makes a lot of sense. And it\u0026rsquo;s valuable, even when you have an application, like a legacy application that wasn\u0026rsquo;t built with domain‑driven design. Let\u0026rsquo;s go ahead and look at some more terms here. For instance, we\u0026rsquo;ve got what you were just talking about, I think of as context mapping. And even in a legacy application, it can be valuable to kind of map out what are all the concepts in this application and where are the overlaps with different subdomains that maybe we haven\u0026rsquo;t even defined in this legacy application. ‑‑Yeah. Even if you\u0026rsquo;re not planning on making huge changes to it, it\u0026rsquo;s still really, really helpful to just kind of update your perspective on things. Sometimes it just leads to new understandings. ‑‑I think the shared kernel is a really important part of this, too, because in almost every real‑world organization I\u0026rsquo;ve worked with, there are different types of cross‑cutting concerns, and we talked about one of them being the authentication piece, and that\u0026rsquo;s definitely a really common one. But there are usually others too that you want to share. ‑‑Yeah, and, again, it\u0026rsquo;s another one of those things that sounds like it might be a big, scary, mysterious thing because you haven\u0026rsquo;t referred to it that way, but if you really just start out thinking of it as the common stuff, but then‑‑‑I think one of the important things, though, is even within the context of domain‑driven design, we have a ubiquitous language because if I say common, you might have a different idea of what I mean by common, but if I say shared kernel, we\u0026rsquo;ve got an agreed‑upon understanding of what we\u0026rsquo;re talking about there. So at first, I really kind of pushed back against using these terms because I felt like a lot of the DDD experts were just throwing them around all the time. And then I started really getting a better understanding of why it\u0026rsquo;s important to use those terms. It\u0026rsquo;s about‑‑‑it\u0026rsquo;s the ubiquitous language of domain‑driven design so everybody\u0026rsquo;s on the same page. ‑‑Yeah, I do agree that that\u0026rsquo;s an important part of learning about DDD and other areas of software development, like, for instance, design patterns. These things give us these terms that we can use that are very, very dense. If we talk about shared kernel, it would take me three or four sentences to describe what I meant by that. But in these two words, you know exactly what I mean, just like if I talk about using a strategy design pattern, that is much easier to convey than if I were to try and describe it with words and have to draw a UML diagrams to say what I mean. ‑‑And it\u0026rsquo;s the same, again, with the ubiquitous language because now I really have a better understanding of the fact that what it means is the language is ubiquitous throughout a particular bounded context. When we\u0026rsquo;re talking about a scheduling app, we\u0026rsquo;re going to use these terms all the way through, like you were saying before, we use it not just when we\u0026rsquo;re talking to the domain expert but in our class names, in our methods, it\u0026rsquo;s just ubiquitous throughout all of the pieces of the things that are involved in that bounded context from one end all the way to the other of it. ‑‑And I think as we\u0026rsquo;ll see when we look at the code again, some of the constructs in .NET, like namespaces, are really appropriate to ubiquitous language because when you prefix that same term in your code with a particular namespace, that tells all the other programmers that if I say SchedulingApp.notification, we know that that has a different meaning that if I\u0026rsquo;m talking about EmailReminder.notification. ‑‑Or SchedulingApp.client versus Billing.client. ‑‑Exactly.\nReview and Resources In this module, we learned about our domain, in this case, a veterinary practice. We talked about it at length with a real live domain expert and identified the core elements of our domain model. We identified a variety of subdomains and focused in on the key area that we would be addressing first with our application. ‑We spent some time designing the system based on our conversations with Michelle, identifying boundaries between different contexts, and noting how sometimes the same object with the same name might mean something different within a different context. ‑Finally, we talked about the importance of communication in general and in particular having a ubiquitous language. We know that Domain‑Driven Design can help us avoid many design errors and wasted time miscommunicating as we work on a complex project. ‑Steve and I are so grateful to Eric Evans for spending time with us while we were creating this course in order to share his luminous advice and insights. In the next module, we\u0026rsquo;ll drill into the domain model so you can have a good understanding of its critical elements. ‑This is Steve smith, ‑and this is Julie Lerman. Thanks again for watching Domain‑Driven Design Fundamentals.\nElements of a Domain Model Introduction and Overview Hello, this is Julie Lerman, ‑and this is Steve Smith. ‑In this module, we\u0026rsquo;re going to focus on the elements of a domain model which are in our bounded context. ‑You\u0026rsquo;ve seen these in the mind map. It\u0026rsquo;s patterns like entities and aggregates and more. ‑You can find me online at ardalis.com or on Twitter as @ardalis. ‑And you can find me online at thedatafarm.com or on Twitter at @julielerman. ‑In this module, we\u0026rsquo;ll focus on the technical aspects involved when modeling a bounded context. We use these terms while modeling, and these same terms refer to patterns we\u0026rsquo;ll use when we code. The concepts flow through the entire process, which is great. You don\u0026rsquo;t have to keep switching hats or mindsets. ‑We\u0026rsquo;ll start by grounding ourselves in the domain and understand why it\u0026rsquo;s important to stay focused there. DDD models are driven by behaviors, not classes and properties. This is another very cool shift in thinking for those of us who have always focused on objects. Then you\u0026rsquo;ll learn about some terms used to describe domain models, rich and anemic. You learn what the terms mean at a conceptual level and what the code that they\u0026rsquo;re describing looks like. ‑Entities are the key types in your system, but not every type in your system is an entity. ‑You\u0026rsquo;ll learn how entities fit into DDD, how to differentiate entities that have complex needs from simpler entities that might only need some basic CRUD logic, and you\u0026rsquo;ll be able to see how we\u0026rsquo;re implementing all of these concepts in our code.\nThe Importance of Understanding DDD Terms Domain‑Driven Design is filled with lots of specific terms. Much like the ubiquitous language that we use to make it easier to communicate while working within a bounded context, understanding and using the terms of DDD makes it easier to talk about the process. We\u0026rsquo;ll spend the bulk of this module focusing on some of the concepts behind modeling bounded contexts, concepts that are critical to this process, but, unfortunately, often misunderstood. ‑I\u0026rsquo;ve definitely had my challenges with some of the DDD concepts. Some of my issues were because the terms overlap with other technologies I use. For example, I do a lot of work with Microsoft\u0026rsquo;s ORM called Entity Framework. Entities are a key element in Entity Framework, and they\u0026rsquo;re also a key element in DDD. So I thought my understanding of entities from Entity Framework was enough to translate to DDD entities, but it really wasn\u0026rsquo;t, and my less than solid grasp on DDD entities caused problems when I was trying to model domains and implement the model and code. We also have the concept of a context in Entity Framework. While the real goal of that context is to provide interaction with the database, it also does provide a boundary around a model. But it\u0026rsquo;s very different than the concept of a bounded context, and that definitely confused me for a while. Another important element in a DDD model is value objects. These got me pretty confused at first, and my ego was saved by discovering that others have also been confused by value objects. But I\u0026rsquo;ve worked on my DDD education and sorted these problems out, so in this module, it\u0026rsquo;s really important to both Steve and I that you start off on the right foot with a proper understanding of entities, value objects, and some of the other DDD puzzle pieces so that Domain‑Driven Design can help you with your complex problems, not complicate them even more.\nFocusing on the Domain It\u0026rsquo;s important to remember that first D in DDD stands for Domain, and yeah, the other two Ds, Driven and Design. But we really want to focus on Domain here. ‑By now, you\u0026rsquo;ve probably heard us talk about this plenty, but both Julie and I find that we constantly have to remind ourselves to focus on the domain. We hear ourselves begin to talk about the user interaction with the app and have to ask, well, what part of the vet clinic domain is this user? Yeah, obviously we care about the user and how the actual application will work from their perspective, but that\u0026rsquo;s for another conversation, and we have to draw ourselves back to focusing on modeling the domain. ‑I have quite a long history with data access, and I catch myself worrying about how our domain model will translate to the database so that things definitely get persisted correctly. That\u0026rsquo;s when Steve needs to give me that look, you\u0026rsquo;re doing it again, Julie, and I have to bring my focus back to the domain of the vet clinic again. So while it may seem redundant to harp on domain, domain, domain, this diligent focus will help you avoid the complications and distractions that come from thinking outside of the domain or the subdomain that you\u0026rsquo;re focused on. ‑Here\u0026rsquo;s an important quote from Eric Evans\u0026rsquo; book about this focus on the domain. \u0026ldquo;The Domain Layer is responsible for representing concepts of the business, information about the business situation, and business rules. State that reflects the business situation is controlled and used here, even though the technical details of storing it are delegated to the infrastructure. This layer of the domain is the heart of business software.\u0026rdquo; ‑Just to reiterate, the domain model is the heart of the business software. This is the whole point behind Domain‑Driven Design. Focus on the domain, not the technical details of how the software will work. ‑In a typical database‑driven app, we\u0026rsquo;re used to focusing on properties or attributes of classes. Our apps sometimes become all about editing property values and the state of our objects. However, when we are modeling a domain, we need to focus on the behaviors of that domain, not simply about changing the state of objects. ‑Michelle didn\u0026rsquo;t talk to us about setting the name of a dog or editing the time of an appointment. She told us that she needs to schedule an appointment, and when she does that, she needs to book a room and create a schedule item on a doctor\u0026rsquo;s calendar as well. So scheduling appointment is a lot more than setting the attributes of the objects involved, the appointment time and identity of the pet we\u0026rsquo;re making the appointment for. We\u0026rsquo;re talking instead about how the system behaves. In response to scheduling an appointment, the system should also book a room and do something to the calendars of the doctor and any vet techs that might be involved.\nIdentifying Events Leads to Understanding Behaviors An important way to identify behaviors in your system is by focusing on events. Doing so gives you a great path to understanding the behaviors of your domain. Alberto Brandolini devised a great way to brainstorm with clients, which is referred to as event storming. It begins by having a somewhat chaotic brainstorming session with a good number of domain experts writing events on Post‑its and sticking them on a wall. The format of what they write is in the past tense. For example, an appointment was booked, a client contacted the office, or a dog was weighed in. I facilitated quite a few event storming workshops with clients, and I\u0026rsquo;m a big fan of using this process to help get a picture of the domain, discover bounded contexts, and even discover key problems that should be addressed. Another interesting methodology for modeling a system based on events is called Event Modeling. Adam Dymitruk came up with this workflow and has had great success using it to help teams collaborate on learning about the domain and designing the flow of software. I was fortunate to participate in a three‑day workshop with Adam to learn about Event Modeling. We won\u0026rsquo;t be teaching you about event storming or Event Modeling in this course, those are beyond the scope of our goals here, but we did want to be sure you were aware of them. You\u0026rsquo;ll find links for more information about event storming and Event Modeling at the end of this module.\nComparing Anemic and Rich Domain Models In order to understand the difference between design that\u0026rsquo;s focused on attributes versus design focused on behaviors, it will help to understand two commonly‑used terms in domain‑driven design, anemic domain models and rich domain models. An anemic domain model is a domain model that is focused on the state of its objects, which is the antithesis of DDD. While the term is somewhat negative indicating a deficiency, you don\u0026rsquo;t need to perceive it that way. There is nothing wrong with anemic classes when all you need to do is some CRUD logic, but if you are creating a domain model, you\u0026rsquo;ve already made the decision that your domain is too complex for simple CRUD. So anemia in a domain model is considered an anti‑pattern. ‑Martin Fowler writes about anemic domain models with such drama that you may never mistakenly use them in your domain model. He says the basic symptom of an anemic domain model is that at first blush it looks like the real thing. There are objects, many named after the nouns in the domain space, and these objects are connected with the rich relationships and structure that true domain models have. The catch comes when you look at the behavior and you realize that there is hardly any behavior on these objects making them little more than bags of getters and setters. Indeed, often these models come with design rules that say you are not to put any domain logic in the domain objects. Instead, there are a set of service objects would capture all the domain logic. These services live on top of the domain model and use the domain model for data. ‑What we aim for then is rich domain models, not anemic domain models when we are modelling our domain. Rich domain models will represent the behaviors and business logic of your domain. Classes that simply affect state are considered an anti‑pattern in a domain model, and therefore, get the nasty label of anemic, even though they are perfectly fine in a CRUD model. Martin Fowler doesn\u0026rsquo;t mince words when it comes to anemic domain models saying the fundamental horror of this anti‑pattern is that it\u0026rsquo;s so contrary to the basic idea of object‑oriented design, which is to combine data and process together. I have to say I agree and I\u0026rsquo;ve worked with many teams who have had to deal with the self‑inflicted pain of treating their domain entities like DTOs lacking any encapsulation or behavior. That can work for simple CRUD apps, but it\u0026rsquo;s often a disaster in a DDD model. ‑While Martin Fowler and other DDDers have strong words to say about anemic domain models, we\u0026rsquo;d like to share a gentler message, which is to strive for rich domain models and have an awareness of the strengths and weaknesses of those that are not so rich.\nUnderstanding Entities Even though a DDD app is driven by behavior, we still need objects. DDD expresses two types of objects, those which are defined by an identity and those which are defined by their values. We\u0026rsquo;ll focus first on the objects that are defined by their identity. These objects are called entities. ‑An entity is something we need to be able to track, locate, retrieve, and store, and we do that with an identity key. Its properties may change, so we can\u0026rsquo;t use its properties to identify the object. If you\u0026rsquo;ve done any type of data persistence in software, you\u0026rsquo;re probably pretty familiar with entities and their keys. When we are modeling a problem, we can talk about entities without having to think about how they are implemented in the resulting software. But when it is time to start coding, there are patterns to follow to ensure that these objects have the technical attributes of Domain‑Driven Design entities. ‑As you can see from this section of the DDD navigation map, entities are pretty integral to our software. So, before we can learn about these other elements, domain events, repositories, factories, and more, you should have a very good understanding of an entity. ‑The most important entity in our model is Appointment. This is what we will be creating, editing, and retrieving in the context of scheduling appointments. Appointment inherits from a base class we\u0026rsquo;ve created called Entity. We\u0026rsquo;ll look at that more in just a bit. Notice that all of the classes shown here are inheriting from the identity base class. However, although the other classes are entities, after our discussions with Michelle, we came to the conclusion that we would like to have a separate utility for managing client and patient information and to manage information about staff and staff scheduling. Thus, we don\u0026rsquo;t need very much information or behavior related to these collaborating entities within the bounded context of appointment scheduling.\nDifferentiating CRUD from Complex Problems that Benefit from DDD ‑Let\u0026rsquo;s take a closer look at that data that supports scheduling appointments in our system. ‑We determined that managing the client, patient, and staff information, which is external to this model, was well‑suited to just simple CRUD. We didn\u0026rsquo;t identify complex rules or behaviors for creating and editing that data. Thus, the concepts of doctors, rooms, clients, and patients are managed outside of the scheduling bounded context. ‑For comparison, look at the CRUD classes for Patient and Client in the other bounded context. They\u0026rsquo;re very simple. They don\u0026rsquo;t inherit from our entity base class, and most interestingly, their ID properties are integers. We\u0026rsquo;ll let the database assign the IDs when we create these classes. So these classes are not designed using domain‑driven design. Now let\u0026rsquo;s go back to the appointment scheduling context. The client, patient, doctor, and room classes here are completely different from the CRUD classes we just saw. However, they do have a subset of the same fields from those CRUD classes. All we need to know about these objects when we\u0026rsquo;re scheduling is their IDs, their names, and maybe a few other details. But here, they\u0026rsquo;re simply used as look‑up data, and they\u0026rsquo;reread‑only.\nSwitching Between Contexts in a UI Even though our domain is split up into a number of bounded context, the user interface can be designed in a way that moving from one context to another is seamless to the end users, they don\u0026rsquo;t need to know that these things are in separate bounded contexts. While maintaining client and patient data is a completely separate task from scheduling appointments, Michelle wanted to be sure that anyone working at the front desk is able to easily move between these tasks in the software without disrupting their workflow. So let\u0026rsquo;s say the person at the clinic who does the scheduling is on the phone with Kim and about to make an appointment for Roxy to come in, but then the other line rings, they put Kim on hold, and it\u0026rsquo;s me. And in the nicest way possible, I\u0026rsquo;ve called to just let her know they\u0026rsquo;ve got my last name spelled wrong. That happens all the time. People just want to put that h in there. Even though they\u0026rsquo;re in the middle of scheduling and scheduling has its own backend, its own bounded context, and is totally separate from client management, they can still drive the app right over to the Client Management area and very quickly fix my name and save that. Then they can just flip back to the schedule. Notice that Kim is still the active scheduling client that\u0026rsquo;s showing up in the left‑hand corner and the change to the spelling of my last name is already visible on the schedule. And so now that person can go ahead and finish up with Kim scheduling the very adorable Roxy for a wellness exam. To the user, there is no real difference between doing the scheduling and doing the client management, it\u0026rsquo;s just a nice smooth flow between the two, it doesn\u0026rsquo;t feel like, oh, now we have to open up a different application in order to do this other thing and doesn\u0026rsquo;t break everything they\u0026rsquo;re in the middle of, but for the purposes of designing our application, everything is bound within its own individual context. And when designing this context, we don\u0026rsquo;t have to worry about switching from one context to another. ‑So remember, we\u0026rsquo;re talking about what makes these all entities. An appointment object needs to be located and tracked and we need to be able to edit them easily. Using a unique identity allows us to persist and retrieve an appointment even if some of its values change. Appointment is definitely an entity in our system. We actually had to think a little more about client, patient, doctor, and room in this particular context. Our discussions highlighted the fact that when creating appointments, we only need access to some of the high‑level information about the client, patient, doctor, and room, but these objects won\u0026rsquo;t be edited. So we wanted these stripped down read‑only types that give us minimal amount of detail for each. We do still need to be able to uniquely identify them though, they do have some identity. If the client\u0026rsquo;s name changes, a change we would make in the client management system, that new name will need to be reflected when we look at the appointment scheduling for that client. There should only ever be one record to represent a particular client in this bounded context. So client and the other types that are reference types in this context are still entities. We triple checked our decision with another kind of domain expert, Vaughn Vernon, a DDD expert, and we were happy to get his thumbs up on this particular decision. So Julie, Michelle, and I also talked about how to name the types that are simply reference types in this particular bounded context. At first, we were worried that we might get confused by having different definitions of client, patient, doctor, and room. We wanted to call them client details or client view or something like that, but thanks to the ubiquitous language, the fact that we are in the scheduling context drives our comprehension of what a client means in this particular space. ‑A client in scheduling is still a client, so we use the same name, even though it\u0026rsquo;s a differently defined pipe than the client we work with in the Client/Patient Management app. ‑Right, and thanks to namespaces in our code, we\u0026rsquo;re able to keep it clear which ones are which in the code.\nUsing GUIDs or Ints for Identity Values So, all these types inherit from our base entity class. However, notice that those reference types use int for their base entity\u0026rsquo;s ID and not the GUID that\u0026rsquo;s used by appointment. That\u0026rsquo;s because all of the management of those other types happens to be done using CRUD, and with CRUD, it\u0026rsquo;s easy to just use database‑generated ints. Appointment is built using DDD principles, and you\u0026rsquo;ll see that it\u0026rsquo;s much easier to use GUIDs when building DDD entities and their related logic rather than relying on the database to provide the identity values. Not only is it easier, but it follows DDD principals more clearly, since we will build all of our domain logic around appointments without involving the database. We would have a hard time working with appointments in our model and in our unit tests as we develop the application if we always needed a database to assign their IDs. ‑So that\u0026rsquo;s not to say that you can\u0026rsquo;t use integer IDs If you\u0026rsquo;re going to use a DDD style of application; it just makes it a little harder. Wouldn\u0026rsquo;t you say, Julie? ‑Yeah, yeah, and I\u0026rsquo;ve definitely come up against that. With the stuff that I do with Entity Framework, I\u0026rsquo;ve made sure that I show patterns for continuing to use the database‑generated ints because I didn\u0026rsquo;t want to give people the impression that they had to throw away, like, for me like 25 years of this dependency. And like all of a sudden I have to go cold turkey and move over to GUIDs. ‑Sure, I mean, there\u0026rsquo;s trade‑offs in what you choose to use for your ID, but having an ID that we can generate in the client and just in our code has a lot of value. ‑Every time we\u0026rsquo;ve been working on some of our different unit tests and we needed as part of the test to instantiate something that was an int, we were like, ugh, now we have to find another way to get that in there because we were protecting it and it was a problem. As our own experience grew, we realized there\u0026rsquo;s another way to bridge this conflict by using both GUIDs and database‑generated ints in an entity. This way, while creating objects, you\u0026rsquo;ve got the control over key generation with the GUIDs, and they\u0026rsquo;re not depending on the database. However, once the data has been created in the database and int keys exist for it, then you can benefit from those when adding indexes and performing queries in the database.\nTalking with Eric Evans About the Responsibility of Entities We talked with Eric Evans to gain some additional insight into entities. Specifically, I asked him how entities align with the single responsibility principle. ‑‑If you\u0026rsquo;re not familiar with this object‑oriented programming principle, you can learn more about it in Steve\u0026rsquo;s SOLID course right here, on Pluralsight. ‑‑One of the questions that I\u0026rsquo;ve heard is, What is the single responsibility for an entity? Or to put it another way, does having an entity that has a lot of business logic in it violate the single responsibility principle? ‑‑Eric told us that entities are very central, and so it\u0026rsquo;s natural that they get heaped up with lots of functionality. ‑‑But there\u0026rsquo;s a downside to this. As you build out the system, there are more and more conflicting demands for these central entities, so they end up being huge. Evans said that the main responsibility is the identity and the lifecycle. ‑‑Eric also told us that single responsibility is a good principle to apply to entities, and it points you towards the sort of responsibility that an entity should retain. Anything that doesn\u0026rsquo;t fall into that category, we ought to put somewhere else.\nImplementing Entities in Code Let\u0026rsquo;s take a look at an entity in our veterinary appointment scheduling application, FrontDesk. We\u0026rsquo;re going to look at the Appointment class, which defines all the information that we need to schedule an appointment for a particular animal or patient. It associates the patient with the doctor, room, and appointment type, and also includes the start and end time for the appointment. Now, the Appointment class inherits from BaseEntity, which is a generic base class. In this case, it\u0026rsquo;s BaseEntity, as you can see here. The GUID is defining the type of our identity property, our ID. ‑Right. And we talked about that earlier when we were looking at the structure of the different entities in this model. We wanted Appointment to have a GUID because we\u0026rsquo;re creating new appointments on the fly. So, let\u0026rsquo;s take a look at that BaseEntity class. First of all, it\u0026rsquo;s an abstract class. So we can\u0026rsquo;t just create a BaseEntity object, we have to create something that is a BaseEntity, such as an appointment. And using generics, we\u0026rsquo;re saying that the BaseEntity is going to use whatever type we ask it to, and that type is for defining the ID. So for Appointment, we said BaseEntity is going to be using a GUID as its identity. I mentioned this earlier, why I would need GUID for appointment in this context because I need to be able to create new appointments in this context, and I\u0026rsquo;m not going to be waiting for the database to generate the ID for me. So using a GUID lets me create that ID right up front as I\u0026rsquo;m creating that new appointment. So I\u0026rsquo;m giving it its ID. The BaseEntity class also has a property to hold a list of domain events that will define explicitly for each of the types that inherit from this base entity. You\u0026rsquo;ll learn more about domain events further on in this course. ‑All right, so let\u0026rsquo;s take a look back at the rest of Appointment. Now, since Appointment has more behavior than just state, we don\u0026rsquo;t want to have it just be a bag of properties that our application can get and set however they would like. ‑Because that would be an anemic domain model. ‑Yes, because that would tend to lead us toward a more anemic domain model. ‑And we want a rich one. ‑Now, in particular, we\u0026rsquo;re also constraining how we create this appointment. We want to ensure we create appointments in a valid state, so that means passing in the minimum necessary elements an appointment needs to have. Sometimes we\u0026rsquo;ll want to update an appointment. Remember, these aren\u0026rsquo;t value objects. They\u0026rsquo;re not immutable, so we can change them. When we need to modify an appointment, we\u0026rsquo;re going to do that through methods. And so, for instance, if we decide we want to modify what room an appointment is scheduled in, we\u0026rsquo;re going to do that through a method rather than just a setter. We do this because there\u0026rsquo;s additional behavior we may want to do. In this case, we have some guards, again to ensure a valid value is being passed. ‑These guards are a set of reusable functions that you\u0026rsquo;ll find in the shared kernel of our solution. ‑And we also want to raise an appointmentUpdatedEvent, that we might handle and send a notification or perform some other action as a result of what happened. ‑And that also gives us the flexibility in the future to change what type of logic we want to trigger. ‑And that\u0026rsquo;s something we can\u0026rsquo;t do very easily If we just let anybody in the application set the value. ‑Right. ‑By providing a method to use to update room explicitly and otherwise making the setter private, we force all interaction with the model to use this method, which gives us just one place to model behavior that should be associated with this operation. It\u0026rsquo;s the same as with the constructor, we need to do our best to keep our domain model in a consistent state so the rest of the application can count on it being correct. ‑Right, because otherwise somebody could satisfy the requirement that they pass in the room ID, but they might pass it in as 0, which would be invalid. So, we\u0026rsquo;re further constraining that they don\u0026rsquo;t do that either. The appointment would be invalid if it had a room ID that didn\u0026rsquo;t correspond to an actual room entity. And in any case, the database wouldn\u0026rsquo;t let that fly since there\u0026rsquo;s a foreign key relationship between appointment and room. ‑Yes, but we want to make at least some effort to catch such problems in our code, rather than relying on the persistent store to inform us of a user error. Overall, using guard clauses, like the ones you\u0026rsquo;ve seen here, help us ensure our entities aren\u0026rsquo;t partially constructed and inconsistent. Once we\u0026rsquo;ve created an appointment, we need to record it as part of the clinic schedule, which involves some additional rich behavior. So, if we scroll down to the bottom, we have this method called Schedule. And this is where we\u0026rsquo;re going to do the additional work involved with actually saving an appointment and ensuring it fits in with other appointments that have already been scheduled. We\u0026rsquo;re not going to worry about the code at the moment, but the idea is that this method would query the database for other appointments that might be near this one and make sure there is an available slot in the schedule that this one fits into. Then it will save the appointment and raise an event, letting the rest of the app know that a new appointment has been scheduled. In the next module, we\u0026rsquo;ll investigate this design further and revise it a little bit. Now, let\u0026rsquo;s look at one more simple entity that this bounded context needs, the Doctor class. You can see that Doctor inherits from BaseEntity as well, but in this case it\u0026rsquo;s using an int for its key. The only other property it has is a string Name property. ‑This is a minimal implementation of the Doctor type that satisfies the scheduling bounded context. It\u0026rsquo;s essentially no more than a reference type. Doctor and the other similar types, Patient, Room, etc., are all organized into this folder called SyncedAggregates.\nSynchronizing Data Across Bounded Contexts Let\u0026rsquo;s dig a little more into how these reference types in the scheduling bounded context are getting their data from the Clinic Management app, especially if the two BCs aren\u0026rsquo;t sharing a database. If you recall from seeing the class descriptions of all of these classes, the AppointmentType, Client, Doctor, Patient, and Room, we had explicitly decided that these are reference entities where we\u0026rsquo;re actually doing their maintenance elsewhere so they\u0026rsquo;re not adding any unneeded complexity to the Front Desk application. ‑‑Right. And they\u0026rsquo;re just READONLY. So we\u0026rsquo;re never having to create or modify them. ‑‑And we\u0026rsquo;re using the ints that were created by the database when we persisted these with a CRUD context in a different application, but there are still entities here, just entities of type integer. The Clinic Management bounded context is responsible for updating these types. When changes are made, application events are published by Clinic Management, and this Front Desk bounded context subscribes to those events and updates its copies of the entities. ‑‑One of the questions we get all the time when we describe how bounded contexts have separate databases is, How do we synchronize changes between these two apps? This is one of the simplest and most common approaches. One app is responsible for updates, and the other apps just subscribe to the changes and are notified when they occur. ‑‑This is an example of eventual consistency. The two systems aren\u0026rsquo;t immediately kept in sync using a transaction or something similar, but through message queues, eventually the different bounded contexts are updated to the new state when a change is made.\nReview and Resources We\u0026rsquo;ve covered a lot of ground in this module and you\u0026rsquo;ve learned a lot of new terms, so we just want to review some of them with you before we move onto the next module. The first is a pair of terms that often go hand in hand, anemic domain models versus rich domain models. And remember the anemic domain models, while often looked down upon from the perspective of DDD, they\u0026rsquo;re perfectly fine for CRUD. These are models that look a lot more like a database schema than a class that has lots of methods and rich behavior in it. On the other side of that is a rich domain model, which is what we strive for in domain‑driven design, and that\u0026rsquo;s a model that really is focused on behavior, not just changing the values of properties. ‑Then we talked about entities and entities tend to be one of the core pieces of our domain model. The key thing that distinguishes an entity from other types in our model is that it has some kind of identity that we can use to track it over time and to bring it in and out of persistence. This module provided you with your first look at implementing a bounded context in code, an important part of tactical design. You learned about the difference between anemic models and rich models, and that while anemic models have their place, focusing on behavior with rich domain models is how DDD lets us solve complex problems. Entities are the classes in our domain models that are tracked by an identifier allowing us to build graphs and eventually persist and retrieve that data. ‑Sometimes we are working with entities whose behavior and rules are critical to the bounded context in which we\u0026rsquo;re working. Other entities may only provide supporting or reference data. You learned how to help identify the differences between them. Then you got to look at the appointment class in our scheduling app to see how we have applied rules and behaviors in that entity. You also looked at one of the reference entities and learned how we use message queues to ensure the reference and the data that is maintained in the clinic management app is made available to the scheduling bounded context, even though they do not share a database. ‑In the next module, we\u0026rsquo;ll focus on some more important elements of a domain model, value objects and domain services. We\u0026rsquo;ve referenced a lot of interesting and helpful resources in this module and here are two pages of links for you to follow up with if you want to dig in a little further, including Steve\u0026rsquo;s Pluralsight course on SOLID principles of object‑oriented design and information on event storming and event modeling. This is Julie Lerman ‑and this is Steve Smith, and thanks for watching our course, Domain‑Driven Design Fundamentals.\nUnderstanding Value Objects \u0026amp; Services in the Model Introduction and Overview Hello! I\u0026rsquo;m Julie Lerman. ‑And I\u0026rsquo;m Steve Smith. Welcome back to Domain‑Driven Design Fundamentals. In this module, we\u0026rsquo;ll continue exploring the elements of a domain model as we dig into value objects and domain services. ‑Value objects are a confusing concept. So we\u0026rsquo;ll begin by looking at where they fit into the mind map and introducing what makes an object a value object, and how they relate to entities in a model. ‑We\u0026rsquo;ll share some more guidance from Eric Evans and Vaughn Vernon, and then show how we\u0026rsquo;ve implemented value objects in our code. ‑Next, you\u0026rsquo;ll gain a high‑level understanding of domain services, and solidify that by exploring their features, and then some examples of domain services.\nGetting Acquainted with Value Objects When introducing entities, Steve and I talked about objects that were defined by a thread of continuity and identity, not defined by their values. So, what about objects that are defined by their values? These are called value objects, and they play an equally important role in a domain model, as entity objects do. ‑A value object has very specific characteristics. It is an object that is used to measure, quantify, or describe something in your domain. Rather than having an identity key, its identity is based on the composition of the values of all of its properties. Because the property values define a value object, it should be immutable. In other words, you shouldn\u0026rsquo;t be able to change any of the properties once you\u0026rsquo;ve created one of these objects. Instead, you would simply create another instance with the new values. If you need to compare two value objects to determine if they are equal, you should do so by comparing all of the values. Value objects may have methods and behavior, but they should never have side effects. Any methods on the value objects should only compute things; they shouldn\u0026rsquo;t change the state of the value object, since it\u0026rsquo;s immutable, or the system. If a new value is needed, a new value object should be returned. Don\u0026rsquo;t confuse the value object\u0026rsquo;s pattern with C# and .NET support for value types and reference types. Custom value types in C# are defined with structs, while reference types are defined as classes. In DDD, both entities and value objects are typically defined as classes. Classes have advantages over structs when it comes to encapsulation and support for inheritance‑based extension and reuse.\nRecognizing Commonly Used Value Objects To help you better understand the basics of value objects, let\u0026rsquo;s take a look at some value objects that you probably use all the time as a developer. The most commonly employed value object is a string. In .NET and many other languages, a string type is immutable, and you now know that immutability is one of the key attributes of a value object. A string is a collection of characters, and the combination of all those characters give that string meaning. For example, C‑A‑R in English, a car. If a string were mutable, we could change the R to T. Now the string is C‑A‑T, a cat, which has a very different meaning than a car. Or we could add a letter, maybe put an S in front of it, turning CAR to SCAR, also completely changing the meaning of car. But it\u0026rsquo;s not just the array of characters that gives a string its meaning, the order of them is also critical. Just think of the word dog, d‑o‑g. Shifting its letters around gives us something with a very different meaning. ‑So one of the things that .NET makes it really easy to do is to modify strings, like you can change the length of it or make one all upper case. But when you call, for example, ToUpper on a string, it doesn\u0026rsquo;t just change that string object, it gives you a new instance of a string that now has all uppercase characters. ‑Many developers say that monetary values in financial systems have been perfect candidates for value objects in their system. And Ward Cunningham provides us with a really helpful example, a company\u0026rsquo;s worth. If a company is worth 50 million dollars, that means something, 50 million dollars. It\u0026rsquo;s a very specific measurement. Fifty million on its own is not a measurement, it has no meaning without the unit, which in this case is dollars. But dollars alone doesn\u0026rsquo;t describe worth either. In fact, dollars doesn\u0026rsquo;t really help, does it, because is it US dollars or Canadian dollars, Australian dollars? It only makes sense when you put the two together as 50 million US dollars. There\u0026rsquo;s actually one more factor to take into account, is the point in time of this 50 million dollars because of the way financial systems work and the fluidity of monetary values. ‑We could still just have the two properties in this Company class, but by creating a value object you also protect and constrain the measurement. For instance, we might have a class called Company. It might have one decimal property that represents the worth amount and another string property that represents the worth unit. The problem with this approach is that it doesn\u0026rsquo;t tie these properties together in any way. These two properties appear to be independent of one another, but they\u0026rsquo;re obviously closely related. If an update is made just to the Worth Unit string, it could obviously have a tremendous impact on the company\u0026rsquo;s worth as a combination of these two concepts. Fifty million rupees has a very different worth than 50 million US dollars. To ensure nobody can set the unit without also specifying the amount, a separate value object can be introduced to represent the entire worth concept. This ensures the entire object must be updated as a whole. Since the worth type is immutable, the only way to make updates to the Worth property on the Company class is by replacing the whole instance with a new one, not just changing an isolated field. ‑A value object is not always for a measurement though. It can be another type of description. Eric Evans calls out dates as a great example for value objects. I\u0026rsquo;ve used this one often, DateTimeRange, and it was perfect for the vet appointment scheduling app. We usually set a start and an end time together and can\u0026rsquo;t really set one without the other. Also, we often need to pass the two values, start and end time, around from one method to another. So we\u0026rsquo;ve encapsulated them in a value object called DateTimeRange. The properties have private setters, which makes the object immutable since we can\u0026rsquo;t change them. We aren\u0026rsquo;t showing the full logic of the class here, but when we look at the value objects in our application you\u0026rsquo;ll see more of how we implement a value object in our software to ensure that it meets all of the attributes, not just immutability, but how we handle equality, comparison, and other logic.\nGetting More Insight from Eric Evans and Vaughn Vernon In his book, Implementing Domain‑Driven Design, Vaughn Vernon recommends that we should try to use value objects, instead of entities, wherever possible. He says, it may surprise you to learn that we should strive to model using value objects instead of entities wherever possible. Even when a domain concept must be modeled as an entity, the entity\u0026rsquo;s design should be biased towards serving as a value container rather than a child entity container. What this means is that you\u0026rsquo;ll find that your design will have a number of entities who have very little logic of their own or very few primitives as their properties, but instead will have a number of properties that each are themselves a value object. ‑So he\u0026rsquo;s not saying everything should be value objects, but that it\u0026rsquo;s probably our natural instinct to start by thinking of things as entities and then maybe once in a while go, oh, maybe that should be a value object. So what Vaughn is suggesting is really start by thinking every time should this be a value object and you will surprise yourself at how many times something that you originally might have thought of as an entity really does make a lot more sense as a value object. ‑Or sometimes when you\u0026rsquo;re looking at an entity, there might be a couple of properties that seem to always go together, you might be able to bundle these properties into a single value object. It\u0026rsquo;s interesting to note that identity values can be treated as value objects as well. In many systems, entities have a primitive type, usually int or GUID as their ID, but this means that it\u0026rsquo;s easy to substitute a client ID for a patient ID if developers are not careful. By creating actual value objects for client ID and patient ID, which can still be stored as ints or GUIDs, it can eliminate this kind of error from our design. ‑Here is an example of a Client class that\u0026rsquo;s inheriting from base entity, but specifying that the type will be ClientIdValueObject rather than a scalar type like int or GUID, that\u0026rsquo;s followed by a service class that has a CreateAppointmentFor method which takes a clientId and a patientId. If those IDs were both GUIDs, the runtime code would allow you to accidentally pass them in in the wrong order because the signature is only constraining that you pass in two GUIDs and that could create a big problem when you\u0026rsquo;re trying to build an appointment. But with the specialized value objects, you can tightly constrain the parameters to avoid this problem rather than adding a lot of extra logic elsewhere to protect you from making that mistake. For me, this highlights the beauty of DDD thinking. With this little bit of upfront work, you\u0026rsquo;re removing the complexity of solving the kind of problem that could be created by accidentally transposing the client id and patient id. In our conversations with Eric Evans, we asked him for his thoughts on putting logic into value objects. He told us that he thinks value objects are a really good place to put methods and logic because we can do our reasoning without side effects and especially the complications that identity brings along, all those things that make logic tricky. We can put functions on those value objects and then do the pure reasoning right there in the value object. ‑Eric also called out date libraries as a good example of a value object. They perform common functions on dates so we don\u0026rsquo;t have to keep coding them ourselves in our entities or services. For example, a date library could be used for calculating a person\u0026rsquo;s age from their birth date. As long as the library causes no side effects to the date in question, it can work well as a value object.\nImplementing Value Objects in Code Our primary demo involves scheduling appointments. Appointments have a start and an end time. These two things always go together, so they make sense to extract as a value object. Here\u0026rsquo;s a closer look at the DateTimeRange ValueObject we created for the course\u0026rsquo;s demo. We also have a DateTimeOffsetRange, which is identical, but includes support for time zones. Because DateTimeRange is a pretty low‑level concept that could be useful in a number of different applications, it\u0026rsquo;s implemented in the shared kernel package. The class inherits from a ValueObject base class that provides flexible equality checking behavior, so we don\u0026rsquo;t need to clutter our class with overloads for Equals, GetHashCode, et cetera. It was written by fellow author and DDD expert, Vladimir Khorikov. ‑Because this is a ValueObject, you can see that all of its properties are read only. Recent versions of C# and Entity Framework Core do allow us to avoid even having a setter in there when we want to define read‑only properties, and we also now have the use of records in C#. EF Core can comprehend read‑only properties that don\u0026rsquo;t have any setters at all, and it takes advantage of fields. But here we\u0026rsquo;ve written our value objects in a more generalized way that\u0026rsquo;s not taking advantage of any specific or specialized features. However, you can adapt these samples to benefit from those specific APIs and language versions that you\u0026rsquo;re working with. The important goal here, though, however you implement it, is that the state of the value object should not be changed once it\u0026rsquo;s been created and as part of the domain model. ‑Right. Value objects should get all of their state through their constructor, and any invariants that need to be checked should happen in a constructor as well. In this case, the date time range is guarding against having a start time that exceeds its end time. If it does, an exception will be thrown. The second constructor that takes a timespan calls the first one using constructor chaining, so in either case, the guard will always be enforced. Since the DateTimeRange is immutable and cannot be created in an invalid state, the rest of the domain model can count on it being valid. ‑Our DateTimeRange type does have some additional methods that let us create new DateTimeRange instances from existing ones, much like the DateTime type provides options to create new date times by adding time to an existing instance. In our type, for example, to change an appointment set to end at 10:30 instead of ending at 11:00, a new instance of DateTimeRange can be created using the newEnd method. Finally, the base ValueObject class requires overriding a GetEqualityComponents method. This is used when comparing two instances of the ValueObject, and it\u0026rsquo;s up to you to decide which properties should or shouldn\u0026rsquo;t be included. In the case of DateTimeRange, the start and end times are sufficient. If two DateTimeRange instances have the same start and end values, they should be considered equal. ‑Custom logic needed to determine whether one appointment overlaps with another is another area where the ValueObject can help. The whole appointment isn\u0026rsquo;t needed to determine if there is an overlap in appointments. Only the DateTimeRange is used in such a calculation. Thus, the Overlaps method, shown here, has been moved out of the Schedule and Appointment classes and into the ValueObject, where it is more reusable, and it reduces the complexity and responsibilities of the other domain types. ‑We asked Eric to share his thoughts on moving logic out of entities into value objects. He agreed that it\u0026rsquo;s a good idea. What he said was if there\u0026rsquo;s logic that\u0026rsquo;s really the classic software logic, I like to add that in value objects. You can really test value objects much easier than entities, and you can use them much more freely. So your entity becomes this critical piece of glue, an orchestrator among different value objects. But that doesn\u0026rsquo;t mean that you won\u0026rsquo;t have some logic in the entity. It\u0026rsquo;ll just be very concise. ‑Eric also said that it\u0026rsquo;s a nice way to work towards the ubiquitous language to the point where you look in the methods of the entity and you see higher‑level things. They read like use case level communication, rather than nitty gritty detail. My personal takeaway from this is to keep an eye on the properties of your entities, and specifically, their types. If you find that they\u0026rsquo;re all primitive types, like ints and strings, think about if any of those primitive things could be grouped together as value objects instead. Another value object that we can point out here is the AnimalType. This is just to give you an idea that our value objects can be extremely simple. In this case, AnimalType is just a combination of the species and the breed of a particular pet or patient that we\u0026rsquo;re dealing with at the vet clinic. And there\u0026rsquo;s not a whole lot of other behavior here. But it does provide us with a container by encapsulating these two related properties together as a single value object.\nUnderstanding Domain Services When an operation is important to the model but doesn\u0026rsquo;t necessarily belong on any one entity or value object, a service is often appropriate. But don\u0026rsquo;t be too quick to give up on finding a natural home for the operation on an existing entity or value object or you may end up with a very procedural anemic model. Frequently, domain services serve as orchestrators for operations that require several different collaborating entities or value objects. Evans notes that good domain services must first and foremost not be a natural part of an existing entity or value object. Again, we don\u0026rsquo;t want to shift all of our rich behavior from our entities and value objects to our services. Services should also have a defined interface that\u0026rsquo;s comprised of domain model elements. And finally, domain services should be stateless, though they may have side effects. What this means is we should always be able to simply create a new instance of a service to perform an operation, rather than having to rely on any previous history that might have occurred within a particular service instance. But of course, the result of calling a method on a service might result in changes to the state of the system itself. These rules apply specifically to domain services which belong in the core of our application. Your software will likely also use services to perform work related to infrastructure or as part of the front end of the application. ‑Here are some examples of the kinds of services we might find in different layers of a DDD application. The UI layer represents the front end of the system and should have as little business logic as possible. It is frequently combined with the application layer, which should be concerned with behavior necessary for the application, but unrelated to the customer\u0026rsquo;s problem domain. For example, the application may need to work with file formats or parse some XML, and it might have services for these purposes, but these are unrelated to the domain. In the core of the application where we store our core model and domain objects, we will define any domain services for operations that don\u0026rsquo;t belong somewhere else. These services will frequently involve operations on multiple domain elements or may be responsible for orchestrating some kind of workflow. For instance, processing an order might involve a series of steps and multiple domain elements as the system checks inventory, verifies customer information, maybe charges a credit card, and then sends messages to ship the order, notify the customer, and reduce inventory. Finally, we have infrastructure‑level services. These will usually implement interfaces that are defined in the core of the domain, such as I send email. But since they require access to external dependencies, like file systems, databases, or network resources, they live in the infrastructure layer of the system. With respect to our domain, you may find infrastructure not very interesting, ‑although the people who create the internal workings of those services might find them quite fascinating. We\u0026rsquo;ll look at implementing services in our application later on in the course.\nReview and Resources Let\u0026rsquo;s review some of the important terms you learned in this module. You heard us talk about immutability, which is a really critical attribute for value objects. And immutability just means once an object has been instantiated, you can\u0026rsquo;t change the value of any of its properties. ‑Another important term we learned about is the value object. A value object is an immutable class that is defined by the sum of the different properties that it has. We don\u0026rsquo;t need an identity for a particular value object. In fact, a value object doesn\u0026rsquo;t have any identity outside of the individual properties that it has. And in order for us to compare value objects, we simply compare all of its properties, and if they all match, then we can consider these two value objects to be equal. We also learned about domain services and these are interesting because domain services give you a place to put logic and behavior that you can\u0026rsquo;t find a home for in the entities and value objects in your domain. ‑And the last term that we want to review is side effects. Side effects are changes that occur in your application or any kind of interaction with the outside world. Now, technically any change to the state of the application can be considered a side effect, but generally when we\u0026rsquo;re talking about them, we\u0026rsquo;re talking about things that changed other than the main intent of the operation that you\u0026rsquo;re performing. For instance, it\u0026rsquo;s often a good idea to keep operations that query information separate from those that change state, and if you follow this practice, then any queries that you make, that result in changes to state would be said to have side effects. That brings us to this module\u0026rsquo;s key takeaways. Most of this module was focused on value objects, which are used in your domain model to measure quantify or describe something in the domain. Value objects typically don\u0026rsquo;t exist alone, they\u0026rsquo;re usually applied to an entity to describe something about it. ‑Value objects should be compared using only their values. They don\u0026rsquo;t have an identity. Any two value objects that share the same values should be considered equal. And value objects in our domain should be designed to be immutable taking all of their needed values in their constructor and they shouldn\u0026rsquo;t have any side effects. ‑We looked at a few examples of value objects in this module. We mentioned the .NET Framework string type that you\u0026rsquo;ve no doubt used. Strings and datetimes are value objects that are available to any .NET application and can be used as a model for how you should design your own value objects. We also looked at a couple of custom value objects we used in our sample application, the datetime range and the animal type objects. ‑Finally, we wrapped up the module by introducing domain services, which are used to orchestrate operations between different parts of your domain model. Remember that domain services should generally only be used if you don\u0026rsquo;t have an entity or value object where the behavior makes sense. Overuse of domain services can lead to an anemic domain model. In the next module, you\u0026rsquo;ll learn how to build aggregates from entities and value objects while respecting their relationships. Here are some links and resources relevant to the topics of value objects and domain services that we discussed in this module. Thanks for watching Domain‑Driven Design Fundamentals.\nTackling Complexity with Aggregates Introduction and Overview Hello, this is Julie Lerman. ‑And this is Steve Smith. ‑Welcome back to Domain‑Driven Design Fundamentals. In this module, you\u0026rsquo;ll learn more about aggregates and the associations between entities. ‑We\u0026rsquo;ve talked about the domain model and the need to have effective communication in order to ensure the model is a useful representation of the customer\u0026rsquo;s problem space. However, most problems that weren\u0026rsquo;t using domain‑driven design can be quite complex. So now we\u0026rsquo;re going to specifically look at some patterns and techniques that can be used to manage this complexity. ‑We\u0026rsquo;ll cover several new terms along the way, including aggregates and aggregate roots. You\u0026rsquo;ll learn about invariants and the aggregate roots\u0026rsquo; responsibility for them. Aggregates often contain related data, so we will explore how to model relationships, often referred to as associations in DDD. ‑Then, we\u0026rsquo;ll look at our application and see how thinking about the aggregate roots pattern helps us revise and simplify our model. ‑And finally, we\u0026rsquo;ll walk through how we\u0026rsquo;ve implemented this pattern in our code.\nTackling Data Complexity Let\u0026rsquo;s start by considering data complexity. If you\u0026rsquo;ve ever worked on a relatively large or mature application, you\u0026rsquo;ve probably seen some fairly complex data models. One way to reduce the complexity that we already talked about is using aggregates and aggregate roots, which you\u0026rsquo;ve seen in the DDD mind map. Another is by limiting how many bidirectional relationships you have in that data model. ‑If your design doesn\u0026rsquo;t have any clear notion of aggregates, the dependencies between your entities may grow out of control, resulting in a model like this one. And if your object model reflects a data model like this one, trying to populate all of the dependent objects of one object might result in trying to load the entire database into memory. And the same problem exists when it comes time to save changes. With a model like this, there\u0026rsquo;s just no limit to which areas of the data model might be affected. ‑Even though in the real world at the highest levels of your system all of these things really do interrelate, we need to be able to separate them to keep the complexity of the system in check. ‑I\u0026rsquo;ve gone into a lot of clients where their entity data model looks like this, and they\u0026rsquo;re using this one big, huge single model throughout their entire system. So, one of the things that I work on with them is breaking this down and using the whole concept of bounded contexts to start looking at what makes sense for smaller models. ‑Yeah, a system that\u0026rsquo;s designed like this is what we tend to call a big ball of mud because everything is just kind of slapped together, and it collapses under its own weight once it gets to a certain level of complexity. ‑Great. So, let\u0026rsquo;s see how we can use aggregates to help solve the problem.\nIntroducing Aggregates and Aggregate Roots Aggregates consist of one or more entities and value objects that change together. We need to treat them as a unit for data changes, and we need to consider the entire aggregate\u0026rsquo;s consistency before we apply changes. In the examples shown here, the address is part of the customer and the component is quite literally a part of the product. We can treat a set of changes to a customer and their address as a single transaction. Every aggregate must have an aggregate root, which is the parent object of all members of the aggregate, and it\u0026rsquo;s possible to have an aggregate that consists of just one object, in which case that object would still be the aggregate root. ‑In some cases, the aggregate may have rules that enforce data consistency that apply across multiple objects. For instance, maybe our product consists of a collection of components, but in order to be in a valid state, it needs to have a specific set of such components. As an example, if the product is a Lego minifig, the collection of parts won\u0026rsquo;t be a valid product unless it includes a head, an upper torso, a lower torso, two arms, two hands, and two legs. If we allowed the collection of components to be modified independently of the product it was associated with, we could easily end up with consistency problems. If we want to modify the composition of a product, in this example, we should do so as a transaction, so that we start and end with a valid product. Data changes to the aggregate should follow ACID, that is they should be atomic, consistent, isolated, and durable. It\u0026rsquo;s also the responsibility of the aggregate root to maintain its invariants, such as the number and type of components it requires in the example. An invariant is a condition that should always be true for the system to be in a consistent state. When considering whether particular objects should be treated as an aggregate root, you should think about whether deleting it should cascade, in other words, if you need to also delete the other objects in its aggregate hierarchy. If so, it\u0026rsquo;s likely the object in question should be considered an aggregate root. ‑Another way to think about whether it makes sense to have an object as an aggregate root is to ask, does it make sense to have just this object detached from its parent? In the example shown here, if you\u0026rsquo;re deleting the minifig, then you have to delete all of its parts. Conversely, if you have to delete a head, maybe it got broken, you don\u0026rsquo;t need to delete the rest of the parts. Therefore it doesn\u0026rsquo;t make sense for the head to be the root of this aggregate. ‑In the Domain‑Driven Design book, Eric Evans states this pretty simply, he says, an aggregate is a cluster of associated objects that we treat as a unit for the purpose of data changes.\nConsidering Associations in Aggregates When considering aggregates, which, as Evan says is a cluster of associated objects, it\u0026rsquo;s also important to think about relationships between those associated objects, especially those which exist within the aggregate. Before diving into how related entities participate in an aggregate, it\u0026rsquo;s important to learn some important concepts that DDD brings to us when considering relationships among entities. ‑Many developers, myself included, tend to define relationships between classes in both directions. For example, an order has a line item and a line item has an order, a pet owner has pets and a pet has an owner. Many of us tend to think in bidirectional relationships by default. Because domain‑driven design aims for simplicity in the model, we start recognizing more quickly that the bidirectional relationships can often make things overly complex. For instance, I\u0026rsquo;ve often found this to be true when it comes to adding in my persistence layer, and I happen to mostly use an ORM Entity Framework, which brings along its own behavior and assumptions about how relationships are managed. Sometimes the fact that my model includes navigation properties that may not be totally necessary can be the cause of some grief that\u0026rsquo;s led me to take some time to consider if I really need that navigation or not. ‑Domain‑driven design guides you to default to one way, or unidirectional relationships. That\u0026rsquo;s not to say that you shouldn\u0026rsquo;t ever have bidirectional relationships, but that because of the extra complexity involved, you should spend some time considering if that complexity is justified. ‑A relationship, also known as an association, should be part of a type\u0026rsquo;s definition, and we do that using properties that allow us to traverse from one end of the relationship to the other. In this example, we have a client type with a Patients property, and in a patient type, we have a Client property; not just an ID value, but a property that leads to a complete object or set of objects. If you introduce a bidirectional relationship, as shown in this code, using properties that let you traverse in both directions, you should only do so when neither object can be defined without the other. If that\u0026rsquo;s not the case, then you need to be specific about the direction of the relationship, also called the traversal direction, to keep your model design simple. ‑Eric Evans puts it this way, \u0026ldquo;A bidirectional association means that both objects can be understood only together. When application requirements do not call for traversal in both directions, adding a traversal direction reduces interdependence and simplifies the design.\u0026rdquo; ‑So with a DDDI, we can look at our model and ask, can we define a client without identifying their pets? Can we define a pet without identifying the client who\u0026rsquo;s responsible for them? ‑This may sound like a simple set of questions, but it could lead to a whole lot of debate. For example, why would a person be scheduling an appointment if they didn\u0026rsquo;t have a pet? So in the context of scheduling appointments, a client doesn\u0026rsquo;t make a whole lot of sense without one or more pets or patients. ‑Or from another perspective, a cat can\u0026rsquo;t pay a bill or call to make an appointment, so how can we define a pet without a client? These are both pretty reasonable arguments, but neither one gets us anywhere. ‑So, let\u0026rsquo;s start again with defaulting to a one‑way relationship. A client would need a patient to schedule an appointment. A client would not need a patient to pay a bill. ‑Okay, and if we started from the patient end, a patient doesn\u0026rsquo;t schedule an appointment, so that becomes a moot point. Nor does a patient pay the bill. And, you know, because my dog doesn\u0026rsquo;t have a credit card. He can\u0026rsquo;t use the phone very well, either. So, when would you start with a patient and need to know something about the client responsible for that patient? That\u0026rsquo;s an interesting question. So, in the context of scheduling an appointment, one could argue that we should define the traversal from client to patient and that we gain nothing by having a way to traverse from a patient back to a client. You may balk at that notion, but remember that all we care about right now is scheduling an appointment, not all the other possible scenarios where it might make sense to traverse from patient to client. ‑Sure. It\u0026rsquo;s another example of YAGNI, you\u0026rsquo;re not going to need it. In fact, we originally had owner as a property on patient in this context, but we realized it wasn\u0026rsquo;t necessary, so we removed it. However, we kept the ID because we had some scenarios where it was useful. ‑So in the end, we chose to define relationships that traverse from appointment to doctor, patient, and client, and to define one that traverses from client to patients or their pets, but not the other way. ‑You may have experienced another type of bidirectional relationship problem if you\u0026rsquo;ve seen related data gets serialized in your applications. When objects are serialized, the serializer typically traverses all of the object\u0026rsquo;s properties recursively, If there is a bidirectional relationship, it can create a loop that will cause serialization to fail. You can think of saving aggregates in much the same way, and in fact, depending on how your persistence layer is implemented, serialization may actually be required as part of how your app persists its aggregates. In our aggregates, the single direction that we would use would go from the root to its dependents, and never the other way around.\nHandling Relationships that Span Aggregates Aggregates serve as boundaries between logical groupings within our application. We enforce these boundaries by prohibiting direct references to objects within an aggregate that aren\u0026rsquo;t the root of the aggregate. Consider the customer with the address. It\u0026rsquo;s perfectly okay for customer to reference address. Address might be an entity, or it might be a value object; it doesn\u0026rsquo;t really matter in this scenario. What\u0026rsquo;s important, though, is that the only way to get to the address in this aggregate is through the customer. We won\u0026rsquo;t be referencing an address by some identity outside of this aggregate, but that\u0026rsquo;s not the case for customer. Since the customer is the aggregate root, it can be referenced from other aggregates. ‑In this common example, an order might reference a customer. Depending on our context, it might make sense for a customer to reference an order. In this case, let\u0026rsquo;s assume it only makes sense for the order to be central to the application\u0026rsquo;s design. What\u0026rsquo;s not okay is for the order to reference a customer\u0026rsquo;s address directly. This violates the integrity of the customer aggregate. ‑Remember that aggregates and aggregate roots only apply to objects, not data. And when we\u0026rsquo;re talking about references, we\u0026rsquo;re talking about object references, properties that use an object directly. This is especially important with ORMs. For example, if you were to save an address that had a customer object attached to the customer property, there are scenarios in which Entity Framework would involve the customer in the database INSERT or UPDATE, possibly even a DELETE. And this behavior leads to a lot of confusion. I frequently advise developers to just remove the navigation property and use the foreign key ID instead. It\u0026rsquo;s a little more work, but removing some of the ORM magic results in more control over the behavior. And this aligns perfectly with the fact that one common way to enforce aggregates is to replace direct navigation properties in the model\u0026rsquo;s non‑root types with key references, and this reduces the number of dependency relationships within the model.\nEvolving the Appointments Aggregate Since we\u0026rsquo;re dealing with appointment scheduling, our initial design might look something like this. An appointment involves bringing together a patient and a doctor in an exam room for a particular type of exam, and since we\u0026rsquo;ll typically need to know the owner\u0026rsquo;s information when we deal with the scheduling, it\u0026rsquo;s important to have a reference to the client from the patient also. So if we model our system this way, any time we saved an appointment, it\u0026rsquo;s going to scan all of these objects for changes and save them as well. So modeling it this way, the scope of our domain for appointment scheduling is much greater than it needs to be since, in our case, we don\u0026rsquo;t expect to modify any of the other objects when we\u0026rsquo;re creating an appointment. ‑Right, an appointment is basically just a list of resources tied to a particular timespan, it models who, what, when, and where, but it doesn\u0026rsquo;t ever need to change any of these associated concepts. As a result, we can simplify our design by eliminating most of these object relationships from the appointment classes designed. Recall that for an object to be a good candidate for being an aggregate root, it should be the case that deleting an object should also delete the other objects within the aggregate. In the design shown here, if a customer cancels an appointment and we delete it from the system, it doesn\u0026rsquo;t make sense that this should delete all of the associated objects. ‑So here is another perspective on that same model. By simply including the IDs of the related concepts rather than object references, we\u0026rsquo;re able to ensure that creating and changing appointments has a minimal impact on our system when we persist the appointment. This relationship works because an appointment in the real world is really just a note that includes a place, time, and additional details. Adding and removing appointments shouldn\u0026rsquo;t impact the people and places involved, and this revised design reflects this.\nUsing Invariants to Better Understand Our Aggregate We do still have a bit more learning to do with this model though. Somewhere in our design, we need to enforce certain invariants about appointments like that they shouldn\u0026rsquo;t be double booked. Our current thinking is that appointments need to include this rich behavior with regard to how they\u0026rsquo;re scheduled. It\u0026rsquo;s the aggregate roots responsibility to verify any invariance the aggregate may have, and in this case, the appointment is still acting as an aggregate root, even if we have eliminated the navigation properties to the other objects that it might be working with. Let\u0026rsquo;s make sure we\u0026rsquo;re clear on invariants and then we\u0026rsquo;ll see how invariants in our application impact our design. An example of an invariant in the real world is the speed of light, which is a constant that you just can\u0026rsquo;t break in terms of the physics of the universe as we know it. Some things in your system must be true in order for the model to be consistent or valid. Other examples of invariants might be that the total of the items on a purchase order do not exceed the PO amount, or that appointments do not overlap, or that an end date on an object must follow the begin date on that object. Sometimes an invariant only involves a single object, maybe a particular property or field such as name is required. In this case, we may model the system such that one can\u0026rsquo;t even create the object without the required information. Our value objects are like this. For example, you can\u0026rsquo;t create an instance of a datetime range object without defining both the start and end time. However, sometimes the invariants involved how multiple objects relate to one another. ‑In the example here, the purchase order and the individual line items would most likely be modeled as separate objects, however, the purchase order would be the aggregate root, and as such, it would be responsible for verifying this invariant. The individual line items on the purchase order probably don\u0026rsquo;t know anything about one another nor should they, so it wouldn\u0026rsquo;t make sense to put the responsibility for enforcing this invariant in the line item object. What about appointments? How does one appointment know whether it overlaps another?\nModeling Breakthroughs and Refactoring As we focused on these invariants and where they belong in our design, it became clear to us that the appointment didn\u0026rsquo;t really make sense as an aggregate root. If you apply this thinking to our appointment scheduling context, it follows that one appointment doesn\u0026rsquo;t really know anything about other appointments, but the schedule knows about such things. Let\u0026rsquo;s evolve our domain model to follow this pattern and see where that leads us. ‑This feels like a big change to the model, and these kind of epiphanies happen when you\u0026rsquo;re working on the model. But that\u0026rsquo;s not a bad thing. It\u0026rsquo;s not like you\u0026rsquo;ve wasted a lot of time focusing on appointment as an aggregate root. This is the beauty of modeling your domain, having conversations with different people, with the domain experts, because ideas like this bubble up, and suddenly, something big like this becomes clear. So, you\u0026rsquo;re not going to get it 100% right the first time. Your understanding will evolve as you learn more about the domain. And from time to time, you\u0026rsquo;ll realize there are big changes that can dramatically improve your design. In the Domain‑Driven Design book, Eric Evans talks about these breakthroughs in his section about refactoring toward deeper insight. This is really an important part of domain‑driven design, and about a quarter of the book is dedicated to it.\nRecognizing Signs of a Misidentified Aggregate Let\u0026rsquo;s take a look at the signs that Steve and I eventually recognized in our domain, which led us to shift our appointment aggregate to a schedule aggregate. ‑Originally, our solution had the appointment as the central focus of the design. I had figured it would be its own aggregate with appointment at the root and its various properties as its children. As we\u0026rsquo;ve just discussed, that doesn\u0026rsquo;t really work as well as I\u0026rsquo;d hoped, so now we\u0026rsquo;re refactoring the design to introduce a new type, the schedule. Before we show that, though, let\u0026rsquo;s review the original structure and some of the reasons it didn\u0026rsquo;t work as well as an aggregate in our solution. ‑You can see the original structure had appointment in its own folder and marked with the IAggregateRoot interface, which is required for it to be accessible from our repository methods. It has essentially the same properties as the later version, except for ScheduleId, since there\u0026rsquo;s no schedule type yet. And it has the same basic set of methods for modifying its room, doctor, time, and other properties. None of that really changed since all of those operations only had to deal with this single appointment instance. ‑However, when the appointment tried to enforce the invariant that appointments whose times overlap for the same pet should be marked as potentially conflicting, things were a bit messier. You see, this appointment doesn\u0026rsquo;t actually have any association with any other appointments, so the only way to enforce this is to use a repository to get those other appointments for the same date as this one. Since entities don\u0026rsquo;t support dependency injection through their constructor, this means an instance of the repository needs to be passed into this method. Creating this repository instance was the responsibility of the calling code, which may not otherwise have needed it. Note also that because the repository\u0026rsquo;s interface is async, this method must now be async as well, even though no other methods on the appointment entity are async. ‑The real problem here, from a DDD perspective, is that cross‑aggregate invariants should not be enforced by any one aggregate. In the case of something like a unique constraint between all aggregates, you might need to use a domain service, or another approach. However, in other cases, the need to do this may indicate that you\u0026rsquo;ve missed an important part of your model. ‑Right. In this case, the whole thing that the user is interacting with is the clinic schedule, but nothing in our original model referred to the schedule itself. Since some of our business rules, like what to do with appointments that conflict, only make sense at this higher level, it made sense to introduce a change to our model, the schedule aggregate.\nConsidering Schedule as Our New Aggregate So, even though the initial design we had was about scheduling, the schedule itself was never part of our model. Once we include schedule as its own explicit object in our model, it makes the design much simpler. Appointments no longer need to know anything about other appointments. The responsibility for ensuring that appointments are not double booked and similar invariants can be performed by the schedule, which is the aggregate root. ‑So, let\u0026rsquo;s see if this passes our other tests about defining aggregate roots. A schedule will certainly help us ensure that appointments don\u0026rsquo;t overlap one another. When we save changes to a schedule, does it make sense to update any changed appointments? Yes, it does make sense. And if we were to delete an entire schedule, would it make sense to delete all of its appointments? Yeah, I think that would make sense also. ‑Yeah, I think this is the schedule for a particular clinic. At the moment, we only have one clinic, but if we imagine a scenario in which multiple clinics each have their own schedule, it wouldn\u0026rsquo;t make sense to delete a clinic\u0026rsquo;s schedule but then keep its appointments floating around. So I think that works. ‑Great. And if a schedule exists for each clinic, then it makes sense to persist the schedule, which means that it needs an ID, and therefore is truly an entity. And when we retrieve a schedule, we\u0026rsquo;ll most likely be filtering which related appointments we want to look at, for example today\u0026rsquo;s schedule or this week\u0026rsquo;s schedule. That would mean we want all of today\u0026rsquo;s or all of this week\u0026rsquo;s appointments from a particular clinic\u0026rsquo;s schedule. It really does make a lot more sense to me to tie the appointments to a schedule than directly to a clinic. Now, let\u0026rsquo;s see how this effects our design.\nExploring the Schedule Aggregate in Our Application Now I\u0026rsquo;ll show you the new schedule aggregate implementation in our application. In the refactored solution, we\u0026rsquo;ve renamed the folder so that now it\u0026rsquo;s ScheduleAggregate. This folder only includes schedule and appointment, as well as related guards and specifications. In larger applications, it can help to organize your domain model by grouping everything related to a particular aggregate in its folder. Looking at the ScheduleAggregate\u0026rsquo;s code, you can see that it inherits from our common BaseEntity type and uses a GUID for its id key, just like appointment. This lets us set the key ourselves, rather than relying on a database to do it for us. The class is also marked as an aggregate root with an interface. In the next module, you\u0026rsquo;ll see how we use that to protect the integrity of our aggregates. ‑Right. We\u0026rsquo;ll see how that works when we look at our repository and specification implementations. ‑Next, the Schedule\u0026rsquo;s constructor just takes in its id, its dateRange, and its associated clinicId. In our sample, the clinicId is always hard‑coded but in a real application, there might be several clinics using the same software, and they would each have their own ids. The constructor is responsible for ensuring that the incoming values are valid so that it\u0026rsquo;s always created in a consistent state. Schedule has just a few properties. There is the ClinicId, the associated set of appointments, and the DateRange. We\u0026rsquo;re careful to only expose a read‑only IEnumerable of appointments because our aggregate must encapsulate its internal state. We don\u0026rsquo;t want other parts of our application to add or delete appointments without going through the schedule\u0026rsquo;s explicit methods designed for this purpose. Also, the date range isn\u0026rsquo;t persisted since it can vary with any given instantiate ation of the schedule. ‑Yeah, and for performance reasons, you wouldn\u0026rsquo;t really want to load the ScheduleAggregate with every appointment that had ever been made included in it. By using a property like this, we make it clear to the rest of the domain what set of dates this instance of the aggregate holds. The actual population of the appointments that match this range is left as a responsibility of the specification and repository classes that are used to retrieve the schedule from the database. ‑Yes. And the configuration of the aggregate\u0026rsquo;s persistent details is done in the infrastructure project\u0026rsquo;s Data Config folder. This is where every entity\u0026rsquo;s EF Core‑specific mappings and configuration is performed, which keeps these details out of our domain model. You can see here that we\u0026rsquo;re also letting EF Core know that we don\u0026rsquo;t want the database to supply an id when we create a new schedule. We\u0026rsquo;ve marked that property as ValueGeneratedNever. ‑Getting back to the schedule, let\u0026rsquo;s have a look at its methods. The first method is for adding new appointments. Our design forces all new appointments to come through this method, so we don\u0026rsquo;t have to have duplicate behavior anywhere else in the application to take care of whatever should happen when a new appointment is added. It\u0026rsquo;s all right here in one place, easy to understand, and easy to test. The method validates the inputs to ensure we\u0026rsquo;re not adding bad data to our aggregate, and then it adds the appointment. When a new appointment is added, the schedule is responsible for marking any appointments that might be conflicting. It\u0026rsquo;s the right place for this behavior to live, since the schedule knows about all the appointments and knows anytime appointments are added or removed. After marking any conflicts, an appointmentScheduledEvent is added to the aggregate\u0026rsquo;s event collection. We\u0026rsquo;ll see how this works in the module on domain events. The DeleteAppointment method is similar. After deleting an appointment, the schedule needs to once more mark any appointments that might be conflicting. There\u0026rsquo;s also a TODO comment here. These are left as exercises for you to learn more about how to work with the patterns introduced in this course. You\u0026rsquo;ll find a number of TODO exercises scattered throughout the sample. ‑We hope you\u0026rsquo;ll take some time to download the code, run it locally, and try implementing some of the TODO tasks using the existing functionality as a guide. There are a couple more in the MarkConflictingAppointments method, which, remember, was originally on the appointment type when we started out with that as its own aggregate. This method is responsible for detecting and marking appointments that might conflict. The basic rule, shown here, just checks whether the patient has two appointments that overlap. If any such appointments are found, they are updated to set their conflicting property to true. Then, the current appointment\u0026rsquo;s property is set based on whether there are any other appointments that conflict with it. ‑This is an important part of the business logic for this application, and it\u0026rsquo;s encapsulated right in our schedule aggregate. In a lot of data‑driven applications, this kind of logic might be in a stored procedure, or perhaps just implemented in the user interface. But in a domain‑driven application, we want these rules to be explicit and defined in our domain model. ‑The last method on schedule provides a hook for its appointments to use to notify it when changes are made to one of them. Because we don\u0026rsquo;t have navigation properties from appointment back to schedule, we can\u0026rsquo;t directly call methods on the aggregate root from appointment methods. There are a few different patterns we can use to accomplish this task. For this sample, we chose this one because it\u0026rsquo;s simple and easy to follow. This handler simply calls MarkConflictingAppointments, but it\u0026rsquo;s exposed as its own separate method because it could do other things as well, and we don\u0026rsquo;t want to expose the internal behavior of the schedule to the rest of the app. To see how it\u0026rsquo;s used, let\u0026rsquo;s look at the appointment class\u0026rsquo;s UpdateStartTime method. When the application needs to update the start time for an appointment, it will call this method. Because appointment is part of a scheduling aggregate, we know the app will already have loaded the schedule before calling this method. So the second parameter in the method asks for the handler on the schedule that will be called. The call to update the schedule is made after updating the TimeRange property on the appointment, so when mark conflicting appointments is called, it will use the new value for the time range. There are a lot of other ways you can set up this communication, using C# events, static domain events, or some kind of double dispatch approach. They all have trade‑offs, and when you need to do this in your apps, you should choose the one that works best for your app and your team. ‑Let\u0026rsquo;s see the final result in the application. This change to our model of adding in a schedule aggregate made a big difference to how the domain model is organized. It gave us a much better place to put the logic of enforcing business rules around combinations of appointments and business logic that needs to run when appointments are added or removed. ‑Right. Without the schedule, we would have had to use a domain service or something to add behavior around the newly added or removed appointments. But with this design, we can go into the schedule, add a new appointment for Rosie, and then add another one, and you can see the notifications being triggered by the events, as well as the red outline representing the conflict in these two appointments. Not only is our domain model clean and easy to test, but even more important, it actually works! ‑And notice that as we move one of those conflicting appointments to another spot, the red alerts disappear. Good job, Steve! I am so grateful that you let me off the hook for working on the front‑end of this application. You know I\u0026rsquo;m more of a back‑end developer.\nSharing Our Tips for Aggregate Design So let\u0026rsquo;s step back a moment and review some of the things we\u0026rsquo;ve just learned about designing aggregates. First of all, aggregates exist to reduce complexity. You might not always need an aggregate. Don\u0026rsquo;t add complexity just for the sake of using an aggregate. Another is that entities with an aggregate can only reference the root entity of another aggregate. ‑But you can always use foreign key values as a reference to entities inside another aggregate. It\u0026rsquo;s perfectly okay to use this, and it will avoid the need for when you go to save that aggregate for it to cascade its persistence into other aggregates. If you find you\u0026rsquo;re needing to use a lot of foreign key references to aggregate children often, you may need to reconsider the design of your aggregate in your domain model. ‑Another pointer was don\u0026rsquo;t be afraid to have an aggregate of one, in other words, an aggregate that only has one object in it. ‑And finally, don\u0026rsquo;t forget the rule of cascading deletes. Remember, one test for whether or not a particular object makes sense as an aggregate root is to consider whether deleting that object should also delete all of the other child objects in that object\u0026rsquo;s hierarchy. If it doesn\u0026rsquo;t, then you have probably chosen the wrong structure for your aggregate.\nReview and Resources Once again, we have covered quite a bit in this module. Let\u0026rsquo;s review some of the terms that you learned in this video. The first thing we talked about was an aggregate. An aggregate is a group of related objects that work together in a transaction. The root becomes the entry point through which you do any work with the aggregate, and the root also is what\u0026rsquo;s in charge of making sure that all of the rules that apply to that graph of objects are met. ‑Each of the rules that describes the state that the system must be in in order to be valid is called an invariant. Within our aggregates, we have objects that are related to one another. In DDD, we refer to these relationships as associations. If you use an ORM, you may hear the term navigation properties, which refers to those properties that reference the related objects in the model. And we talked about the importance of defaulting to one‑way relationships, which we also refer to as unidirectional relationships. ‑In addition to these important terms, Steve and I shared a lot of guidance around creating aggregates and roots in your domain models. Nobody wants to work with a big ball of mud. We use aggregates to organize our model. An aggregate is a set of related objects that live in a single transaction while encapsulating the rules and enforcing invariance of that transaction, making sure that the system is in a consistent state. When designing how related objects work together, your job will be easier with one‑way relationships. Use those as a default, and only introduce bidirectional navigation if you really need to. ‑And most importantly, don\u0026rsquo;t resist updating your model as you and your team of domain experts learn more about the domain. Hopefully, most of this will happen early on, and then just once in a while you might have a big breakthrough, like we did when we realized that the schedule made more sense as an aggregate root than trying to have each appointment be its own aggregate. Up next, you\u0026rsquo;ll learn about repositories which are a critical pattern in domain‑driven design. This is Steve Smith, ‑and I\u0026rsquo;m Julie Lerman. Thanks for watching Domain‑Driven Design Fundamentals.\nWorking with Repositories Introduction and Overview ‑Hello. I\u0026rsquo;m Julie Lerman. ‑And this is Steve Smith. ‑In this module of Domain‑Driven Design Fundamentals, you\u0026rsquo;ll learn about repositories, another critical pattern for Domain‑Driven Design. ‑We\u0026rsquo;ll start by defining what repositories are, and then we\u0026rsquo;ll provide some tips for working with them, as well as talking about some of their benefits. There are different ways to define repositories and plenty of debate around their use. We\u0026rsquo;ll address some of these points. ‑Next, we\u0026rsquo;ll introduce you to the specification pattern and how it can be really helpful when you\u0026rsquo;re implementing repositories. Then we\u0026rsquo;ll open up Visual Studio again and show you how we\u0026rsquo;ve implemented some repositories in the scheduling app.\nIntroducing Repositories ‑Now, Julie, if this were an in‑person class, I\u0026rsquo;d definitely ask for a show of hands who has heard of the repository design pattern. I would expect most hands to go up. ‑I hope so too. I think the repository pattern is by far the most popular element of DDD to be practiced outside of Domain‑Driven Design. They can be valuable in so many applications as a way to simplify data access and enforce separation of concerns. When I began learning about repositories and implementing them in my own software design, it had a huge impact on my application architecture. Along with automated testing practices, it really forced me to consider separation of concerns with each method and behavior added to my software. ‑Personally, I love the pattern, and I find it makes it much easier for me to write good, testable code. We\u0026rsquo;re going to talk about using repositories within a DDD application, but if you want to learn more about the pattern itself, you can look in the design patterns library, and I know Julie also discusses using them with Entity Framework in her Entity Framework in the Enterprise course. ‑You can see the repositories are part of the DDD mind map, as they\u0026rsquo;re used to access entities and aggregates. Any system that needs to persist between restarts has some kind of persistent storage for the state of the system, like a database. Many applications focus a great deal of effort on the mechanics of querying, fetching, and translating data to and from objects to the point where it distracts from the model that these objects are meant to represent. And having ad hoc access to the data source also promotes having developers query for any bit of data they want anytime they want, rather than using aggregates. This makes it pretty difficult to manage the consistency of aggregates by enforcing their invariants. At best, the logic for enforcing the integrity of the model becomes scattered among many queries, and at worst, it\u0026rsquo;s not done at all. ‑Applying Model‑First design and separation of concerns means pushing persistence behavior into its own set of abstractions, which we refer to as repositories. Only certain objects, like specifically aggregate roots, should be available via global requests. Repositories provide this access, and through omission, prevent access to non‑aggregate objects, except through their aggregate roots. They give you the ability to constrain the data access, so you avoid lots of random data access code throughout your application. ‑When you think about the life cycle of an object in your application, you should consider two cases. In the first case, you have objects that are not persisted. These objects are created, perform some work, and then they\u0026rsquo;re destroyed. In the second case, you have objects that are persisted. These objects have a slightly more involved lifecycle since after the object is created, it must be reconstituted with whatever state it had when it was last saved. Then it can perform whatever work the application needs it to do, after which it may need to save its state to some persistent storage before finally being destroyed. You can use repositories to manage the lifecycle of your persistent objects without the objects having to know anything about their persistence. We call these objects persistence ignorant because they\u0026rsquo;re ignorant of how they\u0026rsquo;re stored into and retrieve from a data store. ‑In his book, Domain‑Driven Design, Eric Evans speaks quite a bit about repositories. They can be summed up by saying that a repository represents all objects of a certain type as a conceptual set, like a collection with more elaborate querying capability.\nRepository Benefits ‑Repositories can add a number of benefits to our application. First of all, they provide a common abstraction for all of our persistence concerns, which provides a means for clients to very simply obtain model objects and to manage their lifecycle. They also promote separation of concerns. The domain logic and the user interface can both vary independently from the data in the back‑end data source that is used by the application. ‑The public interface of a repository very clearly communicates our design decisions. Only certain objects should be accessed directly, so repositories provide and control this access. Another important benefit is that repositories make it easier to test our code. They reduce tight coupling to external resources like database, which would normally make unit testing difficult. Having a repository separate from client code and domain logic means that we can easily make improvements to optimize data access for this application, tuning for performance, adding caching behavior, etc. is all much easier and safer when the code for data access is all encapsulated in one or more well‑known classes. All of this makes your code easier to maintain.\nRepository Tips ‑Here\u0026rsquo;s some basic guidance you should keep in mind when designing repositories. First, a repository should have the illusion of a collection of a specific type of object. You\u0026rsquo;ll be adding the objects to the collection, removing them, and retrieving objects from the collection, but that it is an illusion of a collection is important to keep in mind. When you interact with the repository, these are the types of methods you\u0026rsquo;ll be calling, add, remove, and retrieve. Your calling code doesn\u0026rsquo;t care how the repository performs those actions. So in the repository, you might have code that responds to a retrieve method, goes out to a database and gets data, but it could be getting data that\u0026rsquo;s already in memory, or it might be grabbing data from a text file on your computer. ‑Another important recommendation for repositories is to set up access through a well‑known global interface. That way, developers that need to interact with the repository will be familiar with a common pattern for using it. ‑Here\u0026rsquo;s a simple repository interface example. Depending on the size and complexity of your software, you may have a few layers of interfaces. ‑For example, if you anticipate having a number of repositories for a schedule aggregate used in different bounded contexts, you might want an IScheduleRepository interface that not only implements the lower‑level interface, but defines some other methods or properties that every schedule repository is required to have regardless of the bounded context it might reside in. Because a repository acts like a collection, you\u0026rsquo;ll want methods to add and remove objects to encapsulate the underlying data insertion and deletion operations. We\u0026rsquo;ve got these defined in our IRepository. It is up to each concrete implementation to define how add and remove will actually work. ‑It\u0026rsquo;s not unusual to need to add specific query methods to individual repositories. Whether you need a custom subset of entities or a specific way to load entities\u0026rsquo; relationships, custom methods are a simple way to achieve this. For example, if we wanted to fetch a schedule instance with all the appointments for a given day, we could add a method to the ScheduleRepository that might have an EF Core implementation like this one. ‑Likewise, if we just wanted to be able to fetch a client with their patients, we could add a method like this one, which will eager load the patients when it loads the client. Be careful with this approach though, as it can grow out of hand, and your repositories may end up with many different query methods. A simple way to address this is to use specifications instead, which we\u0026rsquo;ll cover later in this module. In addition to these specific tips for implementing repositories, you should also keep in mind these more overarching tips. First, be sure to provide repositories only for aggregate roots that require direct access. And next, keep the clients focused on the model, while delegating all of the object storage and access concerns to the repositories.\nAvoiding Repository Blunders We\u0026rsquo;re not always going to land on the happy path, so we do want to share with you some common problems that you might run into, how to recognize them, and most importantly, how to avoid them. ‑Remember your client code can be ignorant of the implementation of your repositories, ‑but developers cannot. ‑It\u0026rsquo;s important that developers understand how your specific repository is implemented, otherwise, they can run into a number of different problems. ‑So we\u0026rsquo;re talking about not just the developers who are implementing the repository, but also the developers who are using the repository. ‑One of the common repository problems the developers working with repositories often encounter is called an N+1 query error. This is where in order to display a list of rows from the database, you end up calling one query to get the list and then a number of queries equal to the count of that list to fetch each item individually. ‑Another one that I see a lot is when people are fetching related data. With Entity Framework, they\u0026rsquo;re either using eager loading or lazy loading, and especially with lazy loading, there are a lot of developers who don\u0026rsquo;t really know what to expect from it and just because it\u0026rsquo;s easy and it just works, they use it and then run into all kinds of problems because of it. ‑And depending on how your data is structured, sometimes if you\u0026rsquo;re trying to fetch just one or two properties that are represented in a particular column in a data table, you might end up fetching more data than required if you pull back the entire row which might include dozens of columns and a lot of actual data there. These are things that knowing how your underlying data is persisted and how your repository is implemented, how those things work, can make a huge difference in your application. ‑Most of these blunders impact how data is accessed in a data store and that means that one of the best tools you have for surfacing these problems is profiling your data store. Many of the IDEs we use for managing databases have profilers built in, some examples are SQL Server Profiler, Jetbrains DataGrip, and Azure Data Studio. Many of the APIs we use also have logging capabilities that can relate database activity. As a .NET developer, I often use the .NET Core logging API or some of the features built into Entity Framework Core, but most any language you use can do this and all of the cloud providers have ways to trace activity in their various data stores. There are even third‑party tools dedicated to database profiling. The suite of profilers from Hibernating Rhinos is a great example. They have profilers for RavenDB, Azure CosmosDB, and the EF Core, and Hibernate ORMs.\nAddressing the Debates Around Using Repositories Many developers have strong opinions about the use, and some might say overuse, of the repository design pattern. Let\u0026rsquo;s consider some of the common arguments made about repositories. It\u0026rsquo;s worth remembering that like Bjarne Stroustrup\u0026rsquo;s famous quote about programming languages, there are two kinds of design patterns, too. It\u0026rsquo;s no surprise, really, that as the repository pattern grew in popularity, that there would be many complaints about when and how to implement it. ‑Here\u0026rsquo;s one that really gets me. EF Core, the .NET ORM which we\u0026rsquo;re using this course, has a built‑in repository for its data access. It\u0026rsquo;s called the DbContext. I\u0026rsquo;ve heard and read comments from so many people who say never use a repository on top of EF Core because it already has a repository built in. And then I hear others who say you should always use a repository to interact with EF Core. I am not a fan of the words always and never. Maybe it\u0026rsquo;s because I\u0026rsquo;m a libra, who knows. So, these strongly held opinions really frustrate me. What Steve and I want to do here is give you the information you need so that you can make educated decisions about when to use repository and when to opt for something else. ‑Let\u0026rsquo;s remember for a moment what repositories are and where they live in a domain‑driven application. Repositories are abstractions. They\u0026rsquo;re part of your domain model. They define the persistence operations the model will use. That\u0026rsquo;s it. There\u0026rsquo;s nothing in the domain model patterns produced through model‑driven design espousing the use of Entity Framework, or NHibernate, or any other specific vendor tool for doing persistence. It doesn\u0026rsquo;t even know if you\u0026rsquo;re doing Java or .NET. It\u0026rsquo;s meant to be totally abstract and just types. ‑The domain model should be persistence ignorant, and it shouldn\u0026rsquo;t depend on implementation details. ‑Right. One of the things I really appreciate about DDD and the way it isolates domain expressions within a layered architecture is that it aligns perfectly with SOLID design principles, like the dependency inversion principle. ‑You are a big fan of SOLID, Steve. ‑Guilty! In this case, in terms of SOLID, using an abstraction for persistence enables us to follow dependency inversion because we can define an abstraction in our domain model and then implement it in another project that depends on the domain model. We can also write our application and its user interface so that it depends on our persistence abstraction, too, rather than on the implementation details. That\u0026rsquo;s the heart of dependency inversion. ‑And that makes it easier to follow the interface segregation principle, which I also learned about from your SOLID course. This principle prefers smaller interfaces, so if your app is using a DbContext directly, that is not a small interface. Along with DbContext repository features, it exposes a lot of other functionality. Using an abstraction that limits what your app needs to do with regard to persistence makes for a much simpler design in our model, reducing complexity. ‑Right. In that way, it\u0026rsquo;s similar to the facade pattern because it lets us work with a much simpler view of what could otherwise be a potentially very complex and powerful persistence library. ‑So, when we\u0026rsquo;re following DDD, our domain model shouldn\u0026rsquo;t know anything about EF Core, or whatever APIs you\u0026rsquo;re using for your data persistence. If our model requires persistence, like most do, we should define abstractions in the model that describe what our needs are without specifying how they\u0026rsquo;re done. ‑Exactly. The abstraction defines what needs done, the specific implementation is all about how to do it. ‑And one really popular and powerful way to do persistence in .NET is with Entity Framework Core. And because it implements methods that map pretty closely to most common persistence abstractions, it\u0026rsquo;s usually pretty easy to implement a particular abstraction with a class that calls into EF Core. ‑Definitely. ‑EF Core works great for this in most of the apps I work on, but we should never couple it tightly to our domain model. ‑Exactly. The whole point of DDD is that we shouldn\u0026rsquo;t be coupling our domain problems with our persistence problems.\nReturning IQueryables: Pros and Cons Another question I get all the time, and which I\u0026rsquo;ve discussed in some of my other Entity Framework courses, is whether repositories should return IQueryable, and yes, I do have my opinions on that. ‑Yes, this is another source of some debate. On the face of it, it sounds like it would be a great idea. Your most basic repository abstraction might not provide much in the way of complex filtering options and you can avoid having to think about that sort of thing if you just return an IQueryable. ‑Right, because then any code that consumes an IQueryable can extend the expression adding additional filters or projections to the query before it\u0026rsquo;s actually executed. On the surface, it sounds pretty good, right? ‑Well, it turns out that a lot of query logic is actually business logic, and if you return an IQueryable, it has two not‑so‑good effects. It can leak a lot of the implementation details so your application code\u0026rsquo;s behavior changes significantly based on the implementation of the repository and it tends to put the business rules for querying all over the application. ‑Let\u0026rsquo;s say we have an MVC application with a controller so that\u0026rsquo;s the server‑side logic of the UI layer and it returns a view to the UI. The controller calls into a service to get its list of customers and the service contains a customer repository interface. That repository calls into an infrastructure project and the infrastructure project is where we\u0026rsquo;re using EF Core and it\u0026rsquo;s DBContext, but to limit what\u0026rsquo;s exposed outside of the infrastructure project, there is a repository there as well. The repository and the service makes its calls to the repository in the infrastructure layer. It sounds like a lot of layers, but that\u0026rsquo;s not a problem because we have reduced coupling and made a maintainable solution. The real problem here is where can we put our query logic in this example? ‑Well obviously the repository, and it wouldn\u0026rsquo;t be unusual for the method in the service to further modify the query, but since it\u0026rsquo;s also returning an IQueryable, the controller action could further modify that same expression tree, and assuming the controller just passes that same IQueryable to the view, which we\u0026rsquo;ve both seen teams do, even the view could further refine the query. So is this a good thing or a bad thing? ‑Well on the plus side, we get a lot of flexibility without having to write a lot of code for our repository. We\u0026rsquo;re also able to tailor the data we need to the specific place it\u0026rsquo;s used and even modify the query from multiple steps in the app. At the same time, we get to reuse a simple repository interface everywhere in our app. ‑Right, but on the other hand, that query logic is now spread out everywhere. Every class that\u0026rsquo;s adding query logic, in addition to whatever else it\u0026rsquo;s doing, is now violating the single responsibility principle. Then there is separation of concerns. Query logic should be separate from other concerns in most of these classes. ‑And another problem I see a lot with this approach is confusion about when the actual query is executed and what runs on the database server versus in‑memory in the application. ‑Many developers will assume the query runs inside the repository and the result they get back is from the data store. And of course that\u0026rsquo;s true for most calls, but not necessarily for those that return IQueryable. ‑Right, the query will execute the first time any code tries to enumerate the result. That could happen inside the repository, but it could also happen in the service, or in the controller, or even in the view. ‑Yeah, I see that a lot. a related issue is that developers at any step of this process can add additional logic that may compile just fine, but then at runtime when EF tries to interpret it, it blows up. ‑Anything you add to the query expression that Entity Framework doesn\u0026rsquo;t know how to translate into SQL is likely to cause an exception, at least with recent versions of EF Core. ‑And it may be redundant at this point, but it\u0026rsquo;s probably worth adding here that there is no encapsulation when you use this approach. ‑There is a way we can fix at least some of these issues though. For example, instead of returning IQueryable, we can still create flexible repository methods by passing in predicates. Then in the implementation, this predicate can be passed along to the DBContext as its Where expression providing the necessary filter. If you\u0026rsquo;re not familiar with the term predicate, but you\u0026rsquo;ve used the link where method, that\u0026rsquo;s what the method takes as its parameter, which is why we\u0026rsquo;re able to pass it right to the WHERE clause. ‑That does help part of the problem. Where before the query could have been executed at any of these points, at least now we know that whatever comes back from the repository will be the in‑memory result. The actual query is always executed in the repository itself. Of course, if the service takes in a predicate, it still means that any code anywhere in the system could be responsible for creating the query logic with the possible exception of the view if it\u0026rsquo;s just being passed an IEnumerable at this point. ‑Okay, so with predicates, they\u0026rsquo;re still very flexible, but they\u0026rsquo;re not as easy to build up from multiple locations in your application, especially compared to IQueryable. The rest of the good points still hold though. ‑The only thing we\u0026rsquo;ve really changed on the bad side is confusion about when the query actually executes. Being a fan of solid and encapsulation and knowing some other patterns we\u0026rsquo;ll share later in this module, I\u0026rsquo;m usually going to vote against this approach too. ‑Well another way we tend to solve this conundrum is going the custom query route. We even suggested this as a tip earlier, but you can definitely take it too far. Every little change to a query means another method, customer with orders, customers by shoe size, by shoe size, customers by favorite Netflix show. Hey, you never know what problems your domain experts are going to share with you. ‑The problem with this approach if it goes beyond one or two methods, is that you really start to feel the pain of the open/closed principle violation. Every time another custom query requirement comes in, you have to change the repository abstraction and all of its implementations, and the bigger the type gets, the more it violates the interface segregation principle, too. The more complex your problem is, the more query methods you\u0026rsquo;ll be adding to your solution. This can surely be an untenable situation, and we will show you some better alternatives a little later in this module.\nConsidering Generic Repositories and Interfaces Using generic interfaces for persistence is great from a code‑reuse point of view. With just one simple interface, any entity can be persisted using a standard set of operations. If you\u0026rsquo;re using aggregates, you can use generic constraints in this simple marker interface to ensure that only aggregate roots can be persisted using your interface. It can work really well. ‑But there are trade‑offs. What if you have certain aggregates that should never be deleted, but your generic repository includes a delete method? Does it make sense to have operations defined in your domain model that should never be used? This is where you need to make a judgment call. Is the convenience of having a single consistent way of dealing with persistence throughout your model more valuable than having only the necessary and appropriate persistence operations exposed? There\u0026rsquo;s no one right answer. Pick what makes sense for your app, your model, and your team. ‑In our demo, partially for the sake of simplicity, we are using a single generic repository for all of our operations, even though, yes, this means there are operations on some aggregates that are never called and some that never should be called, for example, deleting the entire schedule. ‑If we didn\u0026rsquo;t go that route, our model would need to include separate repository interfaces for each of the aggregates in our model, including schedule, doctor, room, client, and appointment type. Each would define only the operations that were actually needed by the application. For a larger model, this could result in quite a few interfaces, and possibly implementations, but would provide a more pure representation of the domain model. ‑If you do choose to create a generic repository interface, that doesn\u0026rsquo;t necessarily mean you\u0026rsquo;ll implement it generically. You might only choose to create implementations for each aggregate root, which would comply with DDD recommendations. However, it can be convenient to create a generic Repository of T implementation class that you can then use with any entity. ‑This is what we\u0026rsquo;re using in our sample, both for the front desk app and for the clinic management app. In both cases, if you review the sample, you\u0026rsquo;ll see there\u0026rsquo;s very little persistence‑specific code in either solution. ‑If you really like the code reuse you get from having a generic repository implementation, one way to keep it from allowing too much access to the internals of your aggregates would be to use a marker interface, perhaps one that simply extends the entity interface to identify your aggregate roots. Then you can update your generic repository to require this interface, rather than working with any entity. ‑At that point, code that uses the repository won\u0026rsquo;t be able to instantiate the generic repository with non‑root entities, so we\u0026rsquo;re able to use our repository to restrict access to non‑root entities from client‑server model. Using marker interfaces to identify aggregate roots is one way you can enforce your design decisions in your model using the compiler rather than relying on code reviews or other less effective practices. ‑Repository abstractions, especially generic ones, can sometimes get to be pretty large. Large interfaces violate the interface segregation principle, one of the solid principles that I cover in my Solid Principles for C# Developers course. One way to keep these interfaces smaller and more focused is to split them into read and write operations. This is related to the concept of Command Query Responsibility Segregation, or CQRS. Read operations are queries, write operations are commands. There are many benefits to leveraging CQRS that we don\u0026rsquo;t have time to cover in this course, but one area where you may immediately benefit is with modifying behavior related to these kinds of operations. Queries often benefit from data caching, and it\u0026rsquo;s very easy to add data caching to just the read operations. ‑Commands often benefit from being performed asynchronously using a queue, and having a separate interface for commands makes it easy to implement this behavior. These are just two ways you can quickly leverage splitting up your repository definitions between reads and writes. Of course, if you have a lot of different read methods, this can make it more and more difficult to implement custom caching logic, since every new method will also need to be added to the caching layer. Fortunately, this is easily solved by using the specification pattern.\nExploring Repositories in our Application Steve is going to give you a guided tour of how data access and persistence are handled in the FrontDesk application using repository abstractions. Because he\u0026rsquo;s been fine tuning versions of this demo application for many years, it\u0026rsquo;s quite impressive, and he truly is the best guide for walking you through this implementation. ‑We\u0026rsquo;ll start from the front end of the application, which is our Blazor client. Let\u0026rsquo;s take a look at editing an appointment. Here\u0026rsquo;s an appointment for Julie\u0026rsquo;s dog, Samson. You can see that on the edit screen, in addition to showing the details for the appointment, it also provides us with a list of the doctors and appointment types. When we hit the drop‑down list, we can see all of the different doctors who are available that we could schedule to work with this particular appointment. That\u0026rsquo;s actually accomplished through a back end API that\u0026rsquo;s coming from a different project. Let\u0026rsquo;s take a look at that. We\u0026rsquo;ll start by examining the API using our Swagger endpoint. Looking at Swagger for DoctorEndpoints, you can see that there are two endpoints, one to get a specific doctor by ID and another one that returns a list of doctors. We just saw the list of doctors in action. Let\u0026rsquo;s go ahead and run it again from Swagger. Here you can see the resulting set of three doctors, just like we saw in the drop‑down list. You\u0026rsquo;ll find the code for this particular endpoint inside the FrontDesk.Api project. Within there, there\u0026rsquo;s an Endpoints folder with subfolders for each of the different types of entities that we expose API endpoints for. Inside of Doctor, you can see there\u0026rsquo;s a GetById and a List, and we\u0026rsquo;re looking at the List endpoint here. When we define an endpoint, we simply inherit from BaseAsyncEndpoint, and specify the request type, if any, and the response type, if any. We can also do dependency injection through the constructor, just as you would with a controller. Each endpoint has a single Handle or HandleAsync method, and this is where the actual work of the endpoint is done. You can see in this example that we are simply awaiting on the repository\u0026rsquo;s ListAsync method in order to get our list of doctors. Once we have the list, we map it to our DTO that we\u0026rsquo;re going to actually return, and pass that back as part of that response type. The response, as we just saw in Swagger, includes the Doctors as JSON, as well as a Count property that includes the total number of those doctors. Now let\u0026rsquo;s look a little bit more closely at that repository. You can see in the dependency injection that\u0026rsquo;s occurring in the constructor that we\u0026rsquo;re depending on an IReadRepository, but where is that defined? For that, we need to look at our SharedKernel project. Inside the separate SharedKernel project, which FrontDesk references as a NuGet package, you can see that we have defined an IReadRepository interface. This inherits from IReadRepositoryBase, which is actually itself defined in another NuGet package, the Ardalis.Specification type. The reason why we\u0026rsquo;re creating our own interface here is so that we have complete control over it and we can add additional behavior. For example, in this case we\u0026rsquo;re adding a generic constraint. We\u0026rsquo;ve said that this particular interface will only work with types that have the IAggregateRoot interface attached to them or applied to them. Looking at that particular interface, you can see that there\u0026rsquo;s nothing to it. It\u0026rsquo;s simply a marker. It\u0026rsquo;s a way that we tell the compiler that our intent for a particular class or entity is that it should be treated as an aggregate root. We use that marker to enforce our design and our encapsulation to make it so that we don\u0026rsquo;t accidentally just load up a child entity out of an aggregate, when instead we\u0026rsquo;ve made a design choice that we want to work with that entire aggregate as a unit. You can see that we\u0026rsquo;ve also implemented IRepository similarly. It also inherits from a type that comes from Ardalis.Specification, and also has the same IAggregateRoot restriction. Now let\u0026rsquo;s return to our FrontDesk application and see how we implement this. First, we should look at the DefaultInfrastructureModule. This is an artifact module that defines how we\u0026rsquo;re going to wire up our abstractions with their implementations. And here you can see all the important bits of how we wire up EfRepository to IRepository, as well as IReadRepository. But notice for the IReadRepository we\u0026rsquo;re actually wiring up a different type, a CachedRepository. This acts as a decorator around the underlying EfRepository, and will provide additional caching logic. Inside of the CachedRepository, when we asked for a list of doctors, it actually checked the cache first, and then if it wasn\u0026rsquo;t in the cache, it would go and fetch the result from the EfRepository, which in turn would make the request to the database. We can see in this example here that the logging is showing us that we\u0026rsquo;re actually hitting CachedRepository, and some of the times we\u0026rsquo;re fetching the source data and other times were fetching the data from the cache. The actual EfRepository that is also defined inside of FrontDesk.Infrastructure is shown here, and once more, you can see that there\u0026rsquo;s not much to it. Most of the behavior we\u0026rsquo;re simply inheriting from the EfRepository that exists in the Ardalis.Specification package. It\u0026rsquo;s called RepositoryBase. However, when we inherited it, we were able to add additional constraints, and so you\u0026rsquo;ll see here as well that we specify that this only works with IAggregateRoot. You can see the definition of the RepositoryBase in the Ardalis.Specification NuGet package, which is available on GitHub. The details of it are shown here. The ListAsync method simply delegates to dbContext.Set of the appropriate T type, and then calls its ToListAsync, passing along a cancellationToken if one was provided. Now the last piece of the puzzle is our own AppDbContext. Inside our AppDbContext, we define the DB sets that we\u0026rsquo;re working with and we also pass in some additional configuration. One thing to notice and take away from this example is how many places in our solution we have to reference AppDbContext or EntityFramework. It\u0026rsquo;s almost nowhere in the entire code base. The only place that we talk about it at all is inside of AppDbContext, EfRepository, and some related folders such as Configuration and Migrations. Everywhere else, and especially in our domain model, we\u0026rsquo;re completely persistence ignorant, relying only on abstractions that we\u0026rsquo;ve defined.\nIntroducing the Specification Pattern Eric Evans introduces the specification pattern in the original book on domain‑driven design. Although it\u0026rsquo;s covered in Evans\u0026rsquo;s DDD blue book, the specification pattern isn\u0026rsquo;t listed in the book\u0026rsquo;s mind map, and honestly, it doesn\u0026rsquo;t get the attention it deserves. Factories are in the book\u0026rsquo;s mind map, but specifications aren\u0026rsquo;t? Even though in my experience they play a much larger role in producing a clean domain model design. ‑In the book, Evans says that specifications mesh smoothly with repositories, which are the building‑block mechanisms for providing query access to domain objects and encapsulating the interface to the database. It\u0026rsquo;s this powerful combination of specification and repository patterns that truly result in a clean, extensible, and testable design. Let\u0026rsquo;s dig a little more into the specification pattern and how it integrates with repositories before we show you how we\u0026rsquo;ve implemented it in the front desk application. ‑Specifications are used to specify the state of an object, and as such, are primarily used in three ways, validation, selection and querying, and creation for a specific purpose. In our app, we are primarily leveraging specifications in our queries. Create explicit predicate‑like value objects for specialized purposes. A specification is a predicate that determines if an object satisfies some criteria, according to Eric Evans. The most basic specification simply provides a method typically named IsSatisfiedBy, which accepts some object and returns a Boolean. These methods perform their logic in memory, and unfortunately, in remote data querying scenarios, this approach would require every row to be transferred to the application before the specification logic could be run against it. ‑However, more sophisticated specifications can be used in conjunction with ORMs like Entity Framework Core to encapsulate the details of a query while still allowing EF Core to translate the query into SQL that executes on the database server. Our sample application uses such a specification in the form of a NuGet package, ardalis.specification, which is maintained by, guess who, Steve Smith. ‑Recall that one of the benefits of using the repository pattern and abstraction was that it prevented query logic from being spread throughout the application. This was also the reason for not returning IQueryable from repository methods. The same logic can be applied to repositories that accept arbitrary predicates since, again, that means the complexity of these predicates would need to live in the code calling the repository, which might be in the user interface for example. Using repository interfaces that accept specifications instead of custom predicates addresses this problem very elegantly. ‑What about the issue we learned about earlier in this module where generic repositories weren\u0026rsquo;t suited to aggregates with custom query needs? So, individually typed repository interfaces were required, and each additional custom query needed to be added to this new specific interface. Well, specifications solves that problem too. Generic methods accepting generic specifications allows for custom queries where needed for any given aggregate. ‑A few more benefits of specifications. They\u0026rsquo;re named classes that live in your domain model. You can easily unit test them in isolation, or if necessary, integration test them with a test database. They\u0026rsquo;re highly reusable. They keep persistence logic out of your domain and your user interface. They keep business logic out of your database and persistence layer. They help your entities and aggregates follow the single responsibility principle by keeping complex filtering or validation logic out of them. You can easily create your own specification interface and implementation. Feel free to look at the source for ardalis.specification on GitHub and take just the bits you find useful. Or, you can reference that package and leverage all of its features and just start adding the specifications that your domain needs. It\u0026rsquo;s up to you. Either way, you will need to write the specifications themselves. These belong in your domain model. When you don\u0026rsquo;t have many of them, you might just put them in a root specifications folder. However, as your model grows, if you\u0026rsquo;re using aggregates, it may make sense to have each aggregate include in its own folder the specifications that go with it. This makes them easy to locate as they grow in number. ‑Each specification class is a value object, so it should be immutable. Generally, they do all of their work in their constructor. Any variable part of the specification should be supplied as a constructor argument. And once constructed, the specification needs to be supplied to your query implementation. You can use specifications directly with EF Core or you can use a repository abstraction that supports them. In either case, pass the specification to the query object and it will be used to build the query, which is then executed and results are returned. The resulting code for most queries turns into one line to create the specification and another line to execute the query by passing the specification to a repository or a DbContext method. Note that our sample is built on top of a repository abstraction that\u0026rsquo;s provided with the ArdalisSpecification package, and so it\u0026rsquo;s fully compatible with its specification types. We\u0026rsquo;ll look at the code more in the next section. ‑Here\u0026rsquo;s an updated mind map that I have created which shows how specifications work with repositories to define the queries for aggregates and entities. If you\u0026rsquo;ve been using repositories without specifications and have experienced any of the pain points we\u0026rsquo;ve described in this module, try refactoring to use specifications and I\u0026rsquo;ll bet you\u0026rsquo;ll be surprised what a positive difference it makes.\nUsing Specifications with Repositories in Our App Now it\u0026rsquo;s time to see just how specifications are implemented in the sample app. While the application code does lean on Steve\u0026rsquo;s specification API, there is still plenty to see. Most of what you\u0026rsquo;ll see here is the application\u0026rsquo;s code, but occasionally you\u0026rsquo;ll also see some of the code that\u0026rsquo;s in the Ardalis.Specification API. Once again, Steve is going to walk you through this demo, and he\u0026rsquo;ll do so from the perspective of how the app retrieves data, starting with the front‑end. ‑When we first load the schedule page in the FrontDesk app, it loads our Blazor WebAssembly application, which then makes some API calls to fetch the appointments and related data. One of those calls is shown here. It\u0026rsquo;s used to get the list of appointments for the schedule. Looking at Swagger, we can see there are a bunch of appointment endpoints. Our API is designed to serve the needs of the client app. Its endpoints won\u0026rsquo;t necessarily match up with how our domain model is constructed, so it\u0026rsquo;s perfectly fine to have an endpoint for appointments, even though appointment is not an aggregate root. It just means we need to pass in the aggregate root ID as part of the request so that we can get the schedule that owns the appointments. If we test the list AppointmentsEndpoint, we can pass in the same schedule ID that Blazor was using, and we get back a list of appointments as expected, and these are, in fact, the same appointments that are being used in the front end. Looking at the source code for this endpoint, you can see that, again, it\u0026rsquo;s in the API project in the Endpoints folder in an Appointment folder, and within that, we\u0026rsquo;re looking at the List endpoint. Now, when we pass in the request, we\u0026rsquo;re specifying a ScheduleId, and if that ScheduleId is missing or empty, then we\u0026rsquo;re going to return NotFound from this API. Otherwise, it uses the ScheduleByIdWithAppointmentSpec to encapsulate the query that it\u0026rsquo;s going to use. On the page in question, we only want the appointments for one day. It\u0026rsquo;s worth noting that this specification does not perform any filtering by date; it returns all appointments for this schedule. We\u0026rsquo;ve left a to do task here for you to implement this behavior by creating a new specification. Now, the specification that we\u0026rsquo;re using here is passed to the repository method, GetBySpecAsync. We\u0026rsquo;ll look at that in a moment. For now, let\u0026rsquo;s take a look at this specification. All of the schedule specifications are in the ScheduleAggregate folder in the Core project. The ScheduleByIdWithAppointmentSpec is pretty simple and has just three details worth pointing out. First, it has a WHERE clause, making sure it only matches schedules that have a matching ID. Second, it eager loads it\u0026rsquo;s associated appointments by using it .Include statement. And third, it implements another marker interface, ISingleResultSpecification. This interface is used to mark specifications that are expected to only return a single result. It is required when passing a specification to a repository method that only returns a single instance of a type rather than a collection or enumerable. Considering that this is being called from a List endpoint on the API, this may seem strange, but remember, we are only loading a single schedule aggregate, and it is then just the container for the set of appointments that the endpoint is going to return. The method the endpoint is calling, GetBySpecAsync, is defined in Ardalis.Specification, as shown here. Note that it has a generic constraint requiring any specification passed to it to have that ISingleResultSpecification marker interface. The sample code is calling this first method, which just works with one entity type and then returns it. If you need to use projection, though, you can use the second method, which operates on your entity type, but returns a different type using a .select. You can use this to optimize queries to return only needed properties. Remember that specifications are useful to define the expected shape of returned data in a query. This doesn\u0026rsquo;t just mean filtering the number of rows using a WHERE clause, but also determining which associations should be brought back with the query, and even which columns should be included. Let\u0026rsquo;s see an example of that. Returning to the specifications for the schedule, there\u0026rsquo;s another one called ScheduleForClinicAndDateWithAppointmentsSpec. One of the newer features in EF Core is \u0026ldquo;filtered includes,\u0026rdquo; and so by adding an include filter, we can make sure that this schedule, which is being used with a particular ClinicId, will only load in its appointments where they are for a given date that gets passed into the specification. You can use this specification, by the way, as an example when you complete that to do task that we just saw in the list endpoint. Compare this code to how we solve this problem in the previous version of this course using custom SQL queries and a custom ScheduleRepository. The specification has replaced all of that with a single specification class containing all the query logic, and the calling code simply needs to create the specification and then pass it to the repository. Unlike custom LINQ expressions that might be anywhere in our application, specifications are easily tested in isolation. In the IntegrationTests project, you\u0026rsquo;ll see several different tests that demonstrate the various schedule specifications and ensures they work as expected. These tests use a real database, since .include logic can\u0026rsquo;t be tested with an in‑memory collection. For the last specification that we looked at, which only includes the appointments for a given date, you\u0026rsquo;ll see that there\u0026rsquo;s an integration test that adds a number of appointments on different dates and then uses a repository to fetch back a schedule using the ScheduleForClinicAndDateWithAppointmentsSpec and a specific date, and it verifies that we only get back the appointments for that date and not the appointments that are on different dates, which verify the behavior of many of the abstractions and implementations in our domain model.\nReview and Resources Once again, let\u0026rsquo;s begin a review with some of the important terms you learned in this module. First, and most importantly, the focus of the module, repositories, which encapsulate the data persistence logic, add, update, delete, and retrieve. In the case of domain‑driven design, we use repositories to focus on aggregate roots. Key to building flexible repositories is the specification pattern, which guides you to encapsulate business rules in a way that they can be passed around and acted upon in other methods, classes or APIs. You learned about persistence ignorance, which describes objects being ignorant about how they are persisted into data storage. It\u0026rsquo;s another critical aspect of domain‑driven design. Steve and I also talked about ACID, an acronym to describe transactions as being atomic, consistent, isolated, and durable. Another acronym we talked about is SOLID, which is a collection of software design patterns. ‑After introducing you to repositories and how they fit into the DDD mind map, you learned about their benefits and some tips for designing them. ‑We also addressed some of the debates around repositories, not only if you should even use them, but how to use them, for example, whether or not to return IQueryables. Many of these debates exist because of the complexity of balancing clean repositories with repositories that help you achieve the variations of queries required by your domain. ‑We introduced you to an often overlooked pattern, the specification, that plays a critical role in solving this problem with DDD. Remember that you are not on your own building specifications. You can lean on the NuGet packages that I created or just dig into my GitHub repo to pick and choose what you want to adopt. Links are coming up. ‑Steve gave you a great tour of how repositories are implemented in the FrontDesk application and then more deeply to see how these repositories are using specifications to provide the rich querying needed in the application. ‑Here are a number of links to not only my GitHub repo and NuGet packages, but a number of other resources we referenced, as well as some additional ones that we think you\u0026rsquo;ll find useful. ‑In the next module, you\u0026rsquo;ll learn about two more critical pieces of the DDD mind map, domain events and anti‑corruption layers, both which help provide some data pathways between the various parts of your software. Thanks again for watching Domain‑Driven Design Fundamentals. I\u0026rsquo;m Julie Lerman, ‑and I\u0026rsquo;m Steve Smith. Thanks for watching.\nAdding in Domain Events and Anti-corruption Layers Introduction and Overview Hi, this is Steve Smith. ‑And this is Julie Lerman. ‑In this module of Domain‑Driven Design Fundamentals, you will learn about domain events and anti‑corruption layers, two patterns for decoupling how the domain model communicates internally and with other systems. ‑We\u0026rsquo;ll start with domain events, which can be used to separate concerns, allowing different areas of the application to evolve independently, and sometimes helping with scalability as well. You\u0026rsquo;ll learn how to identify domain events in your system, and how to design domain event classes. Then we\u0026rsquo;ll show you domain events being used in a simple application, so you can get a feel for the structure and the workflow. ‑Then, you\u0026rsquo;ll get to see the domain events we built in our sample application, which are a bit more realistic. After this, we\u0026rsquo;ll turn our attention to another important element of domain modeling, anti‑corruption layers, which can be used as translators between bounded contexts and Legacy APIs.\nIntroducing Domain Events Domain events are a critical part of a bounded context. They provide a way to describe important activities or state changes that occur in the system. Then, other parts of the domain can respond to these events in a loosely coupled manner. ‑In this way, the objects that are raising the events don\u0026rsquo;t need to worry about the behavior that needs to occur when the event happens. And likewise, the event handling objects don\u0026rsquo;t need to know where the event came from. This is similar to how repositories allow us to encapsulate all of our data access codes, so the rest of the domain doesn\u0026rsquo;t need to know about it. ‑We can also use events to communicate outside of our domain, which we\u0026rsquo;ll look at in just a moment. Another thing that\u0026rsquo;s worth remembering is that domain events are encapsulated as objects. This may be different from how you\u0026rsquo;re used to coding events. It certainly was different for me when I first started learning about them. For example, in a user interface, events are more commonly written as some form of a delegate in another class, but here they\u0026rsquo;re first class members of the domain model. ‑Right. Although you can implement domain events using techniques, like the event keyword in C#, the domain events themselves should be full‑fledged classes. In fact, all of these parts of domain‑driven design are defined as objects in our domain model. ‑Vaughn Vernon describes domain events simply, saying we should use a domain event to capture an occurrence of something that happened in the domain. The domain events should be part of our ubiquitous language. The customer or domain expert should understand what you\u0026rsquo;re talking about when you say when an appointment is confirmed, an appointment confirmed event is raised. ‑You may already be familiar with the idea of events from working with user interfaces. ‑Many user interface clients, like .NET Windows Forms, Electron, or web pages, like the one shown here, make heavy use of events and event handlers. In this example, there\u0026rsquo;s a single page with a single button, and in the markup, you can see there\u0026rsquo;s an onclick attribute in the button that leads to a little JavaScript method defining what the app should do in response to a user clicking the button. ‑Events are helpful because they let us avoid a lot of conditional logic. Instead, we can write code that signals a certain thing has happened, and we can have other code in our system listen for these signals and take action accordingly. So in this kind of code, you don\u0026rsquo;t have a separate class for an onclick event, and it may take some getting used to that now in our model, we\u0026rsquo;re going to create a whole class to represent an event. Domain events offer the same advantages to our model as the events in the user interface. Rather than having to include all of the behavior that might need to occur whenever the state of one of our objects changes, instead, we can raise an event. Then, we could write separate code to deal with the event, keeping the design of our model simple, and helping to ensure that each of our classes has only one responsibility. Essentially, a domain event is a message, a record about something that occurred in the past, which may be of interest to other parts of our application, or even other applications entirely.\nIdentifying Domain Events in Our System ‑Be especially attentive to these kinds of phrases when discussing the application with your domain experts. When this happens, then something else should happen. If that happens, notify the user when, or inform the user if, these types of phrases frequently refer to situations that are important to the domain expert, the system, or the user. It might therefore be worth modeling these types of things as domain events. You may also discover behavior in the application that will benefit from being treated as domain events that may be the domain expert isn\u0026rsquo;t initially aware of. ‑Remember that domain events represents something that happened. Since we can\u0026rsquo;t generally alter history, this means they should be immutable. It\u0026rsquo;s a good idea to name the event using terms from the bounded context\u0026rsquo;s ubiquitous language describing clearly what occurred. If they\u0026rsquo;re fired as part of a command on a domain object, be sure to use the command name. Here\u0026rsquo;s some examples. ‑Depending on the application, it might be important to have events to represent when a user has authenticated, when an appointment has been confirmed, or when a payment has been received. Be sure to only create events as you need them in your model. You should follow the YAGNI principle, that\u0026rsquo;s you ain\u0026rsquo;t gonna need it. In other words, don\u0026rsquo;t create domain events unless you have some behavior that needs to occur when the event takes place, and you want to decouple the behavior from its trigger. You really only need to do this when the behavior doesn\u0026rsquo;t belong in the class that\u0026rsquo;s triggering it.\nDesigning Domain Events Here\u0026rsquo;s some more things to keep in mind when you\u0026rsquo;re creating domain events. We\u0026rsquo;ve already mentioned that domain events are objects, but to be more specific, each domain event should be its own class. It\u0026rsquo;s also usually a good idea to note when the event took place since frequently the code that\u0026rsquo;s handling the event might run some time after the event occurred. It can be helpful to create an interface or a base class that defines the common requirements of your domain events. For example, capturing the date and time the event occurred. ‑Also, when you\u0026rsquo;re designing your event, you need to think about the event‑specific details you want to capture. If it\u0026rsquo;s related to an entity, you might want to include the current state of the entity in the events definition. Think about what information you would need to trigger the event again. This can provide you with the set of information that is important to this event. Similarly, you may need to know the identities of any aggregates involved in the event, even if you don\u0026rsquo;t include the entire aggregate itself. This will allow event handlers to pull the information back from the system that they might require when they\u0026rsquo;re handling the event. Ideally, domain event objects should be lightweight, so you want to be sure you capture sufficient information to handle the event, but not so much that the event object itself becomes bloated. Since the main events are immutable, they\u0026rsquo;re typically fully instantiated via their constructors. And since they\u0026rsquo;re simply noting that something has happened in the system, they don\u0026rsquo;t usually have any behavior or side effects of their own.\nApplying Domain Events to a Simple App We\u0026rsquo;ve put together a simple console application that we\u0026rsquo;re going to use to demonstrate the value that domain events can have in your application. The idea behind this is to strip things down to as small a level as possible. Then, we\u0026rsquo;ll also show how domain events are playing a real role in a more real‑world way when we get to our veterinary scheduling application. This is a .NET console application with dependency injection. The main program just loads the needed services and runs the app. The app has a simple run method, which goes through the following steps. We can step through it with the debugger, so you can see the output in real time. The app loads services and starts running. It shows what happens when an appointment is created using a service. The service calls a factory method that creates the appointment. After instantiating the appointment, the factory method sends an email, which you can imagine includes code like what is in the comments here. Then, it similarly sends a notification to the user interface, again, with code like what\u0026rsquo;s in the comments before finally returning to the service. The service, then saves the new appointment in the database. Then, the app creates a different appointment and saves it directly using a repository instead of a service. And once more, the notifications and the save occur in the same order. Finally, the appointment is confirmed, which triggers some UI notification, and then that change, too, is saved. The main thing to take away from this example so far is that the Appointment class has a lot of concerns. The act of creating an appointment, especially, involves a lot of code that could fail. It\u0026rsquo;s also worth noting that notifications and emails are going out before the state of the entity is saved. So if something goes wrong, users will have been told the operation was successful, and people may have been notified via email when, in fact, the update itself might never go through. ‑The reason we\u0026rsquo;re showing the behavior both from a service and with the appointment directly is because our domains should be designed to work either way. Earlier in this course when you learned about domain services, we explained that forcing all operations on your domain to go through a set of services tends to lead to an anemic domain. Ideally, your aggregates and entities should behave correctly, whether they\u0026rsquo;re being used directly or through a set of services. One way we can improve this design would be to move the responsibilities of actually sending emails or updating the UI to help our methods or other services. Then, we could call them from appointment.create instead of having all the code in here. This would make for less code inside of Appointment. ‑That would definitely be better, but it would still mean that appointment would need to be updated every time a new requirement came along. There\u0026rsquo;s a principle we can use to avoid that, though, called the Hollywood principle. ‑I love the name of this principle. Its name comes from an old saying from Hollywood agents, don\u0026rsquo;t call us, we\u0026rsquo;ll call you. ‑Exactly. Applied to software, the principle is closely related to dependency inversion from solid. Instead of forcing appointment.create to have to know about and call every possible thing that might be involved in the appointment creation workflow, instead, it can just let the app know something happened and let the app respond by calling handlers. ‑Instead of putting all the logic into this method, potentially making it huge and complicated and really hard to read, we move that logic into handlers, and the app calls the handlers. We don\u0026rsquo;t call the handlers, the app calls us. And beyond just reducing the amount of code and responsibility inside Appointment, this approach also lets us make sure that notifications to the user don\u0026rsquo;t occur until persistence is successful. And it still keeps the model\u0026rsquo;s behavior consistent without requiring a service to perform any of the work. Let\u0026rsquo;s see how it works. ‑Domain events is a pretty simple pattern, but you do need to have some plumbing code to support it. You also need to think about whether you want your events to fire before or after persistence. In many cases, what you really want is postpersistence events for the reasons we mentioned above. You want to make sure your persistance succeeds before you send any notifications outside of your app. Also, although occasionally I\u0026rsquo;ve used them for validation in the past, ideally, your domain events and handlers should never fail. That is, don\u0026rsquo;t build your behavior around exceptions that might be thrown from event handlers. Use a different pattern if you need that type of behavior. ‑In this simple demo, which mirrors how our sample app works, we just need a collection of events on each entity. We\u0026rsquo;re creating simplistic types to represent domain events and the respective handlers. You can implement the logic to find and call handlers whenever an event is dispatched in a number of ways. For this sample, we\u0026rsquo;re using the MediatR NuGet package created by Jimmy Bogard. Steve mentioned that you\u0026rsquo;ll need some plumbing to start, and that plumbing is the interfaces or base classes, if you prefer, for handler and domain event classes. In our example, we\u0026rsquo;re using interfaces. Here\u0026rsquo;s the IDomainEvent interface and the IHandle interface. ‑Once you\u0026rsquo;ve set up your event and handler interfaces or base types, it\u0026rsquo;s time to create some events and their associated handlers. ‑For this scenario, there are two things happening, an appointment is scheduled or created and an appointment is confirmed. An event is something that already happened. So we name our events in the past tense, and we have AppointmentCreated and AppointmentConfirmed. The event classes are pretty simple and just include the instance that triggered them, so handlers have access to any properties they might need from it. Once the events have been defined, you just take each individual responsibility out of the original method and create a separate handler for it. It\u0026rsquo;s fine to have multiple handlers for the same event. Ideally, your design shouldn\u0026rsquo;t depend on the order in which the handlers execute. But if it does, you can think about adding a sequence to your handler interface and ensuring they\u0026rsquo;re called in sequence order. ‑The last thing you need to do is register or record the events on the entity. In this sample, that just means adding them to the list of events that are on that entity. The actual implementation for dispatching the events is done in the repository after the save is successful. And in our veterinary sample, this work is done in the DbContext SaveChanges method. ‑Let\u0026rsquo;s step through the code again now that it\u0026rsquo;s using domain events. ‑The app starts up as before. We enter the appointment.create method. ‑And look how much smaller that method is now. ‑Definitely. It\u0026rsquo;s way easier to see what\u0026rsquo;s going on here. Now the domain event is added to the collection, but notice that when we step over this, nothing actually happens yet. ‑Right, it\u0026rsquo;s just holding it until after the entity is persisted. ‑Which is now. Notice that we\u0026rsquo;re in the repository Save method. And for every event that we have stored on this entity, we\u0026rsquo;re using MediatR to publish it at this point in time. ‑This is still in process on the same thread. There\u0026rsquo;s no out‑of‑process queue or anything involved here. ‑Right, there\u0026rsquo;s nothing to install using this pattern except for MediatR, and that just runs in‑memory. And, of course, you could wire this up with your own code that simply loops over your set of events and then dispatches out to your handlers. There\u0026rsquo;s nothing that says you have to use MediatR. Notice in the output that the DATABASE Saved occurred, and then the UI and email notifications. ‑As expected, we only triggered side effects outside our domain after persisting. Now let\u0026rsquo;s see the version that uses the repository directly and doesn\u0026rsquo;t bother going through the service. ‑We basically see the same behavior, DATABASE Saved, UI, EMAIL. ‑All that\u0026rsquo;s left now is the confirm and save, which should look similar, entity saved, and then the UI is updated. ‑That\u0026rsquo;s basically it. I created a small GitHub repo, which has just this sample in it. It\u0026rsquo;s at github.com/ardalis/DomainEventsConsole. There\u0026rsquo;s a branch there showing how things work without events. Of course, you can also download it from the course details. ‑If you want to start your solution with all of this plumbing already in place, you can use Steve\u0026rsquo;s CleanArchitecture solution template, which is also on GitHub. He is one productive guy. Everything shown here is already in place in the template, which is designed for you to use as a starting point for your app.\nExploring Domain Events in Our Application Now let\u0026rsquo;s look at how we\u0026rsquo;re leveraging domain events in the veterinary FrontDesk scheduling app that we\u0026rsquo;ve been working with. Again, we\u0026rsquo;ll start by showing you the code, and then we\u0026rsquo;ll debug through it so you can see it in action. ‑In our Appointment class, we\u0026rsquo;re going to record a domain event when certain changes are made to the appointment. So, if we scroll down and take a look at the UpdateRoom method, you\u0026rsquo;ll see that it creates and saves an appointmentUpdatedEvent. The same is true for the other update methods like UpdateDoctor, UpdateStartTime, etc. They each will create an appointmentUpdatedEvent and pass it the current instance of the appointment, and then this is saved into the entity\u0026rsquo;s Events collection. ‑In the case of the Confirm method, it\u0026rsquo;s similar, but it creates a different event, an appointmentConfirmedEvent. Essentially, the appointment entity can trigger two kinds of events directly, change and confirmed. And you\u0026rsquo;ll notice it only does so if an actual change takes place. Calling an update that doesn\u0026rsquo;t change the current value will not trigger a new event. ‑Let\u0026rsquo;s take a look at the appointmentUpdatedEvent, and this is similar to the one we saw in the simpler console app in the previous demo. It inherits from BaseDomainEvent, which is defined in our shared kernel, and it adds a UTC timestamp property called DateOccurred that is set when the event is created. This can be useful for debugging purposes. The only other property the class takes is the appointment itself. The AppointmentConfirmedEvent, shown here, is similar. ‑Notice that these domain events are all defined in the core project with our domain model. For this sample, they\u0026rsquo;re in an Events folder in the root. However, in a large application with many events, it might make more sense to put them with the aggregate that they correspond to. In this case, the ScheduleAggregate. There\u0026rsquo;s one more domain event in our sample, which is the AppointmentScheduled event. It\u0026rsquo;s similar in structure to the others, but it\u0026rsquo;s actually created elsewhere. ‑Once you start working in event‑driven applications, it can be a bit more difficult to follow the flow of execution in the app where events are concerned. It really just takes some getting used to, and then you\u0026rsquo;ll find it to be second nature. The best way to see where events are raised and where they are handled is by looking at an individual event and examining its references. Looking at AppointmentScheduled, you can see that it is handled in the API project and in the core project. It is only created inside of the ScheduleAggregate itself. Let\u0026rsquo;s have a look at where that happens. ‑In Schedule, the AddNewAppointment method creates and saves the AppointmentScheduled event after adding the appointment to its collection and marking whether or not it\u0026rsquo;s conflicting. Once the schedule is saved, any appointments that have had domain events added to their respective collections will have them dispatched after the save to persistence is complete. ‑Before we step through the code, let\u0026rsquo;s have a look at one of the AppointmentScheduledEvent handlers. The thing to notice is that these handlers don\u0026rsquo;t get created or called anywhere in our code. That\u0026rsquo;s that Hollywood agent again from the Hollywood principle saying, don\u0026rsquo;t call us, we\u0026rsquo;ll call you. The event dispatching logic, in this case, using MediatR, is what calls these handlers at runtime. But at compile time, nothing references them directly. ‑Now let\u0026rsquo;s see the flow of domain events in our application when we change an appointment. We\u0026rsquo;ll modify this appointment for my little baby, Sampson, and change the appointment from a wellness exam to a diagnostic exam. But a diagnostic exam takes more time, and this will automatically change the duration of the visit, which should trigger a conflict with one of Sampson\u0026rsquo;s other appointments. Yes, he likes to go to the vet quite a lot. ‑The change initially hits the AppointmentUpdate endpoint. It loads the schedule and the appropriate appointment and calls its Update methods. In this case, the only one that has a change is the change to the appointment type. This intern adds an appointmentUpdatedEvent. Once the change is saved, the event is dispatched. The API project also has a handler, AppointmentUpdateHandler, that responds to this event by sending a message to the Blazor client using a SignalR hub. This will trigger a real‑time notification in the app. ‑What about communication between bounded context or apps using events? Applications and microservices frequently use events to communicate, too, but these aren\u0026rsquo;t domain events since they extend beyond a single domain. They\u0026rsquo;re frequently called integration events, and they may be defined as part of your domain or in a separate project or package. For simplicity, ours are here in this IntegrationEvents folder. ‑The FrontDesk has just two integration events, the AppointmentConfirmLinkClickedIntegrationEvent is published by another app and consumed by this one, and AppointmentScheduledIntegrationEvent is an event this app publishes and another app consumes. It\u0026rsquo;s important that the structure of the published and consumed types match, which is why frequently a shared package is used to define these kinds of events. ‑We don\u0026rsquo;t have time to dive deeply into distributed application architecture, but one thing you need to remember when designing integration events is that they typically will be enriched and denormalized when compared to a similar domain event. For instance, the AppointmentScheduled domain event just has a reference to appointment, and that only has IDs for the client, patient, and doctor. However, the integration event includes many more details like client name and email, patient name, and doctor name. The reason for this is to ensure that consumers of the event have enough information from the event to perform whatever actions they need to without having to immediately call back to the publishing app to ask it for more details. You can imagine that the performance of a system would suffer if every time an appointment event was published, one or possibly many apps that were consuming that event, turned around and immediately had to make calls to this app\u0026rsquo;s API asking for client details, patient details, and doctor details. Hence, we have a handler that is responsible for taking in a domain event and enriching it with the additional details shown here on the integration event. We\u0026rsquo;ll put these integration events to use in the next module.\nIntroducing Anti-Corruption Layers The last topic we want to discuss in this module is anti‑corruption layers. An anti‑corruption layer, as the name implies, helps to prevent corruption in your domain model. ‑Right, just like superheroes help to fight corruption, these layers provide a sense of security to your model when it needs to interact with other systems or bounded contexts. ‑Returning to our mind map, you can see that the anti‑corruption layer is used to translate and insulate as part of a context map, mapping between a bounded context and foreign systems. ‑When your system needs to communicate with other systems, especially legacy applications that weren\u0026rsquo;t written or modeled as well as your current system, you need to be careful not to let assumptions and design decisions from that system bleed into your model. For instance, if the other system\u0026rsquo;s model includes a customer, even if that customer refers to the same actual business customer, it\u0026rsquo;s likely that it will be modeled differently than a customer in your system. It\u0026rsquo;s best to have a layer that can translate to and from other systems\u0026rsquo; models. In DDD, this is the job of an anti‑corruption layer. ‑Right, like we mentioned in the beginning of the course, even other bounded contexts in your own system may be different enough to merit having an anti‑corruption layer in place to protect the two distinct models from one another. And, of course, legacy applications frequently use very different models from newer systems. An anti‑corruption layer isn\u0026rsquo;t a design pattern, however, it\u0026rsquo;s usually comprised of several design patterns. The job of the layer is simply to translate between the foreign system\u0026rsquo;s model and your own. ‑In addition to translating the objects themselves, the anti‑corruption layer can also clean up the way in which you must communicate with the other system. It may provide a façade to simplify the API or an adapter to make the foreign system behave in a way that is known to your system. You can learn more about these design patterns in the Design Patterns Library on Pluralsight. ‑We\u0026rsquo;re usually most concerned with having an anti‑corruption layer in place when communicating with legacy systems. Eric Evans notes why that\u0026rsquo;s important. ‑Even when the other system is well designed, it is not based on the same model as the client, and often the other system is not well designed. ‑Since this is a fundamentals course, we\u0026rsquo;re not going to dig deeply into anti‑corruption layers, because they can be fairly complex, as well as very customized to each scenario, but here\u0026rsquo;s an example structure of one which comes from Eric Evans\u0026rsquo; book, showing how an anti‑corruption layer can connect your beautiful system on the left with a not so beautiful system on the right. ‑I really like this diagram. I think Eric had some fun putting it together. ‑Gee, what gives you that impression, Steve? ‑Of course, in the middle you can see how the anti‑corruption layer is using a façade and some adapters, but on the right it\u0026rsquo;s protecting us from a big complicated interface, some messy classes, and some things we just don\u0026rsquo;t even want to know about. ‑Right, and of course, your own system is comprised of an elegant class, a very expressive class, and of course even more good stuff, and maybe even some stuff we should be refactoring as well. ‑There\u0026rsquo;s no one way to create an anti‑corruption layer. Whatever you need in order to insulate your system from the systems it works with is what you should put inside of this layer, which should allow you to simplify how you interact with other systems, ensure that their domain decisions do not bleed into your design, and ensure any necessary translation is done along the way.\nReview and Resources We\u0026rsquo;ve covered some new topics in this module, and there\u0026rsquo;s a few new terms that we want to make sure we review. Domain events are a type of object that actually represents something that occurred within the domain that other parts of the system may find interesting and want to tie their behavior to. And this is a great way to keep your system decoupled and to keep your individual objects simpler because they don\u0026rsquo;t have to know about all of the behavior that might occur when some event takes place. We also referred to the Hollywood principle, which can be summed up as don\u0026rsquo;t call us, we\u0026rsquo;ll call you. This principle is related to the dependency inversion principle from SOLID and is frequently used to decouple systems from one another. Instead of us putting all the logic we need in our code, we architect the system so that it calls back to us at the appropriate time. And we put our code into handlers that the app calls, rather than directly coupling our model to these actions. ‑And finally, we looked at anti‑corruption layers, which can be used to ensure that our model that we worked so hard to produce doesn\u0026rsquo;t become polluted by the models of other systems we work with based on objects they wanted to return to us or the type of API that they want us to code to. So we put anti‑corruption layers in place to shield our model from those other systems or bounded contexts that we might work with from our bounded context. ‑In this module, we introduced domain events, and hopefully, you have a good idea of what they are at this point. ‑We\u0026rsquo;ve talked about how you can identify opportunities to use domain events based on the kinds of requirements your customers give you, as well as when you see code in your model that\u0026rsquo;s doing too much and could be more loosely coupled. ‑We gave you some tips for designing and naming domain events, and then we showed them in action, both in a relatively simple console app, as well as in our much larger veterinary clinic sample application. ‑Finally, we introduced the concept of anti‑corruption layers, which use a variety of design patterns to insulate our model from the design choices of other applications or bounded contexts. Here are a number of resources where you can learn more about domain events and anti‑corruption layers. Some of these, including a few Pluralsight courses, we mentioned in this module, but there are others that we find to be relevant, even if we didn\u0026rsquo;t explicitly mention them. ‑Up next, we\u0026rsquo;re going to wrap up this course by adding a new feature to the application. Because of our clean architecture and well‑designed domain model, it\u0026rsquo;s going to be pretty easy to integrate into our existing app. I\u0026rsquo;m Steve Smith, ‑and I\u0026rsquo;m Julie Lerman, and thanks for watching this module of our Domain‑Driven Design Fundamentals course.\nEvolving the Application Easily Thanks to DDD Introduction and Overview Hello, this is Julie Lerman, ‑and this is Steve Smith. In this module, we\u0026rsquo;re going to wrap up our course on Domain‑Driven Design Fundamentals by showing how we can reap the benefits of our design when it\u0026rsquo;s time to add additional functionality to the system. ‑In this module, we\u0026rsquo;ll first review our current system design and see how it incorporates DDD patterns and practices. Then, we\u0026rsquo;ll circle back to our customer, Michelle, to see how the new vet clinic appointment management system is working out. ‑During that quick conversation, we\u0026rsquo;ll learn about a new feature, and we\u0026rsquo;ll show how we can implement that feature. ‑We\u0026rsquo;ll leverage message queues to implement this feature, so we\u0026rsquo;ll definitely be sure to share with you some of the basics about message queues before we show you that code. ‑The main benefit of our design choices is the ease with which the system can be extended and maintained in the future. And we hope you\u0026rsquo;ll agree that adding to the current design is quite straightforward.\nReviewing Our Current System Design So far, our system is pretty simple, though it\u0026rsquo;s fairly complex, as most course demo apps go. ‑The system is currently two different web applications, although the user interface makes it look like a single app. Our main focus has been the application used by clinic employees to schedule appointments. There\u0026rsquo;s a lot of complexity with scheduling, so this benefited from domain‑driven design. There\u0026rsquo;s also a clinic management application that\u0026rsquo;s used to do simpler data‑in/data‑out tasks like record keeping and maintaining information about doctors, clients, patients, and more. Let\u0026rsquo;s review the scheduling app a little more closely. ‑We have a single aggregate for a schedule, which contains a number of appointments. We limit access to the schedule through the schedule repository class, which is responsible for retrieving and storing the schedule in our database. We\u0026rsquo;ve identified a couple of value objects that allow us to better model concepts in the domain, and we\u0026rsquo;re making use of domain events to allow our domain in other parts of our system to respond to changes in the state of our model. ‑It\u0026rsquo;s taken us a while to get to this point, but now that we\u0026rsquo;re here, the design of the system is very clean, and it reflects the customers domain, as well as we\u0026rsquo;ve been able to model it so far, of course, given some time constraints. ‑Yes, we do have to ship the app, I mean, this course, at some point. ‑Right, of course, as we build on this application, our model would continue to evolve. But we\u0026rsquo;ve shown you techniques you can use to ensure that you can grow the application without being overwhelmed by the complexity you\u0026rsquo;re trying to model. ‑Actually, as it turns out, the customer does have one more request for us. She said something about customers forgetting their appointments. Let\u0026rsquo;s have another quick conversation.\nAddressing a New Feature with the Domain Expert As it turns out, the customer does have one more request for us. She said something about customers forgetting their appointments. Let\u0026rsquo;s have another quick conversation. ‑Hey, Michelle, great to see you. How are things going with the new scheduling application? ‑It\u0026rsquo;s been fantastic. We\u0026rsquo;re really able to see very easily who scheduled each day, and book new appointments, and move things around is needed, and the front desk folks really appreciate that it highlights the appointments that are conflicting or unconfirmed. That makes it much easier for them. But one thing that\u0026rsquo;s still a problem is the fact that sometimes our clients forget their appointments. It probably happens at least a couple of times every day, and our staff really don\u0026rsquo;t have the time to call every client to make sure they remember ahead of time. ‑So, you\u0026rsquo;d like the system to call them then? ‑Well, we understand there\u0026rsquo;s services that\u0026rsquo;ll do that sort of thing and we might move to that eventually, but for now, if we could just send an email that would probably help remind clients to put it in their calendar. ‑Oh, okay, so, do you want an email to go out when they schedule the appointment or on the day before they\u0026rsquo;re scheduled to come in, or maybe even both? ‑Oh wow, if we could do both, that would be great, one to let them know when they\u0026rsquo;ve booked so that they know that we\u0026rsquo;ve got it in our schedule and another one to remind them that they have an appointment the next day, just in case they forgot. ‑That shouldn\u0026rsquo;t be too hard. Our model already handles certain events that occur, like when appointments are scheduled, and appointments already support being marked as confirmed too. ‑Sure, and I think all we\u0026rsquo;ll really need to build that\u0026rsquo;ll be new is some kind of service for sending the emails and some way for clients to click a link in the email so they can confirm the appointment. Since it\u0026rsquo;s email, it shouldn\u0026rsquo;t be a problem to send these out the day before, even if that day isn\u0026rsquo;t a week day or a work day, right? ‑No, I think that should be fine. It shouldn\u0026rsquo;t hurt anything to send an email on a Sunday or a holiday, and of course, we\u0026rsquo;ll ask our clients to opt into these reminders so we\u0026rsquo;re not sending anything unsolicited. ‑Sounds good. We\u0026rsquo;ll get started, and should have something for you to review real soon.\nPlanning Our Implementation Steps Before we get into the gory details of the implementation, we just want to make sure that you understand the very high level of what we\u0026rsquo;re doing here. The first thing is triggered when the appointment is scheduled. And in response to that, our system will send a confirmation email to a client. ‑Once the client gets that confirmation email, they can click a link to confirm that they\u0026rsquo;re going to make it to the appointment, and the system will then mark that appointment as confirmed so that on the schedule, the staff will see that it\u0026rsquo;s got a green box around it, and they should expect the client will actually show up. ‑What\u0026rsquo;s nice about this implementation is that it benefits so much from a lot of the infrastructure we already have in place. And thanks to our DDD‑based architecture, it\u0026rsquo;s just as easy to add in a few extra features that we need to make this work. ‑So as we go through this, you\u0026rsquo;ll see us using some existing and some new domain events, some application events, a number of event handlers and services. One new tool you\u0026rsquo;ll see is something we haven\u0026rsquo;t talked about yet, messaging queues to communicate between separate applications. The application we\u0026rsquo;ve been working with will need to communicate with a public website that the customers will interact with when they confirm their appointment.\nIntroducing Message Queues Before we go any further, we did just mention something new, which is message queues. And we just want to talk about that a little bit. It\u0026rsquo;s a pretty advanced topic for this fundamentals course, so we\u0026rsquo;re going to talk about it at pretty much a high level. ‑Message queues are nice to use between applications for a number of reasons. They can help decouple them and make it so that one of the applications can just drop off something into a message queue and continue on with its work and not have to worry about what happens to the message after that. ‑Right, or if whichever application or applications it\u0026rsquo;s trying to communicate with, it doesn\u0026rsquo;t need to worry if that application is available and listening at that very moment. The message can sit in the queue and when the other application is ready to grab it, it does. With a message queue, we\u0026rsquo;re really just dealing with a single message. One application drops it, and the other one takes it, and then the message is gone. ‑Yeah, and there\u0026rsquo;s lots of different implementations of message queues that you can find online. Some of them are free. Most of the cloud services that are out there now have these types of things built in as well. ‑And what we\u0026rsquo;re doing here is dealing with a single message at a time in something of a silo app since we control both applications that are communicating with each other. But sometimes you need to have a lot more flexibility than that, you might actually have a number of applications that are interested in that message and you may not even know in advance or control those applications. So this is when something called a service bus comes into play. ‑Right, so you\u0026rsquo;ll frequently hear about something called an enterprise service bus. And there\u0026rsquo;s, again, a number of examples of these that you can find available. It usually sits on top of message queues and other features. And one of the responsibilities it has is making sure that messages get delivered to the different applications that care about that message. ‑It might even be an application that didn\u0026rsquo;t even exist or you didn\u0026rsquo;t know about when you were first setting up the message queue. So even at that point, because service bus allows you to decouple the routing of the message, it\u0026rsquo;s possible to go ahead and hook up other applications to listen to the queue. ‑Right, so you\u0026rsquo;ll see in our scenario that we have our scheduling application raising an event that an appointment was created. And it might be that maybe in the future we would want to add some other application that wants to react to that event. ‑We could publish it to social media, hey, I\u0026rsquo;m going to go see the vet. ‑Exactly. If we had a service bus, we could simply wire up in our service bus for this new social media notifier service, pick up that event. But with just message queues, as you\u0026rsquo;ll see in our implementation, we would have to change our scheduler application to know about this new app and write to its queue because we don\u0026rsquo;t have any advanced routing, everything\u0026rsquo;s hardcoded in our simple scenario. The message queue we are using is RabbitMQ. It\u0026rsquo;s a mature, open‑source message broker that you can get set up and running with zero install by using a prebuilt Docker container. It has a lot of capabilities, but we\u0026rsquo;re keeping it simple and just using it to define a few specific queues, which are separate bounded contexts we\u0026rsquo;ll use to publish and consume events.\nSending a Message to the Queue Now let\u0026rsquo;s take a look at how we\u0026rsquo;re adding message queues into our solution. The first part of the process happens when the appointment is scheduled. And you\u0026rsquo;ve already seen our AddNewAppointment method inside the schedule aggregate root. And you saw how the domain uses domain events and domain services to notify the user interface if there\u0026rsquo;s a conflict in the schedule. In the previous module, we showed you MediatR, which we\u0026rsquo;re using to publish these domain events. And we also talked about integration events, which are structured to be shared between different applications. So what we\u0026rsquo;re going to do in our system is add RabbitMQ into the mix at the same point where MediatR is publishing the domain events. But we\u0026rsquo;ll ask RabbitMQ to publish our integration events. These events will be formatted as JSON data before they\u0026rsquo;re inserted into the queue. So let\u0026rsquo;s see what this looks like in the application. We\u0026rsquo;ll be looking at the code that makes all of this work a little further on in this module. We\u0026rsquo;ll go ahead and create a new appointment. Let\u0026rsquo;s bring Sampson in to see Dr. Jones again. So there\u0026rsquo;s the appointment. Nothing has changed from the perspective of the user. RabbitMQ includes a user interface to inspect the queues, and in the Front Desk app the menu has a link so that you can open up this admin page and see what\u0026rsquo;s going on with the queues that are associated with this application. We\u0026rsquo;ll head to the Queues page and then drill into the vetclinicpublic queue, which is a queue that we set up to handle communication between the Front Desk app and the VetClinicPublic app. And you can see that the one and only message that RabbitMQ is tracking is in that queue. So we\u0026rsquo;ll drill into that queue and then scroll down to see the details of the message itself. And the most interesting part, the payload, which is the JSON expression of the event data. You can see the GUID value of the AppointmentId, the ClientName is Julie Lerman, an email address, which is not really my email address, the PatientName is Sampson, and other relevant details that came from the integration event. So the Front Desk app knew to publish the message to this queue, and our VetClinicPublic app knows to read from this very specific queue in order to perform the task of emailing the client.\nReading From the Message Queue and Acting on the Message Now that the message is waiting in the message queue, it\u0026rsquo;s time to read the message and act on it. And acting on it is the next step in a workflow, sending an email to the client to let them know about the appointment they\u0026rsquo;ve just scheduled. We can\u0026rsquo;t do this easily from our scheduler application because we need for the user to be able to click on a link that specifies that they want to confirm their appointment, so it needs to be publicly accessible. So we\u0026rsquo;ve decided to put this on the veterinary clinic\u0026rsquo;s public website, and so that will be responsible both for sending the emails and for hosting the link that the customer will click. The public site uses a hosted service to periodically check for new things in its queue. Once it finds a message on the queue, it will retrieve the information from that message to create a confirmation email using code like what you see here. One of the most important pieces of this email is a link back to the public website, not really localhost, which includes the GUID that represents the appointment ID. The website then sends the email. That\u0026rsquo;s what the user will end up clicking on in their email and trigger a confirmation using the website. Alright, so now we\u0026rsquo;re looking at the vet clinic public website, which is a super simple demo solution that we put together. And one of the things it does when it starts is start checking for messages, which you can see here. But we don\u0026rsquo;t have it running quite yet because it would\u0026rsquo;ve already pulled the message out of the queue. First, we\u0026rsquo;ll show you the code that\u0026rsquo;s making this all work, and in a bit, we\u0026rsquo;ll step through while debugging. The public website has a hosted service called FrontDeskRabbitMqService, which periodically checks the message queue to see if anything new has arrived. As soon as it finds one of those messages off of the message queue, it\u0026rsquo;s going to send an email, and we\u0026rsquo;re going to use a tool called Papercut, which will emulate a local email server for the purpose of testing. Rather than installing this on our dev machines, we\u0026rsquo;re running a Docker container to host Papercut. You can view emails Papercut has received by clicking the Sent Emails link from the FrontDesk app\u0026rsquo;s menu. Currently, there aren\u0026rsquo;t any emails in Papercut, but as soon as we start the web application, it\u0026rsquo;s going to check our message queue and then send an email that we should see appear in Papercut. There\u0026rsquo;s a message, the same message that we sent out for Sampson\u0026rsquo;s appointment. There\u0026rsquo;s a hyperlink that leads us back to being able to confirm. Let\u0026rsquo;s see first, high level, what happens when we click on that CONFIRM button, and then we\u0026rsquo;ll come back and click it and watch it in action. So now the user has the email, and their beautiful CONFIRM link in the email. When they click that, it opens up the website, browsing directly to the GUID that was their appointment. And in response, the website calls its own method called confirm, which takes the relevant appointment ID and pushes it into another one of the queues. You\u0026rsquo;ve seen the message queue that was used for relaying the message from FrontDesk to the public website, and that was named fdvcp‑vetclinicpublic‑in. Try to say that five times fast. But you can have as many queues defined in your system as you need. And one of the other queues that we\u0026rsquo;ve defined is for relaying messages from the public website, in other words, when the client has clicked on the button to confirm their appointment back to the FrontDesk app.\nUsing Multiple Queues to Handle Various Communications Now that the email\u0026rsquo;s been sent, let\u0026rsquo;s see what happens when the client clicks on the CONFIRM link in that email. ‑When we click on that, we\u0026rsquo;ve now confirmed the appointment. Once the user clicks on the CONFIRM link, it drops the message with the confirmation back into the scheduler queue, and you can see that message right here. ‑Yeah, this middle queue shows that there\u0026rsquo;s one message. Let\u0026rsquo;s look at it. We\u0026rsquo;ll scroll down to the Get Message(s) button, and the message is retrieved and displayed. We\u0026rsquo;ve seen this before where the payload is the JSON data we\u0026rsquo;re looking for, and this one contains the appointment ID that\u0026rsquo;s just been confirmed. Now you can see that the two different applications are communicating back and forth with each other using their two separate message queues. We\u0026rsquo;ve named the queues so that it\u0026rsquo;s clear which applications are using them to communicate and in which direction. The initial acronym specifies which two applications are involved. Fdvcp means frontdesk and vet clinic public. The latter part of the queue\u0026rsquo;s name says which app is listening to it. The last step now is for this confirmation information that\u0026rsquo;s sitting in the queue to get back to the scheduling app. ‑Now in our scheduler application, we have implemented a hosted service just like you saw in the public website This one is called the VetClinicPublicRabbitMQService, and it listens to the appropriate queue to see if there are incoming messages that it needs to deal with. When it finds one, it responds to the AppointmentConfirmLinkClickedIntegrationEvent, yes, it\u0026rsquo;s a long name, with the email confirmation handler. The handler looks up the appointment from the AppointmentId that was contained inside of the message, and from there, it calls Appointment.Confirm. Appointment, as you recall, is our entity, and its confirm method also then triggers some domain events, which for instance, our user interface listens to. And when it sees that that event has been fired, it triggers a change in the UI, enhancing the appointment with a green bar across the top to show that the appointment has been confirmed. Okay, so all that\u0026rsquo;s going to happen at this point is that when the message comes through, it\u0026rsquo;s going to make the Sampson appointment right here have a green border and pop up a dialog to let us know that a change has occurred. ‑It\u0026rsquo;s very slick. This is actually really easy to implement because we already had the website listening for events. Remember how it was able to display new appointments and display conflicts? We\u0026rsquo;ve implemented another design role based on a particular property of the appointment, which is confirm. All we did was set up another event handler. ‑We wrote the original sample for the first version of this course in 2013. At the time, things like SignalR and WebSocket, as well as emails with confirmation links were relatively rare, although we certainly didn\u0026rsquo;t invent these kinds of app interactions. ‑Right, but now, every time I make an appointment for my dentist or hair and even for Sampson in real life to go to the vet, I\u0026rsquo;m getting texts or emails with exactly these kinds of confirmation links. ‑I know, I guess maybe a lot of businesses watched our course.\nDebugging to See the Detailed Implementation in Code Now we\u0026rsquo;re going to take a deep dive into the code that makes all this work, and we\u0026rsquo;ll go through it step by step so that you can see how all this is wired together. And we\u0026rsquo;ll do that by literally just debugging through the whole process, so you can see how all the code links up. Remember, all of the code for this sample is available on GitHub, and we encourage you to run it yourself to really understand how it works. The README file has instructions for running the solution using Docker, which is the recommended approach if you just want to see it running. There are also instructions for using Visual Studio or VS Code, which you will need if you want to debug the apps as we\u0026rsquo;re about to do. For instance, I need to run RabbitMQ and PaperCut using the Docker commands shown here, before I can debug the app, as we\u0026rsquo;re about to see. We\u0026rsquo;re back in the vet manager, and the user is on the phone with Steve who wants to make an appointment with Darwin. Everything works just the same way it\u0026rsquo;s worked before. We\u0026rsquo;ll go ahead and add a new appointment and save the appointment, which triggers the ScheduleAggregate root\u0026rsquo;s AddNewAppointment method. We\u0026rsquo;ll leave the Locals window open while we\u0026rsquo;re debugging so that if you want to pause the video and take a look at any of those values, you can do that. We haven\u0026rsquo;t changed anything in the method. The only thing that\u0026rsquo;s different is that now we\u0026rsquo;ve got an additional subscriber that\u0026rsquo;s listening for this domain event, this particular domain event, the AppointmentScheduled event, to be raised. So we\u0026rsquo;ll go ahead and raise the event and watch what happens. At this point, we\u0026rsquo;re looking at a new class that we created, which is this RelayAppointmentScheduled service, and what it\u0026rsquo;s responsible for is creating the event that is going to get pushed onto the message queue that the public website is listening to. This is the new piece of logic that\u0026rsquo;s listening for the event that we just raised. You can see it\u0026rsquo;s listening for AppointmentScheduledEvent, a domain event, and in the method, the first thing we do is to create the AppointmentScheduledIntegrationEvent that represents our cross‑domain message that will be sent using RabbitMQ. The functionality we need from this event right now is to be able to send an email to the client, so we make sure to include all of the data that such an email would require. Now we\u0026rsquo;re in the Publish method that lives inside of RabbitMessagePublisher, and that\u0026rsquo;s inside of an infrastructure project. We\u0026rsquo;ve moved out of the core domain, but this is still part of the main front desk scheduling application. Yes, and what it\u0026rsquo;s responsible for doing is actually getting that message into a structure, a format that RabbitMQ can use. That means putting things into JSON format in this case, and then actually sending the message. Once this fires, we should be able to inspect the message queue in RabbitMQ, and verify that our message has actually been queued up for the VetClinicPublic input queue as expected. That\u0026rsquo;s what we did before, but this time we\u0026rsquo;re actually seeing the code that\u0026rsquo;s making all of this happen. Alright, so that completes the actual thread of the UI. The response is complete for this part of the application. Now we\u0026rsquo;ll pause this and switch over to the VetClinicPublic application. We\u0026rsquo;ve just started it up again, and we\u0026rsquo;ve shown this to you before. Now we\u0026rsquo;re going to watch the flow of the code after the hosted service starts up. Jumping to the next breakpoint, you can see now we\u0026rsquo;re inside of the actual HandleMessage method, which gets the message as a string. It\u0026rsquo;s responsible for parsing the string using JSON, and deserializing it into an appropriate type. This is just demo code, so it\u0026rsquo;s not the most reusable or elegant, but it works for this app. Remember that any change to the integration event in the front desk app will require changes here as well, which is one reason why a shared package can be useful for keeping applications in sync. Once we\u0026rsquo;ve deserialized the message into a command, we use mediator to send the command, and a separate handler to actually send the email. This keeps extra code out of the hosted service, and lets the handler use dependency injection to get any services it needs. In this case, it\u0026rsquo;s an implementation of, I send confirmation emails, called ConfirmationEmailSender. It\u0026rsquo;s the service that builds the email with its details, including the URL behind the CONFIRM link in the email that the client receives. Remember, the whole reason why we need a separate app to implement this feature is that the end user needs to be able to click a link that goes to a public location on the internet. The front desk app is an internal app that runs inside the vet clinic\u0026rsquo;s network so it\u0026rsquo;s not accessible. The public website is a good place to send users, and while they\u0026rsquo;re there, they can get more details about the clinic, or buy something from its theoretical online store, etc. After the email has been sent, we can see it in PaperCut, and opening it, we can see the CONFIRM hyperlink. Clicking the link brings us back into the VetClinicPublic application\u0026rsquo;s, AppointmentController class. This endpoint simply creates a new event. This is the one with a really long name, AppointmentConfirmLinkClickedIntegrationEvent. Unlike the name of the event, the message itself is really simple, and just includes the appointment ID that was confirmed, and when it happened. The controller action then sends the event using a RabbitMQ messagePublisher that\u0026rsquo;s identical to the one we just saw the front desk app use. However, this publisher\u0026rsquo;s destination is actually a different queue, the front desk input queue. Technically, the front desk has two input queues, one for messages from the ClinicManagement app, and another for messages from the VetClinicPublic app. In this case, we\u0026rsquo;re talking about the VetClinicPublic one. Back in the front desk scheduling app\u0026rsquo;s hosted service, it discovers the message on the queue, and calls into the HandleMessage method in the service we\u0026rsquo;ve seen a number of times, the VetClinicPublicRabbitMqService. Here, it parses the message and extracts the appointment ID, which it then uses to create and publish that really long‑named event again, AppointmentConfirmLinkClickedIntegrationEvent internally. This integration event triggers a call to the EmailConfirmationHandler, which loads the schedule aggregate, then locates the appropriate appointment, and calls its Confirm method. Finally, it saves the schedule. The appointment.confirm method makes an appointmentConfirmed domain event, which is fired once the aggregate is saved, and this event in turn triggers a handler in the UI. The appointmentConfirmed handler in the FrontDesk UI sends a message via SignalR, indicating the message was confirmed. This results in the browser showing a notification, and changing the format of the appointment to have a green border. You already saw similar logic used for the AppointmentUpdate and AppointmentScheduled handlers. That\u0026rsquo;s the full round trip for how creating an appointment, getting an email, clicking a link, and confirming that appointment works for this application.\nConsidering Microservices Since we published our original version of this course, which if you haven\u0026rsquo;t watched, you\u0026rsquo;ll find a link from either of our author pages, microservices have become incredibly popular. There are some benefits to microservices, even if they\u0026rsquo;re probably a bit overhyped at the moment, and there are some obvious parallels between microservice design and DDD. ‑Microservices should be self‑contained and should not depend on other microservices. They should be independently deployable. Changing the internal behavior of a microservice should not break services that work with it, as long as it maintains compatibility with its external APIs and message interfaces. ‑So, basically what you\u0026rsquo;re saying is each microservice should have a boundary around it, and within that boundary it should focus on a specific set of behaviors that its free to model however it sees fit. ‑That\u0026rsquo;s right. ‑It\u0026rsquo;s almost like each microservice can be considered its own context, and it has its own terminology and even language for how it\u0026rsquo;s designed. ‑It is a lot like that, it\u0026rsquo;s true, and it\u0026rsquo;s not unusual for teams to treat individual microservices like bounded context with their own ubiquitous language and everything else that goes along with being a bounded context. But, beware of assuming that microservices and bounded context always have a perfect alignment. There can be plenty of scenarios where this could be a problem. My brilliant friend, Vladik Khononov, not to be confused with the also brilliant Pluralsight author, Vladimir Khorikov, has shared his experiences along these lines in his blog and also in recorded conference presentations. We\u0026rsquo;ll include links to his content in the resources at the end of this module. ‑Now, this isn\u0026rsquo;t a microservices course, but obviously if you\u0026rsquo;re working on microservices, it would be helpful for you to have a good understanding of DDD concepts, because many of the problems that microservices solve are also solved by domain‑driven design. ‑In our sample application, there is an obvious candidate for a microservice. In fact, it\u0026rsquo;s almost there already, the confirmation email sending logic that currently runs inside the public website. ‑We put the hosted service in that existing web application because it was convenient and because the two are loosely related since the emails include a clickable link that goes to a page on that public website. ‑But we could easily move that hosted service into its own process and treat it like a separate microservice, and that would simplify the public web app, so it would no longer need to have a two‑way relationship with a front desk app by way of message queues. Also, the front desk app is likely to be updated more frequently than the confirmation email logic, so it\u0026rsquo;s possible that changes to the front desk application could break the email logic. ‑Yes, one of my favorite benefits of carving out a microservice is that if it\u0026rsquo;s something stable and working, you get the benefit of just leaving it the heck alone. Updates to other parts of the app or system are much less likely to break a microservice that is in production and working, and not being deployed frequently. ‑Right, and the email sending logic is about as micro as a microservice can get, but in the future we might want to add other kinds of customer emails to send, and it would be a logical place to hold that logic. ‑Exactly, and since it has no user‑facing logic, it\u0026rsquo;s a pretty simple change to make. Maybe some of our students could do that as another exercise.\nSharing Some Tips for Extending and Running the Sample Application As we wrap up the course, we want to remind you, once more, that there are a number of to‑do items in the sample that you can use as ideas for ways to extend this demo app. Doing so would help you gain real experience working with the architecture and patterns you\u0026rsquo;ve learned in this course. You\u0026rsquo;re sure to learn and retain more from actually working with the code than from just listening to us or watching us show you the code. ‑We do have detailed instructions in the README for how to run the app. You can run the individual solutions in Visual Studio, but if you do so, keep in mind, you\u0026rsquo;ll also need to make sure you have a local SQL Server running, and you\u0026rsquo;ll need to update the connection strings and app settings for the applications to access it. You\u0026rsquo;ll also need your own RabbitMQ and Papercut or similar test email server running, either as Docker containers or locally‑installed services. There\u0026rsquo;s definitely a bit of effort involved in getting all of this set up and running the first time. ‑Alternatively, if you just want to run the app and see everything working, you should be able to do so with just two commands, assuming you have Docker installed. Just run docker‑compose build ‑‑parallel and then docker‑compose up. Each of these commands might take a few minutes. It usually takes about 2 minutes for the build step on my machine, and it\u0026rsquo;s normal to see some errors when the docker‑compose up command runs until all of the services are up and running. Once the process stops outputting messages to the log window, you should be able to hit the application. To do that, take a look at the ports that are shown in the README file. And in the Docker column, you\u0026rsquo;ll see the ports for all of the different applications and utilities that are used.\nConsidering the UI in the Domain Design The control we used solved a number of the problems we thought we were going to have when embarking on this application. But the fact that the UI kind of impacted how we designed our domain begs the question about, well, if you\u0026rsquo;re totally focused on the domain, why would you even be thinking about the UI? But thinking about the UI while we\u0026rsquo;re working on the domain is not the anti‑pattern you may think it is. ‑Yes, we\u0026rsquo;ve been focusing on the domain, but frequently the user interface needs to be considered, especially in the early stages of planning. You don\u0026rsquo;t want to try to flesh out the whole domain design before you start thinking about the UI. ‑In a TechEd session I attended in 2013, Jimmy Nilsson, who\u0026rsquo;s the author of the book Applying Domain‑Driven Design and Patterns, talked about the importance of thinking about the UI in the early stages of planning and revisiting it while modeling the domain, rather than ignoring it until the end. In his session, he describes how even the UI sketching he does in the early stages of his application planning can affect the whole design of the system. As we were building this scheduler sample for this course, we actually discovered a huge benefit to considering the UI early in the process. We initially had expected to encounter a lot of complexity in the appointment scheduling problem, but we found a UI control that helped visualize the schedule for the user, such that the system no longer needed to be as complex. In our scenario, scheduling is a big part of the application, but it isn\u0026rsquo;t our domain, our domain is the veterinary clinic. We consider scheduling to be more of a cross‑cutting concern, and one that could be partially solved through a rich user interface. ‑By considering and using a rich user interface, we were able to do things like allowing conflicting appointments while making it obvious to the user that this had occurred. This gives the user more information, and they can make decisions about whether or not they need to correct the problem. When we initially considered the problem of appointment conflicts, we had thought the domain model would throw exceptions anytime something like that occurred. But this would have resulted in a much worse user experience. Frequently, in domain‑driven design, you need to consider the user experience, which at times may need to allow for models that are, at least temporarily, in an invalid or incomplete state. Keep this in mind as you design your domain model, and be careful not to make it too rigid to support scenarios your users may benefit from. ‑Thinking about the UI up front and discovering this kind of solution kept us from wasting a lot of time trying to solve certain scheduling problems in our domain. Of course, you don\u0026rsquo;t want your UI to totally drive how you model your domain, but as Jimmy Nilsson notes, you shouldn\u0026rsquo;t ignore it, either.\nModeling with Event Storming and Other Techniques When you\u0026rsquo;re developing apps using DDD, it can be helpful to visualize how processes communicate both within a bounded context and between context as part of a business process. As we mentioned earlier in this course, Alberto Brandolini has done a lot of work on a related practice called event storming. Event storming can be used by all parts of a business, not just developers, to describe how a part of the business works and to make the whole thing visible. Once this is done, later iterations of the diagrams and artifacts produced can be useful for modeling the software that will be used by the business. ‑You might recall the image we showed earlier of Julie facilitating an event storming workshop with a client. The result of that first iteration, called chaotic discovery, is not so easily captured, but it provides guidance for the later modeling you might do. ‑There are many ways to model your system. Another method, Event Modeling, championed by Adam Dymitruk, is another process, and this focuses on the inputs and outputs of events and how each of those events changes the system and changes state. And you can describe an entire system with this flow. ‑We\u0026rsquo;ve used the wonderful online tool called a Miro board at miro.com to show one perspective of the scheduling system as information flows through the front desk application and into the VetClinicPublic website bounded context. The colors used here correspond to different things in our model, like aggregates, events, and other processes. ‑And there are other modeling processes that have been invented, adopted, and adapted within the DDD community. And many of us rely on a combination of processes and tools to help us and help our clients better understand their systems before embarking on design. But as always, balance is important. You\u0026rsquo;ll want to beware of analysis paralysis. ‑Definitely. That reminds me of something Eric Evans talked to us about.\nEric Evans on the Fallacy of Perfectionism Steve and I believe that it would be fitting to leave you with one last thought from the father of domain‑driven design, Eric Evans. Eric was kind enough to talk to us about DDD when we originally created this course so that we could share with you some of his wisdom. Eric talked about the fallacy of perfectionism, which aligns with our own sentiments about considering what you\u0026rsquo;ve learned here to be guidance to help you solve complex software problems, not a roadblock to productivity. ‑Eric shared with us that what he\u0026rsquo;s noticed is that there seems to be something about DDD that brings out the perfectionist in people, and they say, this model is not really good enough and churn and churn, trying to improve it. He says, no model is ever going to be perfect. ‑Eric goes on to say that we need to know what we\u0026rsquo;re doing with this thing, the scenarios we\u0026rsquo;re trying to address. We want a model that helps us do that, that makes it easier to make software that solves those problems. That\u0026rsquo;s it. ‑This reminds me of the saying, all models are wrong, but some are useful. Our domain models don\u0026rsquo;t need to be perfect. They just need to help us build the software that helps people solve problems and get work done. Don\u0026rsquo;t strive for a perfect model, but rather just aim to develop a useful one.\nLessons Learned Since Our 2014 Course Julie and I wanted to finish this course by spending a couple of minutes talking about some of the things we\u0026rsquo;ve learned since we published the first edition of the course in 2014. ‑We\u0026rsquo;ve received a ton of positive feedback from so many of you over the last few years, and we really appreciate it. So we did our best not to change the overall flow of this course too much since we know the last one was so well‑received. ‑Definitely. If you watched the original version, hopefully you found this one to be fresh, but familiar, and I suspect a lot of students will end up watching both as a way to cement some of these concepts or just to spend more time with us, right, Julie? ‑Maybe. Now let\u0026rsquo;s highlight some of the things that have changed in the last few years. From a strict DDD perspective, there are a lot of new resources and techniques that have emerged as more and more companies are adopting DDD. Things like event storming an event modeling, which we\u0026rsquo;ve touched on in this course, are starting to become mainstream parts of DDD for many organizations. ‑Yes, and the industry\u0026rsquo;s use of some patterns have shifted too. There\u0026rsquo;s a lot of pushback against the repository pattern these days. I think, in part, because it became very popular, but was often used without the context of DDD or other complementary patterns like the specification, and these can really help it shine. Our first course didn\u0026rsquo;t really talk much about specification as a core DDD pattern, but it\u0026rsquo;s something I use on most of my projects now. ‑From a technology perspective, our previous course was built for .NET developers, and at the same time, that meant .NET 4. The original veterinary application used ASP .NET, MVC, and Web API, and an early version of SignalR. And for data access, we used Entity Framework 6. ‑Since then, .NET Core, which is now .NET 5, has shipped and become the new standard for .NET developers, and the latest versions of EF Core have added a number of features that we\u0026rsquo;re leveraging to help improve the design of our model like owned objects and filtered includes. We also shifted our use of domain events from being prepersistence to postpersistence. There are valid use cases for both kinds of domain events, but the latter is safer for any events that communicate outside of the domain, so we\u0026rsquo;re defaulting to that this time around. ‑Right, especially since one of our key demos involve sending emails to the client. The original sample also used SQL Server for its message broker, which we chose because we didn\u0026rsquo;t want to force our students to have to install a custom tool. But Docker is another technology that wasn\u0026rsquo;t mainstream in 2014, but it is today, and it makes it a breeze to use custom bits of infrastructure. In this update to the course, we\u0026rsquo;re definitely leveraging Docker to provide RabbitMQ messaging with 0 install, as well as to capture emails during development using Papercut in another Docker container. ‑Yeah, Docker should really make it trivial for students to run the application locally, even though it has a bunch of moving parts. If you don\u0026rsquo;t have Docker, you can still run it in your IDE or from the command line, but with Docker, it\u0026rsquo;s just a lot simpler to get going. ‑And along with Docker and containers, microservices have become a huge buzzword in the industry. Of course, Docker makes it much easier to deploy microservices, and DDD principles really shine when designing them. So all of these things, I think, are really complimentary. ‑Definitely, although I do think some companies are too quick to jump to microservices without fully understanding their domain and where to separate out different contexts. And on the topic of separation, our previous sample put everything in one giant solution, too, mostly to make it easier to find things. ‑This time, we went with something that should resemble a real‑world application even more with separate solutions for each bounded context. We even published the shared kernel as a NuGet package, in our case, hosted on nuget.org, although typically, your organization would probably have a private NuGet feed. ‑If you\u0026rsquo;re still working with .NET Framework apps and you haven\u0026rsquo;t watched the previous course, we encourage you to give it a look. Its samples are geared more toward that framework, and you should find a link to it on Julie or my author page here, on Pluralsight, or at this bit.ly link here. ‑And don\u0026rsquo;t feel bad if it feels like there\u0026rsquo;s still a lot you have to learn about DDD. It\u0026rsquo;s a big topic. And as we\u0026rsquo;ve just shared, Steve and I are constantly learning new ways to apply it, too. Be sure to check out other DDD courses here, on Pluralsight, and if you need direct help for you or your team, you can reach out to Steve or me, directly.\nReview and Resources If you remember nothing else from this particular module, the one thing to keep in mind is how simple it was for us to add in what was potentially a really complicated feature. Because of our DDD implementation and some of the infrastructure we had already built, it wasn\u0026rsquo;t really very challenging to plug these new puzzle pieces into the application. ‑Right, we introduced a couple of new concepts. We talked about message queues, and those fit really nicely into our existing architecture because we were already using events to correspond to interesting things happening within our application. ‑And the message queue allowed us to stick a message in an external place by one application, and another application can come along and retrieve that message. So the message queue allows our applications to communicate with each other, but they can do it in a disconnected way. ‑And then we mentioned, but we didn\u0026rsquo;t show, this concept of a service bus, often called an enterprise service bus, which you may want to introduce if you start having more than just a couple applications needing to talk to one another. ‑At the risk of being redundant, let\u0026rsquo;s just pay homage one more time to how the decisions we made earlier on, when implementing the vet clinic solution, allowed us to add in a potentially complicated new feature, email notifications and responses into the application. ‑While we had used mediator to transfer domain events within the FrontDesk application, this time we took advantage of message queues to help us move events back and forth between applications. ‑Using RabbitMQ\u0026rsquo;s API, we created three different queues that were specific to the cross‑application communications we needed. For example, a queue that the vet clinic public app could publish messages into for the FrontDesk application to retrieve so it could update the UI. ‑It\u0026rsquo;s also important to note that we leveraged existing tools like RabbitMQ and Papercut to perform certain tasks. In DDD, we would refer to these as generic domains. You\u0026rsquo;ve got to look under the covers to see how the code was making all the communication between the apps and the message keys possible, but without our domain model having to know about any of the details. ‑And then we shared some additional knowledge as we wrapped up the course. We talked about modeling practices like event storming and tools like MURAL. We talked about all of the new ideas that have evolved since we first published this course in 2014 and how they impacted this new version of the course and the sample application. ‑And we ended with some more wisdom from Eric Evans, to whom we are eternally grateful not only for bringing DDD to the software community, but also for spending time with us when we created the original course so that we could share his perspective and insights with you. ‑Like the end of a fireworks display when they shoot up many, many fireworks at once, we\u0026rsquo;re sharing here a lot of resources and links because of the great many topics we brought into this last module. There are two pages of links here to articles and videos and other Pluralsight courses, so you might want to pause the video to be sure that you see them all. ‑So, from me, Steve Smith, ‑and from me, Julie Lerman, thanks so much for taking this journey with us through Domain‑Driven Design Fundamentals.Course Overview Welcome to Pluralsight. My name is Julie Lerman, and this is Steve Smith. Together, we\u0026rsquo;d like to welcome you to our course, Domain‑Driven Design Fundamentals. Steve is a trainer and architect with NimblePros and spends a lot of time helping teams write better code, faster. And Julie is well known in the DDD community for helping reluctant teams embrace domain‑driven design. In this course, we give you a strong foundation for learning how to build applications and microservices using domain‑driven design. DDD has proven to be a very effective approach for managing complex requirements. The original version of this course has helped many thousands of learners leverage domain‑driven design, and they have shared amazing feedback. Now, we\u0026rsquo;ve updated the course and its sample application to reflect ideas and tools that have emerged since that first version. Some of the major topics that we\u0026rsquo;ll cover include what are the essential ideas of domain‑driven design? What are the main patterns used in domain models? We\u0026rsquo;ll also talk about how to break up concepts into smaller parts and how these smaller aggregates and contexts communicate with one another. By the end of this course, you\u0026rsquo;ll know how to break down customer requirements into a maintainable domain model and structure a solution using domain‑driven design. Before beginning the course, you should at least be familiar with software development, ideally using C#. From here, you should feel comfortable diving into DDD and design patterns with courses on the DDD learning path and the design patterns learning path. We hope you\u0026rsquo;ll join us on this journey to learn domain‑driven design with the Domain‑Driven Design Fundamentals course, at Pluralsight.\nIntroducing Domain-Driven Design Introduction and Overview Hi, this is Steve Smith ‑and this is Julie Lerman. Welcome to our course, Domain‑Driven Design Fundamentals. ‑We\u0026rsquo;re looking forward to sharing our experience with DDD and how it\u0026rsquo;s helped us and our clients. You\u0026rsquo;re welcome to reach out to us online. ‑You can find me online at thedatafarm.com or on Twitter @julielerman. ‑And I\u0026rsquo;m online at ardalis.com or on Twitter as @ardalis. ‑Eric Evans coined the term Domain‑Driven Design in his groundbreaking book with the same title published in 2004. Since then, other titles have followed, including great books expanding on the subject by Jimmy Nilsson and Vaughn Vernon and so many who are now also great experts at DDD. And there are also now a number of fantastic DDD conferences and even a well‑established virtual meetup. ‑There\u0026rsquo;s definitely continued and renewed interest in Domain‑Driven Design as both the demand for and complexity of software continues to grow. Domain‑Driven Design is commonly referred to as DDD and even has its own Twitter hashtag, dddesign. Although DDD has been around for so long, it continues to be a great approach to building software that we both enjoy employing and sharing with others. And as more minds have gotten involved in DDD, it continues to evolve.\nWhat to Expect from This Course and This Module Domain‑Driven Design is a huge topic. Our focus will be on the developer perspective and the technical and coding aspects of DDD more so than architectural concerns. We\u0026rsquo;ll start by talking about why we think you should even be watching this course. Next, we\u0026rsquo;ll jump right into an existing solution so you can get a concept of what the code and the architecture of an application written using DDD practices looks like. Then we\u0026rsquo;ll start digging into the big DDD concepts like modeling problems of the domain, what the various technical components of DDD are, and how you can use DDD to manage complex projects. Throughout the course, we\u0026rsquo;ll use the existing solution so you can see how some of this process works. ‑With this in hand, we\u0026rsquo;ll walk through extending the sample based on a new request from the client. Since this is a fundamentals course, we certainly don\u0026rsquo;t expect to turn you into an expert by the end of it; however, you should be well on your way to understanding the value behind Domain‑Driven Design and how some of the practices can be employed to improve your success with complex software projects. Right now, if you\u0026rsquo;re new to DDD, you don\u0026rsquo;t even know what you don\u0026rsquo;t know yet. However, once you\u0026rsquo;re done with this course, you\u0026rsquo;ll know more about DDD, but of course, you\u0026rsquo;ll also realize how much more there is to learn. That\u0026rsquo;s one of the great things about our industry. The more you know, the more you realize how much more there is you don\u0026rsquo;t know. ‑In this module, we\u0026rsquo;ll focus on the value of Domain‑Driven Design. You\u0026rsquo;ll learn what the term represents and what problems DDD can help you with in your software building process. ‑Not only will we share the benefits of DDD, but we will be sure to highlight some of the potential drawbacks. Finally, you\u0026rsquo;ll get a look at a small application that we\u0026rsquo;ll be using throughout the course as you learn DDD.\nUnderstanding the Value of Domain-Driven Design Domain‑Driven Design focuses on the problems of the business domain that you\u0026rsquo;re attempting to solve. Its a critical shift from decades of focusing on how to store your data and then letting that drive how the software is designed. But that workflow added a lot of unnecessary complexity to the task of building software. So why should you watch this course? Why should you care about learning Domain‑Driven Design. Steve and I have both been designing and developing software for a very long time. Without giving away our ages, we\u0026rsquo;ve got over 40 years of experience between the two of us, and we\u0026rsquo;ve both been very inspired by Domain‑Driven Design. In many ways, it aligns very naturally with ideas that we\u0026rsquo;ve each come to from our own experience. It also takes these ideas and lays them out in a way that\u0026rsquo;s not only illuminating, but it\u0026rsquo;s repeatable. When Eric Evans wrote his book, his goal was to understand what was behind the successes he had achieved with large‑scale, complex software projects and what were the patterns. That\u0026rsquo;s what he laid out in the book. ‑This is why we care about DDD, and we hope that you can gain from our experience, which is why we put together this course. DDD provides principles and patterns to help us tackle difficult software problems and even business problems. These are patterns that are being used successfully to solve very complex problems. The more we\u0026rsquo;ve learned about DDD, the more we found these ideas aligned with the approaches we\u0026rsquo;ve learned from our many combined years of experience. DDD provides us with a clean representation of the problem in code that we can readily understand and verify through tests. We developers live to code. When starting on a new project, we\u0026rsquo;re eager to jump in and start coding so that we can build some software. But you can\u0026rsquo;t build software unless you truly understand the client\u0026rsquo;s needs. DDD places as much emphasis on not only comprehending what your client wants, but working with them as full partners through a project. The ultimate goal isn\u0026rsquo;t to write code, not even to build software, but to solve problems. ‑You need to realize that nobody really wants your program. They want what it can give them. There\u0026rsquo;s a famous saying in sales. Buy a quarter‑inch drill, they want to buy quarter‑inch holes. Your client\u0026rsquo;s not interested in building software, but in being successful at their mission. Software provides a more efficient means to this end.\nGaining a High-Level Understanding of DDD Domain‑driven design is for solving complex problems. Evans put a lot of thought into the subtitle of his DDD book and came up with Tackling Complexity in the Heart of Software. But DDD itself is a complex topic. To start with, we think it\u0026rsquo;s helpful to look at it from a very high level. We call it the 10,000 foot view here in the US, but that\u0026rsquo;s probably 3,048 meters to the rest of you. ‑One of the critical pieces of DDD is to encourage better interaction with domain experts. These are the people who live and breed the business or process or whatever you are targeting with the software you\u0026rsquo;re planning to write. You may be thinking, but we already talked to them. Perhaps, but probably you\u0026rsquo;re using your terms, not theirs, and maybe talking in the language of tables in a database rather than domain concepts. Or you may presume that after some standard requirements gathering, you can infer enough about the problem at hand to design the solution on your own. After our own history in the business of developing software, we know that that rarely ends well. DDD guides us to engage with the domain experts at much greater length and through much more of the process than many software teams are used to doing. ‑When talking with Eric Evans about this, he told us that you really need to cultivate your ability to communicate with business people in order to free up their creative modeling. Another core theme in DDD is to focus on a single subdomain at a time. Say you\u0026rsquo;re asked to build software for a spaceship manufacturer. They describe their business tasks such as purchasing materials, engineering, managing employees, advertising their spaceships and share with you their dreams about mass producing spaceships when the market\u0026rsquo;s ready. Each one of these tasks are in themselves a complex subdomain filled with their own specific tasks, terminology, and challenges, and those subdomains may have only minimal interaction between them. Many applications just try to do too many things at once, then adding additional behavior gets more and more difficult and expensive. With DDD, you\u0026rsquo;ll divide and conquer. By separating the problem into separate subdomains, each problem can be tackled independently, making the problem much easier to solve. This lets us focus on the problem of employee management separately from the problem of sourcing materials for producing the spaceships. The term modeling is important in DDD and refers to how you decipher and design each subdomain. You\u0026rsquo;ll learn much more about this as you progress through the course. ‑The final theme in our high‑level perspective of DDD is writing the code to implement each subdomain. The principle of separation of concerns not only plays a critical role in identifying the subdomains, but within each subdomain, we use it as well. Many applications spread the domain logic between the persistence layer and the user interface, making it much more difficult to test and to keep all of the business logic consistent. DDD applies separation of concerns to help steer you clear of this problem by focusing on the domain and not on details like how to persist data into a database or how to connect to a service in the cloud. Those become implementation details that you can worry about separately. While implementing these subdomains, the focus is on the subdomain, the problems of the subdomain you are trying to solve with your software. You don\u0026rsquo;t get bogged down worrying about infrastructure concerns.\nExploring the Benefits and Potential Drawbacks of DDD Domain‑Driven Design is a big commitment. While Steve and I have both chosen to leverage pieces of DDD as we learn more about the wider scope, one thing we\u0026rsquo;re both confident about is that it\u0026rsquo;s providing a lot of benefits to our work. Because DDD guides us to focus on small, individual, nearly autonomous pieces of our domain, our process and the resulting software is more flexible. We can easily move or modify the small parts with little or no side effects. It even lets us be more flexible with our project resources as we\u0026rsquo;re building the software. ‑The resulting software also tends to be more closely mapped to the customer\u0026rsquo;s understanding of the problem. DDD gives you a clear and manageable path through a very complex problem. When you look at the code, you can see that it\u0026rsquo;s generally well organized and easily tested, and the business logic all lives in one place. Even if you don\u0026rsquo;t use full DDD for a project, there are many patterns and practices that you can use by themselves to benefit your application. So keep watching, even if you don\u0026rsquo;t think you\u0026rsquo;ll need all of it. ‑We often describe DDD as a way to take big, messy problems and transform them into small, contained, solvable problems. But DDD is not a path for every project. It\u0026rsquo;s real benefit is for complex domains. Even Eric Evans explicitly states that DDD isn\u0026rsquo;t suitable for problems when there\u0026rsquo;s substantial technical complexity, but little business domain complexity. Using DDD is most beneficial when the complexity of the domain makes it challenging for the domain experts to communicate their needs to the software developers. By investing your time and effort into modeling the domain and coming up with a set of terminology that\u0026rsquo;s understood for each subdomain, the process of understanding and solving the problem becomes much simpler and smoother. ‑But all this comes at a cost. You\u0026rsquo;ll spend a lot of time talking about the domain and the problems that need to be solved, and you\u0026rsquo;ll spend plenty of time sorting out what is truly domain logic and what is just infrastructure. The easy example there is data persistence, or for the sake of our spaceship manufacturer, maybe it\u0026rsquo;s how to communicate with an external service that helps to verify that potential buyers are properly vetted for space travel. ‑You\u0026rsquo;ll have a big learning curve as you learn new principles, patterns, and processes. There\u0026rsquo;s no question about that. DDD is a big topic and gaining expertise from end to end is a big commitment. This course doesn\u0026rsquo;t aim to make you an end‑to‑end expert in DDD, but to give you a big step forward that will allow you to not only comprehend the concepts, but you\u0026rsquo;ll gain a lot of new tools that you can use right away, whether or not you choose to dig further. And it\u0026rsquo;s worth restating that DDD is not always the correct path for your applications. And it\u0026rsquo;s helpful to keep in mind some of the scenarios where DDD is just going to be overkill. For example, if you have an application or a subdomain that\u0026rsquo;s just a data‑driven app and doesn\u0026rsquo;t need much more than a lot of CRUD logic, there\u0026rsquo;s really no need to use DDD. It would be a waste of time and effort. ‑And be clear about the difference between complexity in your business domain and technical complexity. DDD is designed to help with complex domains. If your domain is simple, even if you have a lot of technical challenges to overcome, DDD still may not be the right path. For example, if you are writing a tic‑tac‑toe game for a touch screen with a new complex API, the complexity lies in the touch interactions of the two players on the screen. The domain itself is well known and just comes down to Xs and Os. Getting others to follow the DDD approach can also be a drawback. There may be some politics involved in this decision. It really depends on your team and your organization. We hope that another takeaway from this course will be to help you understand the concrete benefits of DDD, which you can show to your coworkers to help convince them.\nInspecting a Mind Map of Domain-Driven Design In his DDD book, Evans included a really useful diagram of how many of the concepts and patterns of DDD are interrelated. Let\u0026rsquo;s take a look at that mind map. ‑Evans refers to this as a navigation map, and it lays out all of the pieces of Domain‑Driven Design and how they relate to one another. We want you to see it so that you have a concept of the big picture, even though in this course we\u0026rsquo;ll spend most of our time on a subset. We will be defining many of these terms later on in the course, so don\u0026rsquo;t panic. We\u0026rsquo;ve mentioned modeling the domain and subdomains a few times. Modeling is an intense examination of the problem space. Key to this is working together with the subject matter experts to identify the core domain and other subdomains that you\u0026rsquo;ll be tackling. Another important aspect of modeling is identifying what\u0026rsquo;s called bounded contexts. And within each of these bounded contexts, you focus on modeling a particular subdomain. As a result of modeling a bounded context, you\u0026rsquo;ll identify entities, value objects, aggregates, domain events, repositories, and more and how they interact with each other. ‑In the image, there\u0026rsquo;s more than just these subdomains, however. For example, there is a concept of an anti‑corruption layer, which allows subdomains to communicate with one another from behind their boundaries. The model also has notes for each element, such as free teams to go separate ways. This is something that can be accomplished once you\u0026rsquo;ve identified the boundaries of each subdomain. Or avoid overinvesting in generic subdomains. That could be something like a credit card verification service that you could choose to use rather than building yourself. As you begin focusing on specific subdomains, another very important DDD concept surfaces, driven by the need for clear, concise communication. It\u0026rsquo;s called the ubiquitous language. A simple definition of a ubiquitous language is to come up with terms that\u0026rsquo;ll be commonly used when discussing a particular subdomain. And they will most likely be terms that come from the problem space, not the software world, but they have to be agreed upon so that as discussions move forward, there is no confusion or misunderstanding created by the terminology used by various members of the team. ‑We invite you to pause this video to look over this map and read the notes associated with the various elements and contemplate what they might mean. We\u0026rsquo;ll revisit this throughout the course, and we hope that the map will make more and more sense as you work through the course.\nIntroducing Our Sample Application Now we want to switch over and show you a relatively small DDD‑based solution that we\u0026rsquo;ll be working on for the rest of the course. This app represents an appointment scheduling system for a veterinary clinic. It\u0026rsquo;s \u0026ldquo;small\u0026rdquo;, but since DDD requires a certain amount of complexity to warrant its use, it\u0026rsquo;s bigger than most demos you\u0026rsquo;ll see in other courses or presentations. For this course, we decided that we would use a veterinary clinic management system because it has a decent amount of complexity, and that means that we can apply some of the DDD principles, but it also gives us an excuse to show off pictures of our pets. ‑And our friends pets too. We\u0026rsquo;ve got a whole bunch of pet pictures from other Pluralsight authors in here, and they\u0026rsquo;re all so cute. ‑We\u0026rsquo;ve got Ben Franklin here from Michael Jenkins. We\u0026rsquo;ve got Patrick Neborg\u0026rsquo;s dog here, Sugar. Aren\u0026rsquo;t these guys cute? And, of course, Julie\u0026rsquo;s got Sampson. ‑Oh, my handsome boy. ‑And I\u0026rsquo;ve got Darwin, the silly poodle. He was just a puppy when we recorded the first version of this course, and he\u0026rsquo;s got a new friend, Rosie. Rosie is just a puppy. I guess every time I get a puppy we have to update this course. ‑So the idea behind this application is that if you\u0026rsquo;re working at the front desk of a vet clinic and someone walks in, maybe they want to schedule an appointment, or the phone rings with someone who wants to schedule an appointment for their pet, the first thing you\u0026rsquo;re going to do is look that client up, the person, in the system. ‑So the user starts by looking up the client, and from there, they can choose which of the clients, animals or patients, they\u0026rsquo;re going to schedule. So here\u0026rsquo;s Julie with Sampson. Here\u0026rsquo;s Kim with Roxy. Next, the user is just going to click on an open slot in the schedule, which opens up the create appointment window. ‑Oh, Roxy, you\u0026rsquo;re such a cutie. We can set up Roxy for a wellness exam with Dr. Smith. ‑Now notice before we save this appointment, it isn\u0026rsquo;t yet confirmed. We\u0026rsquo;ll get to that in a minute. So we save, and the appointment shows up. Now the complexity in this system comes into play when we have to do some checks for certain things. We want to make sure, for instance, that Roxy isn\u0026rsquo;t already scheduled in one of the other rooms at this exact time. We also want to send an email notification to Kim to let her know that Roxy has this appointment scheduled. We\u0026rsquo;ll add a link in the email the client can click to confirm. And in a real system, perhaps it would add it to their calendar of choice. The idea is to cut down on no‑show appointments for the clinic. ‑Of course, there are other features of this application. We\u0026rsquo;re focused on the schedule right now, but we do need to be able to manage client data and manage their pet data, the clinic\u0026rsquo;s patients, and things like that. Admins need to be able to manage doctors and rooms and appointment type since these all might change over time or from one clinic to another that uses the same software. But those are mostly CRUD tasks, which means we\u0026rsquo;re just talking about adding and removing records and maybe making some edits without a whole lot of complexity. We\u0026rsquo;ll talk about those tasks in a different compartment of the application than the schedule, which, of course, has a lot more complexity.\nExploring the Sample App\u0026rsquo;s High-level Structure So why don\u0026rsquo;t we take a look at the structure of our app? This is a distributed application built with ASP.NET Core on .NET 5. It\u0026rsquo;s running Blazor WebAssembly in the front end, which is talking to APIs running on ASP.NET Core. There are three different web apps that the system uses. Two are used internally by client staff, and then there\u0026rsquo;s the public‑facing website for the clinic, which is needed for the confirmation links that users will click. The two clinic apps, Front Desk and Clinic Management, each have their own database, and all three apps communicate with one another using messages transported by RabbitMQ. Like I said, it\u0026rsquo;s maybe a little more complicated than most demos. We want the sample app to be something you spend some time with and extend as part of your experience with this course, so please be sure to check it out and run it locally. It should just work if you have Docker installed. ‑Now let\u0026rsquo;s take a quick look at how the code is organized. The full solution is hosted on Steve\u0026rsquo;s GitHub account. Here\u0026rsquo;s the URL, but we\u0026rsquo;ll definitely also have that URL in the resources slides at the end of this module. PLURALSIGHT DDD FUNDAMENTALS is the name of the root of our GitHub repository. In here, you can see the three web apps, ClinicManagement, FrontDesk, and the public‑facing website, VetClinicPublic. ‑There\u0026rsquo;s also a folder for SharedKernel, which we\u0026rsquo;ll talk about a little bit later. The first app we\u0026rsquo;re going to focus on though is the FrontDesk app. ‑Our main focus for this course is going to be the front desk application and its scheduling functionality. Looking at the solution, you can see it\u0026rsquo;s broken up into seven projects, which seems like a lot, but three of them are just there to support Blazor The server‑side code, where our domain model resides, is just three projects. ‑The most important project is FrontDesk.Core. That\u0026rsquo;s where the domain model is defined. All of the app\u0026rsquo;s infrastructure needs, like how it talks to its database or RabbitMQ, are kept in the FrontDesk.Infrastructure project. In the front end, in this case, ASP.NET Core and its API endpoints, is in the FrontDesk.Api project. This is the front end from the server\u0026rsquo;s perspective. The system is using a clean architecture design which you may also hear referred to as onion architecture or ports and adapters. I cover this in my N‑Tier Applications in C# course, and I have a popular GitHub solution template you can use to set up a new project using this approach. ‑With clean architecture, the project dependencies all point towards the domain model in the core project, so both the API and infrastructure projects have a dependency on Core. Core should never depend on infrastructure concerns, but it can leverage NuGet packages that don\u0026rsquo;t couple it to infrastructure concerns. ‑In this case, it\u0026rsquo;s using a couple of utility packages, as well as the SharedKernel package that\u0026rsquo;s shared by other apps. We\u0026rsquo;ll talk more about SharedKernel later. The ClinicManagement app uses the same kind of structure and also has a Blazor front end because why not? It\u0026rsquo;s pretty much just CRUD, so we don\u0026rsquo;t focus too much on its domain model, but it is a distinct app with its own database, and we do need to build into our design a way to propagate changes from it to the FrontDesk app. ‑Finally, there\u0026rsquo;s the public web app. It\u0026rsquo;s just one project, and it\u0026rsquo;s pretty simple. This is responsible for sending emails, which this demonstration fakes using a tool called PaperCut, and it hosts the link that clients click to confirm appointments. The public web app also needs to communicate with the front desk, but it doesn\u0026rsquo;t have a database of its own, nor does it access any of the other app\u0026rsquo;s databases. ‑That\u0026rsquo;s it in a nutshell. We\u0026rsquo;ll demonstrate the confirmation emails and more complex use cases later in the course. But for now, that should give you an idea of how the ideas we\u0026rsquo;re sharing are put into practice.\nReview and Resources So, as we\u0026rsquo;ve talked about, creating applications is not about writing code, even though often that\u0026rsquo;s a really, really fun part for us developers, but it\u0026rsquo;s about solving problems. And the more complex the problems are, the more difficult the whole project becomes. So Domain‑Driven Design gives us some great patterns and practices for attacking these more complex problems, and they get us to really focus on interacting with the domain experts, breaking apart our domain, and working on things in smaller units and in a very organized fashion. And in the end, it gives us a much more efficient and effective path to success in creating our solutions. ‑Yeah, we talked about some of the benefits that Domain‑Driven Design provides, as well as some of the drawbacks. Specifically, your team just needs to know Domain‑Driven Design, and your domain experts need to be available to work with you on these systems. Domain‑Driven Design is a big topic. We looked at some of the different concepts that are involved in DDD, and we\u0026rsquo;re going to look at a lot more of them in depth through this course. But remember that this is just an introduction to Domain‑Driven Design, so some of these aspects that are a little more advanced, we\u0026rsquo;re not going to be able to cover with a great deal of depth. ‑In the next module, we\u0026rsquo;ll start exploring the process of discovering and modeling domains. Here are some links to resources that we mentioned this module and others that we find relevant. ‑This is Steve Smith ‑and this is Julie Lerman, and thanks for watching Domain‑Driven Design Fundamentals.\nModeling Problems in Software Introduction and Overview Hi. This is Steve Smith. ‑And this is Julie Lerman. Welcome back to our Domain‑Driven Design Fundamentals course. This module will focus on modeling problems in software, and you\u0026rsquo;re welcome to reach out to us online. You can find me online at thedatafarm.com or on Twitter @julielerman. ‑And I\u0026rsquo;m at ardalis.dot com or on Twitter as @ardalis. In this module, we\u0026rsquo;re going to take a look at how we decompose the model for the veterinary office domain. We\u0026rsquo;ll talk about the importance of domain experts in DDD. ‑We\u0026rsquo;ll drive this point home with a play in which we\u0026rsquo;ll consider a few different scenarios for how the project might have gone, which should provide you with examples of ways to involve the domain expert in the design of the system. ‑Next, we\u0026rsquo;ll talk about the domain model and some of the elements that typically are found in this part of the application. It\u0026rsquo;s important to separate the core domain model from related subdomains, and we\u0026rsquo;ll talk about how bounded contexts can help us accomplish this separation. ‑And then we\u0026rsquo;ll wrap things up by talking about ubiquitous language and how this seemingly small thing with a big name can have a large impact on your model, your design, and, of course, your application. So let\u0026rsquo;s get started.\nIntroducing Our Domain Steve and I both have a love for animals. In fact, Steve\u0026rsquo;s wife, Michelle, is a veterinarian. In thinking about a sample application we could use for this course, we wanted to use something complex enough to justify the use of DDD. The veterinary clinic management domain made a lot of sense, allowing us to leverage our own experience as pet owners, as well as having a domain expert available in the form of Michelle, or Dr. Smith as we\u0026rsquo;ll be referring to her in the course. ‑There are many different pieces involved in managing a typical veterinary clinic. The staff needs to be able to schedule appointments. They likely need to schedule their own working shifts as well. They need to be able to invoice for their services and collect payments and, in many cases, send out bills. They\u0026rsquo;ll also need to be able to store and retrieve medical records, as well as work with external labs and specialty clinics. Most veterinary practices also have products for sale and may need to track inventory, as well as sales. And there are often follow‑ups and reminders that may need to be sent by mail, phone, or perhaps email. There is certainly sufficient complexity in this domain to merit the use of domain‑driven design.\nPlanning Ahead to Learn About the Domain Of course, it\u0026rsquo;s a good idea to speak with a domain expert about the systems requirements before diving in and beginning to code a solution. Whether you\u0026rsquo;re tasked with building a full system or just adding a new feature, an overall understanding of the client\u0026rsquo;s business is a critical start. Of course, it\u0026rsquo;s just the beginning. It\u0026rsquo;s also important that you have a continuous conversation with the domain expert throughout the development of the system. The simple system we showed in the last module needs some updates. So we\u0026rsquo;re going to share some conversations we had with the domain expert to help validate our initial assumptions. ‑An important part of this conversation is going to be identifying the things that aren\u0026rsquo;t included in the scope of the project or feature. To that end, we\u0026rsquo;ll try to identify subdomains within the overall problem domain and then determine whether or not we need to concern ourselves with these subdomains at the moment. If not, we can consciously remove them from the scope with the customer\u0026rsquo;s approval and avoid confusion and possible missed expectations later. To get started though, we do want to know a little bit about the big picture.\nConversation with a Domain Expert: Exploring the Domain and Its Subdomains As Julie already mentioned, my wife, Michelle, is a veterinarian. In addition, she has a deep understanding of software development processes, having successfully managed software teams at NimblePros and Teller. She has graciously agreed to play the role of domain expert for our course. In real life, she knows quite a bit about software and technology, but for the purposes of this course, she\u0026rsquo;s playing the more traditional role of a veterinarian with little background in software development. Hi Dr. Smith. Thanks for your time today. Julie and I would like to learn more about what goes on in your veterinary clinic. Can you share some of the big picture processes involved in the day‑to‑day operation of a clinic? ‑So the biggest thing is probably scheduling patients and keeping track of them once they arrive. Clients will usually call ahead unless it\u0026rsquo;s an emergency, and then we need to get them entered into our system. Of course, surgical procedures need to be scheduled in advance. And when they\u0026rsquo;re here, we need to record information about the patient, our observations, notes, and diagnoses. ‑Wow, that\u0026rsquo;s quite a list. Probably not what you were dreaming about when you started vet school. So many of these are all secondary to the core reason for being a vet, keeping pets healthy. And, I think it sets you apart from other businesses that have to manage clients and schedule appointments. But, you can\u0026rsquo;t run a business without it. Is that all? ‑So when the appointment is over, they also have to pay. So most of the time that\u0026rsquo;s done immediately, but we do have some billing that\u0026rsquo;s done after the fact, and when they\u0026rsquo;re checking out, they may need to buy some things for their pets, toys or prescriptions, or maybe some prescription food as well, and we need to track all of that as well. For some of the lab work, we need to send that out and get the results back, and some prescriptions go out to outside pharmacies as well. So we need to manage all of those through the system. ‑Okay, so payments, billing, point of sale, labs, prescriptions, anything else? ‑I think that\u0026rsquo;s about it. Oh, we also use the system to note which staff members are working when, and right now our website isn\u0026rsquo;t integrated into the system at all, but we were thinking it would be great if clients could view information about their pets, maybe schedule appointments, look up prescriptions, and we can make updates to the site without having to go through our computer contractor. ‑Okay, great. So, we\u0026rsquo;ll add staff scheduling and content management to the list. I don\u0026rsquo;t want to assume you know what a content management system is. We also call it a CMS, you might have heard of that. It\u0026rsquo;s a type of software system that lets the owner, that\u0026rsquo;s you, be in charge of the information that\u0026rsquo;s displayed. A blog is a really good example of a CMS that can be managed by its owner. ‑I have a blog, so I understand exactly what you mean. Something like that would be really great for us to have so we can make updates right in‑house. But it\u0026rsquo;s kind of like a blog, especially something that\u0026rsquo;s more professional than my personal blog. ‑Cool. So I think that\u0026rsquo;s probably enough of a big picture view for us to consider at the moment. Now let\u0026rsquo;s try and think about which of these are connected to the others so we can determine which ones we need to worry about for our application\u0026rsquo;s needs. ‑We started with this fairly complicated view of the overall problem domain, but now we\u0026rsquo;ve segregated these into different areas and we know which ones we need to focus on right now and which ones we can treat as external collaborators. ‑Determining where we can safely draw the line between what problem our immediate application needs to solve and what is outside of its area is certainly helpful. It\u0026rsquo;s also important that this be well understood and communicated among everyone involved in the project.\nConversation with a Domain Expert: Exploring the Scheduling Subdomain Now that we have a better understanding of the domain and the other subdomains around the scheduling system, it\u0026rsquo;s time to focus more on understanding the scheduling subdomain. We had another meeting with Dr. Smith, and you can listen in. ‑Hi guys, welcome back to the clinic. How are things going with the computer system? ‑We\u0026rsquo;re making good progress, and now we\u0026rsquo;re ready to look at another more complex feature. ‑We know there\u0026rsquo;s a lot that goes on here, but today we want to focus on appointment scheduling because we realize we\u0026rsquo;re still a little confused about it. ‑Since we\u0026rsquo;ve both owned pets for a long time, we figure we probably have a rough idea of what\u0026rsquo;s needed, but it\u0026rsquo;ll be good to talk through it with you. Do your patients usually schedule their appointments over the phone? ‑Okay, so yeah our patients aren\u0026rsquo;t usually involved in the scheduling. Usually, it\u0026rsquo;s the clients that call in for appointments for their pets. And yeah, usually it\u0026rsquo;s on the phone or in person when they\u0026rsquo;re checking out after an office visit. Julie and I talked about that earlier. ‑Yeah, so Steve, the patients are the animals, and the clients are the people or the pet owners. ‑Right, right, of course, that\u0026rsquo;ll be important to get right. ‑Remember, we talked about that. So the client needs to make an appointment for their pet. They\u0026rsquo;ll talk to a staff member who will schedule the appointment. What kind of information do they need in order to do that? ‑So that really depends on the type of appointment. It could be an office visit, or it could be a surgery. Why don\u0026rsquo;t we talk about the office visits first. If it\u0026rsquo;s just for a wellness exam, that\u0026rsquo;s pretty standard. They just need to choose an available time slot with one of the doctors. Some of the visits can be scheduled with just a technician though, so if they need just their toenails trimmed, for example. ‑Or painted, like Samson. He gets his toenails painted. ‑Does he really? ‑No, I\u0026rsquo;m joking. I just want to, pink. ‑I\u0026rsquo;m sure he\u0026rsquo;d love that. Okay, so office visits might be an exam requiring the doctor or another kind of appointment that only requires a technician. ‑Right. We also have to worry about our rooms too. We only have five exam rooms available, and we try not to overbook. We don\u0026rsquo;t like for our clients to have to wait too long in the reception area, especially if we have a lot of cats and big dogs out there at the same time. It makes them all really nervous. ‑What about other staff? ‑So our technicians will float between the exam rooms and other areas of the clinic as needed, except, of course, for those scheduled technician visits. We do have a schedule for the staff, but it\u0026rsquo;s separate from how we schedule our appointments. ‑Okay, so what about the surgeries? ‑Well, if it\u0026rsquo;s a surgery, those are only scheduled on certain days, and they require that the operating room be available, as well as some recovery space in the kennel area. It also depends on what kind of surgery or procedure we\u0026rsquo;re going to be doing. Something simple like a dental cleaning takes less time and fewer people than a caesarean section for a bulldog. ‑Okay, so an appointment is either an office visit or a surgery. Office visits happen in the exam room; surgeries require the operating room and recovery space. Is that right? ‑Right. And depending on the reason for the visit or the surgery, different staff might need to be involved. ‑So we\u0026rsquo;ll probably want to have separate classes for appointments and surgeries. ‑Classes? No, we refer our clients to obedience and puppy preschool classes at other facilities. We don\u0026rsquo;t actually schedule any of those in the clinic themselves. ‑I\u0026rsquo;m sorry. That\u0026rsquo;s a software term. In software, we have different classifications of concepts in the program, which are called classes. I\u0026rsquo;m just getting ahead of myself here. Sorry. ‑Don\u0026rsquo;t worry. We\u0026rsquo;re not going to make you learn our software terms. Steve and I will try to have a little bit more self control with that. We do want to make sure we\u0026rsquo;re all speaking the same language when it comes to concepts in the application though. ‑Okay, so I have another quick question. Do we have to worry about multiple staff members scheduling appointments at the same time? ‑No, there should only ever be one person doing the scheduling at a time, although I could see if we grew in the future that could change. But I don\u0026rsquo;t think that\u0026rsquo;ll happen in the next couple of years. Okay, then we don\u0026rsquo;t have to worry about the rare occurrence of two people creating a conflict if they\u0026rsquo;re trying to schedule an appointment for different patients in the same room or with the same doctor. That\u0026rsquo;ll keep things a lot simpler. And we need to know before an appointment if certain resources are available, like rooms and doctors. And then if they are and we want to schedule the appointment, then we need to be able to book the doctor, the room, and any other resources. Hey, is it okay if we refer to doctors as resources? ‑Sure, that makes sense. You know, I think it makes sense to use the term resources to refer to the doctors, the rooms, and the technicians since those are all things that can affect whether or not an appointment can be scheduled. But remember, sometimes it\u0026rsquo;ll be just a vet tech in a room, and other times it might be the doctor in the room, but sometimes you might need the doctor, the technician, and a room. ‑Wow, this is a lot more complicated than we\u0026rsquo;d realized, but it\u0026rsquo;s interesting. This is going to be cool to model in the application.\nReviewing Key Takeaways from Meeting with Domain Expert(s) Some of the things we learned in that initial high‑level discussion with the domain expert included the fact that patients and clients are not the same thing to a veterinarian. ‑Yeah, that\u0026rsquo;s pretty obvious in hindsight. But in most other medical professions, it is the patients who make appointments and pay the bills. It\u0026rsquo;s good we were able to get on the same page with the customer on that early on in the process. ‑I think it helped Dr. Smith put some of the processes she uses into explicit terms that we could program against also. A lot of times just describing the process to someone who is unfamiliar with it can really help improve the understanding of it. It\u0026rsquo;s like that idea that when you have to teach something to someone else, it makes you learn it a lot better. Listen to what Dr. Smith had to say at the end of our conversation about this. ‑Yeah, I never really thought about the details of how we do some of these things since it\u0026rsquo;s just something we do, and we don\u0026rsquo;t really think about it. Being more explicit about what the rules are that determine how we do are scheduling could help us avoid some of the occasional scheduling problems we\u0026rsquo;ve had. This is going to be great. ‑We also need to remember not to use too much programmer jargon, especially when there are programming terms that might have a different meaning in the customer\u0026rsquo;s domain. ‑I agree. It\u0026rsquo;s a little early for us to be worrying about how things might end up looking in the code anyway. At this stage, the main focus is on understanding the domain. We\u0026rsquo;ll get to building the software soon enough. But first, we want to make sure we know what problem it\u0026rsquo;s going to be solving. One of the most important things we can do as we explore the problem with the domain expert is to try and make their implicit knowledge about the process they use now explicit. Once we\u0026rsquo;re able to capture the process and its rules and exceptions with some detail, we can start to work on modeling a solution using this information. Building software is hard. One of my favorite sayings is as software developers, we fail in two ways. We build the thing wrong, or we build the wrong thing. By making sure we understand what the customer needs and, of course, working closely with the customer throughout the development process, we can dramatically reduce the likelihood of the second kind of failure, which is much harder to fix typically. ‑Hey, Steve. I like the way you quote yourself here, but it really is a great quote.\nTaking a First Pass at Modeling our Subdomain After talking to Dr. Smith about how appointments work, we\u0026rsquo;ve identified a few high‑level elements of our model. The central concept in this application seems to be the appointment itself. Typically, an appointment is scheduled by a client for a patient. Booking an appointment often requires an exam room and a doctor, but may involve other resources. Appointments might be for office visits or vaccinations, or they might be surgeries, which are a separate kind of thing entirely with their own rules which involved different kinds of procedures. Surgeries require different resources too, like operating rooms and recovery rooms. ‑That\u0026rsquo;s a pretty good high‑level view of the model we have so far for the appointment management part of our application. I think it\u0026rsquo;s worth noting that some of the concerns of this application are going to also play a part in other subdomains. For instance, I\u0026rsquo;m pretty sure we\u0026rsquo;re also going to be working with clients and patients in a lot of the different parts of this application. ‑Yeah, I think it\u0026rsquo;s time we introduce the idea of bounded contexts.\nUsing Bounded Contexts to Untangle Concepts that Appear to Be Shared As you develop your model, remember to identify its bounded context. That is, where is this model valid? If you don\u0026rsquo;t put boundaries around your model, eventually, pieces of it will be used where they don\u0026rsquo;t fit. Concepts that make sense in one part of the application may not make sense in another, even if they have the same name and sometimes even if they literally refer to the same thing. ‑For example, as we built out the appointment scheduling portion of this system, we needed to know some very basic information about clients. But in the context of appointment scheduling, these are very simple concepts with little behavior beyond their names. However, in the billing context, we\u0026rsquo;ll want to include contact and payment information for clients, but that\u0026rsquo;s information we don\u0026rsquo;t care about back in the appointment scheduling context. If we try to reuse the same exact client model in multiple places, it\u0026rsquo;s likely to cause inconsistent behavior in our system. ‑That\u0026rsquo;s right. For instance, we might decide to include some form of validation on clients to ensure we have enough information to bill them. If we\u0026rsquo;re not careful, that validation might inadvertently prevent us from being able to use clients to schedule appointments, which certainly isn\u0026rsquo;t the desired behavior. Maybe the billing system requires that clients have a valid credit card in order to save changes for them, but it wouldn\u0026rsquo;t make sense for a lack of a credit card to prevent us from saving an appointment for a client in the appointment scheduling system. In this example, we have two contexts, but the boundaries between them are blurred and overlapping. Eric Evans notes that models are only valid within specific contexts. Therefore, it\u0026rsquo;s best to explicitly define the context within which a model applies. We should be able to avoid compromising the model within this context, keeping it strictly consistent within these bounds and avoiding distractions or confusion from outside issues. ‑Once we explicitly define our bounded contexts, we can easily see whether or not we have elements of our model that are trying to span multiple contexts. In this example, we\u0026rsquo;d want to keep a simple view of a client in the appointment scheduling up and a richer version of the client with contact and billing information in the billing context. We would define these two views of a client in two separate classes, and they will most likely live in separate applications. In fact, Evans recommends that bounded contexts maintain their separation by giving each context its own team, codebase, and database schema. ‑While this is ideal, in many real‑world apps, we need to work on systems where this level of separation is not present, usually due to resource constraints or for political reasons within the organization. Remember though, if you have multiple contexts, you\u0026rsquo;ll want to keep them bounded. And one way to maintain this separation is to keep their data, code, and team members distinct from one another, although in real world, I\u0026rsquo;ve never seen something with that level of separation. ‑Yeah, but I think even if it\u0026rsquo;s not possible to literally do that with your company and your team, just having that concept in mind really helps in your brain have that idea of separation. ‑I agree. I know that just thinking about the fact that these things ought to be separated and trying to figure out a way to do it means that even if you can\u0026rsquo;t get to the ultimate level where everything is is completely separate, you can still introduce separations through things like namespaces, separate folders, separate projects, anything you can do to make it clear that these are different contexts that shouldn\u0026rsquo;t be sharing too much information. ‑You know, I think that\u0026rsquo;s also really important point about this course in general and DDD in general. For me, it\u0026rsquo;s really hard to think of all of these things we\u0026rsquo;re learning as hard and fast rules, like you have to do it this way or you\u0026rsquo;re not doing it right. I like to see all of this as really good guidance. So, you know, it helps me keep my eye on the prize, and when there\u0026rsquo;s places where I can\u0026rsquo;t truly achieve exactly what DDD kind of directs me to do, you know, I\u0026rsquo;m using my own experience, my own intelligence to make decisions about how to do things, and I\u0026rsquo;m letting DDD guide me in a lot of scenarios. ‑Sure. And some of these ideals, I think of like 100% test coverage. It\u0026rsquo;s almost impossible in most real‑world applications to achieve 100% test coverage. But just because that ideal is not something you can ever achieve doesn\u0026rsquo;t mean that you shouldn\u0026rsquo;t strive for more test coverage. ‑Yeah, yeah, totally, totally agree with that.\nConversation with Eric Evans on Subdomains and Bounded Contexts When learning about DDD, most of us have a hard time understanding how subdomains and bounded contexts are different. We asked Eric Evans about this and got some great insight. He explained that a subdomain is a view on the problem space, how you\u0026rsquo;ve chosen to break down the business or domain activity, whereas a bounded context represents the solution space, how the software and the development of that software has been organized. Quite often, these will match up perfectly, but not always. ‑Eric helped us understand this further with the example of a room that you want to cover with carpeting. The room is the problem space, so it\u0026rsquo;s like a subdomain. You could install a wall‑to‑wall carpet that matches the shape of the room perfectly. This would be like when the subdomain and the bounded context encompass the same thing. But other times you might just use some area rugs to cover the floor, and the area rugs solve the problem. They cover the part of the floor where you walk, and you don\u0026rsquo;t have to worry about cold feet in the winter. And that\u0026rsquo;s a scenario where the area rugs are like bounded contexts that don\u0026rsquo;t match the subdomain, but they solve the problem even though they\u0026rsquo;re not an exact match to the shape of the room.\nIntroducing Context Maps If your organization has multiple bounded contexts, and ideally these are separated, there can be confusion when the different teams are talking to one another. Again, DDD focuses at least as much on effective communication as it does on anything specifically related to the code we produce. Evans recommends using context maps to visualize and demonstrate to all teams where the boundaries between their context lie. ‑Think about a complex topographical map. It will frequently include a legend, like the one shown here, in order to explain what each of the lines and symbols on the map mean. However, this legend is only valid within the context of the map with which it appears. Trying to use this legend on another map would be confusing at best. ‑A good first step for an existing application is to create a map that shows how things are. Remember that the names of your contexts are also important as you\u0026rsquo;ll refer to them frequently when discussing different parts of the application. It may be that things are not as separate as they should be, and that\u0026rsquo;s worth noting. If you have separate teams responsible for different contexts that share resources, it\u0026rsquo;s important that each team understands which aspects of the application they can change on their own and which are shared dependencies they\u0026rsquo;ll need to coordinate with other teams to avoid breaking things. If we look at these two sets of concepts, we can see some obvious overlap. For one thing, Client appears in both contexts, but we know that for appointment scheduling we really only care about the client\u0026rsquo;s name, whereas in the billing system they\u0026rsquo;ll want additional information like address and payment details. However, although the details involved vary, we know that Mr. Jones, the client on the left, is the same actual person as Mr. Jones, the client on the right. However, we also have a concept of notifications on both sides, and in this case, they\u0026rsquo;re referring to different things. On the left, we\u0026rsquo;re talking about sending a notification when an appointment is booked as a reminder, and on the right, we\u0026rsquo;re talking about notifying the client that their payment was received or perhaps that it\u0026rsquo;s past due. ‑Especially in smaller organizations, it\u0026rsquo;s common to have one team responsible for several contexts of the same overall application. In such cases, it\u0026rsquo;s also common for the team to use a single codebase for the bounded context that they\u0026rsquo;re working with and store it in a single repository, such as GitHub. Usually, there will also be a shared database. As we\u0026rsquo;ve already noted, this is not ideal since it makes it much more difficult to maintain the boundaries between the separate contexts. ‑Part of creating a context map involves explicitly identifying its boundaries. If we try to draw the boundaries around these two bounded contexts, we can see there are now several resources that belong to each bounded context. This isn\u0026rsquo;t ideal if the two contexts really are meant to be kept separate. ‑In the ideal case for a large complex system, we would have bounded contexts like these, with their own teams, codebases, and database. For instance, on the left, we have an appointment scheduler application. It\u0026rsquo;s being worked on by Team Awesome, and they\u0026rsquo;re storing all of their code in their own repository called vet‑app‑sched. And, of course, this application has its own database. This team is free to change anything they want with their model or any other part of their system without worrying about breaking anything outside the boundaries for the team on the right, which is working on a billing system, and their team has decided to call themselves Team Ultimate, store their code in a repository called vet‑billing, and, of course, using their own database. By having this separation, this can greatly increase team velocity and reduce integration bugs. ‑Of course, you\u0026rsquo;re probably wondering how the two systems will interoperate. There are a number of patterns that can be applied to enable this kind of integration. We won\u0026rsquo;t be covering all of them in this course, but one question that frequently comes up is how to share cross‑cutting concerns like blogging and shared abstractions such as people names that are used by multiple bounded contexts. For this scenario, a common approach is to designate these shared concepts or resources as what we call a shared kernel. Team Awesome and Team Ultimate agreed to share the subset of the domain model. Since they\u0026rsquo;re sharing it, they also agree not to change it without coordinating with the other team first. Frequently, the shared kernel will either be a part of the customer\u0026rsquo;s core domain, or some set of generic subdomains, or even both, though it could be any part of the model that both teams require. Using a shared kernel is a tradeoff between code reuse and consistency and the overhead involved in integrating changes to the shared kernel across multiple teams and bounded contexts. It works best when the shared model is relatively stable.\nAddressing the Question of Separate Databases per Bounded Context The concept of having separate databases for each bounded context often throws people for a loop. But with the advent of microservices, which also, by definition, each have their own database, teams are beginning to get more accustomed to the idea. Here\u0026rsquo;s what Eric Evans said to us when we talked with him about the problems created by trying to share a database across teams. \u0026ldquo;If you\u0026rsquo;re in a company where you share your database and it gets updated by hundreds of different processes, it\u0026rsquo;s very hard to create the kind of models that we\u0026rsquo;re talking about and then write software that does anything interesting with those models.\u0026rdquo; Given that sharing a database across bounded contexts is really not a great idea, then we have another important question. ‑Another question that comes up often is how to sync data between the individual databases that are tied to each of the bounded contexts. Some different patterns you can use are publisher/subscriber, commonly referred to as pub/sub, and two‑way synchronization. Pub/sub is definitely simpler and preferable when you can manage it. You can use different implementations like message queues, database processes, batch jobs, or synchronous API calls. It\u0026rsquo;s really up to you how you want to design your synchronization between bounded contexts. The point is just that you don\u0026rsquo;t get the integration for free from using a shared database.\nSpecifying Bounded Contexts in our Application We talked with Eric again to get his perspective on defining context boundaries. Some of the key points he shared were that first, it\u0026rsquo;s important to understand that it\u0026rsquo;s never a simple task whether you\u0026rsquo;re new to it or not. And he\u0026rsquo;s seen stumbling blocks of all sorts. The most common is not having a clear enough context boundary, so the effort of applying DDD isn\u0026rsquo;t clearly separated from other tasks related to building software. ‑He also reminded us that the bounded context is such an essential ingredient that is probably the biggest stumbling block. And it\u0026rsquo;s not often one that an individual on a project can usually addressed by themselves. It kind of has to be dealt with at the team level or even the organizational level. In our application, we\u0026rsquo;ve organized the solution to make it clear where the boundaries are between our contexts. The main area that we are currently focused on is the appointment scheduling bounded context. ‑We\u0026rsquo;ve identified two other bounded contexts that are involved in the overall application or will be eventually. For instance, it\u0026rsquo;ll be important for users to be able to manage clients and their patients. The staff of the clinic also needs a way to manage their schedules so they know who\u0026rsquo;s working on different days. We\u0026rsquo;re referring to these two bounded contexts as client patient management and resource scheduling. ‑We also have a few parts of the application that are common to several bounded contexts. These are cross‑cutting concerns that we have consciously chosen to share. In DDD, we isolate such code into its own package referred to as a shared kernel, and it\u0026rsquo;s worth noting that a bounded context does not always mean a separate application, even though we\u0026rsquo;ve identified several different bounded contexts. ‑It\u0026rsquo;s also a great opportunity to consider packaging logic up into microservices. Do keep in mind, however, that there\u0026rsquo;s not always a 1:1 alignment between bounded contexts and microservices or applications. Also, let\u0026rsquo;s not forget that our application will definitely need a front end.\nUnderstanding the Ubiquitous Language of a Bounded Context We\u0026rsquo;ve mentioned already that an important part of DDD is an emphasis on effective communication among the stakeholders in the project. And remember, if you\u0026rsquo;re a programmer, count yourself as one of the stakeholders in whatever you\u0026rsquo;re working on since you certainly have a stake in its success. The language we use to describe the problem and how we choose to model it is key to the shared understanding we want to have with our domain experts in order to be successful. Having a single, shared, ubiquitous language helps avoid unnecessary confusion and translation within the team building the software and is one of the fundamental practices of Domain‑Driven Design. And when I talk about the team building the software, I don\u0026rsquo;t just mean the programmers. I mean the whole team, including the business people that are deriving what the software should do. The discovery of the Rosetta Stone allowed us to unlock several different languages by showing the same message in three different texts. We don\u0026rsquo;t want to have to have a Rosetta Stone or any other sort of tool to help us translate between what the business is talking about and what the programmers are talking about. We want to make sure that everyone is speaking the same language the whole time so that translation is unnecessary. ‑Think about if you\u0026rsquo;ve ever used an online translation tool to round trip a sentence. You can run into similar communication issues in your application if you\u0026rsquo;re constantly having to translate to and from the domain expert terms or the programmer\u0026rsquo;s terms. Here\u0026rsquo;s an example of a user story for a sample system about creating appointments. ‑We have a lot of developer friends in Nigeria, so I thought it would be fun to try out Igbo for our translation. We used a website to translate between English and Igbo a few times, and in the end, the user story has changed just enough to create confusion. Translation software is pretty good these days, and we were hoping for a more humorous result, but according to animal experts, it\u0026rsquo;s close, but not the same as a veterinary technician. ‑But the point here, of course, isn\u0026rsquo;t just relating to different international languages, but to the different languages spoken by business experts and programmers. ‑Incidentally, a great practice when you\u0026rsquo;re discussing your system requirements with customers is to always try and explain back to them what you think it is they want the system to do so they have an opportunity to correct your understanding of what they think they just told you. ‑Definitely. Remember, one of the key benefits of using a ubiquitous language is that all parties can understand it without having to perform any translation. This means when you show a test or some code to a domain expert, you don\u0026rsquo;t have to explain that in the system you call something an animal when the domain expert calls it a patient. ‑Evans cautions that a project faces serious problems when it\u0026rsquo;s language is fractured. When domain experts stick to using their jargon while the technical team members have their own language tuned to discussing the domain terms in the design, translation errors will manifest as software bugs. Neither the customers nor the developer\u0026rsquo;s language is sufficient for all parties to discuss the application effectively. What is needed is a shared common language that incorporates and uses terms defined in the domain model. The use of this language must be ubiquitous, and the more the language is used, the more will force deficiencies in the model into the open. ‑And by ubiquitous, we mean it must be used everywhere within the bounded context. The vocabulary of the language includes the names of model classes and prominent operations. The team should use these common terms in code, in diagrams, on the whiteboard, in design documents, and especially when discussing the system. ‑Yeah, pretty much ubiquitous means everywhere, all the time. Even in that one email you\u0026rsquo;re sending off to another developer, stick to using the terms that you\u0026rsquo;ve agreed makes sense for this bounded context.\nConversation with a Domain Expert: Working on our Ubiquitous Language You\u0026rsquo;ve heard some of our conversations that helped lead to a ubiquitous language for the scheduling app. There was another important one that happened early on between Michelle and me that we want to share with you now. ‑Pay attention to not only the clarification of the terms, but also to the fact that Julie and Michelle are equal partners in this conversation. Although Julie is trying to lead the conversation towards the goal of identifying the correct terms, she\u0026rsquo;s careful not to make assumptions about Michelle\u0026rsquo;s domain. ‑So Michelle, last time you and Steve and I got together to talk, Steve and I have been working on just kind of fleshing things out and planning things, and I realized that we had some confusion over some of the common terms, like things that, as real pet owners, we would kind of assume the terms are, but then when we\u0026rsquo;re thinking about business and software, we\u0026rsquo;re thinking of the terms a little differently. So I was wondering if we could just sort that out with you so that we\u0026rsquo;re all on the same page and using the same terms and using terms that none of us have to stop and think about what we\u0026rsquo;re talking about. We\u0026rsquo;ll always know what they mean. ‑Sure. ‑The first thing is we have these clients, those are the people who own the pet. So when thinking about the software and business, we think of them as clients, but kind of in the real world, and me, I have a pet, I go to the vet all the time. I think of myself as a pet owner. So what do you refer to those people who bring the pets, pay their bills, call and make the appointments, etc? ‑Most of the time, I mean those would be listed as as clients. ‑Okay, so you do call them clients. You don\u0026rsquo;t worry about calling them owners, and of course, it sounds kind of weird to say I own a dog, right? ‑He kind of owns you. ‑Yeah, that\u0026rsquo;s more like it. You\u0026rsquo;re the pro you know. So then what about that dog, like are they patients, are they pets, are they clients? What do you refer to the pets as? ‑So for the purpose of the medical record, we refer to them as the patient. ‑Okay. So it would be client and patient. ‑Exactly. And actually in veterinary medicine they talk a lot about this triad, the veterinary client/patient relationship, where all three are really important in that. ‑Okay. So those are actually terms that are commonly used in your industry. Industry, that sounds so weird, but with that. Cool. Alright, so the next one we were also going back and forth on was an appointment or an office visit. When somebody is scheduling a visit, scheduling to come in, how do you refer to that? ‑So there would be two big subsets of what they might be scheduling to come in for. They might schedule a surgery, which is an easy one to define. They\u0026rsquo;re going to come in, we\u0026rsquo;re going to do some sort of a procedure. Usually, there is going to be some anesthetic involved. That would be a surgery and that would be outside of our normal office hours. ‑Oh, okay. So what about when they just come in for regular stuff? ‑So when they come in for regular appointments, you could call those office visits or appointments, and there are a few different subsets of those. You may have an appointment that\u0026rsquo;s a wellness exam, and in that exam, we would be doing, of course, a physical examination and generally wellness treatments like vaccination, some blood work, generally your healthy pet who is coming in for a routine checkup. ‑So that\u0026rsquo;s an office visit and there is a couple other things that come under the umbrella of office visit, but if I, I\u0026rsquo;m also thinking about scheduling because that\u0026rsquo;s the thing we\u0026rsquo;re really going to be focused on is the scheduling portion of the app. So we\u0026rsquo;re always scheduling an appointment, an appointment for a surgery, an appointment for an office visit, whatever type of office visit that is, so is using the term appointment, does that make sense? Would you, if if I said appointment would you think that could be a surgery, that could be a checkup, that could be whatever. This thing to be scheduled is what I want to define. ‑Yeah, I mean I think you could call them all appointments, but I would differentiate between the surgery and something that\u0026rsquo;s done in the office, but then I would further differentiate in the office between a wellness exam, an exam for somebody that\u0026rsquo;s coming in with a problem, or an exam that doesn\u0026rsquo;t need to see a doctor, but could just be done by a technician like a toenail trim. ‑Oh good. Yeah, we always need those, clickety‑clack on the floors. Alright, so I think then we\u0026rsquo;ll use just the overall umbrella of we\u0026rsquo;ll schedule an appointment and then we\u0026rsquo;ll be more explicit about what type of an appointment that\u0026rsquo;s going to be. Would that feel okay to you? ‑Yeah, that makes sense to me. ‑Great. Excellent. Alright, so I\u0026rsquo;ll get back to Steve and then we\u0026rsquo;ve got another meeting set up I think in a few days to just hash out some more details after Steve and I\u0026rsquo;ve gotten some more of our ducks in a row. ‑Sounds great! ‑Excellent. Thanks Michelle. Bye bye. ‑Thank you. Bye. ‑Now we have a stake in the ground for our ubiquitous language. As we continue working with Michelle, not only will we learn more items for the bounded context, but there is also a chance that the ubiquitous language will evolve. Eric Evans guides us to pay attention to those changes because a change in the ubiquitous language is also likely to mean a change in the domain model. We have to update our design to accommodate what we\u0026rsquo;ve learned.\nReviewing Important Concepts from This Module We\u0026rsquo;ve covered quite a few concepts in this module. One of the most important ones is just understanding the problem domain and the overall thing that your software is working within. ‑‑And breaking things apart. I know that when I started out, I had a really hard time really understanding differences between the core domain, the subdomains, and the bounded context, especially the subdomains and the bounded context because at first glance, they looked like the same thing to me. ‑‑Sure, it\u0026rsquo;s really easy to have an application where you have some kind of a concept, like a customer that you know is used by every system that your organization uses. And it ends up becoming this like God object in your database and in your different applications where any given application might only care about a tiny subset of that concept. ‑‑Yeah. So, for me, I think the most important thing is really focusing on the bounded context. Getting down to that and understanding about the boundaries. One thing that helps me a lot is just stating within the context of this and then suddenly like, oh right, that\u0026rsquo;s what a context is. It\u0026rsquo;s not like some mysterious new term that Eric Evans invented. He just is leveraging what makes sense. Within the context of appointment scheduling, this is what a client looks like. Within the context of billing, this is what a client looks like. ‑‑Sure, I think that makes a lot of sense. And it\u0026rsquo;s valuable, even when you have an application, like a legacy application that wasn\u0026rsquo;t built with domain‑driven design. Let\u0026rsquo;s go ahead and look at some more terms here. For instance, we\u0026rsquo;ve got what you were just talking about, I think of as context mapping. And even in a legacy application, it can be valuable to kind of map out what are all the concepts in this application and where are the overlaps with different subdomains that maybe we haven\u0026rsquo;t even defined in this legacy application. ‑‑Yeah. Even if you\u0026rsquo;re not planning on making huge changes to it, it\u0026rsquo;s still really, really helpful to just kind of update your perspective on things. Sometimes it just leads to new understandings. ‑‑I think the shared kernel is a really important part of this, too, because in almost every real‑world organization I\u0026rsquo;ve worked with, there are different types of cross‑cutting concerns, and we talked about one of them being the authentication piece, and that\u0026rsquo;s definitely a really common one. But there are usually others too that you want to share. ‑‑Yeah, and, again, it\u0026rsquo;s another one of those things that sounds like it might be a big, scary, mysterious thing because you haven\u0026rsquo;t referred to it that way, but if you really just start out thinking of it as the common stuff, but then‑‑‑I think one of the important things, though, is even within the context of domain‑driven design, we have a ubiquitous language because if I say common, you might have a different idea of what I mean by common, but if I say shared kernel, we\u0026rsquo;ve got an agreed‑upon understanding of what we\u0026rsquo;re talking about there. So at first, I really kind of pushed back against using these terms because I felt like a lot of the DDD experts were just throwing them around all the time. And then I started really getting a better understanding of why it\u0026rsquo;s important to use those terms. It\u0026rsquo;s about‑‑‑it\u0026rsquo;s the ubiquitous language of domain‑driven design so everybody\u0026rsquo;s on the same page. ‑‑Yeah, I do agree that that\u0026rsquo;s an important part of learning about DDD and other areas of software development, like, for instance, design patterns. These things give us these terms that we can use that are very, very dense. If we talk about shared kernel, it would take me three or four sentences to describe what I meant by that. But in these two words, you know exactly what I mean, just like if I talk about using a strategy design pattern, that is much easier to convey than if I were to try and describe it with words and have to draw a UML diagrams to say what I mean. ‑‑And it\u0026rsquo;s the same, again, with the ubiquitous language because now I really have a better understanding of the fact that what it means is the language is ubiquitous throughout a particular bounded context. When we\u0026rsquo;re talking about a scheduling app, we\u0026rsquo;re going to use these terms all the way through, like you were saying before, we use it not just when we\u0026rsquo;re talking to the domain expert but in our class names, in our methods, it\u0026rsquo;s just ubiquitous throughout all of the pieces of the things that are involved in that bounded context from one end all the way to the other of it. ‑‑And I think as we\u0026rsquo;ll see when we look at the code again, some of the constructs in .NET, like namespaces, are really appropriate to ubiquitous language because when you prefix that same term in your code with a particular namespace, that tells all the other programmers that if I say SchedulingApp.notification, we know that that has a different meaning that if I\u0026rsquo;m talking about EmailReminder.notification. ‑‑Or SchedulingApp.client versus Billing.client. ‑‑Exactly.\nReview and Resources In this module, we learned about our domain, in this case, a veterinary practice. We talked about it at length with a real live domain expert and identified the core elements of our domain model. We identified a variety of subdomains and focused in on the key area that we would be addressing first with our application. ‑We spent some time designing the system based on our conversations with Michelle, identifying boundaries between different contexts, and noting how sometimes the same object with the same name might mean something different within a different context. ‑Finally, we talked about the importance of communication in general and in particular having a ubiquitous language. We know that Domain‑Driven Design can help us avoid many design errors and wasted time miscommunicating as we work on a complex project. ‑Steve and I are so grateful to Eric Evans for spending time with us while we were creating this course in order to share his luminous advice and insights. In the next module, we\u0026rsquo;ll drill into the domain model so you can have a good understanding of its critical elements. ‑This is Steve smith, ‑and this is Julie Lerman. Thanks again for watching Domain‑Driven Design Fundamentals.\nElements of a Domain Model Introduction and Overview Hello, this is Julie Lerman, ‑and this is Steve Smith. ‑In this module, we\u0026rsquo;re going to focus on the elements of a domain model which are in our bounded context. ‑You\u0026rsquo;ve seen these in the mind map. It\u0026rsquo;s patterns like entities and aggregates and more. ‑You can find me online at ardalis.com or on Twitter as @ardalis. ‑And you can find me online at thedatafarm.com or on Twitter at @julielerman. ‑In this module, we\u0026rsquo;ll focus on the technical aspects involved when modeling a bounded context. We use these terms while modeling, and these same terms refer to patterns we\u0026rsquo;ll use when we code. The concepts flow through the entire process, which is great. You don\u0026rsquo;t have to keep switching hats or mindsets. ‑We\u0026rsquo;ll start by grounding ourselves in the domain and understand why it\u0026rsquo;s important to stay focused there. DDD models are driven by behaviors, not classes and properties. This is another very cool shift in thinking for those of us who have always focused on objects. Then you\u0026rsquo;ll learn about some terms used to describe domain models, rich and anemic. You learn what the terms mean at a conceptual level and what the code that they\u0026rsquo;re describing looks like. ‑Entities are the key types in your system, but not every type in your system is an entity. ‑You\u0026rsquo;ll learn how entities fit into DDD, how to differentiate entities that have complex needs from simpler entities that might only need some basic CRUD logic, and you\u0026rsquo;ll be able to see how we\u0026rsquo;re implementing all of these concepts in our code.\nThe Importance of Understanding DDD Terms Domain‑Driven Design is filled with lots of specific terms. Much like the ubiquitous language that we use to make it easier to communicate while working within a bounded context, understanding and using the terms of DDD makes it easier to talk about the process. We\u0026rsquo;ll spend the bulk of this module focusing on some of the concepts behind modeling bounded contexts, concepts that are critical to this process, but, unfortunately, often misunderstood. ‑I\u0026rsquo;ve definitely had my challenges with some of the DDD concepts. Some of my issues were because the terms overlap with other technologies I use. For example, I do a lot of work with Microsoft\u0026rsquo;s ORM called Entity Framework. Entities are a key element in Entity Framework, and they\u0026rsquo;re also a key element in DDD. So I thought my understanding of entities from Entity Framework was enough to translate to DDD entities, but it really wasn\u0026rsquo;t, and my less than solid grasp on DDD entities caused problems when I was trying to model domains and implement the model and code. We also have the concept of a context in Entity Framework. While the real goal of that context is to provide interaction with the database, it also does provide a boundary around a model. But it\u0026rsquo;s very different than the concept of a bounded context, and that definitely confused me for a while. Another important element in a DDD model is value objects. These got me pretty confused at first, and my ego was saved by discovering that others have also been confused by value objects. But I\u0026rsquo;ve worked on my DDD education and sorted these problems out, so in this module, it\u0026rsquo;s really important to both Steve and I that you start off on the right foot with a proper understanding of entities, value objects, and some of the other DDD puzzle pieces so that Domain‑Driven Design can help you with your complex problems, not complicate them even more.\nFocusing on the Domain It\u0026rsquo;s important to remember that first D in DDD stands for Domain, and yeah, the other two Ds, Driven and Design. But we really want to focus on Domain here. ‑By now, you\u0026rsquo;ve probably heard us talk about this plenty, but both Julie and I find that we constantly have to remind ourselves to focus on the domain. We hear ourselves begin to talk about the user interaction with the app and have to ask, well, what part of the vet clinic domain is this user? Yeah, obviously we care about the user and how the actual application will work from their perspective, but that\u0026rsquo;s for another conversation, and we have to draw ourselves back to focusing on modeling the domain. ‑I have quite a long history with data access, and I catch myself worrying about how our domain model will translate to the database so that things definitely get persisted correctly. That\u0026rsquo;s when Steve needs to give me that look, you\u0026rsquo;re doing it again, Julie, and I have to bring my focus back to the domain of the vet clinic again. So while it may seem redundant to harp on domain, domain, domain, this diligent focus will help you avoid the complications and distractions that come from thinking outside of the domain or the subdomain that you\u0026rsquo;re focused on. ‑Here\u0026rsquo;s an important quote from Eric Evans\u0026rsquo; book about this focus on the domain. \u0026ldquo;The Domain Layer is responsible for representing concepts of the business, information about the business situation, and business rules. State that reflects the business situation is controlled and used here, even though the technical details of storing it are delegated to the infrastructure. This layer of the domain is the heart of business software.\u0026rdquo; ‑Just to reiterate, the domain model is the heart of the business software. This is the whole point behind Domain‑Driven Design. Focus on the domain, not the technical details of how the software will work. ‑In a typical database‑driven app, we\u0026rsquo;re used to focusing on properties or attributes of classes. Our apps sometimes become all about editing property values and the state of our objects. However, when we are modeling a domain, we need to focus on the behaviors of that domain, not simply about changing the state of objects. ‑Michelle didn\u0026rsquo;t talk to us about setting the name of a dog or editing the time of an appointment. She told us that she needs to schedule an appointment, and when she does that, she needs to book a room and create a schedule item on a doctor\u0026rsquo;s calendar as well. So scheduling appointment is a lot more than setting the attributes of the objects involved, the appointment time and identity of the pet we\u0026rsquo;re making the appointment for. We\u0026rsquo;re talking instead about how the system behaves. In response to scheduling an appointment, the system should also book a room and do something to the calendars of the doctor and any vet techs that might be involved.\nIdentifying Events Leads to Understanding Behaviors An important way to identify behaviors in your system is by focusing on events. Doing so gives you a great path to understanding the behaviors of your domain. Alberto Brandolini devised a great way to brainstorm with clients, which is referred to as event storming. It begins by having a somewhat chaotic brainstorming session with a good number of domain experts writing events on Post‑its and sticking them on a wall. The format of what they write is in the past tense. For example, an appointment was booked, a client contacted the office, or a dog was weighed in. I facilitated quite a few event storming workshops with clients, and I\u0026rsquo;m a big fan of using this process to help get a picture of the domain, discover bounded contexts, and even discover key problems that should be addressed. Another interesting methodology for modeling a system based on events is called Event Modeling. Adam Dymitruk came up with this workflow and has had great success using it to help teams collaborate on learning about the domain and designing the flow of software. I was fortunate to participate in a three‑day workshop with Adam to learn about Event Modeling. We won\u0026rsquo;t be teaching you about event storming or Event Modeling in this course, those are beyond the scope of our goals here, but we did want to be sure you were aware of them. You\u0026rsquo;ll find links for more information about event storming and Event Modeling at the end of this module.\nComparing Anemic and Rich Domain Models In order to understand the difference between design that\u0026rsquo;s focused on attributes versus design focused on behaviors, it will help to understand two commonly‑used terms in domain‑driven design, anemic domain models and rich domain models. An anemic domain model is a domain model that is focused on the state of its objects, which is the antithesis of DDD. While the term is somewhat negative indicating a deficiency, you don\u0026rsquo;t need to perceive it that way. There is nothing wrong with anemic classes when all you need to do is some CRUD logic, but if you are creating a domain model, you\u0026rsquo;ve already made the decision that your domain is too complex for simple CRUD. So anemia in a domain model is considered an anti‑pattern. ‑Martin Fowler writes about anemic domain models with such drama that you may never mistakenly use them in your domain model. He says the basic symptom of an anemic domain model is that at first blush it looks like the real thing. There are objects, many named after the nouns in the domain space, and these objects are connected with the rich relationships and structure that true domain models have. The catch comes when you look at the behavior and you realize that there is hardly any behavior on these objects making them little more than bags of getters and setters. Indeed, often these models come with design rules that say you are not to put any domain logic in the domain objects. Instead, there are a set of service objects would capture all the domain logic. These services live on top of the domain model and use the domain model for data. ‑What we aim for then is rich domain models, not anemic domain models when we are modelling our domain. Rich domain models will represent the behaviors and business logic of your domain. Classes that simply affect state are considered an anti‑pattern in a domain model, and therefore, get the nasty label of anemic, even though they are perfectly fine in a CRUD model. Martin Fowler doesn\u0026rsquo;t mince words when it comes to anemic domain models saying the fundamental horror of this anti‑pattern is that it\u0026rsquo;s so contrary to the basic idea of object‑oriented design, which is to combine data and process together. I have to say I agree and I\u0026rsquo;ve worked with many teams who have had to deal with the self‑inflicted pain of treating their domain entities like DTOs lacking any encapsulation or behavior. That can work for simple CRUD apps, but it\u0026rsquo;s often a disaster in a DDD model. ‑While Martin Fowler and other DDDers have strong words to say about anemic domain models, we\u0026rsquo;d like to share a gentler message, which is to strive for rich domain models and have an awareness of the strengths and weaknesses of those that are not so rich.\nUnderstanding Entities Even though a DDD app is driven by behavior, we still need objects. DDD expresses two types of objects, those which are defined by an identity and those which are defined by their values. We\u0026rsquo;ll focus first on the objects that are defined by their identity. These objects are called entities. ‑An entity is something we need to be able to track, locate, retrieve, and store, and we do that with an identity key. Its properties may change, so we can\u0026rsquo;t use its properties to identify the object. If you\u0026rsquo;ve done any type of data persistence in software, you\u0026rsquo;re probably pretty familiar with entities and their keys. When we are modeling a problem, we can talk about entities without having to think about how they are implemented in the resulting software. But when it is time to start coding, there are patterns to follow to ensure that these objects have the technical attributes of Domain‑Driven Design entities. ‑As you can see from this section of the DDD navigation map, entities are pretty integral to our software. So, before we can learn about these other elements, domain events, repositories, factories, and more, you should have a very good understanding of an entity. ‑The most important entity in our model is Appointment. This is what we will be creating, editing, and retrieving in the context of scheduling appointments. Appointment inherits from a base class we\u0026rsquo;ve created called Entity. We\u0026rsquo;ll look at that more in just a bit. Notice that all of the classes shown here are inheriting from the identity base class. However, although the other classes are entities, after our discussions with Michelle, we came to the conclusion that we would like to have a separate utility for managing client and patient information and to manage information about staff and staff scheduling. Thus, we don\u0026rsquo;t need very much information or behavior related to these collaborating entities within the bounded context of appointment scheduling.\nDifferentiating CRUD from Complex Problems that Benefit from DDD ‑Let\u0026rsquo;s take a closer look at that data that supports scheduling appointments in our system. ‑We determined that managing the client, patient, and staff information, which is external to this model, was well‑suited to just simple CRUD. We didn\u0026rsquo;t identify complex rules or behaviors for creating and editing that data. Thus, the concepts of doctors, rooms, clients, and patients are managed outside of the scheduling bounded context. ‑For comparison, look at the CRUD classes for Patient and Client in the other bounded context. They\u0026rsquo;re very simple. They don\u0026rsquo;t inherit from our entity base class, and most interestingly, their ID properties are integers. We\u0026rsquo;ll let the database assign the IDs when we create these classes. So these classes are not designed using domain‑driven design. Now let\u0026rsquo;s go back to the appointment scheduling context. The client, patient, doctor, and room classes here are completely different from the CRUD classes we just saw. However, they do have a subset of the same fields from those CRUD classes. All we need to know about these objects when we\u0026rsquo;re scheduling is their IDs, their names, and maybe a few other details. But here, they\u0026rsquo;re simply used as look‑up data, and they\u0026rsquo;reread‑only.\nSwitching Between Contexts in a UI Even though our domain is split up into a number of bounded context, the user interface can be designed in a way that moving from one context to another is seamless to the end users, they don\u0026rsquo;t need to know that these things are in separate bounded contexts. While maintaining client and patient data is a completely separate task from scheduling appointments, Michelle wanted to be sure that anyone working at the front desk is able to easily move between these tasks in the software without disrupting their workflow. So let\u0026rsquo;s say the person at the clinic who does the scheduling is on the phone with Kim and about to make an appointment for Roxy to come in, but then the other line rings, they put Kim on hold, and it\u0026rsquo;s me. And in the nicest way possible, I\u0026rsquo;ve called to just let her know they\u0026rsquo;ve got my last name spelled wrong. That happens all the time. People just want to put that h in there. Even though they\u0026rsquo;re in the middle of scheduling and scheduling has its own backend, its own bounded context, and is totally separate from client management, they can still drive the app right over to the Client Management area and very quickly fix my name and save that. Then they can just flip back to the schedule. Notice that Kim is still the active scheduling client that\u0026rsquo;s showing up in the left‑hand corner and the change to the spelling of my last name is already visible on the schedule. And so now that person can go ahead and finish up with Kim scheduling the very adorable Roxy for a wellness exam. To the user, there is no real difference between doing the scheduling and doing the client management, it\u0026rsquo;s just a nice smooth flow between the two, it doesn\u0026rsquo;t feel like, oh, now we have to open up a different application in order to do this other thing and doesn\u0026rsquo;t break everything they\u0026rsquo;re in the middle of, but for the purposes of designing our application, everything is bound within its own individual context. And when designing this context, we don\u0026rsquo;t have to worry about switching from one context to another. ‑So remember, we\u0026rsquo;re talking about what makes these all entities. An appointment object needs to be located and tracked and we need to be able to edit them easily. Using a unique identity allows us to persist and retrieve an appointment even if some of its values change. Appointment is definitely an entity in our system. We actually had to think a little more about client, patient, doctor, and room in this particular context. Our discussions highlighted the fact that when creating appointments, we only need access to some of the high‑level information about the client, patient, doctor, and room, but these objects won\u0026rsquo;t be edited. So we wanted these stripped down read‑only types that give us minimal amount of detail for each. We do still need to be able to uniquely identify them though, they do have some identity. If the client\u0026rsquo;s name changes, a change we would make in the client management system, that new name will need to be reflected when we look at the appointment scheduling for that client. There should only ever be one record to represent a particular client in this bounded context. So client and the other types that are reference types in this context are still entities. We triple checked our decision with another kind of domain expert, Vaughn Vernon, a DDD expert, and we were happy to get his thumbs up on this particular decision. So Julie, Michelle, and I also talked about how to name the types that are simply reference types in this particular bounded context. At first, we were worried that we might get confused by having different definitions of client, patient, doctor, and room. We wanted to call them client details or client view or something like that, but thanks to the ubiquitous language, the fact that we are in the scheduling context drives our comprehension of what a client means in this particular space. ‑A client in scheduling is still a client, so we use the same name, even though it\u0026rsquo;s a differently defined pipe than the client we work with in the Client/Patient Management app. ‑Right, and thanks to namespaces in our code, we\u0026rsquo;re able to keep it clear which ones are which in the code.\nUsing GUIDs or Ints for Identity Values So, all these types inherit from our base entity class. However, notice that those reference types use int for their base entity\u0026rsquo;s ID and not the GUID that\u0026rsquo;s used by appointment. That\u0026rsquo;s because all of the management of those other types happens to be done using CRUD, and with CRUD, it\u0026rsquo;s easy to just use database‑generated ints. Appointment is built using DDD principles, and you\u0026rsquo;ll see that it\u0026rsquo;s much easier to use GUIDs when building DDD entities and their related logic rather than relying on the database to provide the identity values. Not only is it easier, but it follows DDD principals more clearly, since we will build all of our domain logic around appointments without involving the database. We would have a hard time working with appointments in our model and in our unit tests as we develop the application if we always needed a database to assign their IDs. ‑So that\u0026rsquo;s not to say that you can\u0026rsquo;t use integer IDs If you\u0026rsquo;re going to use a DDD style of application; it just makes it a little harder. Wouldn\u0026rsquo;t you say, Julie? ‑Yeah, yeah, and I\u0026rsquo;ve definitely come up against that. With the stuff that I do with Entity Framework, I\u0026rsquo;ve made sure that I show patterns for continuing to use the database‑generated ints because I didn\u0026rsquo;t want to give people the impression that they had to throw away, like, for me like 25 years of this dependency. And like all of a sudden I have to go cold turkey and move over to GUIDs. ‑Sure, I mean, there\u0026rsquo;s trade‑offs in what you choose to use for your ID, but having an ID that we can generate in the client and just in our code has a lot of value. ‑Every time we\u0026rsquo;ve been working on some of our different unit tests and we needed as part of the test to instantiate something that was an int, we were like, ugh, now we have to find another way to get that in there because we were protecting it and it was a problem. As our own experience grew, we realized there\u0026rsquo;s another way to bridge this conflict by using both GUIDs and database‑generated ints in an entity. This way, while creating objects, you\u0026rsquo;ve got the control over key generation with the GUIDs, and they\u0026rsquo;re not depending on the database. However, once the data has been created in the database and int keys exist for it, then you can benefit from those when adding indexes and performing queries in the database.\nTalking with Eric Evans About the Responsibility of Entities We talked with Eric Evans to gain some additional insight into entities. Specifically, I asked him how entities align with the single responsibility principle. ‑‑If you\u0026rsquo;re not familiar with this object‑oriented programming principle, you can learn more about it in Steve\u0026rsquo;s SOLID course right here, on Pluralsight. ‑‑One of the questions that I\u0026rsquo;ve heard is, What is the single responsibility for an entity? Or to put it another way, does having an entity that has a lot of business logic in it violate the single responsibility principle? ‑‑Eric told us that entities are very central, and so it\u0026rsquo;s natural that they get heaped up with lots of functionality. ‑‑But there\u0026rsquo;s a downside to this. As you build out the system, there are more and more conflicting demands for these central entities, so they end up being huge. Evans said that the main responsibility is the identity and the lifecycle. ‑‑Eric also told us that single responsibility is a good principle to apply to entities, and it points you towards the sort of responsibility that an entity should retain. Anything that doesn\u0026rsquo;t fall into that category, we ought to put somewhere else.\nImplementing Entities in Code Let\u0026rsquo;s take a look at an entity in our veterinary appointment scheduling application, FrontDesk. We\u0026rsquo;re going to look at the Appointment class, which defines all the information that we need to schedule an appointment for a particular animal or patient. It associates the patient with the doctor, room, and appointment type, and also includes the start and end time for the appointment. Now, the Appointment class inherits from BaseEntity, which is a generic base class. In this case, it\u0026rsquo;s BaseEntity, as you can see here. The GUID is defining the type of our identity property, our ID. ‑Right. And we talked about that earlier when we were looking at the structure of the different entities in this model. We wanted Appointment to have a GUID because we\u0026rsquo;re creating new appointments on the fly. So, let\u0026rsquo;s take a look at that BaseEntity class. First of all, it\u0026rsquo;s an abstract class. So we can\u0026rsquo;t just create a BaseEntity object, we have to create something that is a BaseEntity, such as an appointment. And using generics, we\u0026rsquo;re saying that the BaseEntity is going to use whatever type we ask it to, and that type is for defining the ID. So for Appointment, we said BaseEntity is going to be using a GUID as its identity. I mentioned this earlier, why I would need GUID for appointment in this context because I need to be able to create new appointments in this context, and I\u0026rsquo;m not going to be waiting for the database to generate the ID for me. So using a GUID lets me create that ID right up front as I\u0026rsquo;m creating that new appointment. So I\u0026rsquo;m giving it its ID. The BaseEntity class also has a property to hold a list of domain events that will define explicitly for each of the types that inherit from this base entity. You\u0026rsquo;ll learn more about domain events further on in this course. ‑All right, so let\u0026rsquo;s take a look back at the rest of Appointment. Now, since Appointment has more behavior than just state, we don\u0026rsquo;t want to have it just be a bag of properties that our application can get and set however they would like. ‑Because that would be an anemic domain model. ‑Yes, because that would tend to lead us toward a more anemic domain model. ‑And we want a rich one. ‑Now, in particular, we\u0026rsquo;re also constraining how we create this appointment. We want to ensure we create appointments in a valid state, so that means passing in the minimum necessary elements an appointment needs to have. Sometimes we\u0026rsquo;ll want to update an appointment. Remember, these aren\u0026rsquo;t value objects. They\u0026rsquo;re not immutable, so we can change them. When we need to modify an appointment, we\u0026rsquo;re going to do that through methods. And so, for instance, if we decide we want to modify what room an appointment is scheduled in, we\u0026rsquo;re going to do that through a method rather than just a setter. We do this because there\u0026rsquo;s additional behavior we may want to do. In this case, we have some guards, again to ensure a valid value is being passed. ‑These guards are a set of reusable functions that you\u0026rsquo;ll find in the shared kernel of our solution. ‑And we also want to raise an appointmentUpdatedEvent, that we might handle and send a notification or perform some other action as a result of what happened. ‑And that also gives us the flexibility in the future to change what type of logic we want to trigger. ‑And that\u0026rsquo;s something we can\u0026rsquo;t do very easily If we just let anybody in the application set the value. ‑Right. ‑By providing a method to use to update room explicitly and otherwise making the setter private, we force all interaction with the model to use this method, which gives us just one place to model behavior that should be associated with this operation. It\u0026rsquo;s the same as with the constructor, we need to do our best to keep our domain model in a consistent state so the rest of the application can count on it being correct. ‑Right, because otherwise somebody could satisfy the requirement that they pass in the room ID, but they might pass it in as 0, which would be invalid. So, we\u0026rsquo;re further constraining that they don\u0026rsquo;t do that either. The appointment would be invalid if it had a room ID that didn\u0026rsquo;t correspond to an actual room entity. And in any case, the database wouldn\u0026rsquo;t let that fly since there\u0026rsquo;s a foreign key relationship between appointment and room. ‑Yes, but we want to make at least some effort to catch such problems in our code, rather than relying on the persistent store to inform us of a user error. Overall, using guard clauses, like the ones you\u0026rsquo;ve seen here, help us ensure our entities aren\u0026rsquo;t partially constructed and inconsistent. Once we\u0026rsquo;ve created an appointment, we need to record it as part of the clinic schedule, which involves some additional rich behavior. So, if we scroll down to the bottom, we have this method called Schedule. And this is where we\u0026rsquo;re going to do the additional work involved with actually saving an appointment and ensuring it fits in with other appointments that have already been scheduled. We\u0026rsquo;re not going to worry about the code at the moment, but the idea is that this method would query the database for other appointments that might be near this one and make sure there is an available slot in the schedule that this one fits into. Then it will save the appointment and raise an event, letting the rest of the app know that a new appointment has been scheduled. In the next module, we\u0026rsquo;ll investigate this design further and revise it a little bit. Now, let\u0026rsquo;s look at one more simple entity that this bounded context needs, the Doctor class. You can see that Doctor inherits from BaseEntity as well, but in this case it\u0026rsquo;s using an int for its key. The only other property it has is a string Name property. ‑This is a minimal implementation of the Doctor type that satisfies the scheduling bounded context. It\u0026rsquo;s essentially no more than a reference type. Doctor and the other similar types, Patient, Room, etc., are all organized into this folder called SyncedAggregates.\nSynchronizing Data Across Bounded Contexts Let\u0026rsquo;s dig a little more into how these reference types in the scheduling bounded context are getting their data from the Clinic Management app, especially if the two BCs aren\u0026rsquo;t sharing a database. If you recall from seeing the class descriptions of all of these classes, the AppointmentType, Client, Doctor, Patient, and Room, we had explicitly decided that these are reference entities where we\u0026rsquo;re actually doing their maintenance elsewhere so they\u0026rsquo;re not adding any unneeded complexity to the Front Desk application. ‑‑Right. And they\u0026rsquo;re just READONLY. So we\u0026rsquo;re never having to create or modify them. ‑‑And we\u0026rsquo;re using the ints that were created by the database when we persisted these with a CRUD context in a different application, but there are still entities here, just entities of type integer. The Clinic Management bounded context is responsible for updating these types. When changes are made, application events are published by Clinic Management, and this Front Desk bounded context subscribes to those events and updates its copies of the entities. ‑‑One of the questions we get all the time when we describe how bounded contexts have separate databases is, How do we synchronize changes between these two apps? This is one of the simplest and most common approaches. One app is responsible for updates, and the other apps just subscribe to the changes and are notified when they occur. ‑‑This is an example of eventual consistency. The two systems aren\u0026rsquo;t immediately kept in sync using a transaction or something similar, but through message queues, eventually the different bounded contexts are updated to the new state when a change is made.\nReview and Resources We\u0026rsquo;ve covered a lot of ground in this module and you\u0026rsquo;ve learned a lot of new terms, so we just want to review some of them with you before we move onto the next module. The first is a pair of terms that often go hand in hand, anemic domain models versus rich domain models. And remember the anemic domain models, while often looked down upon from the perspective of DDD, they\u0026rsquo;re perfectly fine for CRUD. These are models that look a lot more like a database schema than a class that has lots of methods and rich behavior in it. On the other side of that is a rich domain model, which is what we strive for in domain‑driven design, and that\u0026rsquo;s a model that really is focused on behavior, not just changing the values of properties. ‑Then we talked about entities and entities tend to be one of the core pieces of our domain model. The key thing that distinguishes an entity from other types in our model is that it has some kind of identity that we can use to track it over time and to bring it in and out of persistence. This module provided you with your first look at implementing a bounded context in code, an important part of tactical design. You learned about the difference between anemic models and rich models, and that while anemic models have their place, focusing on behavior with rich domain models is how DDD lets us solve complex problems. Entities are the classes in our domain models that are tracked by an identifier allowing us to build graphs and eventually persist and retrieve that data. ‑Sometimes we are working with entities whose behavior and rules are critical to the bounded context in which we\u0026rsquo;re working. Other entities may only provide supporting or reference data. You learned how to help identify the differences between them. Then you got to look at the appointment class in our scheduling app to see how we have applied rules and behaviors in that entity. You also looked at one of the reference entities and learned how we use message queues to ensure the reference and the data that is maintained in the clinic management app is made available to the scheduling bounded context, even though they do not share a database. ‑In the next module, we\u0026rsquo;ll focus on some more important elements of a domain model, value objects and domain services. We\u0026rsquo;ve referenced a lot of interesting and helpful resources in this module and here are two pages of links for you to follow up with if you want to dig in a little further, including Steve\u0026rsquo;s Pluralsight course on SOLID principles of object‑oriented design and information on event storming and event modeling. This is Julie Lerman ‑and this is Steve Smith, and thanks for watching our course, Domain‑Driven Design Fundamentals.\nUnderstanding Value Objects \u0026amp; Services in the Model Introduction and Overview Hello! I\u0026rsquo;m Julie Lerman. ‑And I\u0026rsquo;m Steve Smith. Welcome back to Domain‑Driven Design Fundamentals. In this module, we\u0026rsquo;ll continue exploring the elements of a domain model as we dig into value objects and domain services. ‑Value objects are a confusing concept. So we\u0026rsquo;ll begin by looking at where they fit into the mind map and introducing what makes an object a value object, and how they relate to entities in a model. ‑We\u0026rsquo;ll share some more guidance from Eric Evans and Vaughn Vernon, and then show how we\u0026rsquo;ve implemented value objects in our code. ‑Next, you\u0026rsquo;ll gain a high‑level understanding of domain services, and solidify that by exploring their features, and then some examples of domain services.\nGetting Acquainted with Value Objects When introducing entities, Steve and I talked about objects that were defined by a thread of continuity and identity, not defined by their values. So, what about objects that are defined by their values? These are called value objects, and they play an equally important role in a domain model, as entity objects do. ‑A value object has very specific characteristics. It is an object that is used to measure, quantify, or describe something in your domain. Rather than having an identity key, its identity is based on the composition of the values of all of its properties. Because the property values define a value object, it should be immutable. In other words, you shouldn\u0026rsquo;t be able to change any of the properties once you\u0026rsquo;ve created one of these objects. Instead, you would simply create another instance with the new values. If you need to compare two value objects to determine if they are equal, you should do so by comparing all of the values. Value objects may have methods and behavior, but they should never have side effects. Any methods on the value objects should only compute things; they shouldn\u0026rsquo;t change the state of the value object, since it\u0026rsquo;s immutable, or the system. If a new value is needed, a new value object should be returned. Don\u0026rsquo;t confuse the value object\u0026rsquo;s pattern with C# and .NET support for value types and reference types. Custom value types in C# are defined with structs, while reference types are defined as classes. In DDD, both entities and value objects are typically defined as classes. Classes have advantages over structs when it comes to encapsulation and support for inheritance‑based extension and reuse.\nRecognizing Commonly Used Value Objects To help you better understand the basics of value objects, let\u0026rsquo;s take a look at some value objects that you probably use all the time as a developer. The most commonly employed value object is a string. In .NET and many other languages, a string type is immutable, and you now know that immutability is one of the key attributes of a value object. A string is a collection of characters, and the combination of all those characters give that string meaning. For example, C‑A‑R in English, a car. If a string were mutable, we could change the R to T. Now the string is C‑A‑T, a cat, which has a very different meaning than a car. Or we could add a letter, maybe put an S in front of it, turning CAR to SCAR, also completely changing the meaning of car. But it\u0026rsquo;s not just the array of characters that gives a string its meaning, the order of them is also critical. Just think of the word dog, d‑o‑g. Shifting its letters around gives us something with a very different meaning. ‑So one of the things that .NET makes it really easy to do is to modify strings, like you can change the length of it or make one all upper case. But when you call, for example, ToUpper on a string, it doesn\u0026rsquo;t just change that string object, it gives you a new instance of a string that now has all uppercase characters. ‑Many developers say that monetary values in financial systems have been perfect candidates for value objects in their system. And Ward Cunningham provides us with a really helpful example, a company\u0026rsquo;s worth. If a company is worth 50 million dollars, that means something, 50 million dollars. It\u0026rsquo;s a very specific measurement. Fifty million on its own is not a measurement, it has no meaning without the unit, which in this case is dollars. But dollars alone doesn\u0026rsquo;t describe worth either. In fact, dollars doesn\u0026rsquo;t really help, does it, because is it US dollars or Canadian dollars, Australian dollars? It only makes sense when you put the two together as 50 million US dollars. There\u0026rsquo;s actually one more factor to take into account, is the point in time of this 50 million dollars because of the way financial systems work and the fluidity of monetary values. ‑We could still just have the two properties in this Company class, but by creating a value object you also protect and constrain the measurement. For instance, we might have a class called Company. It might have one decimal property that represents the worth amount and another string property that represents the worth unit. The problem with this approach is that it doesn\u0026rsquo;t tie these properties together in any way. These two properties appear to be independent of one another, but they\u0026rsquo;re obviously closely related. If an update is made just to the Worth Unit string, it could obviously have a tremendous impact on the company\u0026rsquo;s worth as a combination of these two concepts. Fifty million rupees has a very different worth than 50 million US dollars. To ensure nobody can set the unit without also specifying the amount, a separate value object can be introduced to represent the entire worth concept. This ensures the entire object must be updated as a whole. Since the worth type is immutable, the only way to make updates to the Worth property on the Company class is by replacing the whole instance with a new one, not just changing an isolated field. ‑A value object is not always for a measurement though. It can be another type of description. Eric Evans calls out dates as a great example for value objects. I\u0026rsquo;ve used this one often, DateTimeRange, and it was perfect for the vet appointment scheduling app. We usually set a start and an end time together and can\u0026rsquo;t really set one without the other. Also, we often need to pass the two values, start and end time, around from one method to another. So we\u0026rsquo;ve encapsulated them in a value object called DateTimeRange. The properties have private setters, which makes the object immutable since we can\u0026rsquo;t change them. We aren\u0026rsquo;t showing the full logic of the class here, but when we look at the value objects in our application you\u0026rsquo;ll see more of how we implement a value object in our software to ensure that it meets all of the attributes, not just immutability, but how we handle equality, comparison, and other logic.\nGetting More Insight from Eric Evans and Vaughn Vernon In his book, Implementing Domain‑Driven Design, Vaughn Vernon recommends that we should try to use value objects, instead of entities, wherever possible. He says, it may surprise you to learn that we should strive to model using value objects instead of entities wherever possible. Even when a domain concept must be modeled as an entity, the entity\u0026rsquo;s design should be biased towards serving as a value container rather than a child entity container. What this means is that you\u0026rsquo;ll find that your design will have a number of entities who have very little logic of their own or very few primitives as their properties, but instead will have a number of properties that each are themselves a value object. ‑So he\u0026rsquo;s not saying everything should be value objects, but that it\u0026rsquo;s probably our natural instinct to start by thinking of things as entities and then maybe once in a while go, oh, maybe that should be a value object. So what Vaughn is suggesting is really start by thinking every time should this be a value object and you will surprise yourself at how many times something that you originally might have thought of as an entity really does make a lot more sense as a value object. ‑Or sometimes when you\u0026rsquo;re looking at an entity, there might be a couple of properties that seem to always go together, you might be able to bundle these properties into a single value object. It\u0026rsquo;s interesting to note that identity values can be treated as value objects as well. In many systems, entities have a primitive type, usually int or GUID as their ID, but this means that it\u0026rsquo;s easy to substitute a client ID for a patient ID if developers are not careful. By creating actual value objects for client ID and patient ID, which can still be stored as ints or GUIDs, it can eliminate this kind of error from our design. ‑Here is an example of a Client class that\u0026rsquo;s inheriting from base entity, but specifying that the type will be ClientIdValueObject rather than a scalar type like int or GUID, that\u0026rsquo;s followed by a service class that has a CreateAppointmentFor method which takes a clientId and a patientId. If those IDs were both GUIDs, the runtime code would allow you to accidentally pass them in in the wrong order because the signature is only constraining that you pass in two GUIDs and that could create a big problem when you\u0026rsquo;re trying to build an appointment. But with the specialized value objects, you can tightly constrain the parameters to avoid this problem rather than adding a lot of extra logic elsewhere to protect you from making that mistake. For me, this highlights the beauty of DDD thinking. With this little bit of upfront work, you\u0026rsquo;re removing the complexity of solving the kind of problem that could be created by accidentally transposing the client id and patient id. In our conversations with Eric Evans, we asked him for his thoughts on putting logic into value objects. He told us that he thinks value objects are a really good place to put methods and logic because we can do our reasoning without side effects and especially the complications that identity brings along, all those things that make logic tricky. We can put functions on those value objects and then do the pure reasoning right there in the value object. ‑Eric also called out date libraries as a good example of a value object. They perform common functions on dates so we don\u0026rsquo;t have to keep coding them ourselves in our entities or services. For example, a date library could be used for calculating a person\u0026rsquo;s age from their birth date. As long as the library causes no side effects to the date in question, it can work well as a value object.\nImplementing Value Objects in Code Our primary demo involves scheduling appointments. Appointments have a start and an end time. These two things always go together, so they make sense to extract as a value object. Here\u0026rsquo;s a closer look at the DateTimeRange ValueObject we created for the course\u0026rsquo;s demo. We also have a DateTimeOffsetRange, which is identical, but includes support for time zones. Because DateTimeRange is a pretty low‑level concept that could be useful in a number of different applications, it\u0026rsquo;s implemented in the shared kernel package. The class inherits from a ValueObject base class that provides flexible equality checking behavior, so we don\u0026rsquo;t need to clutter our class with overloads for Equals, GetHashCode, et cetera. It was written by fellow author and DDD expert, Vladimir Khorikov. ‑Because this is a ValueObject, you can see that all of its properties are read only. Recent versions of C# and Entity Framework Core do allow us to avoid even having a setter in there when we want to define read‑only properties, and we also now have the use of records in C#. EF Core can comprehend read‑only properties that don\u0026rsquo;t have any setters at all, and it takes advantage of fields. But here we\u0026rsquo;ve written our value objects in a more generalized way that\u0026rsquo;s not taking advantage of any specific or specialized features. However, you can adapt these samples to benefit from those specific APIs and language versions that you\u0026rsquo;re working with. The important goal here, though, however you implement it, is that the state of the value object should not be changed once it\u0026rsquo;s been created and as part of the domain model. ‑Right. Value objects should get all of their state through their constructor, and any invariants that need to be checked should happen in a constructor as well. In this case, the date time range is guarding against having a start time that exceeds its end time. If it does, an exception will be thrown. The second constructor that takes a timespan calls the first one using constructor chaining, so in either case, the guard will always be enforced. Since the DateTimeRange is immutable and cannot be created in an invalid state, the rest of the domain model can count on it being valid. ‑Our DateTimeRange type does have some additional methods that let us create new DateTimeRange instances from existing ones, much like the DateTime type provides options to create new date times by adding time to an existing instance. In our type, for example, to change an appointment set to end at 10:30 instead of ending at 11:00, a new instance of DateTimeRange can be created using the newEnd method. Finally, the base ValueObject class requires overriding a GetEqualityComponents method. This is used when comparing two instances of the ValueObject, and it\u0026rsquo;s up to you to decide which properties should or shouldn\u0026rsquo;t be included. In the case of DateTimeRange, the start and end times are sufficient. If two DateTimeRange instances have the same start and end values, they should be considered equal. ‑Custom logic needed to determine whether one appointment overlaps with another is another area where the ValueObject can help. The whole appointment isn\u0026rsquo;t needed to determine if there is an overlap in appointments. Only the DateTimeRange is used in such a calculation. Thus, the Overlaps method, shown here, has been moved out of the Schedule and Appointment classes and into the ValueObject, where it is more reusable, and it reduces the complexity and responsibilities of the other domain types. ‑We asked Eric to share his thoughts on moving logic out of entities into value objects. He agreed that it\u0026rsquo;s a good idea. What he said was if there\u0026rsquo;s logic that\u0026rsquo;s really the classic software logic, I like to add that in value objects. You can really test value objects much easier than entities, and you can use them much more freely. So your entity becomes this critical piece of glue, an orchestrator among different value objects. But that doesn\u0026rsquo;t mean that you won\u0026rsquo;t have some logic in the entity. It\u0026rsquo;ll just be very concise. ‑Eric also said that it\u0026rsquo;s a nice way to work towards the ubiquitous language to the point where you look in the methods of the entity and you see higher‑level things. They read like use case level communication, rather than nitty gritty detail. My personal takeaway from this is to keep an eye on the properties of your entities, and specifically, their types. If you find that they\u0026rsquo;re all primitive types, like ints and strings, think about if any of those primitive things could be grouped together as value objects instead. Another value object that we can point out here is the AnimalType. This is just to give you an idea that our value objects can be extremely simple. In this case, AnimalType is just a combination of the species and the breed of a particular pet or patient that we\u0026rsquo;re dealing with at the vet clinic. And there\u0026rsquo;s not a whole lot of other behavior here. But it does provide us with a container by encapsulating these two related properties together as a single value object.\nUnderstanding Domain Services When an operation is important to the model but doesn\u0026rsquo;t necessarily belong on any one entity or value object, a service is often appropriate. But don\u0026rsquo;t be too quick to give up on finding a natural home for the operation on an existing entity or value object or you may end up with a very procedural anemic model. Frequently, domain services serve as orchestrators for operations that require several different collaborating entities or value objects. Evans notes that good domain services must first and foremost not be a natural part of an existing entity or value object. Again, we don\u0026rsquo;t want to shift all of our rich behavior from our entities and value objects to our services. Services should also have a defined interface that\u0026rsquo;s comprised of domain model elements. And finally, domain services should be stateless, though they may have side effects. What this means is we should always be able to simply create a new instance of a service to perform an operation, rather than having to rely on any previous history that might have occurred within a particular service instance. But of course, the result of calling a method on a service might result in changes to the state of the system itself. These rules apply specifically to domain services which belong in the core of our application. Your software will likely also use services to perform work related to infrastructure or as part of the front end of the application. ‑Here are some examples of the kinds of services we might find in different layers of a DDD application. The UI layer represents the front end of the system and should have as little business logic as possible. It is frequently combined with the application layer, which should be concerned with behavior necessary for the application, but unrelated to the customer\u0026rsquo;s problem domain. For example, the application may need to work with file formats or parse some XML, and it might have services for these purposes, but these are unrelated to the domain. In the core of the application where we store our core model and domain objects, we will define any domain services for operations that don\u0026rsquo;t belong somewhere else. These services will frequently involve operations on multiple domain elements or may be responsible for orchestrating some kind of workflow. For instance, processing an order might involve a series of steps and multiple domain elements as the system checks inventory, verifies customer information, maybe charges a credit card, and then sends messages to ship the order, notify the customer, and reduce inventory. Finally, we have infrastructure‑level services. These will usually implement interfaces that are defined in the core of the domain, such as I send email. But since they require access to external dependencies, like file systems, databases, or network resources, they live in the infrastructure layer of the system. With respect to our domain, you may find infrastructure not very interesting, ‑although the people who create the internal workings of those services might find them quite fascinating. We\u0026rsquo;ll look at implementing services in our application later on in the course.\nReview and Resources Let\u0026rsquo;s review some of the important terms you learned in this module. You heard us talk about immutability, which is a really critical attribute for value objects. And immutability just means once an object has been instantiated, you can\u0026rsquo;t change the value of any of its properties. ‑Another important term we learned about is the value object. A value object is an immutable class that is defined by the sum of the different properties that it has. We don\u0026rsquo;t need an identity for a particular value object. In fact, a value object doesn\u0026rsquo;t have any identity outside of the individual properties that it has. And in order for us to compare value objects, we simply compare all of its properties, and if they all match, then we can consider these two value objects to be equal. We also learned about domain services and these are interesting because domain services give you a place to put logic and behavior that you can\u0026rsquo;t find a home for in the entities and value objects in your domain. ‑And the last term that we want to review is side effects. Side effects are changes that occur in your application or any kind of interaction with the outside world. Now, technically any change to the state of the application can be considered a side effect, but generally when we\u0026rsquo;re talking about them, we\u0026rsquo;re talking about things that changed other than the main intent of the operation that you\u0026rsquo;re performing. For instance, it\u0026rsquo;s often a good idea to keep operations that query information separate from those that change state, and if you follow this practice, then any queries that you make, that result in changes to state would be said to have side effects. That brings us to this module\u0026rsquo;s key takeaways. Most of this module was focused on value objects, which are used in your domain model to measure quantify or describe something in the domain. Value objects typically don\u0026rsquo;t exist alone, they\u0026rsquo;re usually applied to an entity to describe something about it. ‑Value objects should be compared using only their values. They don\u0026rsquo;t have an identity. Any two value objects that share the same values should be considered equal. And value objects in our domain should be designed to be immutable taking all of their needed values in their constructor and they shouldn\u0026rsquo;t have any side effects. ‑We looked at a few examples of value objects in this module. We mentioned the .NET Framework string type that you\u0026rsquo;ve no doubt used. Strings and datetimes are value objects that are available to any .NET application and can be used as a model for how you should design your own value objects. We also looked at a couple of custom value objects we used in our sample application, the datetime range and the animal type objects. ‑Finally, we wrapped up the module by introducing domain services, which are used to orchestrate operations between different parts of your domain model. Remember that domain services should generally only be used if you don\u0026rsquo;t have an entity or value object where the behavior makes sense. Overuse of domain services can lead to an anemic domain model. In the next module, you\u0026rsquo;ll learn how to build aggregates from entities and value objects while respecting their relationships. Here are some links and resources relevant to the topics of value objects and domain services that we discussed in this module. Thanks for watching Domain‑Driven Design Fundamentals.\nTackling Complexity with Aggregates Introduction and Overview Hello, this is Julie Lerman. ‑And this is Steve Smith. ‑Welcome back to Domain‑Driven Design Fundamentals. In this module, you\u0026rsquo;ll learn more about aggregates and the associations between entities. ‑We\u0026rsquo;ve talked about the domain model and the need to have effective communication in order to ensure the model is a useful representation of the customer\u0026rsquo;s problem space. However, most problems that weren\u0026rsquo;t using domain‑driven design can be quite complex. So now we\u0026rsquo;re going to specifically look at some patterns and techniques that can be used to manage this complexity. ‑We\u0026rsquo;ll cover several new terms along the way, including aggregates and aggregate roots. You\u0026rsquo;ll learn about invariants and the aggregate roots\u0026rsquo; responsibility for them. Aggregates often contain related data, so we will explore how to model relationships, often referred to as associations in DDD. ‑Then, we\u0026rsquo;ll look at our application and see how thinking about the aggregate roots pattern helps us revise and simplify our model. ‑And finally, we\u0026rsquo;ll walk through how we\u0026rsquo;ve implemented this pattern in our code.\nTackling Data Complexity Let\u0026rsquo;s start by considering data complexity. If you\u0026rsquo;ve ever worked on a relatively large or mature application, you\u0026rsquo;ve probably seen some fairly complex data models. One way to reduce the complexity that we already talked about is using aggregates and aggregate roots, which you\u0026rsquo;ve seen in the DDD mind map. Another is by limiting how many bidirectional relationships you have in that data model. ‑If your design doesn\u0026rsquo;t have any clear notion of aggregates, the dependencies between your entities may grow out of control, resulting in a model like this one. And if your object model reflects a data model like this one, trying to populate all of the dependent objects of one object might result in trying to load the entire database into memory. And the same problem exists when it comes time to save changes. With a model like this, there\u0026rsquo;s just no limit to which areas of the data model might be affected. ‑Even though in the real world at the highest levels of your system all of these things really do interrelate, we need to be able to separate them to keep the complexity of the system in check. ‑I\u0026rsquo;ve gone into a lot of clients where their entity data model looks like this, and they\u0026rsquo;re using this one big, huge single model throughout their entire system. So, one of the things that I work on with them is breaking this down and using the whole concept of bounded contexts to start looking at what makes sense for smaller models. ‑Yeah, a system that\u0026rsquo;s designed like this is what we tend to call a big ball of mud because everything is just kind of slapped together, and it collapses under its own weight once it gets to a certain level of complexity. ‑Great. So, let\u0026rsquo;s see how we can use aggregates to help solve the problem.\nIntroducing Aggregates and Aggregate Roots Aggregates consist of one or more entities and value objects that change together. We need to treat them as a unit for data changes, and we need to consider the entire aggregate\u0026rsquo;s consistency before we apply changes. In the examples shown here, the address is part of the customer and the component is quite literally a part of the product. We can treat a set of changes to a customer and their address as a single transaction. Every aggregate must have an aggregate root, which is the parent object of all members of the aggregate, and it\u0026rsquo;s possible to have an aggregate that consists of just one object, in which case that object would still be the aggregate root. ‑In some cases, the aggregate may have rules that enforce data consistency that apply across multiple objects. For instance, maybe our product consists of a collection of components, but in order to be in a valid state, it needs to have a specific set of such components. As an example, if the product is a Lego minifig, the collection of parts won\u0026rsquo;t be a valid product unless it includes a head, an upper torso, a lower torso, two arms, two hands, and two legs. If we allowed the collection of components to be modified independently of the product it was associated with, we could easily end up with consistency problems. If we want to modify the composition of a product, in this example, we should do so as a transaction, so that we start and end with a valid product. Data changes to the aggregate should follow ACID, that is they should be atomic, consistent, isolated, and durable. It\u0026rsquo;s also the responsibility of the aggregate root to maintain its invariants, such as the number and type of components it requires in the example. An invariant is a condition that should always be true for the system to be in a consistent state. When considering whether particular objects should be treated as an aggregate root, you should think about whether deleting it should cascade, in other words, if you need to also delete the other objects in its aggregate hierarchy. If so, it\u0026rsquo;s likely the object in question should be considered an aggregate root. ‑Another way to think about whether it makes sense to have an object as an aggregate root is to ask, does it make sense to have just this object detached from its parent? In the example shown here, if you\u0026rsquo;re deleting the minifig, then you have to delete all of its parts. Conversely, if you have to delete a head, maybe it got broken, you don\u0026rsquo;t need to delete the rest of the parts. Therefore it doesn\u0026rsquo;t make sense for the head to be the root of this aggregate. ‑In the Domain‑Driven Design book, Eric Evans states this pretty simply, he says, an aggregate is a cluster of associated objects that we treat as a unit for the purpose of data changes.\nConsidering Associations in Aggregates When considering aggregates, which, as Evan says is a cluster of associated objects, it\u0026rsquo;s also important to think about relationships between those associated objects, especially those which exist within the aggregate. Before diving into how related entities participate in an aggregate, it\u0026rsquo;s important to learn some important concepts that DDD brings to us when considering relationships among entities. ‑Many developers, myself included, tend to define relationships between classes in both directions. For example, an order has a line item and a line item has an order, a pet owner has pets and a pet has an owner. Many of us tend to think in bidirectional relationships by default. Because domain‑driven design aims for simplicity in the model, we start recognizing more quickly that the bidirectional relationships can often make things overly complex. For instance, I\u0026rsquo;ve often found this to be true when it comes to adding in my persistence layer, and I happen to mostly use an ORM Entity Framework, which brings along its own behavior and assumptions about how relationships are managed. Sometimes the fact that my model includes navigation properties that may not be totally necessary can be the cause of some grief that\u0026rsquo;s led me to take some time to consider if I really need that navigation or not. ‑Domain‑driven design guides you to default to one way, or unidirectional relationships. That\u0026rsquo;s not to say that you shouldn\u0026rsquo;t ever have bidirectional relationships, but that because of the extra complexity involved, you should spend some time considering if that complexity is justified. ‑A relationship, also known as an association, should be part of a type\u0026rsquo;s definition, and we do that using properties that allow us to traverse from one end of the relationship to the other. In this example, we have a client type with a Patients property, and in a patient type, we have a Client property; not just an ID value, but a property that leads to a complete object or set of objects. If you introduce a bidirectional relationship, as shown in this code, using properties that let you traverse in both directions, you should only do so when neither object can be defined without the other. If that\u0026rsquo;s not the case, then you need to be specific about the direction of the relationship, also called the traversal direction, to keep your model design simple. ‑Eric Evans puts it this way, \u0026ldquo;A bidirectional association means that both objects can be understood only together. When application requirements do not call for traversal in both directions, adding a traversal direction reduces interdependence and simplifies the design.\u0026rdquo; ‑So with a DDDI, we can look at our model and ask, can we define a client without identifying their pets? Can we define a pet without identifying the client who\u0026rsquo;s responsible for them? ‑This may sound like a simple set of questions, but it could lead to a whole lot of debate. For example, why would a person be scheduling an appointment if they didn\u0026rsquo;t have a pet? So in the context of scheduling appointments, a client doesn\u0026rsquo;t make a whole lot of sense without one or more pets or patients. ‑Or from another perspective, a cat can\u0026rsquo;t pay a bill or call to make an appointment, so how can we define a pet without a client? These are both pretty reasonable arguments, but neither one gets us anywhere. ‑So, let\u0026rsquo;s start again with defaulting to a one‑way relationship. A client would need a patient to schedule an appointment. A client would not need a patient to pay a bill. ‑Okay, and if we started from the patient end, a patient doesn\u0026rsquo;t schedule an appointment, so that becomes a moot point. Nor does a patient pay the bill. And, you know, because my dog doesn\u0026rsquo;t have a credit card. He can\u0026rsquo;t use the phone very well, either. So, when would you start with a patient and need to know something about the client responsible for that patient? That\u0026rsquo;s an interesting question. So, in the context of scheduling an appointment, one could argue that we should define the traversal from client to patient and that we gain nothing by having a way to traverse from a patient back to a client. You may balk at that notion, but remember that all we care about right now is scheduling an appointment, not all the other possible scenarios where it might make sense to traverse from patient to client. ‑Sure. It\u0026rsquo;s another example of YAGNI, you\u0026rsquo;re not going to need it. In fact, we originally had owner as a property on patient in this context, but we realized it wasn\u0026rsquo;t necessary, so we removed it. However, we kept the ID because we had some scenarios where it was useful. ‑So in the end, we chose to define relationships that traverse from appointment to doctor, patient, and client, and to define one that traverses from client to patients or their pets, but not the other way. ‑You may have experienced another type of bidirectional relationship problem if you\u0026rsquo;ve seen related data gets serialized in your applications. When objects are serialized, the serializer typically traverses all of the object\u0026rsquo;s properties recursively, If there is a bidirectional relationship, it can create a loop that will cause serialization to fail. You can think of saving aggregates in much the same way, and in fact, depending on how your persistence layer is implemented, serialization may actually be required as part of how your app persists its aggregates. In our aggregates, the single direction that we would use would go from the root to its dependents, and never the other way around.\nHandling Relationships that Span Aggregates Aggregates serve as boundaries between logical groupings within our application. We enforce these boundaries by prohibiting direct references to objects within an aggregate that aren\u0026rsquo;t the root of the aggregate. Consider the customer with the address. It\u0026rsquo;s perfectly okay for customer to reference address. Address might be an entity, or it might be a value object; it doesn\u0026rsquo;t really matter in this scenario. What\u0026rsquo;s important, though, is that the only way to get to the address in this aggregate is through the customer. We won\u0026rsquo;t be referencing an address by some identity outside of this aggregate, but that\u0026rsquo;s not the case for customer. Since the customer is the aggregate root, it can be referenced from other aggregates. ‑In this common example, an order might reference a customer. Depending on our context, it might make sense for a customer to reference an order. In this case, let\u0026rsquo;s assume it only makes sense for the order to be central to the application\u0026rsquo;s design. What\u0026rsquo;s not okay is for the order to reference a customer\u0026rsquo;s address directly. This violates the integrity of the customer aggregate. ‑Remember that aggregates and aggregate roots only apply to objects, not data. And when we\u0026rsquo;re talking about references, we\u0026rsquo;re talking about object references, properties that use an object directly. This is especially important with ORMs. For example, if you were to save an address that had a customer object attached to the customer property, there are scenarios in which Entity Framework would involve the customer in the database INSERT or UPDATE, possibly even a DELETE. And this behavior leads to a lot of confusion. I frequently advise developers to just remove the navigation property and use the foreign key ID instead. It\u0026rsquo;s a little more work, but removing some of the ORM magic results in more control over the behavior. And this aligns perfectly with the fact that one common way to enforce aggregates is to replace direct navigation properties in the model\u0026rsquo;s non‑root types with key references, and this reduces the number of dependency relationships within the model.\nEvolving the Appointments Aggregate Since we\u0026rsquo;re dealing with appointment scheduling, our initial design might look something like this. An appointment involves bringing together a patient and a doctor in an exam room for a particular type of exam, and since we\u0026rsquo;ll typically need to know the owner\u0026rsquo;s information when we deal with the scheduling, it\u0026rsquo;s important to have a reference to the client from the patient also. So if we model our system this way, any time we saved an appointment, it\u0026rsquo;s going to scan all of these objects for changes and save them as well. So modeling it this way, the scope of our domain for appointment scheduling is much greater than it needs to be since, in our case, we don\u0026rsquo;t expect to modify any of the other objects when we\u0026rsquo;re creating an appointment. ‑Right, an appointment is basically just a list of resources tied to a particular timespan, it models who, what, when, and where, but it doesn\u0026rsquo;t ever need to change any of these associated concepts. As a result, we can simplify our design by eliminating most of these object relationships from the appointment classes designed. Recall that for an object to be a good candidate for being an aggregate root, it should be the case that deleting an object should also delete the other objects within the aggregate. In the design shown here, if a customer cancels an appointment and we delete it from the system, it doesn\u0026rsquo;t make sense that this should delete all of the associated objects. ‑So here is another perspective on that same model. By simply including the IDs of the related concepts rather than object references, we\u0026rsquo;re able to ensure that creating and changing appointments has a minimal impact on our system when we persist the appointment. This relationship works because an appointment in the real world is really just a note that includes a place, time, and additional details. Adding and removing appointments shouldn\u0026rsquo;t impact the people and places involved, and this revised design reflects this.\nUsing Invariants to Better Understand Our Aggregate We do still have a bit more learning to do with this model though. Somewhere in our design, we need to enforce certain invariants about appointments like that they shouldn\u0026rsquo;t be double booked. Our current thinking is that appointments need to include this rich behavior with regard to how they\u0026rsquo;re scheduled. It\u0026rsquo;s the aggregate roots responsibility to verify any invariance the aggregate may have, and in this case, the appointment is still acting as an aggregate root, even if we have eliminated the navigation properties to the other objects that it might be working with. Let\u0026rsquo;s make sure we\u0026rsquo;re clear on invariants and then we\u0026rsquo;ll see how invariants in our application impact our design. An example of an invariant in the real world is the speed of light, which is a constant that you just can\u0026rsquo;t break in terms of the physics of the universe as we know it. Some things in your system must be true in order for the model to be consistent or valid. Other examples of invariants might be that the total of the items on a purchase order do not exceed the PO amount, or that appointments do not overlap, or that an end date on an object must follow the begin date on that object. Sometimes an invariant only involves a single object, maybe a particular property or field such as name is required. In this case, we may model the system such that one can\u0026rsquo;t even create the object without the required information. Our value objects are like this. For example, you can\u0026rsquo;t create an instance of a datetime range object without defining both the start and end time. However, sometimes the invariants involved how multiple objects relate to one another. ‑In the example here, the purchase order and the individual line items would most likely be modeled as separate objects, however, the purchase order would be the aggregate root, and as such, it would be responsible for verifying this invariant. The individual line items on the purchase order probably don\u0026rsquo;t know anything about one another nor should they, so it wouldn\u0026rsquo;t make sense to put the responsibility for enforcing this invariant in the line item object. What about appointments? How does one appointment know whether it overlaps another?\nModeling Breakthroughs and Refactoring As we focused on these invariants and where they belong in our design, it became clear to us that the appointment didn\u0026rsquo;t really make sense as an aggregate root. If you apply this thinking to our appointment scheduling context, it follows that one appointment doesn\u0026rsquo;t really know anything about other appointments, but the schedule knows about such things. Let\u0026rsquo;s evolve our domain model to follow this pattern and see where that leads us. ‑This feels like a big change to the model, and these kind of epiphanies happen when you\u0026rsquo;re working on the model. But that\u0026rsquo;s not a bad thing. It\u0026rsquo;s not like you\u0026rsquo;ve wasted a lot of time focusing on appointment as an aggregate root. This is the beauty of modeling your domain, having conversations with different people, with the domain experts, because ideas like this bubble up, and suddenly, something big like this becomes clear. So, you\u0026rsquo;re not going to get it 100% right the first time. Your understanding will evolve as you learn more about the domain. And from time to time, you\u0026rsquo;ll realize there are big changes that can dramatically improve your design. In the Domain‑Driven Design book, Eric Evans talks about these breakthroughs in his section about refactoring toward deeper insight. This is really an important part of domain‑driven design, and about a quarter of the book is dedicated to it.\nRecognizing Signs of a Misidentified Aggregate Let\u0026rsquo;s take a look at the signs that Steve and I eventually recognized in our domain, which led us to shift our appointment aggregate to a schedule aggregate. ‑Originally, our solution had the appointment as the central focus of the design. I had figured it would be its own aggregate with appointment at the root and its various properties as its children. As we\u0026rsquo;ve just discussed, that doesn\u0026rsquo;t really work as well as I\u0026rsquo;d hoped, so now we\u0026rsquo;re refactoring the design to introduce a new type, the schedule. Before we show that, though, let\u0026rsquo;s review the original structure and some of the reasons it didn\u0026rsquo;t work as well as an aggregate in our solution. ‑You can see the original structure had appointment in its own folder and marked with the IAggregateRoot interface, which is required for it to be accessible from our repository methods. It has essentially the same properties as the later version, except for ScheduleId, since there\u0026rsquo;s no schedule type yet. And it has the same basic set of methods for modifying its room, doctor, time, and other properties. None of that really changed since all of those operations only had to deal with this single appointment instance. ‑However, when the appointment tried to enforce the invariant that appointments whose times overlap for the same pet should be marked as potentially conflicting, things were a bit messier. You see, this appointment doesn\u0026rsquo;t actually have any association with any other appointments, so the only way to enforce this is to use a repository to get those other appointments for the same date as this one. Since entities don\u0026rsquo;t support dependency injection through their constructor, this means an instance of the repository needs to be passed into this method. Creating this repository instance was the responsibility of the calling code, which may not otherwise have needed it. Note also that because the repository\u0026rsquo;s interface is async, this method must now be async as well, even though no other methods on the appointment entity are async. ‑The real problem here, from a DDD perspective, is that cross‑aggregate invariants should not be enforced by any one aggregate. In the case of something like a unique constraint between all aggregates, you might need to use a domain service, or another approach. However, in other cases, the need to do this may indicate that you\u0026rsquo;ve missed an important part of your model. ‑Right. In this case, the whole thing that the user is interacting with is the clinic schedule, but nothing in our original model referred to the schedule itself. Since some of our business rules, like what to do with appointments that conflict, only make sense at this higher level, it made sense to introduce a change to our model, the schedule aggregate.\nConsidering Schedule as Our New Aggregate So, even though the initial design we had was about scheduling, the schedule itself was never part of our model. Once we include schedule as its own explicit object in our model, it makes the design much simpler. Appointments no longer need to know anything about other appointments. The responsibility for ensuring that appointments are not double booked and similar invariants can be performed by the schedule, which is the aggregate root. ‑So, let\u0026rsquo;s see if this passes our other tests about defining aggregate roots. A schedule will certainly help us ensure that appointments don\u0026rsquo;t overlap one another. When we save changes to a schedule, does it make sense to update any changed appointments? Yes, it does make sense. And if we were to delete an entire schedule, would it make sense to delete all of its appointments? Yeah, I think that would make sense also. ‑Yeah, I think this is the schedule for a particular clinic. At the moment, we only have one clinic, but if we imagine a scenario in which multiple clinics each have their own schedule, it wouldn\u0026rsquo;t make sense to delete a clinic\u0026rsquo;s schedule but then keep its appointments floating around. So I think that works. ‑Great. And if a schedule exists for each clinic, then it makes sense to persist the schedule, which means that it needs an ID, and therefore is truly an entity. And when we retrieve a schedule, we\u0026rsquo;ll most likely be filtering which related appointments we want to look at, for example today\u0026rsquo;s schedule or this week\u0026rsquo;s schedule. That would mean we want all of today\u0026rsquo;s or all of this week\u0026rsquo;s appointments from a particular clinic\u0026rsquo;s schedule. It really does make a lot more sense to me to tie the appointments to a schedule than directly to a clinic. Now, let\u0026rsquo;s see how this effects our design.\nExploring the Schedule Aggregate in Our Application Now I\u0026rsquo;ll show you the new schedule aggregate implementation in our application. In the refactored solution, we\u0026rsquo;ve renamed the folder so that now it\u0026rsquo;s ScheduleAggregate. This folder only includes schedule and appointment, as well as related guards and specifications. In larger applications, it can help to organize your domain model by grouping everything related to a particular aggregate in its folder. Looking at the ScheduleAggregate\u0026rsquo;s code, you can see that it inherits from our common BaseEntity type and uses a GUID for its id key, just like appointment. This lets us set the key ourselves, rather than relying on a database to do it for us. The class is also marked as an aggregate root with an interface. In the next module, you\u0026rsquo;ll see how we use that to protect the integrity of our aggregates. ‑Right. We\u0026rsquo;ll see how that works when we look at our repository and specification implementations. ‑Next, the Schedule\u0026rsquo;s constructor just takes in its id, its dateRange, and its associated clinicId. In our sample, the clinicId is always hard‑coded but in a real application, there might be several clinics using the same software, and they would each have their own ids. The constructor is responsible for ensuring that the incoming values are valid so that it\u0026rsquo;s always created in a consistent state. Schedule has just a few properties. There is the ClinicId, the associated set of appointments, and the DateRange. We\u0026rsquo;re careful to only expose a read‑only IEnumerable of appointments because our aggregate must encapsulate its internal state. We don\u0026rsquo;t want other parts of our application to add or delete appointments without going through the schedule\u0026rsquo;s explicit methods designed for this purpose. Also, the date range isn\u0026rsquo;t persisted since it can vary with any given instantiate ation of the schedule. ‑Yeah, and for performance reasons, you wouldn\u0026rsquo;t really want to load the ScheduleAggregate with every appointment that had ever been made included in it. By using a property like this, we make it clear to the rest of the domain what set of dates this instance of the aggregate holds. The actual population of the appointments that match this range is left as a responsibility of the specification and repository classes that are used to retrieve the schedule from the database. ‑Yes. And the configuration of the aggregate\u0026rsquo;s persistent details is done in the infrastructure project\u0026rsquo;s Data Config folder. This is where every entity\u0026rsquo;s EF Core‑specific mappings and configuration is performed, which keeps these details out of our domain model. You can see here that we\u0026rsquo;re also letting EF Core know that we don\u0026rsquo;t want the database to supply an id when we create a new schedule. We\u0026rsquo;ve marked that property as ValueGeneratedNever. ‑Getting back to the schedule, let\u0026rsquo;s have a look at its methods. The first method is for adding new appointments. Our design forces all new appointments to come through this method, so we don\u0026rsquo;t have to have duplicate behavior anywhere else in the application to take care of whatever should happen when a new appointment is added. It\u0026rsquo;s all right here in one place, easy to understand, and easy to test. The method validates the inputs to ensure we\u0026rsquo;re not adding bad data to our aggregate, and then it adds the appointment. When a new appointment is added, the schedule is responsible for marking any appointments that might be conflicting. It\u0026rsquo;s the right place for this behavior to live, since the schedule knows about all the appointments and knows anytime appointments are added or removed. After marking any conflicts, an appointmentScheduledEvent is added to the aggregate\u0026rsquo;s event collection. We\u0026rsquo;ll see how this works in the module on domain events. The DeleteAppointment method is similar. After deleting an appointment, the schedule needs to once more mark any appointments that might be conflicting. There\u0026rsquo;s also a TODO comment here. These are left as exercises for you to learn more about how to work with the patterns introduced in this course. You\u0026rsquo;ll find a number of TODO exercises scattered throughout the sample. ‑We hope you\u0026rsquo;ll take some time to download the code, run it locally, and try implementing some of the TODO tasks using the existing functionality as a guide. There are a couple more in the MarkConflictingAppointments method, which, remember, was originally on the appointment type when we started out with that as its own aggregate. This method is responsible for detecting and marking appointments that might conflict. The basic rule, shown here, just checks whether the patient has two appointments that overlap. If any such appointments are found, they are updated to set their conflicting property to true. Then, the current appointment\u0026rsquo;s property is set based on whether there are any other appointments that conflict with it. ‑This is an important part of the business logic for this application, and it\u0026rsquo;s encapsulated right in our schedule aggregate. In a lot of data‑driven applications, this kind of logic might be in a stored procedure, or perhaps just implemented in the user interface. But in a domain‑driven application, we want these rules to be explicit and defined in our domain model. ‑The last method on schedule provides a hook for its appointments to use to notify it when changes are made to one of them. Because we don\u0026rsquo;t have navigation properties from appointment back to schedule, we can\u0026rsquo;t directly call methods on the aggregate root from appointment methods. There are a few different patterns we can use to accomplish this task. For this sample, we chose this one because it\u0026rsquo;s simple and easy to follow. This handler simply calls MarkConflictingAppointments, but it\u0026rsquo;s exposed as its own separate method because it could do other things as well, and we don\u0026rsquo;t want to expose the internal behavior of the schedule to the rest of the app. To see how it\u0026rsquo;s used, let\u0026rsquo;s look at the appointment class\u0026rsquo;s UpdateStartTime method. When the application needs to update the start time for an appointment, it will call this method. Because appointment is part of a scheduling aggregate, we know the app will already have loaded the schedule before calling this method. So the second parameter in the method asks for the handler on the schedule that will be called. The call to update the schedule is made after updating the TimeRange property on the appointment, so when mark conflicting appointments is called, it will use the new value for the time range. There are a lot of other ways you can set up this communication, using C# events, static domain events, or some kind of double dispatch approach. They all have trade‑offs, and when you need to do this in your apps, you should choose the one that works best for your app and your team. ‑Let\u0026rsquo;s see the final result in the application. This change to our model of adding in a schedule aggregate made a big difference to how the domain model is organized. It gave us a much better place to put the logic of enforcing business rules around combinations of appointments and business logic that needs to run when appointments are added or removed. ‑Right. Without the schedule, we would have had to use a domain service or something to add behavior around the newly added or removed appointments. But with this design, we can go into the schedule, add a new appointment for Rosie, and then add another one, and you can see the notifications being triggered by the events, as well as the red outline representing the conflict in these two appointments. Not only is our domain model clean and easy to test, but even more important, it actually works! ‑And notice that as we move one of those conflicting appointments to another spot, the red alerts disappear. Good job, Steve! I am so grateful that you let me off the hook for working on the front‑end of this application. You know I\u0026rsquo;m more of a back‑end developer.\nSharing Our Tips for Aggregate Design So let\u0026rsquo;s step back a moment and review some of the things we\u0026rsquo;ve just learned about designing aggregates. First of all, aggregates exist to reduce complexity. You might not always need an aggregate. Don\u0026rsquo;t add complexity just for the sake of using an aggregate. Another is that entities with an aggregate can only reference the root entity of another aggregate. ‑But you can always use foreign key values as a reference to entities inside another aggregate. It\u0026rsquo;s perfectly okay to use this, and it will avoid the need for when you go to save that aggregate for it to cascade its persistence into other aggregates. If you find you\u0026rsquo;re needing to use a lot of foreign key references to aggregate children often, you may need to reconsider the design of your aggregate in your domain model. ‑Another pointer was don\u0026rsquo;t be afraid to have an aggregate of one, in other words, an aggregate that only has one object in it. ‑And finally, don\u0026rsquo;t forget the rule of cascading deletes. Remember, one test for whether or not a particular object makes sense as an aggregate root is to consider whether deleting that object should also delete all of the other child objects in that object\u0026rsquo;s hierarchy. If it doesn\u0026rsquo;t, then you have probably chosen the wrong structure for your aggregate.\nReview and Resources Once again, we have covered quite a bit in this module. Let\u0026rsquo;s review some of the terms that you learned in this video. The first thing we talked about was an aggregate. An aggregate is a group of related objects that work together in a transaction. The root becomes the entry point through which you do any work with the aggregate, and the root also is what\u0026rsquo;s in charge of making sure that all of the rules that apply to that graph of objects are met. ‑Each of the rules that describes the state that the system must be in in order to be valid is called an invariant. Within our aggregates, we have objects that are related to one another. In DDD, we refer to these relationships as associations. If you use an ORM, you may hear the term navigation properties, which refers to those properties that reference the related objects in the model. And we talked about the importance of defaulting to one‑way relationships, which we also refer to as unidirectional relationships. ‑In addition to these important terms, Steve and I shared a lot of guidance around creating aggregates and roots in your domain models. Nobody wants to work with a big ball of mud. We use aggregates to organize our model. An aggregate is a set of related objects that live in a single transaction while encapsulating the rules and enforcing invariance of that transaction, making sure that the system is in a consistent state. When designing how related objects work together, your job will be easier with one‑way relationships. Use those as a default, and only introduce bidirectional navigation if you really need to. ‑And most importantly, don\u0026rsquo;t resist updating your model as you and your team of domain experts learn more about the domain. Hopefully, most of this will happen early on, and then just once in a while you might have a big breakthrough, like we did when we realized that the schedule made more sense as an aggregate root than trying to have each appointment be its own aggregate. Up next, you\u0026rsquo;ll learn about repositories which are a critical pattern in domain‑driven design. This is Steve Smith, ‑and I\u0026rsquo;m Julie Lerman. Thanks for watching Domain‑Driven Design Fundamentals.\nWorking with Repositories Introduction and Overview ‑Hello. I\u0026rsquo;m Julie Lerman. ‑And this is Steve Smith. ‑In this module of Domain‑Driven Design Fundamentals, you\u0026rsquo;ll learn about repositories, another critical pattern for Domain‑Driven Design. ‑We\u0026rsquo;ll start by defining what repositories are, and then we\u0026rsquo;ll provide some tips for working with them, as well as talking about some of their benefits. There are different ways to define repositories and plenty of debate around their use. We\u0026rsquo;ll address some of these points. ‑Next, we\u0026rsquo;ll introduce you to the specification pattern and how it can be really helpful when you\u0026rsquo;re implementing repositories. Then we\u0026rsquo;ll open up Visual Studio again and show you how we\u0026rsquo;ve implemented some repositories in the scheduling app.\nIntroducing Repositories ‑Now, Julie, if this were an in‑person class, I\u0026rsquo;d definitely ask for a show of hands who has heard of the repository design pattern. I would expect most hands to go up. ‑I hope so too. I think the repository pattern is by far the most popular element of DDD to be practiced outside of Domain‑Driven Design. They can be valuable in so many applications as a way to simplify data access and enforce separation of concerns. When I began learning about repositories and implementing them in my own software design, it had a huge impact on my application architecture. Along with automated testing practices, it really forced me to consider separation of concerns with each method and behavior added to my software. ‑Personally, I love the pattern, and I find it makes it much easier for me to write good, testable code. We\u0026rsquo;re going to talk about using repositories within a DDD application, but if you want to learn more about the pattern itself, you can look in the design patterns library, and I know Julie also discusses using them with Entity Framework in her Entity Framework in the Enterprise course. ‑You can see the repositories are part of the DDD mind map, as they\u0026rsquo;re used to access entities and aggregates. Any system that needs to persist between restarts has some kind of persistent storage for the state of the system, like a database. Many applications focus a great deal of effort on the mechanics of querying, fetching, and translating data to and from objects to the point where it distracts from the model that these objects are meant to represent. And having ad hoc access to the data source also promotes having developers query for any bit of data they want anytime they want, rather than using aggregates. This makes it pretty difficult to manage the consistency of aggregates by enforcing their invariants. At best, the logic for enforcing the integrity of the model becomes scattered among many queries, and at worst, it\u0026rsquo;s not done at all. ‑Applying Model‑First design and separation of concerns means pushing persistence behavior into its own set of abstractions, which we refer to as repositories. Only certain objects, like specifically aggregate roots, should be available via global requests. Repositories provide this access, and through omission, prevent access to non‑aggregate objects, except through their aggregate roots. They give you the ability to constrain the data access, so you avoid lots of random data access code throughout your application. ‑When you think about the life cycle of an object in your application, you should consider two cases. In the first case, you have objects that are not persisted. These objects are created, perform some work, and then they\u0026rsquo;re destroyed. In the second case, you have objects that are persisted. These objects have a slightly more involved lifecycle since after the object is created, it must be reconstituted with whatever state it had when it was last saved. Then it can perform whatever work the application needs it to do, after which it may need to save its state to some persistent storage before finally being destroyed. You can use repositories to manage the lifecycle of your persistent objects without the objects having to know anything about their persistence. We call these objects persistence ignorant because they\u0026rsquo;re ignorant of how they\u0026rsquo;re stored into and retrieve from a data store. ‑In his book, Domain‑Driven Design, Eric Evans speaks quite a bit about repositories. They can be summed up by saying that a repository represents all objects of a certain type as a conceptual set, like a collection with more elaborate querying capability.\nRepository Benefits ‑Repositories can add a number of benefits to our application. First of all, they provide a common abstraction for all of our persistence concerns, which provides a means for clients to very simply obtain model objects and to manage their lifecycle. They also promote separation of concerns. The domain logic and the user interface can both vary independently from the data in the back‑end data source that is used by the application. ‑The public interface of a repository very clearly communicates our design decisions. Only certain objects should be accessed directly, so repositories provide and control this access. Another important benefit is that repositories make it easier to test our code. They reduce tight coupling to external resources like database, which would normally make unit testing difficult. Having a repository separate from client code and domain logic means that we can easily make improvements to optimize data access for this application, tuning for performance, adding caching behavior, etc. is all much easier and safer when the code for data access is all encapsulated in one or more well‑known classes. All of this makes your code easier to maintain.\nRepository Tips ‑Here\u0026rsquo;s some basic guidance you should keep in mind when designing repositories. First, a repository should have the illusion of a collection of a specific type of object. You\u0026rsquo;ll be adding the objects to the collection, removing them, and retrieving objects from the collection, but that it is an illusion of a collection is important to keep in mind. When you interact with the repository, these are the types of methods you\u0026rsquo;ll be calling, add, remove, and retrieve. Your calling code doesn\u0026rsquo;t care how the repository performs those actions. So in the repository, you might have code that responds to a retrieve method, goes out to a database and gets data, but it could be getting data that\u0026rsquo;s already in memory, or it might be grabbing data from a text file on your computer. ‑Another important recommendation for repositories is to set up access through a well‑known global interface. That way, developers that need to interact with the repository will be familiar with a common pattern for using it. ‑Here\u0026rsquo;s a simple repository interface example. Depending on the size and complexity of your software, you may have a few layers of interfaces. ‑For example, if you anticipate having a number of repositories for a schedule aggregate used in different bounded contexts, you might want an IScheduleRepository interface that not only implements the lower‑level interface, but defines some other methods or properties that every schedule repository is required to have regardless of the bounded context it might reside in. Because a repository acts like a collection, you\u0026rsquo;ll want methods to add and remove objects to encapsulate the underlying data insertion and deletion operations. We\u0026rsquo;ve got these defined in our IRepository. It is up to each concrete implementation to define how add and remove will actually work. ‑It\u0026rsquo;s not unusual to need to add specific query methods to individual repositories. Whether you need a custom subset of entities or a specific way to load entities\u0026rsquo; relationships, custom methods are a simple way to achieve this. For example, if we wanted to fetch a schedule instance with all the appointments for a given day, we could add a method to the ScheduleRepository that might have an EF Core implementation like this one. ‑Likewise, if we just wanted to be able to fetch a client with their patients, we could add a method like this one, which will eager load the patients when it loads the client. Be careful with this approach though, as it can grow out of hand, and your repositories may end up with many different query methods. A simple way to address this is to use specifications instead, which we\u0026rsquo;ll cover later in this module. In addition to these specific tips for implementing repositories, you should also keep in mind these more overarching tips. First, be sure to provide repositories only for aggregate roots that require direct access. And next, keep the clients focused on the model, while delegating all of the object storage and access concerns to the repositories.\nAvoiding Repository Blunders We\u0026rsquo;re not always going to land on the happy path, so we do want to share with you some common problems that you might run into, how to recognize them, and most importantly, how to avoid them. ‑Remember your client code can be ignorant of the implementation of your repositories, ‑but developers cannot. ‑It\u0026rsquo;s important that developers understand how your specific repository is implemented, otherwise, they can run into a number of different problems. ‑So we\u0026rsquo;re talking about not just the developers who are implementing the repository, but also the developers who are using the repository. ‑One of the common repository problems the developers working with repositories often encounter is called an N+1 query error. This is where in order to display a list of rows from the database, you end up calling one query to get the list and then a number of queries equal to the count of that list to fetch each item individually. ‑Another one that I see a lot is when people are fetching related data. With Entity Framework, they\u0026rsquo;re either using eager loading or lazy loading, and especially with lazy loading, there are a lot of developers who don\u0026rsquo;t really know what to expect from it and just because it\u0026rsquo;s easy and it just works, they use it and then run into all kinds of problems because of it. ‑And depending on how your data is structured, sometimes if you\u0026rsquo;re trying to fetch just one or two properties that are represented in a particular column in a data table, you might end up fetching more data than required if you pull back the entire row which might include dozens of columns and a lot of actual data there. These are things that knowing how your underlying data is persisted and how your repository is implemented, how those things work, can make a huge difference in your application. ‑Most of these blunders impact how data is accessed in a data store and that means that one of the best tools you have for surfacing these problems is profiling your data store. Many of the IDEs we use for managing databases have profilers built in, some examples are SQL Server Profiler, Jetbrains DataGrip, and Azure Data Studio. Many of the APIs we use also have logging capabilities that can relate database activity. As a .NET developer, I often use the .NET Core logging API or some of the features built into Entity Framework Core, but most any language you use can do this and all of the cloud providers have ways to trace activity in their various data stores. There are even third‑party tools dedicated to database profiling. The suite of profilers from Hibernating Rhinos is a great example. They have profilers for RavenDB, Azure CosmosDB, and the EF Core, and Hibernate ORMs.\nAddressing the Debates Around Using Repositories Many developers have strong opinions about the use, and some might say overuse, of the repository design pattern. Let\u0026rsquo;s consider some of the common arguments made about repositories. It\u0026rsquo;s worth remembering that like Bjarne Stroustrup\u0026rsquo;s famous quote about programming languages, there are two kinds of design patterns, too. It\u0026rsquo;s no surprise, really, that as the repository pattern grew in popularity, that there would be many complaints about when and how to implement it. ‑Here\u0026rsquo;s one that really gets me. EF Core, the .NET ORM which we\u0026rsquo;re using this course, has a built‑in repository for its data access. It\u0026rsquo;s called the DbContext. I\u0026rsquo;ve heard and read comments from so many people who say never use a repository on top of EF Core because it already has a repository built in. And then I hear others who say you should always use a repository to interact with EF Core. I am not a fan of the words always and never. Maybe it\u0026rsquo;s because I\u0026rsquo;m a libra, who knows. So, these strongly held opinions really frustrate me. What Steve and I want to do here is give you the information you need so that you can make educated decisions about when to use repository and when to opt for something else. ‑Let\u0026rsquo;s remember for a moment what repositories are and where they live in a domain‑driven application. Repositories are abstractions. They\u0026rsquo;re part of your domain model. They define the persistence operations the model will use. That\u0026rsquo;s it. There\u0026rsquo;s nothing in the domain model patterns produced through model‑driven design espousing the use of Entity Framework, or NHibernate, or any other specific vendor tool for doing persistence. It doesn\u0026rsquo;t even know if you\u0026rsquo;re doing Java or .NET. It\u0026rsquo;s meant to be totally abstract and just types. ‑The domain model should be persistence ignorant, and it shouldn\u0026rsquo;t depend on implementation details. ‑Right. One of the things I really appreciate about DDD and the way it isolates domain expressions within a layered architecture is that it aligns perfectly with SOLID design principles, like the dependency inversion principle. ‑You are a big fan of SOLID, Steve. ‑Guilty! In this case, in terms of SOLID, using an abstraction for persistence enables us to follow dependency inversion because we can define an abstraction in our domain model and then implement it in another project that depends on the domain model. We can also write our application and its user interface so that it depends on our persistence abstraction, too, rather than on the implementation details. That\u0026rsquo;s the heart of dependency inversion. ‑And that makes it easier to follow the interface segregation principle, which I also learned about from your SOLID course. This principle prefers smaller interfaces, so if your app is using a DbContext directly, that is not a small interface. Along with DbContext repository features, it exposes a lot of other functionality. Using an abstraction that limits what your app needs to do with regard to persistence makes for a much simpler design in our model, reducing complexity. ‑Right. In that way, it\u0026rsquo;s similar to the facade pattern because it lets us work with a much simpler view of what could otherwise be a potentially very complex and powerful persistence library. ‑So, when we\u0026rsquo;re following DDD, our domain model shouldn\u0026rsquo;t know anything about EF Core, or whatever APIs you\u0026rsquo;re using for your data persistence. If our model requires persistence, like most do, we should define abstractions in the model that describe what our needs are without specifying how they\u0026rsquo;re done. ‑Exactly. The abstraction defines what needs done, the specific implementation is all about how to do it. ‑And one really popular and powerful way to do persistence in .NET is with Entity Framework Core. And because it implements methods that map pretty closely to most common persistence abstractions, it\u0026rsquo;s usually pretty easy to implement a particular abstraction with a class that calls into EF Core. ‑Definitely. ‑EF Core works great for this in most of the apps I work on, but we should never couple it tightly to our domain model. ‑Exactly. The whole point of DDD is that we shouldn\u0026rsquo;t be coupling our domain problems with our persistence problems.\nReturning IQueryables: Pros and Cons Another question I get all the time, and which I\u0026rsquo;ve discussed in some of my other Entity Framework courses, is whether repositories should return IQueryable, and yes, I do have my opinions on that. ‑Yes, this is another source of some debate. On the face of it, it sounds like it would be a great idea. Your most basic repository abstraction might not provide much in the way of complex filtering options and you can avoid having to think about that sort of thing if you just return an IQueryable. ‑Right, because then any code that consumes an IQueryable can extend the expression adding additional filters or projections to the query before it\u0026rsquo;s actually executed. On the surface, it sounds pretty good, right? ‑Well, it turns out that a lot of query logic is actually business logic, and if you return an IQueryable, it has two not‑so‑good effects. It can leak a lot of the implementation details so your application code\u0026rsquo;s behavior changes significantly based on the implementation of the repository and it tends to put the business rules for querying all over the application. ‑Let\u0026rsquo;s say we have an MVC application with a controller so that\u0026rsquo;s the server‑side logic of the UI layer and it returns a view to the UI. The controller calls into a service to get its list of customers and the service contains a customer repository interface. That repository calls into an infrastructure project and the infrastructure project is where we\u0026rsquo;re using EF Core and it\u0026rsquo;s DBContext, but to limit what\u0026rsquo;s exposed outside of the infrastructure project, there is a repository there as well. The repository and the service makes its calls to the repository in the infrastructure layer. It sounds like a lot of layers, but that\u0026rsquo;s not a problem because we have reduced coupling and made a maintainable solution. The real problem here is where can we put our query logic in this example? ‑Well obviously the repository, and it wouldn\u0026rsquo;t be unusual for the method in the service to further modify the query, but since it\u0026rsquo;s also returning an IQueryable, the controller action could further modify that same expression tree, and assuming the controller just passes that same IQueryable to the view, which we\u0026rsquo;ve both seen teams do, even the view could further refine the query. So is this a good thing or a bad thing? ‑Well on the plus side, we get a lot of flexibility without having to write a lot of code for our repository. We\u0026rsquo;re also able to tailor the data we need to the specific place it\u0026rsquo;s used and even modify the query from multiple steps in the app. At the same time, we get to reuse a simple repository interface everywhere in our app. ‑Right, but on the other hand, that query logic is now spread out everywhere. Every class that\u0026rsquo;s adding query logic, in addition to whatever else it\u0026rsquo;s doing, is now violating the single responsibility principle. Then there is separation of concerns. Query logic should be separate from other concerns in most of these classes. ‑And another problem I see a lot with this approach is confusion about when the actual query is executed and what runs on the database server versus in‑memory in the application. ‑Many developers will assume the query runs inside the repository and the result they get back is from the data store. And of course that\u0026rsquo;s true for most calls, but not necessarily for those that return IQueryable. ‑Right, the query will execute the first time any code tries to enumerate the result. That could happen inside the repository, but it could also happen in the service, or in the controller, or even in the view. ‑Yeah, I see that a lot. a related issue is that developers at any step of this process can add additional logic that may compile just fine, but then at runtime when EF tries to interpret it, it blows up. ‑Anything you add to the query expression that Entity Framework doesn\u0026rsquo;t know how to translate into SQL is likely to cause an exception, at least with recent versions of EF Core. ‑And it may be redundant at this point, but it\u0026rsquo;s probably worth adding here that there is no encapsulation when you use this approach. ‑There is a way we can fix at least some of these issues though. For example, instead of returning IQueryable, we can still create flexible repository methods by passing in predicates. Then in the implementation, this predicate can be passed along to the DBContext as its Where expression providing the necessary filter. If you\u0026rsquo;re not familiar with the term predicate, but you\u0026rsquo;ve used the link where method, that\u0026rsquo;s what the method takes as its parameter, which is why we\u0026rsquo;re able to pass it right to the WHERE clause. ‑That does help part of the problem. Where before the query could have been executed at any of these points, at least now we know that whatever comes back from the repository will be the in‑memory result. The actual query is always executed in the repository itself. Of course, if the service takes in a predicate, it still means that any code anywhere in the system could be responsible for creating the query logic with the possible exception of the view if it\u0026rsquo;s just being passed an IEnumerable at this point. ‑Okay, so with predicates, they\u0026rsquo;re still very flexible, but they\u0026rsquo;re not as easy to build up from multiple locations in your application, especially compared to IQueryable. The rest of the good points still hold though. ‑The only thing we\u0026rsquo;ve really changed on the bad side is confusion about when the query actually executes. Being a fan of solid and encapsulation and knowing some other patterns we\u0026rsquo;ll share later in this module, I\u0026rsquo;m usually going to vote against this approach too. ‑Well another way we tend to solve this conundrum is going the custom query route. We even suggested this as a tip earlier, but you can definitely take it too far. Every little change to a query means another method, customer with orders, customers by shoe size, by shoe size, customers by favorite Netflix show. Hey, you never know what problems your domain experts are going to share with you. ‑The problem with this approach if it goes beyond one or two methods, is that you really start to feel the pain of the open/closed principle violation. Every time another custom query requirement comes in, you have to change the repository abstraction and all of its implementations, and the bigger the type gets, the more it violates the interface segregation principle, too. The more complex your problem is, the more query methods you\u0026rsquo;ll be adding to your solution. This can surely be an untenable situation, and we will show you some better alternatives a little later in this module.\nConsidering Generic Repositories and Interfaces Using generic interfaces for persistence is great from a code‑reuse point of view. With just one simple interface, any entity can be persisted using a standard set of operations. If you\u0026rsquo;re using aggregates, you can use generic constraints in this simple marker interface to ensure that only aggregate roots can be persisted using your interface. It can work really well. ‑But there are trade‑offs. What if you have certain aggregates that should never be deleted, but your generic repository includes a delete method? Does it make sense to have operations defined in your domain model that should never be used? This is where you need to make a judgment call. Is the convenience of having a single consistent way of dealing with persistence throughout your model more valuable than having only the necessary and appropriate persistence operations exposed? There\u0026rsquo;s no one right answer. Pick what makes sense for your app, your model, and your team. ‑In our demo, partially for the sake of simplicity, we are using a single generic repository for all of our operations, even though, yes, this means there are operations on some aggregates that are never called and some that never should be called, for example, deleting the entire schedule. ‑If we didn\u0026rsquo;t go that route, our model would need to include separate repository interfaces for each of the aggregates in our model, including schedule, doctor, room, client, and appointment type. Each would define only the operations that were actually needed by the application. For a larger model, this could result in quite a few interfaces, and possibly implementations, but would provide a more pure representation of the domain model. ‑If you do choose to create a generic repository interface, that doesn\u0026rsquo;t necessarily mean you\u0026rsquo;ll implement it generically. You might only choose to create implementations for each aggregate root, which would comply with DDD recommendations. However, it can be convenient to create a generic Repository of T implementation class that you can then use with any entity. ‑This is what we\u0026rsquo;re using in our sample, both for the front desk app and for the clinic management app. In both cases, if you review the sample, you\u0026rsquo;ll see there\u0026rsquo;s very little persistence‑specific code in either solution. ‑If you really like the code reuse you get from having a generic repository implementation, one way to keep it from allowing too much access to the internals of your aggregates would be to use a marker interface, perhaps one that simply extends the entity interface to identify your aggregate roots. Then you can update your generic repository to require this interface, rather than working with any entity. ‑At that point, code that uses the repository won\u0026rsquo;t be able to instantiate the generic repository with non‑root entities, so we\u0026rsquo;re able to use our repository to restrict access to non‑root entities from client‑server model. Using marker interfaces to identify aggregate roots is one way you can enforce your design decisions in your model using the compiler rather than relying on code reviews or other less effective practices. ‑Repository abstractions, especially generic ones, can sometimes get to be pretty large. Large interfaces violate the interface segregation principle, one of the solid principles that I cover in my Solid Principles for C# Developers course. One way to keep these interfaces smaller and more focused is to split them into read and write operations. This is related to the concept of Command Query Responsibility Segregation, or CQRS. Read operations are queries, write operations are commands. There are many benefits to leveraging CQRS that we don\u0026rsquo;t have time to cover in this course, but one area where you may immediately benefit is with modifying behavior related to these kinds of operations. Queries often benefit from data caching, and it\u0026rsquo;s very easy to add data caching to just the read operations. ‑Commands often benefit from being performed asynchronously using a queue, and having a separate interface for commands makes it easy to implement this behavior. These are just two ways you can quickly leverage splitting up your repository definitions between reads and writes. Of course, if you have a lot of different read methods, this can make it more and more difficult to implement custom caching logic, since every new method will also need to be added to the caching layer. Fortunately, this is easily solved by using the specification pattern.\nExploring Repositories in our Application Steve is going to give you a guided tour of how data access and persistence are handled in the FrontDesk application using repository abstractions. Because he\u0026rsquo;s been fine tuning versions of this demo application for many years, it\u0026rsquo;s quite impressive, and he truly is the best guide for walking you through this implementation. ‑We\u0026rsquo;ll start from the front end of the application, which is our Blazor client. Let\u0026rsquo;s take a look at editing an appointment. Here\u0026rsquo;s an appointment for Julie\u0026rsquo;s dog, Samson. You can see that on the edit screen, in addition to showing the details for the appointment, it also provides us with a list of the doctors and appointment types. When we hit the drop‑down list, we can see all of the different doctors who are available that we could schedule to work with this particular appointment. That\u0026rsquo;s actually accomplished through a back end API that\u0026rsquo;s coming from a different project. Let\u0026rsquo;s take a look at that. We\u0026rsquo;ll start by examining the API using our Swagger endpoint. Looking at Swagger for DoctorEndpoints, you can see that there are two endpoints, one to get a specific doctor by ID and another one that returns a list of doctors. We just saw the list of doctors in action. Let\u0026rsquo;s go ahead and run it again from Swagger. Here you can see the resulting set of three doctors, just like we saw in the drop‑down list. You\u0026rsquo;ll find the code for this particular endpoint inside the FrontDesk.Api project. Within there, there\u0026rsquo;s an Endpoints folder with subfolders for each of the different types of entities that we expose API endpoints for. Inside of Doctor, you can see there\u0026rsquo;s a GetById and a List, and we\u0026rsquo;re looking at the List endpoint here. When we define an endpoint, we simply inherit from BaseAsyncEndpoint, and specify the request type, if any, and the response type, if any. We can also do dependency injection through the constructor, just as you would with a controller. Each endpoint has a single Handle or HandleAsync method, and this is where the actual work of the endpoint is done. You can see in this example that we are simply awaiting on the repository\u0026rsquo;s ListAsync method in order to get our list of doctors. Once we have the list, we map it to our DTO that we\u0026rsquo;re going to actually return, and pass that back as part of that response type. The response, as we just saw in Swagger, includes the Doctors as JSON, as well as a Count property that includes the total number of those doctors. Now let\u0026rsquo;s look a little bit more closely at that repository. You can see in the dependency injection that\u0026rsquo;s occurring in the constructor that we\u0026rsquo;re depending on an IReadRepository, but where is that defined? For that, we need to look at our SharedKernel project. Inside the separate SharedKernel project, which FrontDesk references as a NuGet package, you can see that we have defined an IReadRepository interface. This inherits from IReadRepositoryBase, which is actually itself defined in another NuGet package, the Ardalis.Specification type. The reason why we\u0026rsquo;re creating our own interface here is so that we have complete control over it and we can add additional behavior. For example, in this case we\u0026rsquo;re adding a generic constraint. We\u0026rsquo;ve said that this particular interface will only work with types that have the IAggregateRoot interface attached to them or applied to them. Looking at that particular interface, you can see that there\u0026rsquo;s nothing to it. It\u0026rsquo;s simply a marker. It\u0026rsquo;s a way that we tell the compiler that our intent for a particular class or entity is that it should be treated as an aggregate root. We use that marker to enforce our design and our encapsulation to make it so that we don\u0026rsquo;t accidentally just load up a child entity out of an aggregate, when instead we\u0026rsquo;ve made a design choice that we want to work with that entire aggregate as a unit. You can see that we\u0026rsquo;ve also implemented IRepository similarly. It also inherits from a type that comes from Ardalis.Specification, and also has the same IAggregateRoot restriction. Now let\u0026rsquo;s return to our FrontDesk application and see how we implement this. First, we should look at the DefaultInfrastructureModule. This is an artifact module that defines how we\u0026rsquo;re going to wire up our abstractions with their implementations. And here you can see all the important bits of how we wire up EfRepository to IRepository, as well as IReadRepository. But notice for the IReadRepository we\u0026rsquo;re actually wiring up a different type, a CachedRepository. This acts as a decorator around the underlying EfRepository, and will provide additional caching logic. Inside of the CachedRepository, when we asked for a list of doctors, it actually checked the cache first, and then if it wasn\u0026rsquo;t in the cache, it would go and fetch the result from the EfRepository, which in turn would make the request to the database. We can see in this example here that the logging is showing us that we\u0026rsquo;re actually hitting CachedRepository, and some of the times we\u0026rsquo;re fetching the source data and other times were fetching the data from the cache. The actual EfRepository that is also defined inside of FrontDesk.Infrastructure is shown here, and once more, you can see that there\u0026rsquo;s not much to it. Most of the behavior we\u0026rsquo;re simply inheriting from the EfRepository that exists in the Ardalis.Specification package. It\u0026rsquo;s called RepositoryBase. However, when we inherited it, we were able to add additional constraints, and so you\u0026rsquo;ll see here as well that we specify that this only works with IAggregateRoot. You can see the definition of the RepositoryBase in the Ardalis.Specification NuGet package, which is available on GitHub. The details of it are shown here. The ListAsync method simply delegates to dbContext.Set of the appropriate T type, and then calls its ToListAsync, passing along a cancellationToken if one was provided. Now the last piece of the puzzle is our own AppDbContext. Inside our AppDbContext, we define the DB sets that we\u0026rsquo;re working with and we also pass in some additional configuration. One thing to notice and take away from this example is how many places in our solution we have to reference AppDbContext or EntityFramework. It\u0026rsquo;s almost nowhere in the entire code base. The only place that we talk about it at all is inside of AppDbContext, EfRepository, and some related folders such as Configuration and Migrations. Everywhere else, and especially in our domain model, we\u0026rsquo;re completely persistence ignorant, relying only on abstractions that we\u0026rsquo;ve defined.\nIntroducing the Specification Pattern Eric Evans introduces the specification pattern in the original book on domain‑driven design. Although it\u0026rsquo;s covered in Evans\u0026rsquo;s DDD blue book, the specification pattern isn\u0026rsquo;t listed in the book\u0026rsquo;s mind map, and honestly, it doesn\u0026rsquo;t get the attention it deserves. Factories are in the book\u0026rsquo;s mind map, but specifications aren\u0026rsquo;t? Even though in my experience they play a much larger role in producing a clean domain model design. ‑In the book, Evans says that specifications mesh smoothly with repositories, which are the building‑block mechanisms for providing query access to domain objects and encapsulating the interface to the database. It\u0026rsquo;s this powerful combination of specification and repository patterns that truly result in a clean, extensible, and testable design. Let\u0026rsquo;s dig a little more into the specification pattern and how it integrates with repositories before we show you how we\u0026rsquo;ve implemented it in the front desk application. ‑Specifications are used to specify the state of an object, and as such, are primarily used in three ways, validation, selection and querying, and creation for a specific purpose. In our app, we are primarily leveraging specifications in our queries. Create explicit predicate‑like value objects for specialized purposes. A specification is a predicate that determines if an object satisfies some criteria, according to Eric Evans. The most basic specification simply provides a method typically named IsSatisfiedBy, which accepts some object and returns a Boolean. These methods perform their logic in memory, and unfortunately, in remote data querying scenarios, this approach would require every row to be transferred to the application before the specification logic could be run against it. ‑However, more sophisticated specifications can be used in conjunction with ORMs like Entity Framework Core to encapsulate the details of a query while still allowing EF Core to translate the query into SQL that executes on the database server. Our sample application uses such a specification in the form of a NuGet package, ardalis.specification, which is maintained by, guess who, Steve Smith. ‑Recall that one of the benefits of using the repository pattern and abstraction was that it prevented query logic from being spread throughout the application. This was also the reason for not returning IQueryable from repository methods. The same logic can be applied to repositories that accept arbitrary predicates since, again, that means the complexity of these predicates would need to live in the code calling the repository, which might be in the user interface for example. Using repository interfaces that accept specifications instead of custom predicates addresses this problem very elegantly. ‑What about the issue we learned about earlier in this module where generic repositories weren\u0026rsquo;t suited to aggregates with custom query needs? So, individually typed repository interfaces were required, and each additional custom query needed to be added to this new specific interface. Well, specifications solves that problem too. Generic methods accepting generic specifications allows for custom queries where needed for any given aggregate. ‑A few more benefits of specifications. They\u0026rsquo;re named classes that live in your domain model. You can easily unit test them in isolation, or if necessary, integration test them with a test database. They\u0026rsquo;re highly reusable. They keep persistence logic out of your domain and your user interface. They keep business logic out of your database and persistence layer. They help your entities and aggregates follow the single responsibility principle by keeping complex filtering or validation logic out of them. You can easily create your own specification interface and implementation. Feel free to look at the source for ardalis.specification on GitHub and take just the bits you find useful. Or, you can reference that package and leverage all of its features and just start adding the specifications that your domain needs. It\u0026rsquo;s up to you. Either way, you will need to write the specifications themselves. These belong in your domain model. When you don\u0026rsquo;t have many of them, you might just put them in a root specifications folder. However, as your model grows, if you\u0026rsquo;re using aggregates, it may make sense to have each aggregate include in its own folder the specifications that go with it. This makes them easy to locate as they grow in number. ‑Each specification class is a value object, so it should be immutable. Generally, they do all of their work in their constructor. Any variable part of the specification should be supplied as a constructor argument. And once constructed, the specification needs to be supplied to your query implementation. You can use specifications directly with EF Core or you can use a repository abstraction that supports them. In either case, pass the specification to the query object and it will be used to build the query, which is then executed and results are returned. The resulting code for most queries turns into one line to create the specification and another line to execute the query by passing the specification to a repository or a DbContext method. Note that our sample is built on top of a repository abstraction that\u0026rsquo;s provided with the ArdalisSpecification package, and so it\u0026rsquo;s fully compatible with its specification types. We\u0026rsquo;ll look at the code more in the next section. ‑Here\u0026rsquo;s an updated mind map that I have created which shows how specifications work with repositories to define the queries for aggregates and entities. If you\u0026rsquo;ve been using repositories without specifications and have experienced any of the pain points we\u0026rsquo;ve described in this module, try refactoring to use specifications and I\u0026rsquo;ll bet you\u0026rsquo;ll be surprised what a positive difference it makes.\nUsing Specifications with Repositories in Our App Now it\u0026rsquo;s time to see just how specifications are implemented in the sample app. While the application code does lean on Steve\u0026rsquo;s specification API, there is still plenty to see. Most of what you\u0026rsquo;ll see here is the application\u0026rsquo;s code, but occasionally you\u0026rsquo;ll also see some of the code that\u0026rsquo;s in the Ardalis.Specification API. Once again, Steve is going to walk you through this demo, and he\u0026rsquo;ll do so from the perspective of how the app retrieves data, starting with the front‑end. ‑When we first load the schedule page in the FrontDesk app, it loads our Blazor WebAssembly application, which then makes some API calls to fetch the appointments and related data. One of those calls is shown here. It\u0026rsquo;s used to get the list of appointments for the schedule. Looking at Swagger, we can see there are a bunch of appointment endpoints. Our API is designed to serve the needs of the client app. Its endpoints won\u0026rsquo;t necessarily match up with how our domain model is constructed, so it\u0026rsquo;s perfectly fine to have an endpoint for appointments, even though appointment is not an aggregate root. It just means we need to pass in the aggregate root ID as part of the request so that we can get the schedule that owns the appointments. If we test the list AppointmentsEndpoint, we can pass in the same schedule ID that Blazor was using, and we get back a list of appointments as expected, and these are, in fact, the same appointments that are being used in the front end. Looking at the source code for this endpoint, you can see that, again, it\u0026rsquo;s in the API project in the Endpoints folder in an Appointment folder, and within that, we\u0026rsquo;re looking at the List endpoint. Now, when we pass in the request, we\u0026rsquo;re specifying a ScheduleId, and if that ScheduleId is missing or empty, then we\u0026rsquo;re going to return NotFound from this API. Otherwise, it uses the ScheduleByIdWithAppointmentSpec to encapsulate the query that it\u0026rsquo;s going to use. On the page in question, we only want the appointments for one day. It\u0026rsquo;s worth noting that this specification does not perform any filtering by date; it returns all appointments for this schedule. We\u0026rsquo;ve left a to do task here for you to implement this behavior by creating a new specification. Now, the specification that we\u0026rsquo;re using here is passed to the repository method, GetBySpecAsync. We\u0026rsquo;ll look at that in a moment. For now, let\u0026rsquo;s take a look at this specification. All of the schedule specifications are in the ScheduleAggregate folder in the Core project. The ScheduleByIdWithAppointmentSpec is pretty simple and has just three details worth pointing out. First, it has a WHERE clause, making sure it only matches schedules that have a matching ID. Second, it eager loads it\u0026rsquo;s associated appointments by using it .Include statement. And third, it implements another marker interface, ISingleResultSpecification. This interface is used to mark specifications that are expected to only return a single result. It is required when passing a specification to a repository method that only returns a single instance of a type rather than a collection or enumerable. Considering that this is being called from a List endpoint on the API, this may seem strange, but remember, we are only loading a single schedule aggregate, and it is then just the container for the set of appointments that the endpoint is going to return. The method the endpoint is calling, GetBySpecAsync, is defined in Ardalis.Specification, as shown here. Note that it has a generic constraint requiring any specification passed to it to have that ISingleResultSpecification marker interface. The sample code is calling this first method, which just works with one entity type and then returns it. If you need to use projection, though, you can use the second method, which operates on your entity type, but returns a different type using a .select. You can use this to optimize queries to return only needed properties. Remember that specifications are useful to define the expected shape of returned data in a query. This doesn\u0026rsquo;t just mean filtering the number of rows using a WHERE clause, but also determining which associations should be brought back with the query, and even which columns should be included. Let\u0026rsquo;s see an example of that. Returning to the specifications for the schedule, there\u0026rsquo;s another one called ScheduleForClinicAndDateWithAppointmentsSpec. One of the newer features in EF Core is \u0026ldquo;filtered includes,\u0026rdquo; and so by adding an include filter, we can make sure that this schedule, which is being used with a particular ClinicId, will only load in its appointments where they are for a given date that gets passed into the specification. You can use this specification, by the way, as an example when you complete that to do task that we just saw in the list endpoint. Compare this code to how we solve this problem in the previous version of this course using custom SQL queries and a custom ScheduleRepository. The specification has replaced all of that with a single specification class containing all the query logic, and the calling code simply needs to create the specification and then pass it to the repository. Unlike custom LINQ expressions that might be anywhere in our application, specifications are easily tested in isolation. In the IntegrationTests project, you\u0026rsquo;ll see several different tests that demonstrate the various schedule specifications and ensures they work as expected. These tests use a real database, since .include logic can\u0026rsquo;t be tested with an in‑memory collection. For the last specification that we looked at, which only includes the appointments for a given date, you\u0026rsquo;ll see that there\u0026rsquo;s an integration test that adds a number of appointments on different dates and then uses a repository to fetch back a schedule using the ScheduleForClinicAndDateWithAppointmentsSpec and a specific date, and it verifies that we only get back the appointments for that date and not the appointments that are on different dates, which verify the behavior of many of the abstractions and implementations in our domain model.\nReview and Resources Once again, let\u0026rsquo;s begin a review with some of the important terms you learned in this module. First, and most importantly, the focus of the module, repositories, which encapsulate the data persistence logic, add, update, delete, and retrieve. In the case of domain‑driven design, we use repositories to focus on aggregate roots. Key to building flexible repositories is the specification pattern, which guides you to encapsulate business rules in a way that they can be passed around and acted upon in other methods, classes or APIs. You learned about persistence ignorance, which describes objects being ignorant about how they are persisted into data storage. It\u0026rsquo;s another critical aspect of domain‑driven design. Steve and I also talked about ACID, an acronym to describe transactions as being atomic, consistent, isolated, and durable. Another acronym we talked about is SOLID, which is a collection of software design patterns. ‑After introducing you to repositories and how they fit into the DDD mind map, you learned about their benefits and some tips for designing them. ‑We also addressed some of the debates around repositories, not only if you should even use them, but how to use them, for example, whether or not to return IQueryables. Many of these debates exist because of the complexity of balancing clean repositories with repositories that help you achieve the variations of queries required by your domain. ‑We introduced you to an often overlooked pattern, the specification, that plays a critical role in solving this problem with DDD. Remember that you are not on your own building specifications. You can lean on the NuGet packages that I created or just dig into my GitHub repo to pick and choose what you want to adopt. Links are coming up. ‑Steve gave you a great tour of how repositories are implemented in the FrontDesk application and then more deeply to see how these repositories are using specifications to provide the rich querying needed in the application. ‑Here are a number of links to not only my GitHub repo and NuGet packages, but a number of other resources we referenced, as well as some additional ones that we think you\u0026rsquo;ll find useful. ‑In the next module, you\u0026rsquo;ll learn about two more critical pieces of the DDD mind map, domain events and anti‑corruption layers, both which help provide some data pathways between the various parts of your software. Thanks again for watching Domain‑Driven Design Fundamentals. I\u0026rsquo;m Julie Lerman, ‑and I\u0026rsquo;m Steve Smith. Thanks for watching.\nAdding in Domain Events and Anti-corruption Layers Introduction and Overview Hi, this is Steve Smith. ‑And this is Julie Lerman. ‑In this module of Domain‑Driven Design Fundamentals, you will learn about domain events and anti‑corruption layers, two patterns for decoupling how the domain model communicates internally and with other systems. ‑We\u0026rsquo;ll start with domain events, which can be used to separate concerns, allowing different areas of the application to evolve independently, and sometimes helping with scalability as well. You\u0026rsquo;ll learn how to identify domain events in your system, and how to design domain event classes. Then we\u0026rsquo;ll show you domain events being used in a simple application, so you can get a feel for the structure and the workflow. ‑Then, you\u0026rsquo;ll get to see the domain events we built in our sample application, which are a bit more realistic. After this, we\u0026rsquo;ll turn our attention to another important element of domain modeling, anti‑corruption layers, which can be used as translators between bounded contexts and Legacy APIs.\nIntroducing Domain Events Domain events are a critical part of a bounded context. They provide a way to describe important activities or state changes that occur in the system. Then, other parts of the domain can respond to these events in a loosely coupled manner. ‑In this way, the objects that are raising the events don\u0026rsquo;t need to worry about the behavior that needs to occur when the event happens. And likewise, the event handling objects don\u0026rsquo;t need to know where the event came from. This is similar to how repositories allow us to encapsulate all of our data access codes, so the rest of the domain doesn\u0026rsquo;t need to know about it. ‑We can also use events to communicate outside of our domain, which we\u0026rsquo;ll look at in just a moment. Another thing that\u0026rsquo;s worth remembering is that domain events are encapsulated as objects. This may be different from how you\u0026rsquo;re used to coding events. It certainly was different for me when I first started learning about them. For example, in a user interface, events are more commonly written as some form of a delegate in another class, but here they\u0026rsquo;re first class members of the domain model. ‑Right. Although you can implement domain events using techniques, like the event keyword in C#, the domain events themselves should be full‑fledged classes. In fact, all of these parts of domain‑driven design are defined as objects in our domain model. ‑Vaughn Vernon describes domain events simply, saying we should use a domain event to capture an occurrence of something that happened in the domain. The domain events should be part of our ubiquitous language. The customer or domain expert should understand what you\u0026rsquo;re talking about when you say when an appointment is confirmed, an appointment confirmed event is raised. ‑You may already be familiar with the idea of events from working with user interfaces. ‑Many user interface clients, like .NET Windows Forms, Electron, or web pages, like the one shown here, make heavy use of events and event handlers. In this example, there\u0026rsquo;s a single page with a single button, and in the markup, you can see there\u0026rsquo;s an onclick attribute in the button that leads to a little JavaScript method defining what the app should do in response to a user clicking the button. ‑Events are helpful because they let us avoid a lot of conditional logic. Instead, we can write code that signals a certain thing has happened, and we can have other code in our system listen for these signals and take action accordingly. So in this kind of code, you don\u0026rsquo;t have a separate class for an onclick event, and it may take some getting used to that now in our model, we\u0026rsquo;re going to create a whole class to represent an event. Domain events offer the same advantages to our model as the events in the user interface. Rather than having to include all of the behavior that might need to occur whenever the state of one of our objects changes, instead, we can raise an event. Then, we could write separate code to deal with the event, keeping the design of our model simple, and helping to ensure that each of our classes has only one responsibility. Essentially, a domain event is a message, a record about something that occurred in the past, which may be of interest to other parts of our application, or even other applications entirely.\nIdentifying Domain Events in Our System ‑Be especially attentive to these kinds of phrases when discussing the application with your domain experts. When this happens, then something else should happen. If that happens, notify the user when, or inform the user if, these types of phrases frequently refer to situations that are important to the domain expert, the system, or the user. It might therefore be worth modeling these types of things as domain events. You may also discover behavior in the application that will benefit from being treated as domain events that may be the domain expert isn\u0026rsquo;t initially aware of. ‑Remember that domain events represents something that happened. Since we can\u0026rsquo;t generally alter history, this means they should be immutable. It\u0026rsquo;s a good idea to name the event using terms from the bounded context\u0026rsquo;s ubiquitous language describing clearly what occurred. If they\u0026rsquo;re fired as part of a command on a domain object, be sure to use the command name. Here\u0026rsquo;s some examples. ‑Depending on the application, it might be important to have events to represent when a user has authenticated, when an appointment has been confirmed, or when a payment has been received. Be sure to only create events as you need them in your model. You should follow the YAGNI principle, that\u0026rsquo;s you ain\u0026rsquo;t gonna need it. In other words, don\u0026rsquo;t create domain events unless you have some behavior that needs to occur when the event takes place, and you want to decouple the behavior from its trigger. You really only need to do this when the behavior doesn\u0026rsquo;t belong in the class that\u0026rsquo;s triggering it.\nDesigning Domain Events Here\u0026rsquo;s some more things to keep in mind when you\u0026rsquo;re creating domain events. We\u0026rsquo;ve already mentioned that domain events are objects, but to be more specific, each domain event should be its own class. It\u0026rsquo;s also usually a good idea to note when the event took place since frequently the code that\u0026rsquo;s handling the event might run some time after the event occurred. It can be helpful to create an interface or a base class that defines the common requirements of your domain events. For example, capturing the date and time the event occurred. ‑Also, when you\u0026rsquo;re designing your event, you need to think about the event‑specific details you want to capture. If it\u0026rsquo;s related to an entity, you might want to include the current state of the entity in the events definition. Think about what information you would need to trigger the event again. This can provide you with the set of information that is important to this event. Similarly, you may need to know the identities of any aggregates involved in the event, even if you don\u0026rsquo;t include the entire aggregate itself. This will allow event handlers to pull the information back from the system that they might require when they\u0026rsquo;re handling the event. Ideally, domain event objects should be lightweight, so you want to be sure you capture sufficient information to handle the event, but not so much that the event object itself becomes bloated. Since the main events are immutable, they\u0026rsquo;re typically fully instantiated via their constructors. And since they\u0026rsquo;re simply noting that something has happened in the system, they don\u0026rsquo;t usually have any behavior or side effects of their own.\nApplying Domain Events to a Simple App We\u0026rsquo;ve put together a simple console application that we\u0026rsquo;re going to use to demonstrate the value that domain events can have in your application. The idea behind this is to strip things down to as small a level as possible. Then, we\u0026rsquo;ll also show how domain events are playing a real role in a more real‑world way when we get to our veterinary scheduling application. This is a .NET console application with dependency injection. The main program just loads the needed services and runs the app. The app has a simple run method, which goes through the following steps. We can step through it with the debugger, so you can see the output in real time. The app loads services and starts running. It shows what happens when an appointment is created using a service. The service calls a factory method that creates the appointment. After instantiating the appointment, the factory method sends an email, which you can imagine includes code like what is in the comments here. Then, it similarly sends a notification to the user interface, again, with code like what\u0026rsquo;s in the comments before finally returning to the service. The service, then saves the new appointment in the database. Then, the app creates a different appointment and saves it directly using a repository instead of a service. And once more, the notifications and the save occur in the same order. Finally, the appointment is confirmed, which triggers some UI notification, and then that change, too, is saved. The main thing to take away from this example so far is that the Appointment class has a lot of concerns. The act of creating an appointment, especially, involves a lot of code that could fail. It\u0026rsquo;s also worth noting that notifications and emails are going out before the state of the entity is saved. So if something goes wrong, users will have been told the operation was successful, and people may have been notified via email when, in fact, the update itself might never go through. ‑The reason we\u0026rsquo;re showing the behavior both from a service and with the appointment directly is because our domains should be designed to work either way. Earlier in this course when you learned about domain services, we explained that forcing all operations on your domain to go through a set of services tends to lead to an anemic domain. Ideally, your aggregates and entities should behave correctly, whether they\u0026rsquo;re being used directly or through a set of services. One way we can improve this design would be to move the responsibilities of actually sending emails or updating the UI to help our methods or other services. Then, we could call them from appointment.create instead of having all the code in here. This would make for less code inside of Appointment. ‑That would definitely be better, but it would still mean that appointment would need to be updated every time a new requirement came along. There\u0026rsquo;s a principle we can use to avoid that, though, called the Hollywood principle. ‑I love the name of this principle. Its name comes from an old saying from Hollywood agents, don\u0026rsquo;t call us, we\u0026rsquo;ll call you. ‑Exactly. Applied to software, the principle is closely related to dependency inversion from solid. Instead of forcing appointment.create to have to know about and call every possible thing that might be involved in the appointment creation workflow, instead, it can just let the app know something happened and let the app respond by calling handlers. ‑Instead of putting all the logic into this method, potentially making it huge and complicated and really hard to read, we move that logic into handlers, and the app calls the handlers. We don\u0026rsquo;t call the handlers, the app calls us. And beyond just reducing the amount of code and responsibility inside Appointment, this approach also lets us make sure that notifications to the user don\u0026rsquo;t occur until persistence is successful. And it still keeps the model\u0026rsquo;s behavior consistent without requiring a service to perform any of the work. Let\u0026rsquo;s see how it works. ‑Domain events is a pretty simple pattern, but you do need to have some plumbing code to support it. You also need to think about whether you want your events to fire before or after persistence. In many cases, what you really want is postpersistence events for the reasons we mentioned above. You want to make sure your persistance succeeds before you send any notifications outside of your app. Also, although occasionally I\u0026rsquo;ve used them for validation in the past, ideally, your domain events and handlers should never fail. That is, don\u0026rsquo;t build your behavior around exceptions that might be thrown from event handlers. Use a different pattern if you need that type of behavior. ‑In this simple demo, which mirrors how our sample app works, we just need a collection of events on each entity. We\u0026rsquo;re creating simplistic types to represent domain events and the respective handlers. You can implement the logic to find and call handlers whenever an event is dispatched in a number of ways. For this sample, we\u0026rsquo;re using the MediatR NuGet package created by Jimmy Bogard. Steve mentioned that you\u0026rsquo;ll need some plumbing to start, and that plumbing is the interfaces or base classes, if you prefer, for handler and domain event classes. In our example, we\u0026rsquo;re using interfaces. Here\u0026rsquo;s the IDomainEvent interface and the IHandle interface. ‑Once you\u0026rsquo;ve set up your event and handler interfaces or base types, it\u0026rsquo;s time to create some events and their associated handlers. ‑For this scenario, there are two things happening, an appointment is scheduled or created and an appointment is confirmed. An event is something that already happened. So we name our events in the past tense, and we have AppointmentCreated and AppointmentConfirmed. The event classes are pretty simple and just include the instance that triggered them, so handlers have access to any properties they might need from it. Once the events have been defined, you just take each individual responsibility out of the original method and create a separate handler for it. It\u0026rsquo;s fine to have multiple handlers for the same event. Ideally, your design shouldn\u0026rsquo;t depend on the order in which the handlers execute. But if it does, you can think about adding a sequence to your handler interface and ensuring they\u0026rsquo;re called in sequence order. ‑The last thing you need to do is register or record the events on the entity. In this sample, that just means adding them to the list of events that are on that entity. The actual implementation for dispatching the events is done in the repository after the save is successful. And in our veterinary sample, this work is done in the DbContext SaveChanges method. ‑Let\u0026rsquo;s step through the code again now that it\u0026rsquo;s using domain events. ‑The app starts up as before. We enter the appointment.create method. ‑And look how much smaller that method is now. ‑Definitely. It\u0026rsquo;s way easier to see what\u0026rsquo;s going on here. Now the domain event is added to the collection, but notice that when we step over this, nothing actually happens yet. ‑Right, it\u0026rsquo;s just holding it until after the entity is persisted. ‑Which is now. Notice that we\u0026rsquo;re in the repository Save method. And for every event that we have stored on this entity, we\u0026rsquo;re using MediatR to publish it at this point in time. ‑This is still in process on the same thread. There\u0026rsquo;s no out‑of‑process queue or anything involved here. ‑Right, there\u0026rsquo;s nothing to install using this pattern except for MediatR, and that just runs in‑memory. And, of course, you could wire this up with your own code that simply loops over your set of events and then dispatches out to your handlers. There\u0026rsquo;s nothing that says you have to use MediatR. Notice in the output that the DATABASE Saved occurred, and then the UI and email notifications. ‑As expected, we only triggered side effects outside our domain after persisting. Now let\u0026rsquo;s see the version that uses the repository directly and doesn\u0026rsquo;t bother going through the service. ‑We basically see the same behavior, DATABASE Saved, UI, EMAIL. ‑All that\u0026rsquo;s left now is the confirm and save, which should look similar, entity saved, and then the UI is updated. ‑That\u0026rsquo;s basically it. I created a small GitHub repo, which has just this sample in it. It\u0026rsquo;s at github.com/ardalis/DomainEventsConsole. There\u0026rsquo;s a branch there showing how things work without events. Of course, you can also download it from the course details. ‑If you want to start your solution with all of this plumbing already in place, you can use Steve\u0026rsquo;s CleanArchitecture solution template, which is also on GitHub. He is one productive guy. Everything shown here is already in place in the template, which is designed for you to use as a starting point for your app.\nExploring Domain Events in Our Application Now let\u0026rsquo;s look at how we\u0026rsquo;re leveraging domain events in the veterinary FrontDesk scheduling app that we\u0026rsquo;ve been working with. Again, we\u0026rsquo;ll start by showing you the code, and then we\u0026rsquo;ll debug through it so you can see it in action. ‑In our Appointment class, we\u0026rsquo;re going to record a domain event when certain changes are made to the appointment. So, if we scroll down and take a look at the UpdateRoom method, you\u0026rsquo;ll see that it creates and saves an appointmentUpdatedEvent. The same is true for the other update methods like UpdateDoctor, UpdateStartTime, etc. They each will create an appointmentUpdatedEvent and pass it the current instance of the appointment, and then this is saved into the entity\u0026rsquo;s Events collection. ‑In the case of the Confirm method, it\u0026rsquo;s similar, but it creates a different event, an appointmentConfirmedEvent. Essentially, the appointment entity can trigger two kinds of events directly, change and confirmed. And you\u0026rsquo;ll notice it only does so if an actual change takes place. Calling an update that doesn\u0026rsquo;t change the current value will not trigger a new event. ‑Let\u0026rsquo;s take a look at the appointmentUpdatedEvent, and this is similar to the one we saw in the simpler console app in the previous demo. It inherits from BaseDomainEvent, which is defined in our shared kernel, and it adds a UTC timestamp property called DateOccurred that is set when the event is created. This can be useful for debugging purposes. The only other property the class takes is the appointment itself. The AppointmentConfirmedEvent, shown here, is similar. ‑Notice that these domain events are all defined in the core project with our domain model. For this sample, they\u0026rsquo;re in an Events folder in the root. However, in a large application with many events, it might make more sense to put them with the aggregate that they correspond to. In this case, the ScheduleAggregate. There\u0026rsquo;s one more domain event in our sample, which is the AppointmentScheduled event. It\u0026rsquo;s similar in structure to the others, but it\u0026rsquo;s actually created elsewhere. ‑Once you start working in event‑driven applications, it can be a bit more difficult to follow the flow of execution in the app where events are concerned. It really just takes some getting used to, and then you\u0026rsquo;ll find it to be second nature. The best way to see where events are raised and where they are handled is by looking at an individual event and examining its references. Looking at AppointmentScheduled, you can see that it is handled in the API project and in the core project. It is only created inside of the ScheduleAggregate itself. Let\u0026rsquo;s have a look at where that happens. ‑In Schedule, the AddNewAppointment method creates and saves the AppointmentScheduled event after adding the appointment to its collection and marking whether or not it\u0026rsquo;s conflicting. Once the schedule is saved, any appointments that have had domain events added to their respective collections will have them dispatched after the save to persistence is complete. ‑Before we step through the code, let\u0026rsquo;s have a look at one of the AppointmentScheduledEvent handlers. The thing to notice is that these handlers don\u0026rsquo;t get created or called anywhere in our code. That\u0026rsquo;s that Hollywood agent again from the Hollywood principle saying, don\u0026rsquo;t call us, we\u0026rsquo;ll call you. The event dispatching logic, in this case, using MediatR, is what calls these handlers at runtime. But at compile time, nothing references them directly. ‑Now let\u0026rsquo;s see the flow of domain events in our application when we change an appointment. We\u0026rsquo;ll modify this appointment for my little baby, Sampson, and change the appointment from a wellness exam to a diagnostic exam. But a diagnostic exam takes more time, and this will automatically change the duration of the visit, which should trigger a conflict with one of Sampson\u0026rsquo;s other appointments. Yes, he likes to go to the vet quite a lot. ‑The change initially hits the AppointmentUpdate endpoint. It loads the schedule and the appropriate appointment and calls its Update methods. In this case, the only one that has a change is the change to the appointment type. This intern adds an appointmentUpdatedEvent. Once the change is saved, the event is dispatched. The API project also has a handler, AppointmentUpdateHandler, that responds to this event by sending a message to the Blazor client using a SignalR hub. This will trigger a real‑time notification in the app. ‑What about communication between bounded context or apps using events? Applications and microservices frequently use events to communicate, too, but these aren\u0026rsquo;t domain events since they extend beyond a single domain. They\u0026rsquo;re frequently called integration events, and they may be defined as part of your domain or in a separate project or package. For simplicity, ours are here in this IntegrationEvents folder. ‑The FrontDesk has just two integration events, the AppointmentConfirmLinkClickedIntegrationEvent is published by another app and consumed by this one, and AppointmentScheduledIntegrationEvent is an event this app publishes and another app consumes. It\u0026rsquo;s important that the structure of the published and consumed types match, which is why frequently a shared package is used to define these kinds of events. ‑We don\u0026rsquo;t have time to dive deeply into distributed application architecture, but one thing you need to remember when designing integration events is that they typically will be enriched and denormalized when compared to a similar domain event. For instance, the AppointmentScheduled domain event just has a reference to appointment, and that only has IDs for the client, patient, and doctor. However, the integration event includes many more details like client name and email, patient name, and doctor name. The reason for this is to ensure that consumers of the event have enough information from the event to perform whatever actions they need to without having to immediately call back to the publishing app to ask it for more details. You can imagine that the performance of a system would suffer if every time an appointment event was published, one or possibly many apps that were consuming that event, turned around and immediately had to make calls to this app\u0026rsquo;s API asking for client details, patient details, and doctor details. Hence, we have a handler that is responsible for taking in a domain event and enriching it with the additional details shown here on the integration event. We\u0026rsquo;ll put these integration events to use in the next module.\nIntroducing Anti-Corruption Layers The last topic we want to discuss in this module is anti‑corruption layers. An anti‑corruption layer, as the name implies, helps to prevent corruption in your domain model. ‑Right, just like superheroes help to fight corruption, these layers provide a sense of security to your model when it needs to interact with other systems or bounded contexts. ‑Returning to our mind map, you can see that the anti‑corruption layer is used to translate and insulate as part of a context map, mapping between a bounded context and foreign systems. ‑When your system needs to communicate with other systems, especially legacy applications that weren\u0026rsquo;t written or modeled as well as your current system, you need to be careful not to let assumptions and design decisions from that system bleed into your model. For instance, if the other system\u0026rsquo;s model includes a customer, even if that customer refers to the same actual business customer, it\u0026rsquo;s likely that it will be modeled differently than a customer in your system. It\u0026rsquo;s best to have a layer that can translate to and from other systems\u0026rsquo; models. In DDD, this is the job of an anti‑corruption layer. ‑Right, like we mentioned in the beginning of the course, even other bounded contexts in your own system may be different enough to merit having an anti‑corruption layer in place to protect the two distinct models from one another. And, of course, legacy applications frequently use very different models from newer systems. An anti‑corruption layer isn\u0026rsquo;t a design pattern, however, it\u0026rsquo;s usually comprised of several design patterns. The job of the layer is simply to translate between the foreign system\u0026rsquo;s model and your own. ‑In addition to translating the objects themselves, the anti‑corruption layer can also clean up the way in which you must communicate with the other system. It may provide a façade to simplify the API or an adapter to make the foreign system behave in a way that is known to your system. You can learn more about these design patterns in the Design Patterns Library on Pluralsight. ‑We\u0026rsquo;re usually most concerned with having an anti‑corruption layer in place when communicating with legacy systems. Eric Evans notes why that\u0026rsquo;s important. ‑Even when the other system is well designed, it is not based on the same model as the client, and often the other system is not well designed. ‑Since this is a fundamentals course, we\u0026rsquo;re not going to dig deeply into anti‑corruption layers, because they can be fairly complex, as well as very customized to each scenario, but here\u0026rsquo;s an example structure of one which comes from Eric Evans\u0026rsquo; book, showing how an anti‑corruption layer can connect your beautiful system on the left with a not so beautiful system on the right. ‑I really like this diagram. I think Eric had some fun putting it together. ‑Gee, what gives you that impression, Steve? ‑Of course, in the middle you can see how the anti‑corruption layer is using a façade and some adapters, but on the right it\u0026rsquo;s protecting us from a big complicated interface, some messy classes, and some things we just don\u0026rsquo;t even want to know about. ‑Right, and of course, your own system is comprised of an elegant class, a very expressive class, and of course even more good stuff, and maybe even some stuff we should be refactoring as well. ‑There\u0026rsquo;s no one way to create an anti‑corruption layer. Whatever you need in order to insulate your system from the systems it works with is what you should put inside of this layer, which should allow you to simplify how you interact with other systems, ensure that their domain decisions do not bleed into your design, and ensure any necessary translation is done along the way.\nReview and Resources We\u0026rsquo;ve covered some new topics in this module, and there\u0026rsquo;s a few new terms that we want to make sure we review. Domain events are a type of object that actually represents something that occurred within the domain that other parts of the system may find interesting and want to tie their behavior to. And this is a great way to keep your system decoupled and to keep your individual objects simpler because they don\u0026rsquo;t have to know about all of the behavior that might occur when some event takes place. We also referred to the Hollywood principle, which can be summed up as don\u0026rsquo;t call us, we\u0026rsquo;ll call you. This principle is related to the dependency inversion principle from SOLID and is frequently used to decouple systems from one another. Instead of us putting all the logic we need in our code, we architect the system so that it calls back to us at the appropriate time. And we put our code into handlers that the app calls, rather than directly coupling our model to these actions. ‑And finally, we looked at anti‑corruption layers, which can be used to ensure that our model that we worked so hard to produce doesn\u0026rsquo;t become polluted by the models of other systems we work with based on objects they wanted to return to us or the type of API that they want us to code to. So we put anti‑corruption layers in place to shield our model from those other systems or bounded contexts that we might work with from our bounded context. ‑In this module, we introduced domain events, and hopefully, you have a good idea of what they are at this point. ‑We\u0026rsquo;ve talked about how you can identify opportunities to use domain events based on the kinds of requirements your customers give you, as well as when you see code in your model that\u0026rsquo;s doing too much and could be more loosely coupled. ‑We gave you some tips for designing and naming domain events, and then we showed them in action, both in a relatively simple console app, as well as in our much larger veterinary clinic sample application. ‑Finally, we introduced the concept of anti‑corruption layers, which use a variety of design patterns to insulate our model from the design choices of other applications or bounded contexts. Here are a number of resources where you can learn more about domain events and anti‑corruption layers. Some of these, including a few Pluralsight courses, we mentioned in this module, but there are others that we find to be relevant, even if we didn\u0026rsquo;t explicitly mention them. ‑Up next, we\u0026rsquo;re going to wrap up this course by adding a new feature to the application. Because of our clean architecture and well‑designed domain model, it\u0026rsquo;s going to be pretty easy to integrate into our existing app. I\u0026rsquo;m Steve Smith, ‑and I\u0026rsquo;m Julie Lerman, and thanks for watching this module of our Domain‑Driven Design Fundamentals course.\nEvolving the Application Easily Thanks to DDD Introduction and Overview Hello, this is Julie Lerman, ‑and this is Steve Smith. In this module, we\u0026rsquo;re going to wrap up our course on Domain‑Driven Design Fundamentals by showing how we can reap the benefits of our design when it\u0026rsquo;s time to add additional functionality to the system. ‑In this module, we\u0026rsquo;ll first review our current system design and see how it incorporates DDD patterns and practices. Then, we\u0026rsquo;ll circle back to our customer, Michelle, to see how the new vet clinic appointment management system is working out. ‑During that quick conversation, we\u0026rsquo;ll learn about a new feature, and we\u0026rsquo;ll show how we can implement that feature. ‑We\u0026rsquo;ll leverage message queues to implement this feature, so we\u0026rsquo;ll definitely be sure to share with you some of the basics about message queues before we show you that code. ‑The main benefit of our design choices is the ease with which the system can be extended and maintained in the future. And we hope you\u0026rsquo;ll agree that adding to the current design is quite straightforward.\nReviewing Our Current System Design So far, our system is pretty simple, though it\u0026rsquo;s fairly complex, as most course demo apps go. ‑The system is currently two different web applications, although the user interface makes it look like a single app. Our main focus has been the application used by clinic employees to schedule appointments. There\u0026rsquo;s a lot of complexity with scheduling, so this benefited from domain‑driven design. There\u0026rsquo;s also a clinic management application that\u0026rsquo;s used to do simpler data‑in/data‑out tasks like record keeping and maintaining information about doctors, clients, patients, and more. Let\u0026rsquo;s review the scheduling app a little more closely. ‑We have a single aggregate for a schedule, which contains a number of appointments. We limit access to the schedule through the schedule repository class, which is responsible for retrieving and storing the schedule in our database. We\u0026rsquo;ve identified a couple of value objects that allow us to better model concepts in the domain, and we\u0026rsquo;re making use of domain events to allow our domain in other parts of our system to respond to changes in the state of our model. ‑It\u0026rsquo;s taken us a while to get to this point, but now that we\u0026rsquo;re here, the design of the system is very clean, and it reflects the customers domain, as well as we\u0026rsquo;ve been able to model it so far, of course, given some time constraints. ‑Yes, we do have to ship the app, I mean, this course, at some point. ‑Right, of course, as we build on this application, our model would continue to evolve. But we\u0026rsquo;ve shown you techniques you can use to ensure that you can grow the application without being overwhelmed by the complexity you\u0026rsquo;re trying to model. ‑Actually, as it turns out, the customer does have one more request for us. She said something about customers forgetting their appointments. Let\u0026rsquo;s have another quick conversation.\nAddressing a New Feature with the Domain Expert As it turns out, the customer does have one more request for us. She said something about customers forgetting their appointments. Let\u0026rsquo;s have another quick conversation. ‑Hey, Michelle, great to see you. How are things going with the new scheduling application? ‑It\u0026rsquo;s been fantastic. We\u0026rsquo;re really able to see very easily who scheduled each day, and book new appointments, and move things around is needed, and the front desk folks really appreciate that it highlights the appointments that are conflicting or unconfirmed. That makes it much easier for them. But one thing that\u0026rsquo;s still a problem is the fact that sometimes our clients forget their appointments. It probably happens at least a couple of times every day, and our staff really don\u0026rsquo;t have the time to call every client to make sure they remember ahead of time. ‑So, you\u0026rsquo;d like the system to call them then? ‑Well, we understand there\u0026rsquo;s services that\u0026rsquo;ll do that sort of thing and we might move to that eventually, but for now, if we could just send an email that would probably help remind clients to put it in their calendar. ‑Oh, okay, so, do you want an email to go out when they schedule the appointment or on the day before they\u0026rsquo;re scheduled to come in, or maybe even both? ‑Oh wow, if we could do both, that would be great, one to let them know when they\u0026rsquo;ve booked so that they know that we\u0026rsquo;ve got it in our schedule and another one to remind them that they have an appointment the next day, just in case they forgot. ‑That shouldn\u0026rsquo;t be too hard. Our model already handles certain events that occur, like when appointments are scheduled, and appointments already support being marked as confirmed too. ‑Sure, and I think all we\u0026rsquo;ll really need to build that\u0026rsquo;ll be new is some kind of service for sending the emails and some way for clients to click a link in the email so they can confirm the appointment. Since it\u0026rsquo;s email, it shouldn\u0026rsquo;t be a problem to send these out the day before, even if that day isn\u0026rsquo;t a week day or a work day, right? ‑No, I think that should be fine. It shouldn\u0026rsquo;t hurt anything to send an email on a Sunday or a holiday, and of course, we\u0026rsquo;ll ask our clients to opt into these reminders so we\u0026rsquo;re not sending anything unsolicited. ‑Sounds good. We\u0026rsquo;ll get started, and should have something for you to review real soon.\nPlanning Our Implementation Steps Before we get into the gory details of the implementation, we just want to make sure that you understand the very high level of what we\u0026rsquo;re doing here. The first thing is triggered when the appointment is scheduled. And in response to that, our system will send a confirmation email to a client. ‑Once the client gets that confirmation email, they can click a link to confirm that they\u0026rsquo;re going to make it to the appointment, and the system will then mark that appointment as confirmed so that on the schedule, the staff will see that it\u0026rsquo;s got a green box around it, and they should expect the client will actually show up. ‑What\u0026rsquo;s nice about this implementation is that it benefits so much from a lot of the infrastructure we already have in place. And thanks to our DDD‑based architecture, it\u0026rsquo;s just as easy to add in a few extra features that we need to make this work. ‑So as we go through this, you\u0026rsquo;ll see us using some existing and some new domain events, some application events, a number of event handlers and services. One new tool you\u0026rsquo;ll see is something we haven\u0026rsquo;t talked about yet, messaging queues to communicate between separate applications. The application we\u0026rsquo;ve been working with will need to communicate with a public website that the customers will interact with when they confirm their appointment.\nIntroducing Message Queues Before we go any further, we did just mention something new, which is message queues. And we just want to talk about that a little bit. It\u0026rsquo;s a pretty advanced topic for this fundamentals course, so we\u0026rsquo;re going to talk about it at pretty much a high level. ‑Message queues are nice to use between applications for a number of reasons. They can help decouple them and make it so that one of the applications can just drop off something into a message queue and continue on with its work and not have to worry about what happens to the message after that. ‑Right, or if whichever application or applications it\u0026rsquo;s trying to communicate with, it doesn\u0026rsquo;t need to worry if that application is available and listening at that very moment. The message can sit in the queue and when the other application is ready to grab it, it does. With a message queue, we\u0026rsquo;re really just dealing with a single message. One application drops it, and the other one takes it, and then the message is gone. ‑Yeah, and there\u0026rsquo;s lots of different implementations of message queues that you can find online. Some of them are free. Most of the cloud services that are out there now have these types of things built in as well. ‑And what we\u0026rsquo;re doing here is dealing with a single message at a time in something of a silo app since we control both applications that are communicating with each other. But sometimes you need to have a lot more flexibility than that, you might actually have a number of applications that are interested in that message and you may not even know in advance or control those applications. So this is when something called a service bus comes into play. ‑Right, so you\u0026rsquo;ll frequently hear about something called an enterprise service bus. And there\u0026rsquo;s, again, a number of examples of these that you can find available. It usually sits on top of message queues and other features. And one of the responsibilities it has is making sure that messages get delivered to the different applications that care about that message. ‑It might even be an application that didn\u0026rsquo;t even exist or you didn\u0026rsquo;t know about when you were first setting up the message queue. So even at that point, because service bus allows you to decouple the routing of the message, it\u0026rsquo;s possible to go ahead and hook up other applications to listen to the queue. ‑Right, so you\u0026rsquo;ll see in our scenario that we have our scheduling application raising an event that an appointment was created. And it might be that maybe in the future we would want to add some other application that wants to react to that event. ‑We could publish it to social media, hey, I\u0026rsquo;m going to go see the vet. ‑Exactly. If we had a service bus, we could simply wire up in our service bus for this new social media notifier service, pick up that event. But with just message queues, as you\u0026rsquo;ll see in our implementation, we would have to change our scheduler application to know about this new app and write to its queue because we don\u0026rsquo;t have any advanced routing, everything\u0026rsquo;s hardcoded in our simple scenario. The message queue we are using is RabbitMQ. It\u0026rsquo;s a mature, open‑source message broker that you can get set up and running with zero install by using a prebuilt Docker container. It has a lot of capabilities, but we\u0026rsquo;re keeping it simple and just using it to define a few specific queues, which are separate bounded contexts we\u0026rsquo;ll use to publish and consume events.\nSending a Message to the Queue Now let\u0026rsquo;s take a look at how we\u0026rsquo;re adding message queues into our solution. The first part of the process happens when the appointment is scheduled. And you\u0026rsquo;ve already seen our AddNewAppointment method inside the schedule aggregate root. And you saw how the domain uses domain events and domain services to notify the user interface if there\u0026rsquo;s a conflict in the schedule. In the previous module, we showed you MediatR, which we\u0026rsquo;re using to publish these domain events. And we also talked about integration events, which are structured to be shared between different applications. So what we\u0026rsquo;re going to do in our system is add RabbitMQ into the mix at the same point where MediatR is publishing the domain events. But we\u0026rsquo;ll ask RabbitMQ to publish our integration events. These events will be formatted as JSON data before they\u0026rsquo;re inserted into the queue. So let\u0026rsquo;s see what this looks like in the application. We\u0026rsquo;ll be looking at the code that makes all of this work a little further on in this module. We\u0026rsquo;ll go ahead and create a new appointment. Let\u0026rsquo;s bring Sampson in to see Dr. Jones again. So there\u0026rsquo;s the appointment. Nothing has changed from the perspective of the user. RabbitMQ includes a user interface to inspect the queues, and in the Front Desk app the menu has a link so that you can open up this admin page and see what\u0026rsquo;s going on with the queues that are associated with this application. We\u0026rsquo;ll head to the Queues page and then drill into the vetclinicpublic queue, which is a queue that we set up to handle communication between the Front Desk app and the VetClinicPublic app. And you can see that the one and only message that RabbitMQ is tracking is in that queue. So we\u0026rsquo;ll drill into that queue and then scroll down to see the details of the message itself. And the most interesting part, the payload, which is the JSON expression of the event data. You can see the GUID value of the AppointmentId, the ClientName is Julie Lerman, an email address, which is not really my email address, the PatientName is Sampson, and other relevant details that came from the integration event. So the Front Desk app knew to publish the message to this queue, and our VetClinicPublic app knows to read from this very specific queue in order to perform the task of emailing the client.\nReading From the Message Queue and Acting on the Message Now that the message is waiting in the message queue, it\u0026rsquo;s time to read the message and act on it. And acting on it is the next step in a workflow, sending an email to the client to let them know about the appointment they\u0026rsquo;ve just scheduled. We can\u0026rsquo;t do this easily from our scheduler application because we need for the user to be able to click on a link that specifies that they want to confirm their appointment, so it needs to be publicly accessible. So we\u0026rsquo;ve decided to put this on the veterinary clinic\u0026rsquo;s public website, and so that will be responsible both for sending the emails and for hosting the link that the customer will click. The public site uses a hosted service to periodically check for new things in its queue. Once it finds a message on the queue, it will retrieve the information from that message to create a confirmation email using code like what you see here. One of the most important pieces of this email is a link back to the public website, not really localhost, which includes the GUID that represents the appointment ID. The website then sends the email. That\u0026rsquo;s what the user will end up clicking on in their email and trigger a confirmation using the website. Alright, so now we\u0026rsquo;re looking at the vet clinic public website, which is a super simple demo solution that we put together. And one of the things it does when it starts is start checking for messages, which you can see here. But we don\u0026rsquo;t have it running quite yet because it would\u0026rsquo;ve already pulled the message out of the queue. First, we\u0026rsquo;ll show you the code that\u0026rsquo;s making this all work, and in a bit, we\u0026rsquo;ll step through while debugging. The public website has a hosted service called FrontDeskRabbitMqService, which periodically checks the message queue to see if anything new has arrived. As soon as it finds one of those messages off of the message queue, it\u0026rsquo;s going to send an email, and we\u0026rsquo;re going to use a tool called Papercut, which will emulate a local email server for the purpose of testing. Rather than installing this on our dev machines, we\u0026rsquo;re running a Docker container to host Papercut. You can view emails Papercut has received by clicking the Sent Emails link from the FrontDesk app\u0026rsquo;s menu. Currently, there aren\u0026rsquo;t any emails in Papercut, but as soon as we start the web application, it\u0026rsquo;s going to check our message queue and then send an email that we should see appear in Papercut. There\u0026rsquo;s a message, the same message that we sent out for Sampson\u0026rsquo;s appointment. There\u0026rsquo;s a hyperlink that leads us back to being able to confirm. Let\u0026rsquo;s see first, high level, what happens when we click on that CONFIRM button, and then we\u0026rsquo;ll come back and click it and watch it in action. So now the user has the email, and their beautiful CONFIRM link in the email. When they click that, it opens up the website, browsing directly to the GUID that was their appointment. And in response, the website calls its own method called confirm, which takes the relevant appointment ID and pushes it into another one of the queues. You\u0026rsquo;ve seen the message queue that was used for relaying the message from FrontDesk to the public website, and that was named fdvcp‑vetclinicpublic‑in. Try to say that five times fast. But you can have as many queues defined in your system as you need. And one of the other queues that we\u0026rsquo;ve defined is for relaying messages from the public website, in other words, when the client has clicked on the button to confirm their appointment back to the FrontDesk app.\nUsing Multiple Queues to Handle Various Communications Now that the email\u0026rsquo;s been sent, let\u0026rsquo;s see what happens when the client clicks on the CONFIRM link in that email. ‑When we click on that, we\u0026rsquo;ve now confirmed the appointment. Once the user clicks on the CONFIRM link, it drops the message with the confirmation back into the scheduler queue, and you can see that message right here. ‑Yeah, this middle queue shows that there\u0026rsquo;s one message. Let\u0026rsquo;s look at it. We\u0026rsquo;ll scroll down to the Get Message(s) button, and the message is retrieved and displayed. We\u0026rsquo;ve seen this before where the payload is the JSON data we\u0026rsquo;re looking for, and this one contains the appointment ID that\u0026rsquo;s just been confirmed. Now you can see that the two different applications are communicating back and forth with each other using their two separate message queues. We\u0026rsquo;ve named the queues so that it\u0026rsquo;s clear which applications are using them to communicate and in which direction. The initial acronym specifies which two applications are involved. Fdvcp means frontdesk and vet clinic public. The latter part of the queue\u0026rsquo;s name says which app is listening to it. The last step now is for this confirmation information that\u0026rsquo;s sitting in the queue to get back to the scheduling app. ‑Now in our scheduler application, we have implemented a hosted service just like you saw in the public website This one is called the VetClinicPublicRabbitMQService, and it listens to the appropriate queue to see if there are incoming messages that it needs to deal with. When it finds one, it responds to the AppointmentConfirmLinkClickedIntegrationEvent, yes, it\u0026rsquo;s a long name, with the email confirmation handler. The handler looks up the appointment from the AppointmentId that was contained inside of the message, and from there, it calls Appointment.Confirm. Appointment, as you recall, is our entity, and its confirm method also then triggers some domain events, which for instance, our user interface listens to. And when it sees that that event has been fired, it triggers a change in the UI, enhancing the appointment with a green bar across the top to show that the appointment has been confirmed. Okay, so all that\u0026rsquo;s going to happen at this point is that when the message comes through, it\u0026rsquo;s going to make the Sampson appointment right here have a green border and pop up a dialog to let us know that a change has occurred. ‑It\u0026rsquo;s very slick. This is actually really easy to implement because we already had the website listening for events. Remember how it was able to display new appointments and display conflicts? We\u0026rsquo;ve implemented another design role based on a particular property of the appointment, which is confirm. All we did was set up another event handler. ‑We wrote the original sample for the first version of this course in 2013. At the time, things like SignalR and WebSocket, as well as emails with confirmation links were relatively rare, although we certainly didn\u0026rsquo;t invent these kinds of app interactions. ‑Right, but now, every time I make an appointment for my dentist or hair and even for Sampson in real life to go to the vet, I\u0026rsquo;m getting texts or emails with exactly these kinds of confirmation links. ‑I know, I guess maybe a lot of businesses watched our course.\nDebugging to See the Detailed Implementation in Code Now we\u0026rsquo;re going to take a deep dive into the code that makes all this work, and we\u0026rsquo;ll go through it step by step so that you can see how all this is wired together. And we\u0026rsquo;ll do that by literally just debugging through the whole process, so you can see how all the code links up. Remember, all of the code for this sample is available on GitHub, and we encourage you to run it yourself to really understand how it works. The README file has instructions for running the solution using Docker, which is the recommended approach if you just want to see it running. There are also instructions for using Visual Studio or VS Code, which you will need if you want to debug the apps as we\u0026rsquo;re about to do. For instance, I need to run RabbitMQ and PaperCut using the Docker commands shown here, before I can debug the app, as we\u0026rsquo;re about to see. We\u0026rsquo;re back in the vet manager, and the user is on the phone with Steve who wants to make an appointment with Darwin. Everything works just the same way it\u0026rsquo;s worked before. We\u0026rsquo;ll go ahead and add a new appointment and save the appointment, which triggers the ScheduleAggregate root\u0026rsquo;s AddNewAppointment method. We\u0026rsquo;ll leave the Locals window open while we\u0026rsquo;re debugging so that if you want to pause the video and take a look at any of those values, you can do that. We haven\u0026rsquo;t changed anything in the method. The only thing that\u0026rsquo;s different is that now we\u0026rsquo;ve got an additional subscriber that\u0026rsquo;s listening for this domain event, this particular domain event, the AppointmentScheduled event, to be raised. So we\u0026rsquo;ll go ahead and raise the event and watch what happens. At this point, we\u0026rsquo;re looking at a new class that we created, which is this RelayAppointmentScheduled service, and what it\u0026rsquo;s responsible for is creating the event that is going to get pushed onto the message queue that the public website is listening to. This is the new piece of logic that\u0026rsquo;s listening for the event that we just raised. You can see it\u0026rsquo;s listening for AppointmentScheduledEvent, a domain event, and in the method, the first thing we do is to create the AppointmentScheduledIntegrationEvent that represents our cross‑domain message that will be sent using RabbitMQ. The functionality we need from this event right now is to be able to send an email to the client, so we make sure to include all of the data that such an email would require. Now we\u0026rsquo;re in the Publish method that lives inside of RabbitMessagePublisher, and that\u0026rsquo;s inside of an infrastructure project. We\u0026rsquo;ve moved out of the core domain, but this is still part of the main front desk scheduling application. Yes, and what it\u0026rsquo;s responsible for doing is actually getting that message into a structure, a format that RabbitMQ can use. That means putting things into JSON format in this case, and then actually sending the message. Once this fires, we should be able to inspect the message queue in RabbitMQ, and verify that our message has actually been queued up for the VetClinicPublic input queue as expected. That\u0026rsquo;s what we did before, but this time we\u0026rsquo;re actually seeing the code that\u0026rsquo;s making all of this happen. Alright, so that completes the actual thread of the UI. The response is complete for this part of the application. Now we\u0026rsquo;ll pause this and switch over to the VetClinicPublic application. We\u0026rsquo;ve just started it up again, and we\u0026rsquo;ve shown this to you before. Now we\u0026rsquo;re going to watch the flow of the code after the hosted service starts up. Jumping to the next breakpoint, you can see now we\u0026rsquo;re inside of the actual HandleMessage method, which gets the message as a string. It\u0026rsquo;s responsible for parsing the string using JSON, and deserializing it into an appropriate type. This is just demo code, so it\u0026rsquo;s not the most reusable or elegant, but it works for this app. Remember that any change to the integration event in the front desk app will require changes here as well, which is one reason why a shared package can be useful for keeping applications in sync. Once we\u0026rsquo;ve deserialized the message into a command, we use mediator to send the command, and a separate handler to actually send the email. This keeps extra code out of the hosted service, and lets the handler use dependency injection to get any services it needs. In this case, it\u0026rsquo;s an implementation of, I send confirmation emails, called ConfirmationEmailSender. It\u0026rsquo;s the service that builds the email with its details, including the URL behind the CONFIRM link in the email that the client receives. Remember, the whole reason why we need a separate app to implement this feature is that the end user needs to be able to click a link that goes to a public location on the internet. The front desk app is an internal app that runs inside the vet clinic\u0026rsquo;s network so it\u0026rsquo;s not accessible. The public website is a good place to send users, and while they\u0026rsquo;re there, they can get more details about the clinic, or buy something from its theoretical online store, etc. After the email has been sent, we can see it in PaperCut, and opening it, we can see the CONFIRM hyperlink. Clicking the link brings us back into the VetClinicPublic application\u0026rsquo;s, AppointmentController class. This endpoint simply creates a new event. This is the one with a really long name, AppointmentConfirmLinkClickedIntegrationEvent. Unlike the name of the event, the message itself is really simple, and just includes the appointment ID that was confirmed, and when it happened. The controller action then sends the event using a RabbitMQ messagePublisher that\u0026rsquo;s identical to the one we just saw the front desk app use. However, this publisher\u0026rsquo;s destination is actually a different queue, the front desk input queue. Technically, the front desk has two input queues, one for messages from the ClinicManagement app, and another for messages from the VetClinicPublic app. In this case, we\u0026rsquo;re talking about the VetClinicPublic one. Back in the front desk scheduling app\u0026rsquo;s hosted service, it discovers the message on the queue, and calls into the HandleMessage method in the service we\u0026rsquo;ve seen a number of times, the VetClinicPublicRabbitMqService. Here, it parses the message and extracts the appointment ID, which it then uses to create and publish that really long‑named event again, AppointmentConfirmLinkClickedIntegrationEvent internally. This integration event triggers a call to the EmailConfirmationHandler, which loads the schedule aggregate, then locates the appropriate appointment, and calls its Confirm method. Finally, it saves the schedule. The appointment.confirm method makes an appointmentConfirmed domain event, which is fired once the aggregate is saved, and this event in turn triggers a handler in the UI. The appointmentConfirmed handler in the FrontDesk UI sends a message via SignalR, indicating the message was confirmed. This results in the browser showing a notification, and changing the format of the appointment to have a green border. You already saw similar logic used for the AppointmentUpdate and AppointmentScheduled handlers. That\u0026rsquo;s the full round trip for how creating an appointment, getting an email, clicking a link, and confirming that appointment works for this application.\nConsidering Microservices Since we published our original version of this course, which if you haven\u0026rsquo;t watched, you\u0026rsquo;ll find a link from either of our author pages, microservices have become incredibly popular. There are some benefits to microservices, even if they\u0026rsquo;re probably a bit overhyped at the moment, and there are some obvious parallels between microservice design and DDD. ‑Microservices should be self‑contained and should not depend on other microservices. They should be independently deployable. Changing the internal behavior of a microservice should not break services that work with it, as long as it maintains compatibility with its external APIs and message interfaces. ‑So, basically what you\u0026rsquo;re saying is each microservice should have a boundary around it, and within that boundary it should focus on a specific set of behaviors that its free to model however it sees fit. ‑That\u0026rsquo;s right. ‑It\u0026rsquo;s almost like each microservice can be considered its own context, and it has its own terminology and even language for how it\u0026rsquo;s designed. ‑It is a lot like that, it\u0026rsquo;s true, and it\u0026rsquo;s not unusual for teams to treat individual microservices like bounded context with their own ubiquitous language and everything else that goes along with being a bounded context. But, beware of assuming that microservices and bounded context always have a perfect alignment. There can be plenty of scenarios where this could be a problem. My brilliant friend, Vladik Khononov, not to be confused with the also brilliant Pluralsight author, Vladimir Khorikov, has shared his experiences along these lines in his blog and also in recorded conference presentations. We\u0026rsquo;ll include links to his content in the resources at the end of this module. ‑Now, this isn\u0026rsquo;t a microservices course, but obviously if you\u0026rsquo;re working on microservices, it would be helpful for you to have a good understanding of DDD concepts, because many of the problems that microservices solve are also solved by domain‑driven design. ‑In our sample application, there is an obvious candidate for a microservice. In fact, it\u0026rsquo;s almost there already, the confirmation email sending logic that currently runs inside the public website. ‑We put the hosted service in that existing web application because it was convenient and because the two are loosely related since the emails include a clickable link that goes to a page on that public website. ‑But we could easily move that hosted service into its own process and treat it like a separate microservice, and that would simplify the public web app, so it would no longer need to have a two‑way relationship with a front desk app by way of message queues. Also, the front desk app is likely to be updated more frequently than the confirmation email logic, so it\u0026rsquo;s possible that changes to the front desk application could break the email logic. ‑Yes, one of my favorite benefits of carving out a microservice is that if it\u0026rsquo;s something stable and working, you get the benefit of just leaving it the heck alone. Updates to other parts of the app or system are much less likely to break a microservice that is in production and working, and not being deployed frequently. ‑Right, and the email sending logic is about as micro as a microservice can get, but in the future we might want to add other kinds of customer emails to send, and it would be a logical place to hold that logic. ‑Exactly, and since it has no user‑facing logic, it\u0026rsquo;s a pretty simple change to make. Maybe some of our students could do that as another exercise.\nSharing Some Tips for Extending and Running the Sample Application As we wrap up the course, we want to remind you, once more, that there are a number of to‑do items in the sample that you can use as ideas for ways to extend this demo app. Doing so would help you gain real experience working with the architecture and patterns you\u0026rsquo;ve learned in this course. You\u0026rsquo;re sure to learn and retain more from actually working with the code than from just listening to us or watching us show you the code. ‑We do have detailed instructions in the README for how to run the app. You can run the individual solutions in Visual Studio, but if you do so, keep in mind, you\u0026rsquo;ll also need to make sure you have a local SQL Server running, and you\u0026rsquo;ll need to update the connection strings and app settings for the applications to access it. You\u0026rsquo;ll also need your own RabbitMQ and Papercut or similar test email server running, either as Docker containers or locally‑installed services. There\u0026rsquo;s definitely a bit of effort involved in getting all of this set up and running the first time. ‑Alternatively, if you just want to run the app and see everything working, you should be able to do so with just two commands, assuming you have Docker installed. Just run docker‑compose build ‑‑parallel and then docker‑compose up. Each of these commands might take a few minutes. It usually takes about 2 minutes for the build step on my machine, and it\u0026rsquo;s normal to see some errors when the docker‑compose up command runs until all of the services are up and running. Once the process stops outputting messages to the log window, you should be able to hit the application. To do that, take a look at the ports that are shown in the README file. And in the Docker column, you\u0026rsquo;ll see the ports for all of the different applications and utilities that are used.\nConsidering the UI in the Domain Design The control we used solved a number of the problems we thought we were going to have when embarking on this application. But the fact that the UI kind of impacted how we designed our domain begs the question about, well, if you\u0026rsquo;re totally focused on the domain, why would you even be thinking about the UI? But thinking about the UI while we\u0026rsquo;re working on the domain is not the anti‑pattern you may think it is. ‑Yes, we\u0026rsquo;ve been focusing on the domain, but frequently the user interface needs to be considered, especially in the early stages of planning. You don\u0026rsquo;t want to try to flesh out the whole domain design before you start thinking about the UI. ‑In a TechEd session I attended in 2013, Jimmy Nilsson, who\u0026rsquo;s the author of the book Applying Domain‑Driven Design and Patterns, talked about the importance of thinking about the UI in the early stages of planning and revisiting it while modeling the domain, rather than ignoring it until the end. In his session, he describes how even the UI sketching he does in the early stages of his application planning can affect the whole design of the system. As we were building this scheduler sample for this course, we actually discovered a huge benefit to considering the UI early in the process. We initially had expected to encounter a lot of complexity in the appointment scheduling problem, but we found a UI control that helped visualize the schedule for the user, such that the system no longer needed to be as complex. In our scenario, scheduling is a big part of the application, but it isn\u0026rsquo;t our domain, our domain is the veterinary clinic. We consider scheduling to be more of a cross‑cutting concern, and one that could be partially solved through a rich user interface. ‑By considering and using a rich user interface, we were able to do things like allowing conflicting appointments while making it obvious to the user that this had occurred. This gives the user more information, and they can make decisions about whether or not they need to correct the problem. When we initially considered the problem of appointment conflicts, we had thought the domain model would throw exceptions anytime something like that occurred. But this would have resulted in a much worse user experience. Frequently, in domain‑driven design, you need to consider the user experience, which at times may need to allow for models that are, at least temporarily, in an invalid or incomplete state. Keep this in mind as you design your domain model, and be careful not to make it too rigid to support scenarios your users may benefit from. ‑Thinking about the UI up front and discovering this kind of solution kept us from wasting a lot of time trying to solve certain scheduling problems in our domain. Of course, you don\u0026rsquo;t want your UI to totally drive how you model your domain, but as Jimmy Nilsson notes, you shouldn\u0026rsquo;t ignore it, either.\nModeling with Event Storming and Other Techniques When you\u0026rsquo;re developing apps using DDD, it can be helpful to visualize how processes communicate both within a bounded context and between context as part of a business process. As we mentioned earlier in this course, Alberto Brandolini has done a lot of work on a related practice called event storming. Event storming can be used by all parts of a business, not just developers, to describe how a part of the business works and to make the whole thing visible. Once this is done, later iterations of the diagrams and artifacts produced can be useful for modeling the software that will be used by the business. ‑You might recall the image we showed earlier of Julie facilitating an event storming workshop with a client. The result of that first iteration, called chaotic discovery, is not so easily captured, but it provides guidance for the later modeling you might do. ‑There are many ways to model your system. Another method, Event Modeling, championed by Adam Dymitruk, is another process, and this focuses on the inputs and outputs of events and how each of those events changes the system and changes state. And you can describe an entire system with this flow. ‑We\u0026rsquo;ve used the wonderful online tool called a Miro board at miro.com to show one perspective of the scheduling system as information flows through the front desk application and into the VetClinicPublic website bounded context. The colors used here correspond to different things in our model, like aggregates, events, and other processes. ‑And there are other modeling processes that have been invented, adopted, and adapted within the DDD community. And many of us rely on a combination of processes and tools to help us and help our clients better understand their systems before embarking on design. But as always, balance is important. You\u0026rsquo;ll want to beware of analysis paralysis. ‑Definitely. That reminds me of something Eric Evans talked to us about.\nEric Evans on the Fallacy of Perfectionism Steve and I believe that it would be fitting to leave you with one last thought from the father of domain‑driven design, Eric Evans. Eric was kind enough to talk to us about DDD when we originally created this course so that we could share with you some of his wisdom. Eric talked about the fallacy of perfectionism, which aligns with our own sentiments about considering what you\u0026rsquo;ve learned here to be guidance to help you solve complex software problems, not a roadblock to productivity. ‑Eric shared with us that what he\u0026rsquo;s noticed is that there seems to be something about DDD that brings out the perfectionist in people, and they say, this model is not really good enough and churn and churn, trying to improve it. He says, no model is ever going to be perfect. ‑Eric goes on to say that we need to know what we\u0026rsquo;re doing with this thing, the scenarios we\u0026rsquo;re trying to address. We want a model that helps us do that, that makes it easier to make software that solves those problems. That\u0026rsquo;s it. ‑This reminds me of the saying, all models are wrong, but some are useful. Our domain models don\u0026rsquo;t need to be perfect. They just need to help us build the software that helps people solve problems and get work done. Don\u0026rsquo;t strive for a perfect model, but rather just aim to develop a useful one.\nLessons Learned Since Our 2014 Course Julie and I wanted to finish this course by spending a couple of minutes talking about some of the things we\u0026rsquo;ve learned since we published the first edition of the course in 2014. ‑We\u0026rsquo;ve received a ton of positive feedback from so many of you over the last few years, and we really appreciate it. So we did our best not to change the overall flow of this course too much since we know the last one was so well‑received. ‑Definitely. If you watched the original version, hopefully you found this one to be fresh, but familiar, and I suspect a lot of students will end up watching both as a way to cement some of these concepts or just to spend more time with us, right, Julie? ‑Maybe. Now let\u0026rsquo;s highlight some of the things that have changed in the last few years. From a strict DDD perspective, there are a lot of new resources and techniques that have emerged as more and more companies are adopting DDD. Things like event storming an event modeling, which we\u0026rsquo;ve touched on in this course, are starting to become mainstream parts of DDD for many organizations. ‑Yes, and the industry\u0026rsquo;s use of some patterns have shifted too. There\u0026rsquo;s a lot of pushback against the repository pattern these days. I think, in part, because it became very popular, but was often used without the context of DDD or other complementary patterns like the specification, and these can really help it shine. Our first course didn\u0026rsquo;t really talk much about specification as a core DDD pattern, but it\u0026rsquo;s something I use on most of my projects now. ‑From a technology perspective, our previous course was built for .NET developers, and at the same time, that meant .NET 4. The original veterinary application used ASP .NET, MVC, and Web API, and an early version of SignalR. And for data access, we used Entity Framework 6. ‑Since then, .NET Core, which is now .NET 5, has shipped and become the new standard for .NET developers, and the latest versions of EF Core have added a number of features that we\u0026rsquo;re leveraging to help improve the design of our model like owned objects and filtered includes. We also shifted our use of domain events from being prepersistence to postpersistence. There are valid use cases for both kinds of domain events, but the latter is safer for any events that communicate outside of the domain, so we\u0026rsquo;re defaulting to that this time around. ‑Right, especially since one of our key demos involve sending emails to the client. The original sample also used SQL Server for its message broker, which we chose because we didn\u0026rsquo;t want to force our students to have to install a custom tool. But Docker is another technology that wasn\u0026rsquo;t mainstream in 2014, but it is today, and it makes it a breeze to use custom bits of infrastructure. In this update to the course, we\u0026rsquo;re definitely leveraging Docker to provide RabbitMQ messaging with 0 install, as well as to capture emails during development using Papercut in another Docker container. ‑Yeah, Docker should really make it trivial for students to run the application locally, even though it has a bunch of moving parts. If you don\u0026rsquo;t have Docker, you can still run it in your IDE or from the command line, but with Docker, it\u0026rsquo;s just a lot simpler to get going. ‑And along with Docker and containers, microservices have become a huge buzzword in the industry. Of course, Docker makes it much easier to deploy microservices, and DDD principles really shine when designing them. So all of these things, I think, are really complimentary. ‑Definitely, although I do think some companies are too quick to jump to microservices without fully understanding their domain and where to separate out different contexts. And on the topic of separation, our previous sample put everything in one giant solution, too, mostly to make it easier to find things. ‑This time, we went with something that should resemble a real‑world application even more with separate solutions for each bounded context. We even published the shared kernel as a NuGet package, in our case, hosted on nuget.org, although typically, your organization would probably have a private NuGet feed. ‑If you\u0026rsquo;re still working with .NET Framework apps and you haven\u0026rsquo;t watched the previous course, we encourage you to give it a look. Its samples are geared more toward that framework, and you should find a link to it on Julie or my author page here, on Pluralsight, or at this bit.ly link here. ‑And don\u0026rsquo;t feel bad if it feels like there\u0026rsquo;s still a lot you have to learn about DDD. It\u0026rsquo;s a big topic. And as we\u0026rsquo;ve just shared, Steve and I are constantly learning new ways to apply it, too. Be sure to check out other DDD courses here, on Pluralsight, and if you need direct help for you or your team, you can reach out to Steve or me, directly.\nReview and Resources If you remember nothing else from this particular module, the one thing to keep in mind is how simple it was for us to add in what was potentially a really complicated feature. Because of our DDD implementation and some of the infrastructure we had already built, it wasn\u0026rsquo;t really very challenging to plug these new puzzle pieces into the application. ‑Right, we introduced a couple of new concepts. We talked about message queues, and those fit really nicely into our existing architecture because we were already using events to correspond to interesting things happening within our application. ‑And the message queue allowed us to stick a message in an external place by one application, and another application can come along and retrieve that message. So the message queue allows our applications to communicate with each other, but they can do it in a disconnected way. ‑And then we mentioned, but we didn\u0026rsquo;t show, this concept of a service bus, often called an enterprise service bus, which you may want to introduce if you start having more than just a couple applications needing to talk to one another. ‑At the risk of being redundant, let\u0026rsquo;s just pay homage one more time to how the decisions we made earlier on, when implementing the vet clinic solution, allowed us to add in a potentially complicated new feature, email notifications and responses into the application. ‑While we had used mediator to transfer domain events within the FrontDesk application, this time we took advantage of message queues to help us move events back and forth between applications. ‑Using RabbitMQ\u0026rsquo;s API, we created three different queues that were specific to the cross‑application communications we needed. For example, a queue that the vet clinic public app could publish messages into for the FrontDesk application to retrieve so it could update the UI. ‑It\u0026rsquo;s also important to note that we leveraged existing tools like RabbitMQ and Papercut to perform certain tasks. In DDD, we would refer to these as generic domains. You\u0026rsquo;ve got to look under the covers to see how the code was making all the communication between the apps and the message keys possible, but without our domain model having to know about any of the details. ‑And then we shared some additional knowledge as we wrapped up the course. We talked about modeling practices like event storming and tools like MURAL. We talked about all of the new ideas that have evolved since we first published this course in 2014 and how they impacted this new version of the course and the sample application. ‑And we ended with some more wisdom from Eric Evans, to whom we are eternally grateful not only for bringing DDD to the software community, but also for spending time with us when we created the original course so that we could share his perspective and insights with you. ‑Like the end of a fireworks display when they shoot up many, many fireworks at once, we\u0026rsquo;re sharing here a lot of resources and links because of the great many topics we brought into this last module. There are two pages of links here to articles and videos and other Pluralsight courses, so you might want to pause the video to be sure that you see them all. ‑So, from me, Steve Smith, ‑and from me, Julie Lerman, thanks so much for taking this journey with us through Domain‑Driven Design Fundamentals.\n","permalink":"http://localhost:1313/posts/domain_driven_transcript_from_pluralsight/","summary":"\u003cp\u003eCourse Overview\nWelcome to Pluralsight. My name is Julie Lerman, and this is Steve Smith. Together, we\u0026rsquo;d like to welcome you to our course, Domain‑Driven Design Fundamentals. Steve is a trainer and architect with NimblePros and spends a lot of time helping teams write better code, faster. And Julie is well known in the DDD community for helping reluctant teams embrace domain‑driven design. In this course, we give you a strong foundation for learning how to build applications and microservices using domain‑driven design. DDD has proven to be a very effective approach for managing complex requirements. The original version of this course has helped many thousands of learners leverage domain‑driven design, and they have shared amazing feedback. Now, we\u0026rsquo;ve updated the course and its sample application to reflect ideas and tools that have emerged since that first version. Some of the major topics that we\u0026rsquo;ll cover include what are the essential ideas of domain‑driven design? What are the main patterns used in domain models? We\u0026rsquo;ll also talk about how to break up concepts into smaller parts and how these smaller aggregates and contexts communicate with one another. By the end of this course, you\u0026rsquo;ll know how to break down customer requirements into a maintainable domain model and structure a solution using domain‑driven design. Before beginning the course, you should at least be familiar with software development, ideally using C#. From here, you should feel comfortable diving into DDD and design patterns with courses on the DDD learning path and the design patterns learning path. We hope you\u0026rsquo;ll join us on this journey to learn domain‑driven design with the Domain‑Driven Design Fundamentals course, at Pluralsight.\u003c/p\u003e","title":"Domain driven Design: Learnings"},{"content":"Introduction One of the design considerations stressed upon by Jeffrey richter about APIs (Read more here) is that \u0026ldquo;API is expected to be stable over long period of time\u0026rdquo;. Recently,for a .NET based project, we decided to upgrade some of the ASMX (legacy SOAP based approach) based APIs and were immediately reminded by Customer(s) to avoid any kind of impact on existing users.\nThis means that upgrade must be done keeping in mind,\nNo changes to API Contract (SOAP remains SOAP and so on) No changes to URLs Testing to ensure no impact Initial plan was to move away from SOAP to adopt REST based approach. This thinking was aided by fact that .NET core may not support WCF (framework that supports SOAP apart from ASMX Web Services) in addition to other aspects like simplicity and wide adoption of REST. However, even microsoft has now decided to support WCF in .NET Core via CoreWCF.\nWith this constraints, below alternatives were considered to upgrade ASMX based services to WCF (the only other framework that supports SOAP based services),\nApproach Description Have existing ASMX Service call new WCF Service using Async/Await This involves hosting additional WCF Service and making HTTP requests to it. It also means maintaining both ASMX \u0026amp; WCF endpoints. Also to be mindful of latency introduced due to HTTP communication between the two. New WCF Service and URL Rewrite rules to handle requests to ASMX This involves developing new WCF Service, compatible to current service contract, and configuration to route/re-write incoming requests to new service. Existing ASMX end point can be sunset New WCF Service and mapping .asmx handler to WCF handler This involves developing new WCF Service,compatible to current service contract, and configuration so that requests to .asmx url will be served by WCF handler. Existing ASMX end point can be sunset. Lets go through above approaches in detail.\nWCF service invoked from ASMX asynchronously This involves developing new WCF Service. Existing ASMX based web service will be modified to invoke new WCF Service. Asynchronously invocation should help in this case since whole operation is I/O bound (Asynchrony is a way to get concurrency without multithreading. E.g., freeing up the calling thread instead of blocking it while an I/O operation is in progress Stephen Cleary). Since ASMX is legacy framework and only support Event-based asynchronous pattern (EAP), it is necessary to combine EAP with Task based asynchronous pattern (TAP) which is what async/await uses. Below is sample snippet,\nprivate async Task\u0026lt;string\u0026gt; FooAsync(int arg) { using (var resp = await client.GetAsync(string.Format(\u0026#34;https://jsonplaceholder.typicode.com/todos/{0}\u0026#34;, arg)).ConfigureAwait(false)) { resp.EnsureSuccessStatusCode(); using (var contentStream = await resp.Content.ReadAsStreamAsync().ConfigureAwait(false)) { APIResponse obj = await JsonSerializer.DeserializeAsync\u0026lt;APIResponse\u0026gt;(contentStream).ConfigureAwait(false); string output = string.Format(\u0026#34;{0} at {1}\u0026#34;, obj.Title, DateTime.Now.Ticks); System.Diagnostics.Debug.WriteLine(output); return output; } } } [WebMethod] public IAsyncResult BeginFoo(int arg, AsyncCallback callback, object state) { return FooAsync(arg).ToApm(callback, state); } [WebMethod] public string EndFoo(IAsyncResult result) { try { return ((Task\u0026lt;string\u0026gt;)result).Result; } catch (AggregateException ae) { throw ae.InnerException; } } Where ToApm is extension function from Stephen Toub\u0026rsquo;s excellent blog (link in code as comment),\npublic static Task\u0026lt;TResult\u0026gt; ToApm\u0026lt;TResult\u0026gt;(this Task\u0026lt;TResult\u0026gt; task, AsyncCallback callback, object state) { if (task.AsyncState == state) { if (callback != null) { task.ContinueWith(delegate { callback(task); }, CancellationToken.None, TaskContinuationOptions.None, TaskScheduler.Default); } return task; } var tcs = new TaskCompletionSource\u0026lt;TResult\u0026gt;(state); task.ContinueWith(delegate { if (task.IsFaulted) tcs.TrySetException(task.Exception.InnerExceptions); else if (task.IsCanceled) tcs.TrySetCanceled(); else tcs.TrySetResult(task.Result); if (callback != null) callback(tcs.Task); }, CancellationToken.None, TaskContinuationOptions.None, TaskScheduler.Default); return tcs.Task; } This approach involves,\nhosting and maintaining both (current and new) API end-points. We also came across issues where async/await was not working properly in case code blocks. Measuring and mitigating any latency induced due to this additional hop Additional Monitoring and logging to track WCF end-point We decided to explore alternative approaches instead of this.\nWCF service with URL re-write This requires hosting WCF Service which is backward compatible with ASMX based SOAP implementation.\nTypically this involves,\nsupporting basicHttpBinding Adding namespaces and support for XML Serialization to Service contract like, [ServiceContract(Name = \u0026#34;RequestReplyService\u0026#34;, Namespace = \u0026#34;http://tempuri.org/\u0026#34;),XmlSerializerFormat] Adding Action to OperationContract attribute like, [OperationContract(IsOneWay = false, Action = \u0026#34;http://tempuri.org/DoWork\u0026#34;)] Additional configuration to re-write incoming requests to .asmx to new service in web.config as below,\n\u0026lt;system.webServer\u0026gt; \u0026lt;validation validateIntegratedModeConfiguration=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;rewrite\u0026gt; \u0026lt;rules\u0026gt; \u0026lt;rule name=\u0026#34;asmxtosvc\u0026#34; stopProcessing=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;match url=\u0026#34;^service.asmx(.*)$\u0026#34; /\u0026gt; \u0026lt;action type=\u0026#34;Rewrite\u0026#34; url=\u0026#34;Service.svc{R:1}\u0026#34;/\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/rules\u0026gt; \u0026lt;/rewrite\u0026gt; \u0026lt;/system.webServer\u0026gt; One may want to test above re-write settings in IIS as older versions of it require installation of URL Rewrite module.\nThis is followed by testing new WCF service from existing client(s), be it .NET based clients or other ones with no changes. .NET based clients typically invoke service through generated proxy class. For other clients, we basically simulated it via Postman.\nThis approach provides cleaner implementation vis-a-vis earlier approach such that it is still new WCF based implementation with no ASMX in use.\nWCF service with .asmx extension mapped to WCF handler This approach is very similar to last one with only change being instead of using URL re-write module, we will map .asmx extension to WCF Handler. So the changes are only in web.config as below,\n\u0026lt;system.web\u0026gt; \u0026lt;httpHandlers\u0026gt; \u0026lt;remove path=\u0026#34;.asmx\u0026#34; verb=\u0026#34;*\u0026#34; /\u0026gt; \u0026lt;add path=\u0026#34;*.asmx\u0026#34; verb=\u0026#34;*\u0026#34; type=\u0026#34;System.ServiceModel.Activation.HttpHandler, System.ServiceModel, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089\u0026#34; validate=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/httpHandlers\u0026gt; \u0026lt;compilation debug=\u0026#34;true\u0026#34; targetFramework=\u0026#34;4.8\u0026#34;\u0026gt; \u0026lt;buildProviders\u0026gt; \u0026lt;remove extension=\u0026#34;.asmx\u0026#34;/\u0026gt; \u0026lt;add extension=\u0026#34;.asmx\u0026#34; type=\u0026#34;System.ServiceModel.Activation.ServiceBuildProvider, System.ServiceModel, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089\u0026#34;/\u0026gt; \u0026lt;/buildProviders\u0026gt; \u0026lt;/compilation\u0026gt; \u0026lt;httpRuntime targetFramework=\u0026#34;4.8\u0026#34;/\u0026gt; \u0026lt;/system.web\u0026gt; .... \u0026lt;system.webServer\u0026gt; \u0026lt;handlers\u0026gt; \u0026lt;remove name=\u0026#34;WebServiceHandlerFactory-Integrated\u0026#34;/\u0026gt; \u0026lt;add name=\u0026#34;MyNewAsmxHandler\u0026#34; path=\u0026#34;*.asmx\u0026#34; verb=\u0026#34;*\u0026#34; type=\u0026#34;System.ServiceModel.Activation.HttpHandler, System.ServiceModel.Activation, Version=4.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35\u0026#34; /\u0026gt; \u0026lt;/handlers\u0026gt; \u0026lt;validation validateIntegratedModeConfiguration=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/system.webServer\u0026gt; This was tested in same way as earlier with existing .NET and other clients.\nThis feels like even more cleaner approach than using URL re-write as it doesn\u0026rsquo;t involve using any additional module/library.\nFinally, we went ahead with this approach.\nHopefully,this article will be helpful to anyone involved in legacy modernization initiatives.\n[Update on 21-May-2021]\nASMX supports both SOAP as well as Form POST (i.e. content type application/x-www-form-urlencoded). This implies that there would be consumers of this API who are using either of the two formats to interact with API. Hence, it is necessary that new WCF based API supports both the formats. One way (If you are aware of any other approach, do let me know via comments) is to, Expose both SOAP and HTTP End-points like below,\n\u0026lt;service name=\u0026#34;wcf.Myservice\u0026#34;\u0026gt; \u0026lt;endpoint address=\u0026#34;\u0026#34; binding=\u0026#34;basicHttpBinding\u0026#34; contract=\u0026#34;wcf.IMyserviceSoap\u0026#34; /\u0026gt; \u0026lt;endpoint address=\u0026#34;http\u0026#34; kind=\u0026#34;webHttpEndpoint\u0026#34; endpointConfiguration=\u0026#34;webEndpointWithHelp\u0026#34; contract=\u0026#34;wcf.IMyservice\u0026#34; /\u0026gt; \u0026lt;endpoint address=\u0026#34;mex\u0026#34; binding=\u0026#34;mexHttpBinding\u0026#34; contract=\u0026#34;IMetadataExchange\u0026#34; /\u0026gt; \u0026lt;/service\u0026gt; This exposes SOAP end point at root (/) and HTTP end-point at (/http).\nSince clients are not aware of this new http end point, additional steps are needed to handle non soap requests seamlessly. This can be done in Global.asax as below,\nprotected void Application_BeginRequest(object sender, EventArgs e) { const string httpAddress = \u0026#34;http/\u0026#34;; if (Request.HttpMethod.ToLowerInvariant() == \u0026#34;post\u0026#34;) { if (!Request.ContentType.ToLowerInvariant().Contains(\u0026#34;xml\u0026#34;) \u0026amp;\u0026amp; !Request.Url.AbsolutePath.ToLowerInvariant().Contains(httpAddress)) { List\u0026lt;string\u0026gt; segments = Request.Url.Segments.ToList(); segments.Insert(segments.Count() - 1, httpAddress); var redirPath = String.Join(\u0026#34;\u0026#34;,segments.ToArray()); Context.RewritePath(redirPath); } } } Above function, injects http in path based on Content-type of incoming request and then re-writes it.\nIdeally, i would have liked to do it via URL Rewrite module in web.config. However, i faced issues while setting up the rule that uses Content-type header.\nHowever, this approach still had issues wherein WCF run-time raised errors when ?singlewsdl url was accessed. It seems problem was due to multiple interfaces (one for SOAP and other for REST) and WCF not being able to generate WSDL for it. Additionally, REST handler is also deserves a look as it simply parses payload as Query String and populating properties of request DTO/class has to be done manually,\nResponseDTO IMyservice.Process(Stream input) { string body = new StreamReader(input).ReadToEnd(); NameValueCollection nvc = HttpUtility.ParseQueryString(body); return new ResponseDTO() { cnField = string.Format(\u0026#34;NVCol --\u0026gt; {0}|{1}\u0026#34;, nvc[\u0026#34;prop1\u0026#34;], nvc[\u0026#34;prop2\u0026#34;]) }; } Overall, WCF does not have great support for handling FORM POST requests. Hence, other alternative is to have ASP.NET MVC Web API handle the post requests. This approach is detailed here, check it out. Additionally, it takes changes to BeginRequest in global.asax to re-write incoming request so that Web API controller can process it, like below,\nprotected void Application_BeginRequest(object sender, EventArgs e) { if (Request.HttpMethod.ToLowerInvariant() == \u0026#34;post\u0026#34;) { if (!Request.ContentType.ToLowerInvariant().Contains(\u0026#34;xml\u0026#34;)) { List\u0026lt;string\u0026gt; segments = Request.Url.Segments.ToList(); Context.RewritePath(string.Format(\u0026#34;/controllers/{0}\u0026#34;,segments[segments.Count()-1])); } } } ASMX and SOAP 1.1 - It was noticed that though ASMX supports SOAP 1.1, it doesn\u0026rsquo;t enforces it when it comes to \u0026ldquo;SOAPAction\u0026rdquo; Header. As per the SOAP 1.1 specification, \u0026ldquo;SOAPAction\u0026rdquo; Http Header is mandatory and is used to determineWebmethod to be invoked. Since WCF is compliant with SOAP 1.1 specification, it required additional step to infer Webmethod by means of parsing the body. Luckily, Microsoft has sample for Dispatch by Body Element and same can be readily used. Overall, WCF Samples is fantastic set of samples that covers wide variety of such scenarios. Do Check it out.\nUseful References Comparing ASMX web services to WCF APM Pattern using Tasks Async in WCF Comparing ASMX with WCF Discussion on ASMX to WCF Happy Coding !!\n","permalink":"http://localhost:1313/posts/apiupgrade/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eOne of the design considerations stressed upon by Jeffrey richter about APIs (Read more \u003ca href=/posts/restapiversioning/\n    \n    \n\u003ehere\u003c/a\u003e) is that \u0026ldquo;API is expected to be stable over long period of time\u0026rdquo;. Recently,for a .NET based project, we decided to upgrade some of the ASMX (legacy SOAP based approach) based APIs and were immediately reminded by Customer(s) to avoid any kind of impact on existing users.\u003c/p\u003e\n\u003cp\u003eThis means that upgrade must be done keeping in mind,\u003c/p\u003e","title":"Upgrading API: Learnings"},{"content":"Introduction In a company/enterprise, typically there are multiple sources of data. This could be result of M\u0026amp;A (where each of those add in a new data store) or result of multi year process of using data stores that are in vogue at that time. Result is combination of various types of relational databases, flat file systems, queues and so on. This results in Data Silos. This scenario is typically observed in companies who are running workloads On-prem (i.e. Pre-cloud, Companies who started on Cloud or have moved to it, typically tend to organize data platform better. This could be because of ease of migrating data on cloud. Typically, they centralize it around cheaper object storage (say AWS S3)).\nCompany will want to utilize this data, accumulated over the years, for business intelligence, machine learning purposes. Usually, it would require querying efficiently across these data sources or first collecting all the data in central location (say Data Lake or Operational Data store) and then querying on it.\nOverall, below are the widely adopted approaches,\nData warehouse with ETL Approach - This involves extracting data from Transactional systems (OLTP), ERP, Events store and so on. Transforming the same and then loading it into Data warehouse which is typically a store used for Analytics. Whole process is orchestrated as workflow using ETL Tools.\nLakehouse - Many companies have two different types of storate: Data Lake and Data warehouse. The data warehouse handles offline analytics, such as BI dashboards and reports, that describe what has or is happening in a business. The data lake is store for raw data (including unstructured). Instead of ETL (Extract - Transform - Load), ELT (Extract - Load - Transform) approach is followed where data from transactional system is loaded into Data Lake. Later, it is transformed/processed for analytics purposes and loaded in data warehouse. Alternatively, there is a trend where data lake itself is used for trend and/or predictive analytics. Data lake is usually based on cheaper, object storage with data stored using open formats (like Parquet , ORC etc.) favouring columnar approach. Columnar store is typically favoured for analytics over relational one.\nAs explained in Emerging Architecture for Data Infrastructure,\nData warehouse is used for analytics use cases i.e. help business make better decisions. Data lake is used for operational use cases. All the above approaches typically assume rather large volume of data being handled. Then what can be approach for companies who are having moderate amount of data (few terabytes) and still want to derive actionable insights from it. Such companies are unlikely to have big data systems like HDFC in place.\nFor these cases, One may consider Presto a.k.a. Trino. At it\u0026rsquo;s core, Presto translates SQL queries (it supports ANSI SQL) into whatever query language is necessary to access the underlying storage medium. Storage medium could be a Elasticsearch cluster, or a set of Parquet files on HDFS, or a relational database.\nPresto uses MPP (Massively parallel processing) architecture in which it has,\nCoordinator node - responsible for creating query plan and distributing the work among workers. Worker node(s) - they push down predicates to those data sources. Only the data necessary to compute join is retrieved. All workers operate in parallel mode. Presto provides many connectors like below (but not limited to),\nRelational Databases MySQL PostGres SQL Server Non-relational Databases Mongodb Redis Cassandra Columnar file formats like ORC, Parquet and Avro – stored on: Amazon S3 Google Cloud Store Azure Blog Store HDFS Clustered file systems It\u0026rsquo;s important to note that Presto does not write intermidiate results to disk, Hence worker nodes are expected to be optimized for processing and memory over storage. A Single Presto query can combine data from multiple sources. Most importantly, Presto can work without Hadoop. Presto has cost-based optimizer which means query plan takes into account the time cost associated with executing that plan and can therefore do various types of optimizations around join ordering and the sequence with which you execute that query plan to deliver the fastest level of performance.\nBelow is apt representation of how Presto works (Ref: prestodb.io)\nWhere Presto fits Typical Presto Deployment Typical use cases for Presto are,\nAd-hoc, Interactive Analytics Batch ETL processing. Centralized Data Access with Query Federation From the consumption perspective, Presto Offers CLI as well as JDBC Driver. However, there are many language specific clients available from Community.\nKey points to note while considering Presto,\nNo need for complex ETL/ELT processes and related Monitoring. No need to provision for specialized data store for Data Lake and/or Data warehouse. However, this may not hold true if Query results from Presto are required to persisted. Although, overall efforts and cost will much lower. This would also mean that existing data stores need to maintain historical data too Any specific use cases not suitable for Presto will have to be alternatively approached. Some of the points to explore further would be ,\nGiven that Presto does not use storage on its own, how can one perform Capacity planning given the expected workflow ? How are failures handled? Useful References/Interesting Links, Trino PostgreSQL protocol gateway for Presto distributed SQL query engine Happy Coding !!\n","permalink":"http://localhost:1313/posts/presto/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn a company/enterprise, typically there are multiple sources of data. This could be result of M\u0026amp;A (where each of those add in a new data store) or result of multi year process of using data stores that are in vogue at that time. Result is combination of various types of relational databases, flat file systems, queues and so on. This results in Data Silos. This scenario is typically observed in companies who are running workloads On-prem (i.e. Pre-cloud, Companies who started on Cloud or have moved to it, typically tend to organize data platform better. This could be because of ease of migrating data on cloud. Typically, they centralize it around cheaper object storage (say AWS S3)).\u003c/p\u003e","title":"Presto - A distributed SQL Engine for variety of data stores"},{"content":"Introduction While gathering data for Analytics, one often has to source data from multiple sources. Traditionally, the approach has been to do ETL (Extract-Transform-load) where,\nExtract - typically involves retrieving data from source. This could also be via streaming Transform - Apply transformation to the extracted data. Load - Loading the data in Operation Data store (ODS) or data warehouse Refer here for more details on ETL. ETL has been made easy by tools like Talend, SSIS and so on. However, there has been shift from above approach due to,\nNeed to handle different kinds of data (Structured and Unstructured) hugh volumes of data (IOT, Customer data management) Availability of cheaper storage and compute along with availability of internet scale cloud based data warehouses has recently caused wide adoption of ELT (Extract-transform-load) over ETL.\nELT offers an alternative to ETL in which data is loaded into the warehouse (sometimes in storage area called as data lake) before transforming it. It allows focussing on extraction and loading with heavy transformation offloaded to later stage. Since the transformation happens in the warehouse, it can potentially be defined using SQL (thus using same language across the pipeline). This allows more roles (say Data Analysts) to contribute to (or entirely own) the transformation logic. Data warehouse becomes single source of truth for data. Ref: ETL vs ELT\nTypically, Data flow pipeline consists of below phases (it also lists available tools for each phase),\nIngestion - Airbyte, Fivetran, Stitch Warehousing - Snowflake, BigQuery, Redshift, PostgreSQL Transformation - dbt Orchestration - Airflow, Prefect, Dagster BI - Superset, Metabase, Redash, Looker etc. I think the best way to understand the landscape is to use above tools. So i decided to implement below problem statement. The requirement is to run a weekly process that,\nDownloads list of CNX 500 companies from Exchange\u0026rsquo;s web site For each of the company , get Last traded price(ltp) and 52 week high price (yearlyhigh) Exclude companies having ltp \u0026lt; 20 or ltp \u0026gt; 50000 Rank companies by closeness of ltp to yearlyhigh Prepare buy list of up to 20 such companies. Earlier short listed stocks, which are not in top 20 this week or further than 5% from their yearlyhigh, should be marked for sell. Above is hypothetical example and using full fledged data stack may be overkill but should suffice the purpose of this article.\nE \u0026amp; L in ELT - Get the list of CNX 500 Companies and also get stock price for each of them Below are some of the options available for this task under extract and load category,\nUse Python to download list of stocks and then use yfinance to get the price and yearly high. Use tool like Airbyte which provides declarative way of importing the data via HTTP. I am planning to explore this option later. Use Go to perform the task. I decided to go with this one and code is available at here. It downloads CSV file from Exchange\u0026rsquo;s website (containing list of stocks in Index) and loads them to database. Since Yahoo finance no longer provides Free tier for API, It uses htmlquery library to parse HTML and retrieve stock price and yearly high value. T in ELT - Transform the company-wise data to arrive at weekly list of momentum stocks This is implemented using dbt. dbt (Data Build Tool) is a framework to facilitate transformations using SQL along with version control, automates tests, support for incremental load, snapshots and so on. It has notion of project or workspace that many developers are familiar with. It is offered as Command line interface (CLI) as well as on cloud which also provides web based UI. I have used CLI for this exercise. For a quick recap of dbt folder structure, refer [here]https://towardsdatascience.com/data-stacks-for-fun-nonprofit-part-ii-d375d824abf3).\nSource code of dbt project here. We will go through key part of this project which are Models that carry out the transformation. After the initial setup of dbt like configuring target (i.e. data source which in this case is a PostgreSQL database), below are Models used,\nSince Loading of company-wise data is already done in earlier step, next step is to rank the companies w.r.t. closeness to their yearly high. Below is dbt SQL which does it (At run time, dbt converts below SQL to the one understood by the Target database),\n``` {{ config( materialized='incremental', ) }} with cnxcompanies as ( select symbol, company, ltp, yearlyhigh, updatedat, rank() over (order by yearlyhigh-ltp) as diff_rank from {{ source('datastore', 'cnx500companies') }} where yearlyhigh::money::numeric::float8 - ltp::money::numeric::float8 \u0026gt; 0 and ltp::money::numeric::float8 \u0026gt; 20 and ltp::money::numeric::float8 \u0026lt; 50000 ), cnxtopstocks as ( select symbol, company, ltp, yearlyhigh, updatedat, diff_rank from cnxcompanies order by updatedat desc,diff_rank ) select * from cnxtopstocks ``` Above model creates corresponding table in database (as such dbt abstracts changes to database from developer and manages it on its own). Note that model is marked incremental so that it doesn\u0026rsquo;t overwrite the table on every run but rather incrementally applies changes.\nNext step is to arrive at Weekly list of stocks to buy and even sell those which are lacking momentum.\n``` {{ config( materialized='incremental', unique_key='concat(symbol,updatedat)' ) }} with currentlist as ( select distinct symbol, company, ltp, yearlyhigh, updatedat,diff_rank,'buy' as buyorsell from {{ref('rankstocks')}} where (yearlyhigh-ltp)/ltp*100 \u0026lt;= 5 order by updatedat desc, diff_rank limit 20 ), finallist as ( {% if is_incremental() %} select symbol, company, ltp, yearlyhigh, updatedat,diff_rank,'sell' as buyorsell from {{this}} as oldlist where not exists (select symbol from currentlist where symbol=oldlist.symbol and (yearlyhigh-ltp)/ltp*100 \u0026lt;= 5 ) union select symbol, company, ltp, yearlyhigh, updatedat,diff_rank,'buy' as buyorsell from currentlist where not exists (select symbol from {{this}} where symbol=currentlist.symbol and buyorsell='buy') {% else %} select * from currentlist {% endif %} ) select * from finallist ``` This model refers to earlier one using {{..}} jinja directive. It also refers to itself using {{this}} directive.\nAmong others, below are key feature of DBT that were observed,\nConcept of Project/Workspace which programmers are typically familiar with Using SQL for Data Transformation Support for Version control Support for testing Support for incremental load Support for snapshots Automatic schema updates Out of the box Documentation browser covering traceability across sources and models. Orchestration After completing ELT aspects, now it\u0026rsquo;s time to orchestrate this pipeline wherein the whole process will run every week. Typically, one can use task scheduler like Airflow or Prefect to do this. But for the purpose of this article, lets use at on windows (or cron if you are using Linux).\nso a simplest possible batch file (as below),\nset http_proxy= set https_proxy= .\\gover\\go run . .\\.venv\\scripts\\activate \u0026amp; .\\dbt\\dbt run will run the whole process and generate weekly list in weeklylist table in database. This batch file can be scheduled to run on weekly basis using command at 23:00 /every:F runscript.bat.\nThis is very basic approach to scheduling (with no error handling/retries or monitoring). Hopefully, i will be able to work on these part (something like this). Till then\u0026hellip;\nUseful References Reverse ETL Data stacks for Fun and Profit What warehouse to use Build Data Lake in PostgreSQL using FDW, Singer, Metabase Happy Coding !!\n","permalink":"http://localhost:1313/posts/elt/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWhile gathering data for Analytics, one often has to source data from multiple sources. Traditionally, the approach has been to do ETL (Extract-Transform-load) where,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eExtract\u003c/strong\u003e - typically involves retrieving data from source. This could also be via streaming\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTransform\u003c/strong\u003e - Apply transformation to the extracted data.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLoad\u003c/strong\u003e -  Loading the data in Operation Data store (ODS) or data warehouse\nRefer \u003ca href=https://www.sas.com/en_us/insights/data-management/what-is-etl.html#close\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehere\u003c/a\u003e for more details on ETL. ETL has been made easy by tools like \u003ca href=https://www.talend.com/products/talend-open-studio/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTalend\u003c/a\u003e, \u003ca href=https://docs.microsoft.com/en-us/sql/integration-services/sql-server-integration-services\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSSIS\u003c/a\u003e and so on.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHowever, there has been shift from above approach due to,\u003c/p\u003e","title":"ELT approach for Data Pipelines"},{"content":"Background Recently, i went through excellent video series on Designing \u0026amp; Versioning HTTP_REST APIs presented by Jeffrey Richter. It is available here. In the past, i had read Jeff\u0026rsquo;s books on CLR and found his writing to be very clear and understandable. So is my experience with this Video Series. Below is summary of learnings from this Video Series. I do not claim that every aspect is covered here so please do check out the videos.\nI have been developing REST APIs for many years but the video series opened up many new aspects that were previously unknown. Jeff starts with Need to Good API Design and related considerations, REST Fundamentals and then dives deeper into aspects like idempotent behavior, versioning, ETags and so on.\nJeff covers REST fundamentals, need for thoughtful API design as it might be difficult to amend it later followed by practices covering Naming,Need for Idempotency, Error Handling and so on. Below is an attempt to summarize aspects from these videos.\nREST Fundamentals REST is an architectural style with emphasis on,\nScalability Reduced latency via Caching Independent Deployment Encapsulating legacy Systems A REST service has resources where they represent state but not behavior. These behaviors are CRUD (Created, Read, Update and Delete). All operations of service must be idempotent.\nURL of the REST Service is expected to be stable over long period of time. URL (apart from HTTP scheme and host name:port), consists of\nDocument (eg. song-management) - sometimes omitted in which case the host determines document. Collection resource (users or playlists) - Hold items; use plural lowercase noun; avoid more than 2 collections. Item resource - Request/Response body holds the item\u0026rsquo;s state Method - Prefer \u0026lsquo;PATCH\u0026rsquo;, with JSON Merge Patch request body, over \u0026lsquo;PUT\u0026rsquo;. \u0026lsquo;PUT\u0026rsquo; for whole creation or replacement but may introduce issues between different versions of service. Avoid \u0026lsquo;POST\u0026rsquo; as it involves challenges in ensuring Idempotent behavior. The argument against \u0026lsquo;POST\u0026rsquo; is that it always creates resource and returns identifier which may get lost and client may retry. . Error Handling Videos contain tables explaining HTTP status code to be returned along with body in different conditions. below is quick summary,\nIf something unexpected happens return Status 500\nIf service is booting, too busy or shutting down then return Status 303\nIf HTTP Version not 1.1 then return status 505\nIf Authorization fails then return status 401\nIf Client makes too many requests/second then return status 429\nIf URL too long then return status 414\nIf HTTP Method not supported at all then return status 501\nIf resource not accessible to client then return status 403\nIf No support for HTTP Method not 1.1 then return status 405\nIf request not in acceptable format then return status 406\nIn case service returns non-success/error response for a request,\nIt is recommended to add header in response that indicates the same (that way client can inspect it before deserializing/inspecting the response).\nAlso if error is recoverable @ runtime then, string is specific else string is list of similar errors. Response body could be in JSON format as,\n{ \u0026#34;error\u0026#34;: { \u0026#34;code\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;message\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;target\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;innererror\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;minLength\u0026#34;: 6 } } } If server is overloaded then return 503\nIf tenant exceeds quota then return 429\nVersioning New version must be backward Compatible\nExamples of versioning in API,\nhttp://api.contoso.com/v1.0/products http://api.contoso.com/products?api-version=1.0 http://api.contoso.com/products?api-version=2021-01-01 Add new API when changing mandatory parameters, payload formats, error codes or behavior\nApproach to API Versioning should not be afterthought\nConsider embedding version number in the data structure\nChecklist for REST APIs Focus on great and consistent naming - This is very important because once in production, this is unlikely to change.\nEnsure that resource path make sense\nAlways try to simplify call to Service (by having fewer query parameters \u0026amp; JSON fields)\nUse\nPUT to Create/Replace whole resources. Last write wins. It should return 200-Ok, 201-Created.\nPATCH to Create/Modify resource with JSON Merge Patch. It should return 200-Ok, 201-Created.\nGET to Get the resource.It should return 200-Ok.\nDELETE to remove resource. It should return 200-Ok, 204-No content but 404-not found should be avoided.\nJeff recommends avoiding usage of POST unless request is idempotent (HTTP does not require it to be idempotent).For API having POST operation, below Idempotency Pattern can be considered,\nClient: Creates ID Client: sends request to server with generated ID (this can be retried) Server: If ID is not in log then, do operation \u0026amp; log ID (This should be part of transaction); respond with OK (Server periodically deletes old log to avoid unbounded growth) A URL should be stable/immutable\nUse proper response codes to enable customers to self-fix\nHave clear contracts for string values\nShare samples (Code) that really use your API\nUse Etag (Entity Tag) to identify the version of the resource,\nEtag is usually computed as checksum or as sequence value (which is incremented on every change) for single item response, it is set in header and for collections, it is added as field in body. Caching - Clients can use it for resource caching (send GET Request with ETag and server responds with 304-Not modified if resource hasn\u0026rsquo;t changed) Concurrent/Conditional Updates -Etag along with \u0026lsquo;if-none-match\u0026rsquo;/\u0026lsquo;if-match\u0026rsquo; headers allows conditional update/delete Services must fail fast if requests are greater than quota (requests/time)\nEvery request must be assigned unique ID for logging /tracing purposes. this ID can be returned in header of response.\nGenerate Telemetry for the Service. It should include User Agent information for diagnostic purposes. Also consider adding Distributed tracing (OpenTelemetry is standardization initiative in this regard).\nIn case of client retries, services must be idempotent (Idempotency indicates retrying a request has same intended effect, even if the original request succeeded, though response might differ)\nService must remain fault-tolerant in case of failures.\nTypically REST is meant for State transfer/CRUD Operations but many times the purpose of end point is to offer action. In such cases specify the action being performed at the end , i.e. after establishing the exact resource, of URL like, /user-management/users/{userid}/:send-sms. In this,\n\u0026lsquo;user-management\u0026rsquo; indicates host \u0026lsquo;users\u0026rsquo; indicates users collection \u0026lsquo;{userid}\u0026rsquo; is to identify user by ID \u0026lsquo;:send-sms\u0026rsquo; indicates action (prefixed with \u0026lsquo;:\u0026rsquo;) to be performed. Use tools like Swagger for API documentation and to create language-specific client libraries\nReviewing REST APIs While reviewing HTTP REST APis, below aspects should be evaluated,\nDoes the API Match Customer\u0026rsquo;s Expectation? Aspects to check are,\nURLs idempotency atomicity json casing status codes paging long running operations Consistency with other Services\nIs the Service/API sustainable over time i.e. API must be able to grow/version over time without breaking customer apps\nIn no way, the above covers everything available in the Video series. So do check it out here.\nUseful References Making retries safe with Idempotent APIs Happy API designing !!\n","permalink":"http://localhost:1313/posts/restapiversioning/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eRecently, i went through excellent video series on  \u003ccode\u003eDesigning \u0026amp; Versioning HTTP_REST APIs\u003c/code\u003e presented by \u003ca href=https://www.linkedin.com/in/jeffrichter/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJeffrey Richter\u003c/a\u003e. It is available \u003ca href=https://www.youtube.com/watch?v\u0026#61;9Ng00IlBCtw\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehere\u003c/a\u003e. In the past, i had read Jeff\u0026rsquo;s books on CLR and found his writing to be very clear and understandable. So is my experience with this Video Series. Below is summary of learnings from this Video Series. I do not claim that every aspect is covered here so please do check out the videos.\u003c/p\u003e","title":"Learnings from Jeff Richter's Designing and Versioning HTTP REST APIs Video Course"},{"content":"Background In a typical workflow of software development, Developer implements a Unit/component, tests it and pushes the changes to source control repository. It then goes through Continuous integration, automated testing, provisioning and deployment. Given High availability requirements expected (or should i say assumed) nowadays, As much as functional correctness of the Unit, it is also important to test how a Unit/Component handles failures, delays etc. in distributed environment. Often, such behavior is observed in production itself, unless project team is following practices of Chaos engineering.\nWouldn\u0026rsquo;t it be great if it is possible to start testing the resiliency features as part of development and during CI/CD pipeline execution itself ? Enter Toxiproxy\nToxiproxy is a TCP Proxy to simulate network and system conditions for chaos and resiliency Testing.\nToxiproxy essentially acts as middleman between your application and remote service/system being tested, allowing injection of delays, simulate Bandwidth restriction or turn interface off (down) etc.\nIt provides CLI as well as http API for applications to inject these behaviors or toxics. Refer here for various toxics supported.\nLets use Toxiproxy Lets see how one can use it in typical use case where Application uses PostgreSQL database and requirement is to benchmark it against database hosted remotely. Toxiproxy can help simulate production like behavior by means of introducing network delay.\nThe full source code of this application is available here. One can refer to Numbers (only as reference cause live conditions may widely vary) here while deciding on how much toxicity to introduce.\nApplication itself is a Web server in Go using excellent HTTPRouter, It does,\nprovision a table in Postgresql and load dummy data in it.\nExposes REST API that reads data from database and returns JSON\nSetup proxy between application and database either through Toxiproxy CLI (it can also be done programmatically using Toxiproxy-Go client),\n[ { \u0026#34;name\u0026#34;: \u0026#34;pgsql\u0026#34;, \u0026#34;listen\u0026#34; : \u0026#34;[::]:6000\u0026#34;, \u0026#34;upstream\u0026#34; : \u0026#34;127.0.0.1:5432\u0026#34;, \u0026#34;enabled\u0026#34;: true } ] or through Code like,\n// InjectLatency helper func InjectLatency(name string, delay int) *toxiproxy.Proxy { proxy, err := toxiClient.Proxy(name) if err != nil { panic(err) } proxy.AddToxic(\u0026#34;\u0026#34;, \u0026#34;latency\u0026#34;, \u0026#34;\u0026#34;, 1, toxiproxy.Attributes{ \u0026#34;latency\u0026#34;: delay, }) return proxy } Use hey or any other HTTP Benchmarking tool to test end points with and without toxicity\nor\nGo benchmark tests tests that are executed against HTTP end points. In my opinion, Toxiproxy allows us to embed aspect(s) of resiliency verification in the code itself so developer can test it before committing the code and it can be embedded in DevOps pipeline to get early feedback before facing the music in production environment.\nLike latency, one can easily introduce other Toxics like Bandwidth, Down and Timeout to check Application\u0026rsquo;s behavior when faced with such occurrences.\nUseful References, ToxiProxy - for all details on the tool like Clients available in various languages, server releases and so on. Happy Coding !!\n","permalink":"http://localhost:1313/posts/resiliencytoxiproxy/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eIn a typical workflow of software development, Developer implements a Unit/component, tests it and pushes  the changes to source control repository. It then goes through Continuous integration, automated testing, provisioning and deployment. Given High availability requirements expected (or should i say assumed) nowadays,  As much as functional correctness of the Unit, it is also important to test how a Unit/Component handles failures, delays etc. in distributed environment.  Often, such behavior is observed in production itself, unless project team is following practices of \u003ca href=https://netflixtechblog.com/tagged/chaos-engineering\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChaos engineering\u003c/a\u003e.\u003c/p\u003e","title":"Resiliency Testing with Toxiproxy"},{"content":"Background In a typical business Application, there are often requirements for,\nBatch processing - Often long running Tasks like data import/export, End of day processing etc. These tasks are often scheduled to be executed at pre-defined interval or on occurance of an Event. Asychronous processing - Tasks, often part of business process / workflow, that can be performed asychronously or offloaded. Such requirements are often fulfilled with custom approaches like batch processing frameworks, ETL Tools or using Queues or specific database features.\nI had been following how Uber fulfils these requirements using their Cadence platform. Cadence (now Temporal) is a distributed, scalable, durable, and highly available orchestration engine to execute asynchronous long-running business logic in a scalable and resilient way.\nTemporal defines workflow as any program which,\ngoes beyond single request-reply has multiple steps tied together with inherent state can be short or long lived. performs Event processing involves infrastructure automation This is interesting perspective that accommodates various use cases irrespective of architecture style (i.e. Monolith, Microservices) in use. In Temporal, one has to create workflow which in turn consists of one or more activities. Activities are functions containing actions to be taken on each step of the workflow. Temporal transparently preserves all the state associated with workflow and its activities.\nBelow is System architecture of Temporal, more details here,\nTemporal Architecture Overall, Temporal offers following features,\nWorkflow implemented as Application code - Basically it allows to implement Workflow as code, just like rest of the codebase of the application. Thus allowing one to concentrate on business logic and reduces complexity about authoring workflow as DSL, JSON etc. Retries and Timeouts - Nowadays, quite a few steps in workflow involve remote service invocation and whenever one crosses boundary of the application, it is important to have retries and timeouts in place. Reliability - Robustness against failure Scalability - Horizontally Scalable Support for SAGAs - If a Workflow calls multiple external/remote services and if one of them fails then, compensation call to other services will have to be made to complete rollback. Distributed Cron - Scheduled processing of workflow or steps in workflow. Persistent Storage in MySQL, Cassandra among others Frontend for tracking and diagnostics Monitoring using Prometheus or other backends. It is very easy to get basic \u0026ldquo;Helloworld\u0026rdquo; workflow up and running using detailed instructions on setup provided here provided docker desktop or such environment is easily available. Temporal documentation does a great job on this.\nTo evaluate Temporal further, we will orchestrate below,\nList of users are imported/received (say from a file or provided as input) These users are verified/validated by Admin through some Frontend (to simulate a maker/checker process). This may not resemble real world scenario but it will help evaluate features of Temporal like Signals - Waiting on Events (such as human intervention).\nWe will have below activities in our workflow,\nImport users - This activity will import list of users from file/stream. For the sake of simplicity, we will just pass it as string. func ImportUsers(ctx context.Context, userdata string, DbConnectionString string) (int, error) { logger := activity.GetLogger(ctx) logger.Info(\u0026#34;ImportUsers activity started.\u0026#34;, zap.String(\u0026#34;Dbconn\u0026#34;, DbConnectionString)) // Open connection to database db, close, err := GetSQLXConnection(context.Background(), DbConnectionString) if err != nil { logger.Error(\u0026#34;Cant open connection to database\u0026#34;, zap.Error(err)) return 0, err } defer close() if _, err := db.Exec(DBSchema); err != nil { logger.Error(\u0026#34;Error while executing Schema\u0026#34;, zap.Error(err)) return 0, err } logger.Info(\u0026#34;Database connection opened, now parsing user data\u0026#34;) sqlStmt := \u0026#34;insert into users(name,dob,city) values(?,?,?)\u0026#34; tx := db.MustBegin() defer func() { if err != nil { tx.Rollback() } tx.Commit() }() r := csv.NewReader(strings.NewReader(string(userdata))) r.Comma = \u0026#39;,\u0026#39; r.Comment = \u0026#39;#\u0026#39; records, err := r.ReadAll() if err != nil { logger.Error(\u0026#34;Error while reading\u0026#34;, zap.Error(err)) return 0, err } i := 0 for i, record := range records { if i == 0 { continue } logger.Info(\u0026#34;Record read is -\u0026gt;\u0026#34;, record[0]) if _, err := tx.Exec(sqlStmt, record[0], record[1], record[2]); err != nil { logger.Error(\u0026#34;Error while writing user record\u0026#34;, zap.Error(err)) return 0, err } } return i, nil } Approve users - This activity will mark all those users, Approved by Admininstrator via Service, as approved. func ApproveUsers(ctx context.Context, DbConnectionString string, Users string) (int, error) { logger := activity.GetLogger(ctx) logger.Info(\u0026#34;ApprovedUsers called\u0026#34;, zap.String(\u0026#34;Dbconn\u0026#34;, DbConnectionString), zap.String(\u0026#34;Userlist\u0026#34;, Users)) db, close, err := GetSQLXConnection(context.Background(), DbConnectionString) if err != nil { logger.Error(\u0026#34;Cant open connection to database\u0026#34;, zap.Error(err)) return 0, err } defer close() if _, err := db.Exec(DBSchema); err != nil { logger.Error(\u0026#34;Error while executing Schema\u0026#34;, zap.Error(err)) return 0, err } r := csv.NewReader(strings.NewReader(Users)) tx := db.MustBegin() defer func() { if err != nil { tx.Rollback() } tx.Commit() }() sqlStmt := \u0026#34;update users set isapproved =1 where id =:1\u0026#34; i := 0 for { record, err := r.Read() if err == io.EOF { break } if err != nil { logger.Error(\u0026#34;Error while reading from file\u0026#34;, zap.Error(err)) return 0, err } if i == 0 { continue } i++ if _, err := tx.Exec(sqlStmt, record[0]); err != nil { logger.Error(\u0026#34;Error while writing user record\u0026#34;, zap.Error(err)) return 0, err } } return i, nil } HTTP Service - This service will receive list of approved users and send it over to workflow via Signal, func (s *server) UpdateUsers(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { creader := csv.NewReader(r.Body) records, err := creader.ReadAll() if err != nil { log.Fatal(err.Error()) http.Error(w, err.Error(), http.StatusBadRequest) return } // Create the client object just once per process c, err := client.NewClient(client.Options{}) if err != nil { log.Fatalln(\u0026#34;unable to create Temporal client\u0026#34;, err) http.Error(w, \u0026#34;Internal Error :Temporal\u0026#34;, http.StatusInternalServerError) return } defer c.Close() workflowOptions := client.StartWorkflowOptions{ ID: app.UserApprovalWorkflow, TaskQueue: app.UserApprovalTaskQueue, RetryPolicy: \u0026amp;temporal.RetryPolicy{ InitialInterval: time.Second, BackoffCoefficient: 2.0, MaximumInterval: time.Minute, MaximumAttempts: 5, }, } _, err = c.SignalWithStartWorkflow(r.Context(), app.UserApprovalWorkflow, app.ApprovalSignalName, records, workflowOptions, app.OnboardUsers, app.Userdata, s.DBConnection) if err != nil { log.Fatal(err.Error()) http.Error(w, \u0026#34;Internal Error: Workflow\u0026#34;, http.StatusInternalServerError) return } fmt.Fprint(w, \u0026#34;Success\u0026#34;) } HTTP service uses workflow.SignalWithStartWorkflow function. This function sends the signal to running instance of workflow or starts new if none is in progress. Full source code is available here\nTemporal documentation has reference to Helm charts for deploying temporal in clustered configuration, for organization who is managing own data center it would be interesting to know if it also supports bare metal based deployment in addition to Kubernetes. Will update this post as and when details are available on this.\nOverall, Temporal provides a different approach to workflow orchestration. Its been battle tested at Uber and host of other companies. Temporal Community is a very active one with founders actively participating in discussions.\nCollection of Temporal related stuff Happy Coding !!\n","permalink":"http://localhost:1313/posts/temporalworkflow/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eIn a typical business Application, there are often requirements for,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBatch processing - Often long running Tasks like data import/export, End of day processing etc. These tasks are often scheduled to be executed at pre-defined interval or on occurance of an Event.\u003c/li\u003e\n\u003cli\u003eAsychronous processing - Tasks, often part of business process / workflow, that can be performed asychronously or offloaded.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSuch requirements are often fulfilled with custom approaches like batch processing frameworks, ETL Tools or using Queues or specific database features.\u003c/p\u003e","title":"Using Temporal.io to build Long running Workflows"},{"content":"Background How many times have we landed up in a meeting staring at random slowness or such production issues in a distributed Application ? only to experience helplessness with limited (or often times no) visibility available about the runtime behavior of the Application. It often ends up in manually correlating whatever diagnostic data available from Application and combining it with trace/logs that are available from O/S, databases etc. and trying to figure out \u0026ldquo;Root cause\u0026rdquo; of the issue.\nToday’s mission critical, distributed applications and systems make it even more important to observe them, be it serving web requests, processing stream of data or handling events. The scale at which these applications/systems operate at, often hundreds or thousands of requests, requires watching how well system is working, instead of waiting for failure or doing analysis post failure.\nIn distributed systems, telemetry can be divided into three overarching flavors:\n(Distributed) Traces: detailed records of the paths that distinct requests take as they propagate across an entire system (including across service boundaries) Metrics: aggregate statistics (mostly counters and gauges) about processes and infrastructure, typically with key:value tags attached to disaggregate patterns Logs: timestamped messages – sometimes structured – emitted by services or other components (though, unlike traces, not necessarily associated with any particular user request or transaction) To this effect, Cloud Native Computing Foundation (CNCF) has been working on Opentelemetry.\nWhat is OpenTelemetry? OpenTelemetry is a vendor-neutral standard for collecting telemetry data for applications, their supporting infrastructures, and services.\nFor deep dive, history etc., refer to Overview here.\nSo is this standard already available? As of this writing, it is about to go GA soon. This makes it more important to be aware of its scope (subjected to change). Let\u0026rsquo;s see how it is proposing to address/implement Observability.\nBelow diagram depicts what OpenTelemetry does in Nutshell (Source: Opentelemetry.io),\nOpenTelemetry in Nutshell The general process of using OpenTelemetry is,\nInstrumentation of Application Code (including libraries) Validate Instrumentation by sending it to Collector like Jaeger (For simplicity, we will only be using Console exporter) Learn how Instrumentation helps in correlating, watching runtime behavior While vendors, having back-end systems, are providing or working on integrations with OpenTelemetry. The OpenTelemetry team has provided client libraries for Instrumentation in Go, .NET, Java,JavaScript, Python (and more coming). So lets us see what these libraries offer as of today by implementing .NET library.\nIn this post, We will look at how Opentelemetry helps us with \u0026ldquo;Distributed tracing\u0026rdquo;.\nOpenTelemetry for .NET .NET client of OpenTelemetry supports both .NET Framework as well as .NET Core.\nFor list of available instrumentation libraries and exporters, refer here\nIn the below sections, We will try to simulate a scenario, which is typical in Microservices style of Architecture, where service invokes another service using HTTP. Now, aim is to verify how using OpenTelemetry will help in watching traffic between these two services.\nSample Scenario Lets start,\nCreate Web Service (I am using .NET Core SDK 3.1.300 on Windows)\nUse dotnet new webapi to scaffold a REST API\nAdd references to below packages using Nuget,\nOpenTelemetry.Exporter.Console - Exporter package to output telemetry to Console OpenTelemetry.Instrumentation.AspNetCore - Package that transparently instruments ASP.NET Core request processing pipeline OpenTelemetry.Instrumentation.Http - Package that transparently instruments HTTP Communication. Startup.cs - It configures OpenTelemetry instrumentation with Console Exporter and instrumentation for HTTP requests. Below is ConfigServices function of Startup class.\npublic void ConfigureServices(IServiceCollection services) { services.AddOpenTelemetryTracing( (builder) =\u0026gt; builder.AddAspNetCoreInstrumentation(opt =\u0026gt; opt.Enrich = (activity, eventName, rawObject) =\u0026gt; { if (eventName.Equals(\u0026quot;OnStartActivity\u0026quot;)) { if (rawObject is HttpRequest httpRequest) { activity.SetTag(\u0026quot;requestProtocol\u0026quot;, httpRequest.Protocol); } } else if (eventName.Equals(\u0026quot;OnStopActivity\u0026quot;)) { if (rawObject is HttpResponse httpResponse) { activity.SetTag(\u0026quot;responseLength\u0026quot;, httpResponse.ContentLength); } } }) .AddHttpClientInstrumentation() .AddConsoleExporter() //opt =\u0026gt; opt.DisplayAsJson = true) ); } WeatherForecastController.cs - This is default controller added by dotnet new webapi command. We will add GET endpoint to simulate a dummy HTTP Request. This is to verify telemetry produced for the same.\n[HttpGet(\u0026#34;{key}\u0026#34;)] public async Task\u0026lt;IEnumerable\u0026lt;WeatherForecast\u0026gt;\u0026gt; Get(string key) { // Making an http call here to serve as an example of // how dependency calls will be captured and treated // automatically as child of incoming request. var res = await httpClient.GetStringAsync(string.Format(\u0026#34;https://www.google.com/search?q={0}\u0026#34;, key)); var rng = new Random(); return Enumerable.Range(1, 5).Select(index =\u0026gt; new WeatherForecast { Date = DateTime.Now.AddDays(index), TemperatureC = rng.Next(-20, 55), Summary = Summaries[rng.Next(Summaries.Length)], }) .ToArray(); } Lets create a Service 1 For the sake of simplicity, we will have \u0026ldquo;Service 1\u0026rdquo; implemented as Console Application,\nUse dotnet new console to create new App.\nAdd reference to \u0026ldquo;OpenTelemetry.Exporter.Console\u0026rdquo; using dotnet add OpenTelemetry.Exporter.Console -version 0.7.0-beta.1. This package is specifically meant for exporting telemetry to Console. There are other exporters available to export to Jaegar, Zipkin etc. but this is simplest one to setup.\nAdd reference to \u0026ldquo;OpenTelemetry.Instrumentation.Http\u0026rdquo; using dotnet add OpenTelemetry.Instrumentation.Http -version 0.7.0-beta.1. This package helps in instrumenting HTTP requests.\nAdd below code to program.cs,\nstatic async Task Main(string[] args) { // Configure OpenTelemetry Tracer with Console exported and initiate it Sdk.CreateTracerProviderBuilder() .AddHttpClientInstrumentation() .AddConsoleExporter() .Build();\ntry { // Simulate HTTP Request to our service string responseBody = await client.GetStringAsync(\u0026quot;https://localhost:5001/weatherforecast/abc\u0026quot;); Console.WriteLine(responseBody); } catch (HttpRequestException e) { Console.WriteLine(\u0026quot;\\nException Caught!\u0026quot;); Console.WriteLine(\u0026quot;Message :{0} \u0026quot;, e.Message); } Console.WriteLine(\u0026quot;Done!\u0026quot;); } In this class, we have configured OpenTelemetry tracer with Console Exported and intialized it. Further, HTTP requests are automatically instrumented since we have added OpenTelemetry.Instrumentation.Http package.\nObserve the Telemetry,\nStart the Web Service. Check that it is listening on port 8080 by visiting https://localhost:8080. Note: you may have to install Client certificate to enable SSL. Start the Console Application. This application will send HTTP request to the service. Observe the telemetry produced by, Console Application,\nDefault Telemetry generated Activity Id (GUID) is generated for a Span (Refer here for details on what span means) It also records start and end time Web Service, Default Telemetry Observations\nCheck Activity ID being shown is same as one reported by Console Application. So correlation has been established across process boundaries. This is important when tracing end to end across processes. This is achieved by means of passing Activity ID as HTTP Header. In a Visualization tool, this correlation is used to depict end to end flow with time at each step. By default, it logs start and end time. For any HTTP request, it generates additional telemetry covering URL to which request was sent and start and end time. In Summary, this default telemetry can obviously be enhanced by adding Tags. When coupled with additional telemetry in the form of metering (to statistically observe behavior of high traffic, large scale system) and telemetry from Infrastructure (i.e. OS) and other Systems (e.g. Databases), it truly provides complete view of proceedings end to end.\nHope this provides overview of instrumentation as provided by OpenTelemetry. Let me know if you have any questions or suggestions in Comments section below.\nInstrumenting .NET framework based Apps for same scenario is similar to above, refer folder Opentelemetry in repository here\nUseful References, OpenTelemetry in 2023 OpenTelemetry in .NET Short course on OpenTelemetry) Happy Coding !!\n","permalink":"http://localhost:1313/posts/opentelemetry/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eHow many times have we landed up in a meeting staring at random slowness or such production issues in a distributed Application ? only to experience helplessness with limited (or often times no) visibility available about the runtime behavior of the Application. It often ends up in manually correlating whatever diagnostic data available from Application and combining it with  trace/logs that are available from O/S, databases etc. and trying to figure out \u0026ldquo;Root cause\u0026rdquo; of the issue.\u003c/p\u003e","title":"Getting Started with OpenTelemetry"},{"content":"Background I primarily work on Windows for development purposes. Whenever its about writing code in Golang, invariably one comes across usage of Make. A quick check on popular Go projects on Github will show Makefile being used to automate tasks like linting, build, testing and deployment.\nBeing on Windows, i have been looking for alternative build tool that is easy to setup (i.e. doesn\u0026rsquo;t require mingw and such environments) and use compared to Make (which is primarily targetted at Unix and Unix like Operating Systems).\nFollowing a wonderful post by Julia Evans (read here) on Ninja. I decided to give it a try for a Golang Application.\nJulia, in her post, has covered important aspects of Ninja but to summarize, Ninja is,\nA build automation tool Lightweight, with focus on speed Easy to configure Cross platform (Easy to setup across Windows and Linux) With this, lets give it a try,\nTo start with, lets create a simple go \u0026lsquo;Hello World\u0026rsquo; project,\nInitiate Go Module (in a Empty folder), go mod init github.com/sachinsu/ninjabuild\nCreate a \u0026lsquo;main.go\u0026rsquo; that prints \u0026lsquo;Hello World\u0026rsquo;,\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;hello world\u0026#34;) } Now setup Ninja, It is as easy as downloading binary for your Platform. It is also possible to build it locally, if you prefer it that way. For details, refer here\nOnce ninja is setup, lets create build configuration file (i.e. build.ninja),\nGOARCH = amd64 GOOS = linux rule lint command = go vet -mod=vendor ./... build lintoutput: lint rule unit command = go test -mod=vendor -cover -v -short ./... build utest: unit rule compile command = cmd /c go mod tidy \u0026amp;\u0026amp; go mod vendor \u0026amp;\u0026amp; go build -o $out $in \u0026amp;\u0026amp; echo \u0026#34;build done.\u0026#34; description = compile $in build ninjabuild.exe: compile . lets go through the contents of this file,\nOne can define variables GOARCH = amd64 and refer them as $GOARCH\nNinja configuration is combination of build step and associated rule, for e.g.\nrule compile command = cmd /c go mod tidy \u0026amp;\u0026amp; go mod vendor \u0026amp;\u0026amp; go build -o $out $in \u0026amp;\u0026amp; echo \u0026#34;build done.\u0026#34; description = compile $in build ninjabuild.exe: compile . Above snippet, defines rule compile with associated command that builds the code. Being on Windows, i have used cmd /c to start a new shell and concatenate multiple commands as part of compile rule using \u0026amp;\u0026amp; which chains the commands and executes next one only if current one succeeds. As demonstrated in above file, Ninja can be used to automate wide variety of tasks like build, tests, deployment and so on.\nMany of you using Make will find the approach similar to it. In contrast to Make, Ninja lacks features such as string manipulation, as Ninja build files are not meant to be written by hand. Instead, a \u0026ldquo;build generator\u0026rdquo; should be used to generate Ninja build files.\nI found simplicity (of installation and configuration) and easy of use to be key aspects of this tool.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/ninjabuildsystem/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI primarily work on Windows for development purposes. Whenever its about writing code in Golang, invariably one comes across usage of Make. A quick check on popular Go projects on Github will show Makefile being used to automate tasks like linting, build, testing and deployment.\u003c/p\u003e\n\u003cp\u003eBeing on Windows, i have been looking for alternative build tool that is easy to setup (i.e. doesn\u0026rsquo;t require mingw and such environments) and use compared to Make (which is primarily targetted at Unix and Unix like Operating Systems).\u003c/p\u003e","title":"Ninja - Using lightweight build system for Go projects "},{"content":"Background I started this blog, https://sachinsu.github.io few months back .\nIn this relatively short period of time, Blog has sizeable number of useful links across various categories in addition to the detailed blog post like this one.\nAs an ongoing activity, I think that it is necessary to verify links mentioned on this blog.\nSo how can it be done ? obviously one way is to do it manually by visiting each link and updating/removing those that are no longer available. but there is always of better way of doing things.\nThe requirement is to,\nParse all the files to links (being in Markdown links will be enclosed in brackets) Send request to each link and verify if its active using HTTP Status (say 200 or 302) Approach Enter Automation !!\nIt is possible to write a utility/tool (or it might be already available) or can good old command line utlities be used for this task?\nI decided to go for dos / shell script way and surprisingly all the necessary tools are already available.\nBelow is single command line that fulfils the requirement,\ngrep -E -i -w \u0026quot;http|https\u0026quot; *.md | sed 's/](http/\\nhttp/g' | sed 's/)/\\n/g' | grep ^http | xargs curl -s -I -w 'URL:%{url_effective} - %{http_code}\\n' | grep ^URL:\nIn above chain,\nI am using excellent Cmder console emulator, which also makes above nice tools (grep, sed etc.) available on Windows.\ngrep -E -i -w \u0026ldquo;http|https\u0026rdquo; *.md - this command extracts all the lines containing http(s) from all the markdown (.md) files\nPipe | - Pipe command streams output of command to the next one.\nsed \u0026rsquo;s/](http/\\nhttp/g\u0026rsquo; - this sed (stream editor) command adds line break before http for better extraction.\nsed \u0026rsquo;s/)/\\n/g\u0026rsquo; - this sed (stream editor) command removes trailing ) bracket.\ngrep ^http - this command removes all lines not containing http.\nxargs - xargs is a command on Unix and most Unix-like operating systems used to build and execute commands from standard input.\ncurl -s -I -w \u0026lsquo;URL:%{url_effective} \u0026mdash;\u0026gt; %{http_code}\u0026rsquo;\u0026rsquo; - previously used xargs command feeds each line (url) to this command as last argument. This command sends tcp request to the URL and prints out http status code along with URL.\ngrep ^URL: - For some reason, CURL outputs content even if -s (silent) parameter is passed. Hence, this grep command is used to ignore all lines not containing URL and HTTP Status.\nThe output is as below,\nList of URLs with HTTP Status code So, It is possible to quickly come up with this using built-in tools if writing a program is not an option or cumbersome for task at hand.\nAs a next step, Plan is to automatically run this script as part of Github Build and notify in case of any URL is failing so that appropriate action can be taken.\nHat Tip Suppose the requirement is to extract a particular text by recursively searching through files(for e.g. extract Target .NET Framework version across each of the project in a folder) then grep can be used as below,\ngrep -r --include \u0026quot;*.csproj\u0026quot; -oP \u0026quot;\u0026lt;TargetFrameworkVersion(?:\\s[^\u0026gt;]*)?\u0026gt;\\K.*?(?=\u0026lt;/TargetFrameworkVersion\u0026gt;)\u0026quot; .\nThis command will recursively search through all folders and print names of all those .csproj files containg \u0026lt;TargetFrameworkVersion\u0026gt; tag.\nLet me know (in comments) if you are aware of any alternate better way of achieving this.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/urlhealthchecks/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI started this blog, \u003ca href=https://sachinsu.github.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehttps://sachinsu.github.io\u003c/a\u003e few months back .\u003c/p\u003e\n\u003cp\u003eIn this relatively short period of time, Blog has sizeable number of useful links across various categories in addition to the detailed blog post like this one.\u003c/p\u003e\n\u003cp\u003eAs an ongoing activity, I think that it is necessary to verify links mentioned on this blog.\u003c/p\u003e\n\u003cp\u003eSo how can it be done ? obviously one way is to do it manually by visiting each link and updating/removing those that are no longer available. but there is always of better way of doing things.\u003c/p\u003e","title":"Validating urls from 'Useful Links' section using bash / command line tools"},{"content":"Background I recently had opportunity to support team who has been battling with Intermittent (scary i know :)) issues with TCP connectivity in Production.\nSimplified deployment Architecture is as below,\nHigh Level Architecture Technology Stack used is Microsoft .NET Framework 4.8 using ODP.NET for Oracle Connectivity (Oracle Server is 8 CPU box). Each of Web Servers in cluster have IIS hosted on it with multiple Applications (Application domains) serving HTTP(s) based traffic. These applications connect to Oracle Database.\nTeam is experienced in developing and running .NET Apps, but they needed help to diagnose and fix \u0026ldquo;Connection request timed out\u0026rdquo; exceptions being thrown while connecting to backend database.\nProblem Statement Host of .NET Applications (Web Applications, Web APIs) connect to Oracle Database. Each of them use ODP.NET. ODP.NET maintains connection pool per Application domain (Database resident Connection pool is not used). Some of these applications receive high number of requests per second compared to others.\nOracle.ManagedDataAccess.Client.OracleException (0x80004005): Connection request timed out.... has been reported randomly which results in failure of business transactions. ODP.NET provides extensive trace and along with above trace also contains OracleInternal.Network.NetworkException (0x80004005): Network Transport: TCP transport address connect failure ---\u0026gt; System.Net.Sockets.SocketException (0x80004005): A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\nSpecifically, Applications, receiving less traffic, were reporting it often compared to those with high traffic.\nApproach Simulate the Exception in Test Environment - We decided to try and simulate this exception in a Test Environment. Test environment is scaled down (50%) compared to production. Random Exceptions in production could not be simulated due to lack of Test Automation. for example, In Production, each server receives traffic for multiple HTTP End points whereas in Test environment, load testing was being done only against Single Application. This was like a end of the road since simulation would have greatly helped in diagnosing the issue. However, the show must go on so we decided to,\nCheck online documentation regarding this exception,\n\u0026ldquo;Pooled\u0026rdquo; or \u0026ldquo;Non-pooled\u0026rdquo; Connection - Whenever, ODP.NET raises \u0026ldquo;..timed out\u0026rdquo; error, it diffrentiates the same to indicate whether error is due to delay in retrieving connection from pool or if it is due to delay from the database server (Ref: Here). From this, it was clear that issue is clearly due to delay in obtaining response from database server.While this was happening , Database server (8 CPU Core box) was reporting less than 50% CPU Usage but it still had large number of inactive sessions originated from IIS Servers.\nSince the exception was reported frequently in low traffic applications, it was decided to track and verify the same on firewall and database server,\nFirewall - Firewall had TCP Timeout of 30 minutes and maintains detailed log of sessions. Quick analysis of it revealed that,\nProduction Environment - Unusually high number of sessions were being destroyed due to \u0026ldquo;Age out\u0026rdquo; (i.e. time out) Test Environment - No abnormal activity was reported. Most probably because of differences in traffic. Database Server - Listener Log on Oracle Database server did not had any log entry for request at the precise time when Application(s) had reported Exception.\nNext is to check settings in Application for connectivity with Oracle. Though ODP.NET does not have any direct \u0026ldquo;Time out\u0026rdquo; or \u0026ldquo;Time to live\u0026rdquo; settings, it does provide few parameters that can influence it,\n\u0026ldquo;Connection Lifetime\u0026rdquo; - ODP.NET uses this whenever Connection is closed and disposed by the Application. It will be destroyed (after maintaining number of connections as per \u0026ldquo;Min Pool Size\u0026rdquo;) if it has exceeded life time. For whatever reasons, this was set to unusually high duration (i.e. 90000 seconds). \u0026ldquo;Connection Timeout\u0026rdquo; - Period for which ODP.NET waits for the connection to be made available. This was set to 60 Seconds. Oracle has articles titled \u0026ldquo;ODP-1000 \u0026ldquo;Connection Request Timed Out\u0026rdquo; Explained\u0026rdquo; and \u0026ldquo;Resolving Problems with Connection Idle Timeout With Firewall (Doc ID 257650.1)\u0026rdquo; where it primarily recommends measures for tuning Application as well as database.\nOn the basis of above, it was decided to modify the code for below,\nThorough code review to verify that every ODP.NET Project is closed/disposed. Upgrade ODP.NET to latest version (v19.8.0 as of this writing) Turn \u0026ldquo;KeepAlive\u0026rdquo; while connecting to database Leverage ODP.NET tracing in case of exception Modify the connection lifetime to be less than time out at firewall and increase the \u0026ldquo;Time out\u0026rdquo; period. Introduce Retry functionality using Excellent Polly library with exponential back-off. These changes have been deployed to production and so far % of \u0026ldquo;Connection Request Timed out\u0026rdquo; errors have gone down significantly.\nWrap up Some key areas of focus are,\nFor a distributed system, Always validate assumptions by dignosing end to end. Plan to have test automation readyness to simulate production like load. Monitoring the behavior end to end using logs. Currently, Pool settings across applications is not optimal going by Oracle Real world Guidelines, also be mindful of Connection Storms Happy Troubleshooting !!\n","permalink":"http://localhost:1313/posts/connectiontimeouts/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI recently had opportunity to support team who has been battling with Intermittent (scary i know :)) issues with TCP connectivity in Production.\u003c/p\u003e\n\u003cp\u003eSimplified deployment Architecture is as below,\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/conntimeoutarch.png\"/\u003e \u003cfigcaption\u003e\n            High Level Architecture\n        \u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eTechnology Stack used is Microsoft .NET Framework 4.8 using ODP.NET for Oracle Connectivity (Oracle Server is 8 CPU box). Each of Web Servers in cluster have IIS hosted on it with multiple Applications (Application domains) serving HTTP(s) based traffic. These applications connect to Oracle Database.\u003c/p\u003e","title":"Trobleshooting TCP Connection request time outs"},{"content":"Background I recently came across bounty by Balaji Srinivasan to send Direct Message to all twitter followers. Currently, i do not intend to participate in bounty and this is mere exercise.\nThis is an attempt to write CLI tool in Golang in response to it.\nFor detailed requirements, refer here\nApproach In Brief,\nCLI should,\naccept arguments like Twitter API Key,Auth token, DM Message Download all followers (with profile details) Rank them by Criteria (e.g. Location) Send each follower a DM with provided message (upto daily DM Limit) be easy to use and maintain Notes,\nDue to Daily DM Limit, Follower details will have to be persisted alongside flag indicating if DM has been sent. SQLIte is used from simplicity perspective. There should be a scheduled job that will send the DM upto daily DM Limit. At the same time, it needs to refetch any new followers and push them in the flow (reconcile). Potentially, this could be extended to other social media providers other than twitter. Milestones, Create code structure Plan is to have separation between CLI \u0026amp; have twitter as go package Accept Arguments and Connect to Twitter Study and complete follower retrieval Ranking of followers Persisting followers Sending DM upto Daily limit Rules, Use golang\u0026rsquo;s in-built packages as much as possible Every milestone to have associated Unit test cases Current Status The code is ready and functionality to retrieve followers and saving in local DB is tested. Code to send DM is not yet tested as it will require setting up dummy twitter account.\nRoadmap In addition to CLI, Expose the utility as responsive Web Application Possibly extend this to social media platforms other than Twitter Have a look at code on Github and let me know what you think.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/massdmgolang/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eI recently came across bounty by \u003ca href=https://twitter.com/balajis/status/1271945241881268224?s\u0026#61;20\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBalaji Srinivasan\u003c/a\u003e to send Direct Message to all twitter followers. \u003cem\u003eCurrently, i do not intend to participate in bounty and this is mere exercise.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThis is an attempt to write CLI tool in \u003ca href=https://golang.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGolang\u003c/a\u003e in response to it.\u003c/p\u003e\n\u003cp\u003eFor detailed requirements, refer \u003ca href=https://github.com/balajis/twitter-export\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"approach\"\u003eApproach\u003c/h2\u003e\n\u003cp\u003eIn Brief,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eCLI should,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eaccept arguments like Twitter API Key,Auth token, DM Message\u003c/li\u003e\n\u003cli\u003eDownload all followers (with profile details)\u003c/li\u003e\n\u003cli\u003eRank them by Criteria (e.g. Location)\u003c/li\u003e\n\u003cli\u003eSend each follower a DM with provided message (upto daily DM Limit)\u003c/li\u003e\n\u003cli\u003ebe easy to use and maintain\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNotes,\u003c/p\u003e","title":"Tool to mass DM followers on Twitter in Go"},{"content":"Section covering resources for Online learning etc.\nExploring basics of Computer Science, bit by bit Exploring basics of Distributed Systems Awesome List of Free Learning Resources Collection of online learning resources Complete intro to Linux and CLI Linux System Administration - Skill challenge ","permalink":"http://localhost:1313/links/onlearn/","summary":"\u003cp\u003eSection covering resources for  Online learning etc.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://medium.com/basecs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExploring basics of Computer Science, bit by bit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/baseds\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExploring basics of Distributed Systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ebookfoundation.github.io/free-programming-books/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome List of Free Learning Resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stackoverflow.blog/2020/04/27/build-your-technical-skills-at-home-with-online-learning/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of online learning resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://btholt.github.io/complete-intro-to-linux-and-the-cli/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComplete intro to Linux and CLI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/snori74/upskillchallenge\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLinux System Administration - Skill challenge\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Resources for Online Learning"},{"content":"Python has become pervasive all throught Data Science be it Machine learning, Deep learning, Data Processing and general purpose tasks like Web Development.\nCourses, Trainings Python Tutorials Python for Beginners from MSDN Nice Collection of trainings per level of complexity Python Programming And Numerical Methods: A Guide For Engineers And Scientists Practical Python Projects Articles Getting machine learning to production A quick-and-dirty guide on how to install packages for Python What to do when data doesn’t fit in memory DataSette - Architecture Notes Packages EasyOCR - supports 40\u0026#43; languages Simplified Static file serving for Python Static Site generator (with Markdown support) JupyterLab Desktop App Python helper library for ETL between databases Podcasts Talkpython ","permalink":"http://localhost:1313/links/python/","summary":"\u003cp\u003ePython has become pervasive all throught Data Science be it Machine learning, Deep learning, Data Processing and general purpose tasks like Web Development.\u003c/p\u003e\n\u003ch2 id=\"courses-trainings\"\u003eCourses, Trainings\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/norvig/pytudes\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePython Tutorials\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://channel9.msdn.com/Series/Intro-to-Python-Development/Python-for-Beginners-1-of-44-Programming-with-Python#comments\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePython for Beginners from MSDN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://forums.fast.ai/t/recommended-python-learning-resources/26888\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNice Collection of trainings per level of complexity\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pythonnumericalmethods.berkeley.edu/notebooks/Index.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePython Programming And Numerical Methods: A Guide For Engineers And Scientists\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://practicalpython.yasoob.me/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePractical Python Projects\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"articles\"\u003eArticles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=http://veekaybee.github.io/2020/06/09/ml-in-prod/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGetting machine learning to production\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://snarky.ca/a-quick-and-dirty-guide-on-how-to-install-packages-for-python/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA quick-and-dirty guide on how to install packages for Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pythonspeed.com/articles/data-doesnt-fit-in-memory/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat to do when data doesn’t fit in memory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://architecturenotes.co/datasette-simon-willison/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDataSette - Architecture Notes\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"packages\"\u003ePackages\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/JaidedAI/EasyOCR\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEasyOCR - supports 40\u0026#43; languages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://whitenoise.evans.io/en/stable/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSimplified Static file serving for Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/getpelican/pelican\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStatic Site generator (with Markdown support)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jupyterlab/jupyterlab_app#download\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJupyterLab Desktop App\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/BritishGeologicalSurvey/etlhelper\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePython helper library for ETL between databases\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"podcasts\"\u003ePodcasts\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://talkpython.fm/episodes/all\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTalkpython\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages - Python"},{"content":"At my current workplace, All Applications are expected to adhere to PCI DSS standards meant for Data protection, Access Regulation and so on. Dedicated SOC Team,consisting of Security analyst who are continously on the prawl to identify breach, conduct periodic auditing of Applications, hardening of Servers.\nWhile all our .NET applications adhere to below guidelines,\nASP.NET Security Overview Secure Coding Guidelines Security Guidelines by OWASP We also use tools like Snyk to perform code vulnerability analysis as part of Jenkins driven CI/CD pipeline. In spite of above, we do come across vulnerabilities identified by SOC Team which we needs to be addressed quickly. SOC team uses tools such as Burp Suite.\nThis post is going to summarize such incidents reported so far (and will keep updating it). In most of these cases, These issues required additional efforts over and above those provided by library or framework. Hopefully, it will be helpful to anyone trying address such vulnerabilities.\nCookie Path Every cookie being sent by the Web application has attributes like,\nHTTPOnly - Indicates whether a cookie is accessible by client-side script Domain - Indicates the domain to associate the cookie with Path - the virtual path to transmit with the current cookie Secure - Indicates whether cookie is sent only on Secure (HTTPS) Connections. OWASP has nice primer on Cookie Security.\nOf the above, Path attribute limits the scope of a cookie to a specific path on the server and can therefore be used to prevent unauthorized access to it from other applications on the same host. Accordingly, SOC Team had recommended that all cookies issued by application must have path attribute set.\nIn case of typical ASP.NET Application, there are cookies generated by .NET framework (like for Session, Anti XSRF Token and son on) and custom ones which are issued and used by Application itself.\nWhile it is fairly easy to set path for custom ones, we had to make code changes for cookies issued by .NET framework libraries. Lets take case of Session ID cookie, by default, this cookie always has root / as path. So how can this be changed as per the application\u0026rsquo;s deployment settings (i.e. specific virtual directory in IIS)?\nWe tried below,\nStep 1, try using httpcookies section in web.config like, \u0026lt;httpCookies requireSSL=\u0026#34;false\u0026#34; httpOnlyCookies=\u0026#34;true\u0026#34; domain=\u0026#34;site.com/myapp\u0026#34;/\u0026gt; First of all, this configuration element does not allow setting Path property and even during runtime, only the Domain property is populated while issuing the cookie. So this definitely does not help address the issue.\nSo other way is to programmatically set the path for Session Cookie. This can be done by providing custom implementation of SessionIDManager class like below,\npublic class MySessionIDManager : SessionIDManager, ISessionIDManager { void ISessionIDManager.SaveSessionID(HttpContext context, string id, out bool redirected, out bool cookieAdded) { base.SaveSessionID(context, id, out redirected, out cookieAdded); if (cookieAdded) { var name = \u0026#34;ASP.NET_SessionId\u0026#34;; var cookie = context.Response.Cookies[name]; // this will be possibly read from configuration cookie.Path = \u0026#34;/myapp\u0026#34;; } } } Thanks to this Stackoverflow thread for listing this approach. Application under consideration only had this particular cookie however, for all other .NET framework issued cookies, similar technique will have to be used.\nSameSite Cookie This is already detailed here\nMasking of Sensitive Data This typically involves masking the sensitive data like\nE-mail id Phone Number Credit/Debit Card Number It could well be used in Web Application or be received or sent as part of HTTP API.\nThe best bet in this case is to mask it on the server side itself before sending/rendering the data in browser. Note that, in some cases, above fields are used for data binding purposes. The approach we followed in such scenario was to use Hash value of it instead of merely masking the data. We have always used SHA256 or above for hashing.\nSummary Addressing security vulnerabilities is continuous process as hackers keep on inventing new ways for breaching and exploiting weak spots. As Application Architect/Developers, we need to brace ourselves for the same.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/websecurity/","summary":"\u003cp\u003eAt my current workplace, All Applications are expected to adhere to  \u003ca href=https://en.wikipedia.org/wiki/Payment_Card_Industry_Data_Security_Standard\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePCI DSS standards\u003c/a\u003e meant for Data protection, Access Regulation and so on.  Dedicated \u003ca href=https://en.wikipedia.org/wiki/Information_security_operations_center\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSOC\u003c/a\u003e Team,consisting of Security analyst who are continously on the prawl to identify breach, conduct periodic auditing of Applications, hardening of Servers.\u003c/p\u003e\n\u003cp\u003eWhile all our .NET applications adhere to below guidelines,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://support.microsoft.com/en-in/help/891028/asp-net-security-overview\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eASP.NET Security Overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/security/secure-coding-guidelines\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSecure Coding Guidelines\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cheatsheetseries.owasp.org/cheatsheets/DotNet_Security_Cheat_Sheet.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSecurity Guidelines by OWASP\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe also use tools like \u003ca href=https://www.snyk.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSnyk\u003c/a\u003e to perform code vulnerability analysis as part of Jenkins driven CI/CD pipeline. In spite of above, we do come across  vulnerabilities identified by SOC Team which we needs to be addressed quickly. SOC team uses tools such as \u003ca href=https://portswigger.net/burp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBurp Suite\u003c/a\u003e.\u003c/p\u003e","title":"Web Security Measures in ASP.NET Applications"},{"content":"Over the last many years, de-facto language of the Web (specifically front-end) has been Javascript (and variants like Typescript, ECMAScript versions and so on). The Web development has been revolving around HTML+CSS+Javascript trio. It all started with support for Javascript in browsers, followed by addition of XMLHTTP API, Rich DOM Manipulation Support in Javascript. To induce order and apply patterns to Javascript\u0026rsquo;s usage in browsers, numerous frameworks and libraries were introduced like React and Vue among others. To begin with, The target used to be browsers on Large Devices like Desktop \u0026amp; Laptops. However, soon all sorts of devices were targetted with advent of Responsive and Progressive CSS+Javascript libraries eg. Bootstrap. Offline Support soon came in ref: Electron and Progressive Web Applications.\nAs a result, Javascript has become lingua franca of Web Development and is being used on server side development (Nodejs).\nThe reason for this whole rant on history (which you are most likely to be aware of) is that latest kid on the Block could possibly challenge Monopoly of Javascript (and its ilk) at far as browsers are concerned.\nEnter WebAssembly (A.K.A. WASM)\nWebAssembly As per Wikipedia,\nWebAssembly (often shortened to Wasm) is an open standard that defines a portable binary-code format for executable programs, and a corresponding textual assembly language, as well as interfaces for facilitating interactions between such programs and their host environment.\nWebAssembly or wasm is a low-level bytecode format for in-browser client-side scripting, evolved from JavaScript. It is intermidiate representation(IR) where IR is transformed into machine instructions for the client architecture by browser.\nWebAssembly executables are precompiled, hence it is possible to use a variety of programming languages to make them. This essentially means that one can use same language for Server Side as well as Client side (i.e. in browser) development like (C# or Golang).\nWebAssembly was announced in 2015 and has since being supported by prominent browser(s) like Chrome and Firefox.\nAlong side browsers, many Vendors and open source communities/contributors have released libraries to make development of WebAssembly easy. We will look at how a WebAssembly can be developed in C# and Golang.\nNote: All major languages now support WebAssembly.\nC# During Microsoft Build 2020 1 event, Steve Sanderson had very good session on building WebAssembly using Blazor framework in .NET. Highly recommended to watch it.\nBlazor scaffolding provided with .NET core allows,\nBlazor Server App - A Template that runs server-side inside an ASP.NET Core app and handles user interactions over a SignalR connection.\nBlazor WebAssembly App - A Template for creating a Blazor app that runs on WebAssembly.\nChoosing Blazor WebAssembly App project type generates a project that has sample WebAssembly running. Overall, it makes development easy for any .NET developer easy since, it usesRazor syntax to add C# code along with HTML. During Build, it generates assembly for C# Code. When Accessed via browser, it downloads .NET runtime for WebAssembly (~ 621 KB) and the project assembly itself apart from static content (i.e. HTML files, images etc). The default scafolding includes Bootstrap CSS and prepares the UI to be responsive.\nThe repository referenced by Steve during presentation is available here.\nGolang Go has got clean, fast tooling. it produces static binaries and has superb concurrency primitives.\nVugu is an open source library that allows building a Web front-end in Go using WebAssembly. Generally static binaries are bulky and Vugu has addressed it using TinyGo compiler. Vugu is still work in progress but does work great in its current form. Check out their getting started page.\nInteresting take on Journey of JavaScript and what lies ahead for it, read it here.\nSummary In nutshell, Concept of WebAssembly provides compelling way to have full stack development in a language of your choice. It remains to be seen how and whether it provides viable alternative to current Javascript driven ecosystem.\nUseful References, Happy Coding !!\nModern Web UI with Blazor\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/webassembly/","summary":"\u003cp\u003eOver the last many years, de-facto language of the Web (specifically front-end) has been Javascript (and variants like Typescript, ECMAScript versions and so on). The Web development has been revolving around HTML+CSS+Javascript trio. It all started with support for Javascript in browsers, followed by addition of XMLHTTP API, Rich DOM Manipulation Support in Javascript. To induce order and apply patterns to Javascript\u0026rsquo;s usage in browsers, numerous frameworks and libraries were introduced like \u003ca href=https://reactjs.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReact\u003c/a\u003e and \u003ca href=https://vuejs.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVue\u003c/a\u003e among others. To begin with, The target used to be browsers on Large Devices like Desktop \u0026amp; Laptops. However, soon all sorts of devices were targetted with advent of Responsive and Progressive CSS+Javascript libraries eg. \u003ca href=https://getbootstrap.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBootstrap\u003c/a\u003e. Offline Support soon came in ref: \u003ca href=https://electronjs.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eElectron\u003c/a\u003e and \u003ca href=https://web.dev/progressive-web-apps/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProgressive Web Applications\u003c/a\u003e.\u003c/p\u003e","title":"Is WebAssembly future of Web Development"},{"content":"Background The source code of tracfee.com is hosted on Github Private.\nAt a High level, Tracfee\u0026rsquo;s Architecture involves,\nSingle Page Application using VueJS, deployed on Netlify API in Go, deployed on Oracle Cloud So far, API testing has been automated and we were looking at ways to automate deployment of both UI and API. Steps required to deploy API are less since we are using Docker to run it on VM. However, in case of Netlify, it is required to build and then upload the output folder on Netlify.\nAccordingly, it was decided to explore Github actions to automate deployment.\nUsing Github actions As per Github,\nGitHub Actions makes it easy to automate all your software workflows, now with world-class CI/CD. Build, test, and deploy your code right from GitHub. Make code reviews, branch management, and issue triaging work the way you want. GitHub actions work by provisioning Virtual machine to run an Event based workflow. It provides option to provision Linux/MacOS/Windows based Virtual machines. Steps in Workflow will have to be configured in YAML file. Trigger for Workflow can be (but not limited to) wide variety of events like on Push or commit on branch and so on.\nPost trigger, set of action(s) can be configured like,\nCheckout the branch Setup environment (Install Node.JS) Perform build Deployment Github has Marketplace which has many pre-built actions available. My requirement was to,\nProvision Linux (i.e. ubuntu-latest) Virtual Machine Checkout the code (using actions/checkout@v2) Setup Node.js (using actions/setup-node) perform Build and test using NPM Deploy to Netlify using netlify/actions/cli@master Any secrets required as part of Workflow can be maintained using Github secrets Above workflow needs to be maintained in .github\\workflows folder in the repository.\nbuild.yml for tracfee.com looks like,\nRefer Gist here.\nTesting the Build Workflow After configuring the workflow steps, next question is to check whether it is possible to test it locally? Luckily, there is tool available to do this. Enter Act , which is a tool to Run your GitHub Actions locally . Local testing is useful for Faster feedback. In Nutshell, Act uses local docker setup to provision container and then runs workflow steps in it. Give it a try !!\nAs a next step, Plan is to automate deployment of API on Oracle Cloud using OCI CLI interface.\nUseful References, Build with GitHub Actions, host on Netlify Adventures in CI/CD [#4]: Deploying A Microservice To The Oracle Cloud With GitHub Actions [OCI CLI Edition] Happy Coding !!\n","permalink":"http://localhost:1313/posts/usinggithubactions/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eThe source code of \u003ca href=https://tracfee.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003etracfee.com\u003c/a\u003e is hosted on Github Private.\u003c/p\u003e\n\u003cp\u003eAt a High level, Tracfee\u0026rsquo;s Architecture involves,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSingle Page Application using VueJS, deployed on \u003ca href=https://netlify.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNetlify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eAPI in \u003ca href=https://golang.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo\u003c/a\u003e, deployed on \u003ca href=https://www.oracle.com/in/cloud/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle Cloud\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSo far, API testing has been automated and we were looking at ways to automate deployment of both UI and API. Steps required to deploy API are less since we are using Docker to run it on VM. However, in case of Netlify, it is required to build and then upload the output folder on Netlify.\u003c/p\u003e","title":"Using Github Actions for Automated Testing and Deployment"},{"content":"Useful links for deep diving in various Cloud Ecosystems\nArticles Cost of Cloud - Paradox Cloud vs. On-premise Computing Zero dollar Infrastructure stack Cloud Server Performance, Prices, Specs and Features The Cost of Cloud, a Trillion Dollar Paradox Why we are leaving cloud General Guidelines when working as Cloud Engineer Articles (GCP) 13 sample architectures to kickstart your Google Cloud journey Using Google Cloud Spanner locally …using Emulator Articles (AWS) Serverless - Event driven Architecture Preparation Guidelines and courses for AWS Certification Saving egress costs on AWS using S3 Reducing AWS Costs Choosing between EC2 and RDS What a typical 100% Serverless Architecture looks like in AWS! Automating safe, hands-off deployments Containerizing legacy ASP.NET applications using AWS App2Container (A2C) Replacing web server functionality with serverless services AWS Lambda vs Cloudflare Workers Unbound One line Explaination for each of AWS Services Building a Multiplayer Game with API Gateway\u0026#43;Websockets, Go and DynamoDB Best Practices To Handle Lambda Timeout Errors Save 99.93% for Lambda with Init time Architecture of SAAS on Cloud managed by One man Team AWS Costs that every programmer should know You should not be probably using AWS Videos, Talks (AWS) DynamoDB - Advanced Design Patterns DynamoDB - Deep Dive Migration from Postgres to DynamoDB Tools Checkov-Prevent cloud misconfigurations during build-time Infracost - Open Source tool that shows Cloud cost estimates for Terraform in pull requests About Infrastructure as a Code Cloud Native Wiki - Cloud native Architectures, DevSecOps etc. Mock AWS Infrastructure ","permalink":"http://localhost:1313/links/cloud/","summary":"\u003cp\u003eUseful links for deep diving in various Cloud Ecosystems\u003c/p\u003e\n\u003ch3 id=\"articles\"\u003eArticles\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/the-cost-of-cloud-a-trillion-dollar-paradox/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCost of Cloud - Paradox\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.scirp.org/journal/paperinfexormation.aspx?paperid\u0026#61;87661\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCloud vs. On-premise Computing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/better-programming/the-zero-dollar-infrastructure-stack-7c840a8b555b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZero dollar Infrastructure stack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.vpsbenchmarks.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCloud Server Performance, Prices, Specs and Features\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/2021/05/27/cost-of-cloud-paradox-market-cap-cloud-lifecycle-scale-growth-repatriation-optimization/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Cost of Cloud, a Trillion Dollar Paradox\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://world.hey.com/dhh/why-we-re-leaving-the-cloud-654b47e0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy we are leaving cloud\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.lockedinspace.com/posts/001.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGeneral Guidelines when working as Cloud Engineer\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"articles-gcp\"\u003eArticles (GCP)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://cloud.google.com/blog/products/application-development/13-popular-application-architectures-for-google-cloud\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e13 sample architectures to kickstart your Google Cloud journey\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cloud.google.com/spanner/docs/emulator\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Google Cloud Spanner locally …using Emulator\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"articles-aws\"\u003eArticles (AWS)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://serverlessland.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eServerless - Event driven Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/training-and-certification/prepare-simultaneously-for-aws-certified-cloud-practitioner-and-aws-certified-solutions-architect-associate/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePreparation Guidelines and courses for AWS Certification\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.bitsand.cloud/posts/slashing-data-transfer-costs/?utm_source\u0026#61;hackernewsletter\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_term\u0026#61;data\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSaving egress costs on AWS using S3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.maxcountryman.com/articles/taming-aws-costs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReducing AWS Costs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.aws.amazon.com/prescriptive-guidance/latest/migration-sql-server/comparison.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChoosing between EC2 and RDS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/serverless-transformation/what-a-typical-100-serverless-architecture-looks-like-in-aws-40f252cd0ecb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat a typical 100% Serverless Architecture looks like in AWS!\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/builders-library/automating-safe-hands-off-deployments/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAutomating safe, hands-off deployments\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/modernizing-with-aws/containerizing-legacy-asp-net-applications-using-aws-app2container-a2c/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContainerizing legacy ASP.NET applications using AWS App2Container (A2C)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/compute/replacing-web-server-functionality-with-serverless-services/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReplacing web server functionality with serverless services\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.cloudflare.com/introducing-workers-unbound/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAWS Lambda vs Cloudflare Workers Unbound\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://adayinthelifeof.nl/2020/05/20/aws.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOne line Explaination for each of AWS Services\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://serialized.net/2020/09/multiplayer/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBuilding a Multiplayer Game with API Gateway\u0026#43;Websockets, Go and DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lumigo.io/learn/aws-lambda-timeout-best-practices/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Practices To Handle Lambda Timeout Errors\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@hichaelmart/shave-99-93-off-your-lambda-bill-with-this-one-weird-trick-33c0acebb2ea\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSave 99.93% for Lambda with Init time\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://anthonynsimon.com/blog/one-man-saas-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArchitecture of SAAS on Cloud managed by One man Team\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://david-codes.hatanian.com/2019/06/09/aws-costs-every-programmer-should-now.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAWS Costs that every programmer should know\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.karlsutt.com/articles/you-should-not-be-using-aws/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou should not be probably using AWS\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"videos-talks-aws\"\u003eVideos, Talks (AWS)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;6yqfmXiZTlM\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDynamoDB - Advanced Design Patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/AWSAktuell/deep-dive-into-dynamodb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDynamoDB - Deep Dive\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.instacart.com/company/how-its-made/from-postgres-to-amazon-dynamodb-%EF%BF%BC/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMigration from Postgres to DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"tools\"\u003eTools\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/bridgecrewio/checkov\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCheckov-Prevent cloud misconfigurations during build-time\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.infracost.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInfracost - Open Source tool that shows Cloud cost estimates for Terraform in pull requests\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://unzip.dev/0x004-infrastructure-as-code/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Infrastructure as a Code\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.aquasec.com/cloud-native-academy/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCloud Native Wiki - Cloud native Architectures, DevSecOps etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/spulec/moto\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMock AWS Infrastructure\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Cloud Tech"},{"content":"Useful links related from Generative AI, ML space\nCollections Gen AI- Collection of Articles on AI Code Generation and its pros and cons AI Guide by Mozilla Collection of resources related to Applied ML List of for MLOps Prompt Engineering Playbook for Programmers Free courses Fast AI by Jeremy Howard AI Canon - List of resources around GPT Free Deep learning course Articles AI native software Engineer in 2025 My LLM codegen workflow atm How to build your own perplexity for any dataset How a Machine Learns Machine learning is still too hard - Year 2022 Neural Networks from Scratch History of AI Machine Learning Algorithms: What is a Neural Network? What is Benford’s Law and why is it important for data science? Benford’s Law and Financial Statements Data Scientists Should Be More End-to-End Team Data science process (Microsoft) Traits of Good Data Scientist The First Rule of Machine Learning: Start without Machine Learning Deep learning is hitting wall Real world Recommendation System Videos Neural Networks Demystified Deep Learning: A Crash course Vector Embeddings, Vector Databases Storing OpenAI embeddings in Postgres with pgvector ChatGPT, LLMs A practical guide to building successful LLM products. Emerging Architecture for LLM Applications LocalGPT - Chat with your documents on your local device using GPT models Run LLMs from command line Resources on LLMs AI based Translation Lokalize - AI based translation of file Vibery - Semantic Search using embeddings and KNN Tools Markitdown - Convert PDF and Office documents to markdown to feed into LLM Aider - AI pair programming in your terminal An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with LlamaIndex, Langchain, OpenAI SDK, LiteLLM, and more. Vespa is an open-source search engine and big data processing platform. It’s particularly well[1]suited for applications that require low latency and high throughput. Our teams like Vespa’s ability to implement hybrid search using multiple retrieval techniques, to efficiently filter and sort many types of metadata, to implement multi-phased ranking, to index multiple vectors (e.g., for each chunk) per document without duplicating all the metadata into separately indexed documents and to retrieve data from multiple indexed fields at once. Kotaemon - An open-source RAG-based tool for chatting with your documents. ","permalink":"http://localhost:1313/links/aiml/","summary":"\u003cp\u003eUseful links related from Generative AI, ML space\u003c/p\u003e\n\u003ch2 id=\"collections\"\u003eCollections\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://addyo.substack.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGen AI- Collection of Articles on AI Code Generation and its pros and cons\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ai-guide.future.mozilla.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAI Guide by Mozilla\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/eugeneyan/applied-ml\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of resources related to Applied ML\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.google.com/spreadsheets/d/1i8BzE4puGQ3dmQueu4LQCcwaqrulgK1Vb-xeFwhy6gY/edit#gid\u0026#61;0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of  for MLOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://addyo.substack.com/p/the-prompt-engineering-playbook-for\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrompt Engineering Playbook for Programmers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"free-courses\"\u003eFree courses\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.fast.ai/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFast AI by Jeremy Howard\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/2023/05/25/ai-canon/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAI Canon - List of resources around GPT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fleuret.org/dlc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFree Deep learning course\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"articles\"\u003eArticles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://addyo.substack.com/p/tbe-ai-native-software-engineer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAI native software Engineer in 2025\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMy LLM codegen workflow atm\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jnnnthnn.com/how-to-build-your-own-perplexity-for-any-dataset\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to build your own perplexity for any dataset\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://janav.wordpress.com/2023/10/10/how-a-machine-learns/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow a Machine Learns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.nyckel.com/blog/ml-too-hard-for-software-developers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMachine learning is still too hard - Year 2022\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sirupsen.com/napkin/neural-net\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNeural Networks from Scratch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://spectrum.ieee.org/history-of-ai\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHistory of AI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.verypossible.com/insights/machine-learning-algorithms-what-is-a-neural-network\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMachine Learning Algorithms: What is a Neural Network?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/what-is-benfords-law-and-why-is-it-important-for-data-science-312cb8b61048\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat is Benford’s Law and why is it important for data science?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.auditanalytics.com/benfords-law-and-financial-statements/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenford’s Law and Financial Statements\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eugeneyan.com/writing/end-to-end-data-science/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Scientists Should Be More End-to-End\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTeam Data science process (Microsoft)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ianwhitestone.work/good-ds-bad-ds/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTraits of Good Data Scientist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eugeneyan.com/writing/first-rule-of-ml/?utm_source\u0026#61;hackernewsletter\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_term\u0026#61;fav\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe First Rule of Machine Learning: Start without Machine Learning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://nautil.us/deep-learning-is-hitting-a-wall-14467/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDeep learning is hitting wall\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.fennel.ai/p/real-world-recommendation-system?s\u0026#61;r\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReal world Recommendation System\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"videos\"\u003eVideos\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/playlist?list\u0026#61;PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNeural Networks Demystified\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;r0Ogt-q956I\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDeep Learning: A Crash course\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"vector-embeddings-vector-databases\"\u003eVector Embeddings, Vector Databases\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://supabase.com/blog/openai-embeddings-postgres-vector\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStoring OpenAI embeddings in Postgres with pgvector\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"chatgpt-llms\"\u003eChatGPT, LLMs\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://applied-llms.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA practical guide to building successful LLM products.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEmerging Architecture for LLM Applications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/PromtEngineer/localGPT\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLocalGPT - Chat with your documents on your local device using GPT models\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/simonw/llm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRun LLMs from command line\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://parlance-labs.com/education/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eResources on LLMs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"ai-based-translation\"\u003eAI based Translation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://lokalise.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLokalize - AI based translation of file\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/veekaybee/viberary/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVibery - Semantic Search using embeddings and KNN\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"tools\"\u003eTools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/markitdown\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMarkitdown - Convert PDF and Office documents to markdown to feed into LLM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/paul-gauthier/aider\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAider - AI pair programming in your terminal \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/lm-sys/FastChat\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAn open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/langfuse/langfuse\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with LlamaIndex, Langchain, OpenAI SDK, LiteLLM, and more.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/vespa-engine/vespa\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVespa is an open-source search engine and big data processing platform. It’s particularly well[1]suited for applications that require low latency and high throughput. Our teams like Vespa’s ability to implement hybrid search using multiple retrieval techniques, to efficiently filter and sort many types  of metadata, to implement multi-phased ranking, to index multiple vectors (e.g., for each chunk) per document without duplicating all the metadata into separately indexed documents and to retrieve data from multiple indexed fields at once.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Cinnamon/kotaemon\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eKotaemon - An open-source RAG-based tool for chatting with your documents. \u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Generative AI, Machine Learning"},{"content":"User Interface / User Experience Design Approach Modern Web - Guides, tools and libraries for modern web development. How Stripe Designs Beautiful Websites Tools for non artistic developers Principles of Design Micro frontends - Techniques, strategies and recipes for building a modern web app with multiple teams that can ship features independently. Thoughts on SPAs 33 JavaScript concepts every Developer should know Server side Events for Real-time streaming Updates Four ways to build Web Apps Parallel Data Fetching in SPA…has Good Primer on React Articles guideline on implementing auth in web applications Examples to manipulate HTML-DOM Comparing Polling vs WebSockets vs SSE A simple, choice-driven chatbot framework with Vanilla Javascript Centering in CSS: A Complete Guide Centering in CSS Full-bleed layout using CSS Grid Blog on HTML,fonts, Asynchronous JavaScript How to pick beautiful colors You dont need Javascript Sign in form Best practices How HTTP Range Requests work (for large file downloads etc.) Beginner’s guide to Next.js Data Model behind Notion’s flexibility How TCP Communication works between Client \u0026amp;amp; Server Practical Frontend Architecture using React,GraphQL, Next.JS and Typescript The baseline for Web development in 2022 Web UI Patterns by Addy Osmani The Web’s Next Transition Everything about HTMX Testing OSS Load and Functional testing tool Puppeteer - Testing using Headless Chrome Nodejs API Playwright - Nodejs library to automate Chromium, WebKit and Firefox Platforms Medusa - Flexible ECommerce Platform Libraries and Tools Bootstrap based Admin theme - Volt RsPack - Fast web bundler like webpack Dash - Python based framework for Visualization with no javascript ObservablePlot T3 - full-stack, typesafe Next.js app Perspective.js - A data visualization and analytics component, especially well-suited for large and/or streaming datasets. Observable - A static site generator for data apps, dashboards, reports Nginx Unit - Web Server with Native support for Languages GoatCounter - Open source Web site Analytics RedwoodJS - App framework Gatsby - React based fast framework Remix - Modern SPA framework Blitz - Modern SPA framework based on React Polaris design system by shopify Qiankun - Complete solution for Micro front-ends Astro - a website build tool Single SPA - Router for Micro front-ends HTMX -access AJAX, CSS Transitions, WebSockets and Server Sent Events directly in HTML, using attributes Bulletproof React - Opinionated React starter kit Javascript based Query/filter creator React based Sci-fi style UI Library with Animation and Sound Javascript libraries for Date and Time (Alternative to Moment.js) Zod - Schema validation in Typescript One line CSS Layouts by Google G9 - Interactive Graphs Interactive CSS Grid generator Msw - Mock Service Worker for REST \u0026amp;amp; GraphQL API Mocking Modern JavaScript Tutorial Web Vitals- Essential metrics for a healthy site. Clerk - User Management as Service Go based Fast Javascript bundler and minifier Finite State Machine in JS/Typescript Observable Plot - Data Visualization Library Shared data types for building collaborative software NoSQL-database for JavaScript Applications like Websites, hybrid Apps, Electron-Apps, Progressive Web Apps and NodeJs RemixIcon - Open Source Icons Repository Mermaid - Generate Diagrams from Markdown AutoMerge - Network agnostic library for JSON-like data structure (a CRDT) that can be modified concurrently by different users, and merged again automatically. Text (DSL) to diagrams Interactive guide to Flexbox End to end encryption in browser Collection of SVG logos Desktop App frameworks Tauri - smaller, faster, and more secure desktop applications with a web frontend (Native Webviews and no chromium) PWA PWABuilder - Publish Progressive Web App as Mobile App What a PWA can do today Step by Step using PWABuilder Mobile App Development Expo - universal native apps with React ","permalink":"http://localhost:1313/links/uiux/","summary":"\u003ch1 id=\"user-interface--user-experience\"\u003eUser Interface / User Experience\u003c/h1\u003e\n\u003ch2 id=\"design-approach\"\u003eDesign Approach\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://modern-web.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModern Web - Guides, tools and libraries for modern web development.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://leerob.io/blog/how-stripe-designs-beautiful-websites\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Stripe Designs Beautiful Websites\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://nodesign.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTools for non artistic developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://principles.design/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrinciples of Design\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://micro-frontends.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicro frontends - Techniques, strategies and recipes for building a modern web app with multiple teams that can ship features independently.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://nolanlawson.com/2022/05/25/more-thoughts-on-spas/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThoughts on SPAs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/leonardomso/33-js-concepts#8-iife-modules-and-namespaces\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e33 JavaScript concepts every Developer should know\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://shopifyengineering.myshopify.com/blogs/engineering/server-sent-events-data-streaming\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eServer side Events for Real-time streaming Updates\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tomhummel.com/posts/four-web-apps/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFour ways to build Web Apps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.martinfowler.com/articles/data-fetch-spa.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eParallel Data Fetching in SPA…has Good Primer on React\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"articles\"\u003eArticles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/pilcrowonpaper/copenhagen\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eguideline on implementing auth in web applications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://phuoc.ng/collection/html-dom/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExamples to manipulate HTML-DOM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://codeburst.io/polling-vs-sse-vs-websocket-how-to-choose-the-right-one-1859e4e13bd9\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComparing Polling vs WebSockets vs SSE\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/peekobot/peekobot\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA simple, choice-driven chatbot framework with Vanilla Javascript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://css-tricks.com/centering-css-complete-guide/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCentering in CSS: A Complete Guide\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ishadeed.com/article/learn-css-centering/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCentering in CSS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://joshwcomeau.com/css/full-bleed/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFull-bleed layout using CSS Grid\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://whistlr.info/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBlog on HTML,fonts, Asynchronous JavaScript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.datawrapper.de/beautifulcolors/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to pick beautiful colors\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/you-dont-need/You-Dont-Need-JavaScript\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou dont need Javascript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://web.dev/sign-in-form-best-practices/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSign in form Best practices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://developer.mozilla.org/en-US/docs/Web/HTTP/Range_requests\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow HTTP Range Requests work (for large file downloads etc.)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://welearncode.com/beginners-guide-nextjs/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBeginner’s guide to Next.js\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.notion.so/blog/data-model-behind-notion\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Model behind Notion’s flexibility\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sirupsen.com/napkin/problem-15/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow TCP Communication works between Client \u0026amp;amp; Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jaredgorski.org/writing/14-practical-frontend-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePractical Frontend Architecture using React,GraphQL, Next.JS and Typescript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.linecorp.com/en/blog/the-baseline-for-web-development-in-2022/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe baseline for Web development in 2022\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.patterns.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb UI Patterns by Addy Osmani\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.epicweb.dev/the-webs-next-transition\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Web’s Next Transition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hypermedia.systems\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEverything about HTMX\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"testing\"\u003eTesting\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://artillery.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOSS Load and Functional testing tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pptr.dev\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePuppeteer - Testing using Headless Chrome Nodejs API\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://playwright.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePlaywright - Nodejs library to automate Chromium, WebKit and Firefox\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"platforms\"\u003ePlatforms\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/medusajs/medusa\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMedusa - Flexible ECommerce Platform\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"libraries-and-tools\"\u003eLibraries and Tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/themesberg/volt-bootstrap-5-dashboard\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBootstrap based Admin theme - Volt\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/web-infra-dev/rspack\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRsPack - Fast web bundler like webpack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/plotly/dash\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDash - Python based framework for Visualization with no javascript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/observablehq/plot\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eObservablePlot\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/t3-oss/create-t3-app\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eT3 - full-stack, typesafe Next.js app\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/finos/perspective?tab\u0026#61;readme-ov-file\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePerspective.js - A data visualization and analytics component, especially well-suited for large and/or streaming datasets.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/observablehq/framework\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eObservable - A static site generator for data apps, dashboards, reports\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nginx/unit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNginx Unit - Web Server with Native support for Languages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/arp242/goatcounter\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoatCounter - Open source Web site Analytics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/redwoodjs/redwood\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedwoodJS - App framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.gatsbyjs.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGatsby - React based fast framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/remix-run/remix\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRemix - Modern SPA framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/blitz-js/blitz\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBlitz - Modern SPA framework based on React\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://polaris.shopify.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePolaris design system by shopify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/umijs/qiankun\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQiankun - Complete solution for Micro front-ends\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/withastro/astro\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAstro - a website build tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://single-spa.js.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSingle SPA - Router for Micro front-ends\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://htmx.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHTMX -access AJAX, CSS Transitions, WebSockets and Server Sent Events directly in HTML, using attributes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/alan2207/bulletproof-react\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBulletproof React - Opinionated React starter kit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://querybuilder.js.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJavascript based Query/filter creator\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://arwes.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReact based Sci-fi style UI Library with Animation and Sound\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dockyard.com/blog/2020/02/14/you-probably-don-t-need-moment-js-anymore\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJavascript libraries for Date and Time (Alternative to Moment.js)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/colinhacks/zod\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZod - Schema validation in Typescript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://1linelayouts.glitch.me/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOne line CSS Layouts by Google\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://omrelli.ug/g9/gallery/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eG9 - Interactive Graphs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://grid.layoutit.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteractive CSS Grid generator\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mswjs.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMsw - Mock Service Worker for REST \u0026amp;amp; GraphQL API Mocking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://javascript.info/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModern JavaScript Tutorial\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://web.dev/vitals\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb Vitals- Essential metrics for a healthy site.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=hthttps://tomhummel.com/posts/four-web-apps/tps://clerk.dev\n    \n    \n\u003eClerk - User Management as Service\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://esbuild.github.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo based Fast Javascript bundler and minifier\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://xstate.js.org/docs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFinite State Machine in JS/Typescript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/observablehq/plot\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eObservable Plot - Data Visualization Library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/yjs/yjs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eShared data types for building collaborative software\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rxdb.info\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNoSQL-database for JavaScript Applications like Websites, hybrid Apps, Electron-Apps, Progressive Web Apps and NodeJs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://remixicon.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRemixIcon - Open Source Icons Repository\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mermaid-js/mermaid\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMermaid - Generate Diagrams from Markdown\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/automerge/automerge\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAutoMerge - Network agnostic library for JSON-like data structure (a CRDT) that can be modified concurrently by different users, and merged again automatically.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://d2lang.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eText (DSL) to diagrams\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.joshwcomeau.com/css/interactive-guide-to-flexbox/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteractive guide to Flexbox\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.excalidraw.com/end-to-end-encryption/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEnd to end encryption in browser\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://svgl.vercel.app/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of SVG logos\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"desktop-app-frameworks\"\u003eDesktop App frameworks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/tauri-apps/tauri\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTauri - smaller, faster, and more secure desktop applications with a web frontend (Native Webviews and no chromium)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"pwa\"\u003ePWA\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.pwabuilder.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePWABuilder - Publish Progressive Web App as Mobile App\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://whatpwacando.today/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat a PWA can do today\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/ifdef-windows/get-started-building-a-progressive-web-app/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStep by Step using PWABuilder\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"mobile-app-development\"\u003eMobile App Development\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://GitHub.com/expo/expo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExpo - universal native apps with React\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"UI/UX"},{"content":"Background Recently, we had requirement wherein a process should,\nPeriodically (Poll) or Asynchronously (Pub-sub) listen on incoming requests/messages. The whole process is expected to be long running. Should also implement clean disposal of in-flight requests and subsequent cleanup using something similar to Cancelble Context in Go The first of the objective is somewhat dependent on mechanism (Pub/sub, Listener), protocol (TCP, HTTP etc.). For the second one, .NET framework (and .NET Core) offers CancellationToken. It is maint for co-operative cancellation between threads and Task Objects. So Armed with this, is it possible to come up with a template that allows cancellation of long running task while also being deployed as Windows Service (or using systemd in Linux) ?\nLets get Started,\nApproach We can use below to construct service,\nTopshelf - Allows Hosting services in-process as console apps or Windows services. NLog - For Logging Accordingly, we will have below Components,\nListener.cs - It wraps the long running process in a C# Task. It exposes Start and Stop functions which are essentially event handlers awaiting for Signal from the service. Refer Gist here\nProgram.cs - It configures the startup parameters for the service and initializes it. Using Topshelf, one can easily debug it as Console Application before deploying it as Service. Refer Gist here\nAbove Code was targetted at .NET Framework but the same can potentially be used on .NET Core thus targetting both Windows and Linux.\nHappy Coding !!\n","permalink":"http://localhost:1313/posts/windowsservicecancellabletask/","summary":"\u003ch3 id=\"background\"\u003eBackground\u003c/h3\u003e\n\u003cp\u003eRecently, we had requirement wherein a process should,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePeriodically (Poll) or Asynchronously (Pub-sub) listen on incoming requests/messages. The whole process is expected to be long running.\u003c/li\u003e\n\u003cli\u003eShould also implement clean disposal of in-flight requests and subsequent cleanup using something similar to Cancelble \u003ca href=https://golang.org/pkg/context/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContext\u003c/a\u003e in Go\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe first of the objective is somewhat dependent on mechanism (Pub/sub, Listener), protocol (TCP, HTTP etc.). For the second one, .NET framework (and .NET Core) offers \u003ca href=https://docs.microsoft.com/en-us/dotnet/api/system.threading.cancellationtoken?view\u0026#61;netcore-3.1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCancellationToken\u003c/a\u003e. It is maint for co-operative cancellation between threads and Task Objects. So Armed with this, is it possible to come up with a template that allows cancellation of long running task while also being deployed as Windows Service (or using systemd in Linux) ?\u003c/p\u003e","title":"Windows Service with Cancelable Task"},{"content":"Background Oftentimes, we come across situation where code does not perform as per expectation. What is typically approch to address it,\nPerformance Testing - Visual Studio Load Tests or Third party tools like Locust, Vegeta, Gatling etc. Visual Studio Diagnostics Tools Or Use tools like Perfview/dotTrace/dotMemory to diagnose bottlenecks What if it is possible to Benchmark code for,\nSet of varying parameter(s) Different runtimes (.NET Framework versions, .NET core, Mono etc.) with option to Benchmark it Observe Memory Allocations for diagnostics Get Detailed report on execution timeline Have it as part of test suite so that it can be easily executed with every iteration involving optimized code to get immediate feedback Enter BenchmarkDotNet, a Powerful .NET library for benchmarking. It is used by DotNET Team, Roslyn, ASP.NET Core and many other projects.\nThough Benchmarkdotnet.org has nice documentation with detailed examples, Below we will look at how to benchmark a code which is aimed at dumping in-memory list of objects to a delimited file. In real-world scenario, the list of objects could be retrieved from external data store.\nSo Lets Start.\nApproach We will have below before we proceed with using BenchmarkDotNet\nDummy class that represents Data Structure to be dumped to a file, Refer Gist here\nClass CardWriter.cs that generates file using,\nUsing StreamWriter with Buffer Using Stringbuilder and StreamWriter Using Open source CSVHelper library Refer Gist here\nNow, let us write code to benchmark above functions with Memory Diagnostics, Refer Gist here\nAbove code,\nClass FileGeneratorBenchmark - This class uses BenchmarkDotNET attributes to decorate set of functions which in turn call functions from CardWriter.cs class. Class Program - General purpose class with static main function that invokes BenchmarkRunner to execute benchmarks. It is required to run these benchmarks in Release mode or else BenchmarkDotNet will alert about the same. After running the benchmark, It will generate detailed report like below,\nReport shows Memory Allocation as well as Execution time lines across Platform (.NET Framework Vesions) and parameters.\nReferences:\nBenchmarkDotNet Introduction to Benchmarking C# Code with Benchmark .NET Happy Coding !!\n","permalink":"http://localhost:1313/posts/usingbenchmarkdotnet/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eOftentimes, we come across situation where code does not perform as per expectation. What is typically approch to address it,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePerformance Testing - Visual Studio Load Tests or Third party tools like  \u003ca href=https://locust.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLocust\u003c/a\u003e, \u003ca href=https://github.com/tsenart/vegeta\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVegeta\u003c/a\u003e, \u003ca href=https://gatling.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGatling\u003c/a\u003e etc.\u003c/li\u003e\n\u003cli\u003eVisual Studio Diagnostics Tools Or\u003c/li\u003e\n\u003cli\u003eUse tools like Perfview/dotTrace/dotMemory to diagnose bottlenecks\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhat if it is possible to Benchmark code for,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSet of varying parameter(s)\u003c/li\u003e\n\u003cli\u003eDifferent runtimes (.NET Framework versions, .NET core, Mono etc.) with option to Benchmark it\u003c/li\u003e\n\u003cli\u003eObserve Memory Allocations for diagnostics\u003c/li\u003e\n\u003cli\u003eGet Detailed report on execution timeline\u003c/li\u003e\n\u003cli\u003eHave it as part of test suite so that it can be easily executed with every iteration involving optimized code to get immediate feedback\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEnter \u003ca href=https://benchmarkdotnet.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenchmarkDotNet\u003c/a\u003e, a Powerful .NET library for benchmarking. It is used by \u003ca href=https://github.com/dotnet/performance\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDotNET\u003c/a\u003e Team, Roslyn, ASP.NET Core and many other projects.\u003c/p\u003e","title":"Optimizing  .NET Code using Benchmarks"},{"content":"Background A Web Application, developed in ASP.NET Core (Runtime Version 3.1.100) using Razor Pages and Web API, is expected to be launched from within third-party Web Application in iframe, with complete HTML being rendered.\nDuring the Development, a mock HTML Page was developed to simulate launching of ASP.NET core based Web Application in iframe. Note that this page as well as Application was hosted on same IIS Server and it worked fine. Subsequently, Web Application was deployed on Test Server and URL was shared for integration with third party Application and then it happened Boom\u0026hellip;. i.e. Application when launched in iframe rendered HTML but none of the post request would work (returning HTTP Error 400). Careful inspection showed that,\nBrowser\u0026rsquo;s Dev tools showed HTTP 400\nThere were no entries in Application\u0026rsquo;s Log File which indicates that Request was rejected either by IIS or ASP.NET Core\u0026rsquo;s chain of filters i.e. even before it reaches handler.\nIIS Log depicted that Request was rejected but had no additional details. May be some of the log settings were missing.\nNext up is to carefully look at Request sent by browser in \u0026lsquo;Network\u0026rsquo; tab of Dev tools. It showed that none of the cookies required by Application (i.e. for Session, CSRF token etc.) were present.\nEnter SameSite\nSameSite SameSite is a standard designed to provide some protection against cross-site request forgery (CSRF) attacks. Support for Samesite was added from .NET Core 2.2 and onwards. It is expected that developer will control the value of SameSite attribute using HttpCookie.SameSite property.Setting the SameSite property to Strict, Lax, or None results in those values being written on the network with the cookie.\nCookies without SameSite header are treated as SameSite=Lax by default. SameSite=None must be used to allow cross-site cookie use. Cookies that assert SameSite=None must also be marked as Secure. Applications that use \u0026lt;iframe\u0026gt; may experience issues with sameSite=Lax or sameSite=Strict cookies because \u0026lt;iframe\u0026gt; is treated as cross-site scenarios. The value SameSite=None is not allowed by the 2016 standard and causes some implementations to treat such cookies as SameSite=Strict. The SameSite=Lax setting works for most application cookies.\nAccordingly, below settings were made in startup.cs of the ASP.NET Core Application.\nservices.AddSession(options =\u0026gt; { options.IdleTimeout = TimeSpan.FromMinutes(30); options.Cookie.HttpOnly = true; // Samesite Settings. options.Cookie.SameSite = SameSiteMode.Lax; options.Cookie.IsEssential = true; }); services.AddAntiforgery(options =\u0026gt; { options.Cookie.SameSite = SameSiteMode.Lax; }); References SameSite cookie updates in ASP.net, or how the .Net Framework from December changed my cookie usage. Changes in SameSite Cookie in ASP.NET/Core and How it Impacts the Browser (Specifically Chrome) HTTP 203 Podcast covering CORS,CORB, Samesite Happy Coding !!\n","permalink":"http://localhost:1313/posts/samesitecookies/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eA Web Application, developed in ASP.NET Core (Runtime Version 3.1.100) using Razor Pages and Web API, is expected to be launched from within third-party Web Application in iframe, with complete HTML being rendered.\u003c/p\u003e\n\u003cp\u003eDuring the Development, a mock HTML Page was developed to simulate launching of ASP.NET core based Web Application in iframe. Note that this page as well as Application was hosted on same IIS Server and it worked fine. Subsequently, Web Application was deployed on Test Server and URL was shared for integration with third party Application and then it happened Boom\u0026hellip;. i.e. Application when launched in iframe rendered HTML but none of the post request would work (returning HTTP Error 400). Careful inspection showed that,\u003c/p\u003e","title":"ASP.NET Core - Mind the SameSite HTTP Cookie settings"},{"content":"Perspectives Section covering Business, project/programming perspectives\nLaws of Frugal Architecture Cognitive load is all that matters Stick to boring Architecture Your tech stack is not the product Architecture anti-patterns Don’t call yourself a programmer Grasp Responsibility Patterns Things every programmer should know Guiding principles after 20 years of programming Programmers: Before you turn 40, get a plan B The New Business of AI (and How It’s Different From Traditional Software) Hype driven Development Momentum vs Urgency in Software Project Management Data Science: Reality Doesn’t Meet Expectations Quantum computing for the very curious How to Speak (MIT) How Software Groups Rot: Legacy of the Expert Beginner What questions should systems architects ask before creating anything Basecamp for Personal Project Management Marketing for Engineers - Resources Approach to Exception Handling PRESALES (SE) LEADER? 10 THINGS YOU MUST BE DOING The Tail at Scale Long tail (99th percentile) latency Models for integrating data science teams within organizations Techniques and numbers for estimating system’s performance from first-principles The Amazon Builder’s library System Design Primer Telemetry Collection - Corelation in Latency Analysis Advice to Young kids by Stephen O’Grady Distributed Systems Reading List Awesome cold showers Behaviors to avoid in Software Architecture Role App Maintenance Cost Can Be Three Times Higher than Development Cost Foundational papers on distributed systems Dont end week with nothing Awesome Scalability - Collection of Articles around Performance, Scalability etc. Ego is the Enemy How to remember what you read? First Principles You are not Google 42 Lessons Learned in building production database Data structures implemented in JavaScript - I Data driven enterprises of 2025 Some Benefits of Simple Software Architecture Determining how Architectural decisions impact business via Value Use just one big Server When are Microservices a bad idea? The best engineers think like Investors not Builders CUPID principles Links for Aspiring CTO First principles thinking How Computer CPUs work A Distributed Systems Reading List 97 things, Pearls of wisdom for programmers collected from leading practitioners Evolutionary Architecture by Example Domain driven design - tools IO Devices and latency Legacy Modernization Patterns of Legacy Modernization Documenting the Architecture Arc42 - Open source Template for documenting the Software Architecture Arc42 \u0026#43; C4 - Example Structurizr - C4 Diagrams as Code Strategic Approach How to build an effective technical strategy Writing an Engineering Strategy A curated and opinionated list of resources for Chief Technology Officers, with the emphasis on startups Best Websites for Programmers Fintech Accounting for Computer Geeks Mifos X - Open source Financial Inclusion platform Moov.io - Tools/Libraries to integrate bank processing into their own software products like ISO8583 Awesome Fintech Resources Scheduling Evidence based scheduling Capacity planning, Database scalability Capacity planning for Web Application Scaling MySQL Web Hosting How i run my Servers? Career Checklist for Senior Engineer Power of Negative Thinking How to negotiate your salary package and much more Curated Lists Awesome Software Architecture Learning resources for curious programmer Documentation Adopting Doc as Code ","permalink":"http://localhost:1313/links/perspectives/","summary":"\u003ch1 id=\"perspectives\"\u003ePerspectives\u003c/h1\u003e\n\u003cp\u003eSection covering Business, project/programming perspectives\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://thefrugalarchitect.com/laws/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLaws of Frugal Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://minds.md/zakirullin/cognitive\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCognitive load is all that matters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://addyosmani.com/blog/boring-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStick to boring Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hoho.com/posts/your-stack-is-not-the-product/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYour tech stack is not the product\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://charity.wtf/2023/03/09/architects-anti-patterns-and-organizational-fuckery/?ref\u0026#61;architecturenotes.co\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArchitecture anti-patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDon’t call yourself a programmer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://en.wikipedia.org/wiki/GRASP_%28object-oriented_design%29\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGrasp Responsibility Patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mtdvio/every-programmer-should-know\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThings every programmer should know\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alexewerlof.medium.com/my-guiding-principles-after-20-years-of-programming-a087dc55596c\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuiding principles after 20 years of programming\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://improvingsoftware.com/2009/05/19/programmers-before-you-turn-40-get-a-plan-b/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProgrammers: Before you turn 40, get a plan B\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe New Business of AI (and How It’s Different From Traditional Software)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.daftcode.pl/hype-driven-development-3469fc2e9b22\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHype driven Development\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://testobsessed.com/2020/02/momentum-urgency/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMomentum vs Urgency in Software Project Management\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dfrieds.com/articles/data-science-reality-vs-expectations.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Science: Reality Doesn’t Meet Expectations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://quantum.country/qcvc#part-I\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuantum computing for the very curious\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ocw.mit.edu/resources/res-tll-005-how-to-speak-january-iap-2018/how-to-speak/index.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to Speak (MIT)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://daedtech.com/how-software-groups-rot-legacy-of-the-expert-beginner/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Software Groups Rot: Legacy of the Expert Beginner\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@budilov/what-questions-should-systems-architects-ask-before-creating-anything-6cd92a01e71b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat questions should systems architects ask before creating anything\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://basecamp.com/personal\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBasecamp for Personal Project Management\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/LisaDziuba/Marketing-for-Engineers\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMarketing for Engineers - Resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://particular.net/blog/but-all-my-errors-are-severe\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproach to Exception Handling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.linkedin.com/pulse/presales-se-leader-10-things-you-must-doing-jon-upton?articleId\u0026#61;6685231165948932097#comments-6685231165948932097\u0026amp;trk\u0026#61;public_profile_article_view\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePRESALES (SE) LEADER? 10 THINGS YOU MUST BE DOING\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/fulltext\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Tail at Scale\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.linkedin.com/performance/who-moved-my-99th-percentile-latency\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLong tail (99th percentile) latency\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@djpardis/models-for-integrating-data-science-teams-within-organizations-7c5afa032ebd\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModels for integrating data science teams within organizations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sirupsen/napkin-math\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTechniques and numbers for estimating system’s performance from first-principles\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/builders-library/?cards-body.sort-by\u0026#61;item.additionalFields.customSort\u0026amp;cards-body.sort-order\u0026#61;asc\u0026amp;awsf.filter-content-type\u0026#61;*all\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Amazon Builder’s library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/donnemartin/system-design-primer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSystem Design Primer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rakyll.medium.com/correlation-in-latency-analysis-419357b93287\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTelemetry Collection - Corelation in Latency Analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://thisistheway.us/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAdvice to Young kids by Stephen O’Grady\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dancres.github.io/Pages/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed Systems Reading List\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/hwayne/awesome-cold-showers\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome cold showers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.danielwatts.info/post/7-behaviours-to-avoid-software-architect/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBehaviors to avoid in Software Architecture Role\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.econnectivity.se/app-maintenance-cost-can-be-three-times-higher-than-development-cost/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApp Maintenance Cost Can Be Three Times Higher than Development Cost\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://muratbuffalo.blogspot.com/2021/02/foundational-distributed-systems-papers.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFoundational papers on distributed systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://training.kalzumeus.com/newsletters/archive/do-not-end-the-week-with-nothing\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDont end week with nothing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/binhnguyennus/awesome-scalability\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Scalability - Collection of Articles around Performance, Scalability etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fs.blog/2016/06/ego-is-the-enemy-genghis-khan/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEgo is the Enemy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fs.blog/2021/08/remember-books/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to remember what you read?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fs.blog/first-principles/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFirst Principles\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.bradfieldcs.com/you-are-not-google-84912cf44afb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou are not Google\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://maheshba.bitbucket.io/blog/2021/10/19/42Things.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e42 Lessons Learned in building production database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/trekhleb/javascript-algorithms\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData structures implemented in JavaScript - I\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/the-data-driven-enterprise-of-2025\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData driven enterprises of 2025\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.wave.com/en/blog/simple-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSome Benefits of Simple Software Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://martinfowler.com/articles/value-architectural-attribute.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDetermining how Architectural decisions impact business via Value\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.specbranch.com/posts/one-big-server/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse just one big Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://semaphoreci.com/blog/bad-microservices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhen are Microservices a bad idea?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://levelup.gitconnected.com/the-best-engineers-think-like-investors-not-builders-cf005e75ab80\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe best engineers think like Investors not Builders\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dannorth.net/2022/02/10/cupid-for-joyful-coding/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCUPID principles\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/kuchin/awesome-cto\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLinks for Aspiring CTO\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://addyosmani.com/blog/first-principles-thinking-software-engineers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFirst principles thinking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cpu.land/editions/one-pager\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Computer CPUs work\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dancres.github.io/Pages/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Distributed Systems Reading List\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/97-things/97-things-every-programmer-should-know\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e97 things, Pearls of wisdom for programmers collected from leading practitioners\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/evolutionary-architecture/evolutionary-architecture-by-example\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvolutionary Architecture by Example\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ddd-crew\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDomain driven design - tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://planetscale.com/blog/io-devices-and-latency\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIO Devices and latency\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"legacy-modernization\"\u003eLegacy Modernization\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://martinfowler.com/articles/patterns-legacy-displacement/#WeWantToBeLikeNetflix\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePatterns of Legacy Modernization\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"documenting-the-architecture\"\u003eDocumenting the Architecture\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://arc42.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArc42 - Open source Template for documenting the Software Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://githdub.com/bitsmuggler/arc42-c4-software-architecture-documentation-example\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArc42 \u0026#43; C4 - Example\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://structurizr.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStructurizr - C4 Diagrams as Code\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"strategic-approach\"\u003eStrategic Approach\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://leaddev.com/tech/how-build-effective-technical-strategy\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to build an effective technical strategy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lethain.com/eng-strategies/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWriting an Engineering Strategy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/kuchin/awesome-cto\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA curated and opinionated list of resources for Chief Technology Officers, with the emphasis on startups\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sdmg15/Best-websites-a-programmer-should-visit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Websites for Programmers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"fintech\"\u003eFintech\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://martin.kleppmann.com/2011/03/07/accounting-for-computer-scientists.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAccounting for Computer Geeks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mifos.org/mifos-x/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMifos X - Open source Financial Inclusion platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/moov-io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMoov.io - Tools/Libraries to integrate bank processing into their own software products like ISO8583\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/moov-io/awesome-fintech\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Fintech Resources\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"scheduling\"\u003eScheduling\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.joelonsoftware.com/2007/10/26/evidence-based-scheduling/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvidence based scheduling\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"capacity-planning-database-scalability\"\u003eCapacity planning, Database scalability\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://kirshatrov.com/posts/capacity-planning-for-web-apps/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCapacity planning for Web Application\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://kirshatrov.com/posts/scaling-mysql-stack-part-1-timeouts/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling MySQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"web-hosting\"\u003eWeb Hosting\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://blog.wesleyac.com/posts/how-i-run-my-servers\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow i run my Servers?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"career\"\u003eCareer\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://littleblah.com/post/2019-09-01-senior-engineer-checklist/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChecklist for Senior Engineer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://archive.is/O5Xcn\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePower of Negative Thinking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.complexsystemspodcast.com/episodes/how-to-negotiate-your-salary-package/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to negotiate your salary package and much more\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"curated-lists\"\u003eCurated Lists\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/mehdihadeli/awesome-software-architecture\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Software Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/charlax/professional-programming\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearning resources for curious programmer\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"documentation\"\u003eDocumentation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://medium.com/pinterest-engineering/adopting-docs-as-code-at-pinterest-4f18ad1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAdopting Doc as Code\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Perspectives"},{"content":"General Purpose tools Section covering useful tools for every day activities, Online learning etc.\nPlane - Open source alternative to JIRA ShareX - Screen capture, file sharing and productivity tools (Windows only) Dark Lang - Declarative platform to build serverless backend OBS Studio - Free and open source software for video recording and live streaming. Open source Wiki platform Open source 3D parametric modeler Backstage - an open platform for building developer portals Zoomit - screen zoom and annotation tool for technical presentations that include application demonstrations revealjs - HTML Presentation framework List of Self hosted software Open source Alternative to Heroku/Netlify for Self hosting A book of Secret knowledge - Collection of Useful tools Parsr - Transform PDF,Image into Structured data SOPS - Tool to secure secrets (JSON,YAML, INI etc.) via Command line and as GO library Windows Powertools for greater productivity Ex-googler’s list similar tools/techniques Recoll - Desktop full search tool Take potentially dangerous PDFs, office documents, or images and convert them to safe PDFs Briar - Secure peer to peer messaging on Android Open source alternative to Jira, slack,notion Useful Command line tools iperf -A TCP, UDP, and SCTP network bandwidth measurement tool Mise - version manager for multiple languages Guide to Linux Bash script Devbox - Quick shell with runtime environment without polluting laptop/desktop Shellcheck- a static analysis tool for shell scripts Useful online playgrounds by Julia Evans New list of useful Command line tools dsq- run sql queries against CSV,JSON,TSV, Web server logs exa - colorful alternative to ls duf - better disk usage/free utility Zmap - collection of open source tools for performing large-scale studies of the hosts and services that compose the public Internet. ripgrep - Recursively search directories for regex ripgrep-all - rigrep \u0026#43; PDFs, E-books, Office documents gron - Make JSON greppable xsv - fast command line CSV toolkit App that corrects previous Console command hstr - view bash shell history Lightening fast Code searching made easy Rewritten in Rust: Modern Alternatives of Command-Line Tools Broot - A better way to navigate directories fd - Alternative to Find bat - cat clone with wings Handy Linux networking tools rclone - manage files on cloud storage, Rsync for Cloud CPU-Z is a freeware system profiling and monitoring application for Microsoft Windows and Android Fselect - Find files with SQL-like queries HTTPie - Command line HTTP Client Visidata - A terminal spreadsheet multitool for discovering and arranging data Nginx - Tips for Sys Admins Avoiding the Top 10 NGINX Configuration Mistakes Listmonk - Open source newsletter and mailing list manager ATOP - Performance monitor for Linux (Better than htop) Below - Analyze Historical performance data for Linux Hyperfine - Generic Benchmarking tool Gmail backup tool gmvault - gmail backup tool Age - Simple File Encryption tool (Go) Encryption with Pass but Age as backend Yark - Archive youtube channels Linux related References Linux Network level performance Parameters Understand grep, awk and sed Awk in 20 minutes Understandin Awk Visual guide to SSH Tunnels Web based interface for Servers Structured data tools Structured data tools Hardware 10 Best Lightweight Operating System for old Laptop How and why I stopped buying new laptops Useful spreadsheet formulas Formulas for Personal finance Search tools Grep app- Search across Git Repos Blogging platforms, RSS etc Writefreely Yarr - Yet another feed aggregator Book of secret knowledge Book of Secret Knowledge Guidance and Templates for Resume Building Harward Uni. guidance on Resume building OpenResume - Professional, Free resume builder ","permalink":"http://localhost:1313/links/tools/","summary":"\u003ch1 id=\"general-purpose-tools\"\u003eGeneral Purpose tools\u003c/h1\u003e\n\u003cp\u003eSection covering useful tools for every day activities, Online learning etc.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/makeplane/plane\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePlane - Open source alternative to JIRA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://getsharex.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eShareX - Screen capture, file sharing and productivity tools (Windows only)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://darklang.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDark Lang - Declarative platform to build serverless backend\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://obsproject.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOBS Studio - Free and open source software for video recording and live streaming.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/BookStackApp/BookStack\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source Wiki platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/FreeCAD/FreeCAD\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source  3D parametric modeler\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://backstage.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBackstage - an open platform for building developer portals\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/sysinternals/downloads/zoomit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZoomit - screen zoom and annotation tool for technical presentations that include application demonstrations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://revealjs.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003erevealjs - HTML Presentation framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/awesome-selfhosted/awesome-selfhosted\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Self hosted software\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/coollabsio/coolify\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source Alternative to Heroku/Netlify for Self hosting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/trimstray/the-book-of-secret-knowledge\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA book of Secret knowledge - Collection of Useful tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/axa-group/parsr\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eParsr - Transform PDF,Image into Structured data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mozilla/sops\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSOPS - Tool to secure  secrets (JSON,YAML, INI etc.) via Command line and as GO library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/PowerToys\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWindows Powertools for greater productivity\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jhuangtw/xg2xg\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEx-googler’s list similar tools/techniques\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.lesbonscomptes.com/recoll/index.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRecoll - Desktop full search tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/freedomofpress/dangerzone\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTake potentially dangerous PDFs, office documents, or images and convert them to safe PDFs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://briarproject.org/quick-start/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBriar - Secure peer to peer messaging on Android\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/hcengineering/platform\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source alternative to Jira, slack,notion\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"useful-command-line-tools\"\u003eUseful Command line tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/esnet/iperf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eiperf -A TCP, UDP, and SCTP network bandwidth measurement tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jdx/mise\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMise - version manager for multiple languages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mywiki.wooledge.org/BashGuide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuide to Linux Bash script\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jetpack-io/devbox\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDevbox - Quick  shell with runtime environment without polluting laptop/desktop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.shellcheck.net/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eShellcheck- a static analysis tool for shell scripts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jvns.ca/blog/2021/09/24/new-tool--an-nginx-playground/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUseful online playgrounds by Julia Evans\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jvns.ca/blog/2022/04/12/a-list-of-new-ish--command-line-tools/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNew list of useful Command line tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/multiprocessio/dsq\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003edsq- run sql queries against CSV,JSON,TSV, Web server logs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ogham/exa\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eexa - colorful alternative to ls\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/muesli/duf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eduf - better disk usage/free utility\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/zmap\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZmap - collection of open source tools for performing large-scale studies of the hosts and services that compose the public Internet.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/BurntSushi/ripgrep\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eripgrep - Recursively search directories for regex\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/phiresky/ripgrep-all\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eripgrep-all - rigrep \u0026#43; PDFs, E-books, Office documents\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tomnomnom/gron\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003egron - Make JSON greppable\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/BurntSushi/xsv\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003exsv - fast command line CSV toolkit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nvbn/thefuck\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApp that corrects previous Console command\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dvorka/hstr\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ehstr - view bash shell history\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/hound-search/hound\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLightening fast Code searching made easy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://zaiste.net/posts/shell-commands-rust/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRewritten in Rust: Modern Alternatives of Command-Line Tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Canop/broot\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBroot - A better way to navigate directories\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sharkdp/fd\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003efd - Alternative to Find\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sharkdp/bat\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ebat - cat clone with wings\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.google.com/presentation/d/1PZ-bp-a00KKjE9bqKOd17ZoroyXHJkm70aXcFBqwXAQ/edit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHandy Linux networking tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rclone.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003erclone - manage files on cloud storage, Rsync for Cloud\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.cpuid.com/softwares/cpu-z.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCPU-Z is a freeware system profiling and monitoring application for Microsoft Windows and Android\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jhspetersson/fselect\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFselect - Find files with SQL-like queries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://httpie.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHTTPie - Command line HTTP Client\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/saulpw/visidata\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisidata - A terminal spreadsheet multitool for discovering and arranging data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alex.dzyoba.com/blog/nginx-features-for-operators/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNginx - Tips for Sys Admins\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.nginx.com/blog/avoiding-top-10-nginx-configuration-mistakes\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAvoiding the Top 10 NGINX Configuration Mistakes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://listmonk.app\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eListmonk - Open source newsletter and mailing list manager\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.atoptool.nl/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eATOP - Performance monitor for Linux (Better than htop)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/facebookincubator/below\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBelow - Analyze Historical performance data for Linux\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/sharkdp/hyperfine\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHyperfine - Generic Benchmarking tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jay0lee/got-your-back\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGmail backup tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/gaubert/gmvaulthttps://github.com/gaubert/gmvault\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003egmvault - gmail backup tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/filosottile/age\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAge - Simple File Encryption tool (Go)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://words.filippo.io/dispatches/passage/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEncryption with Pass but Age as backend\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Owez/yark\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYark - Archive youtube channels\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"linux-related-references\"\u003eLinux related References\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/leandromoreira/linux-network-performance-parameters\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLinux Network level performance Parameters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www-users.york.ac.uk/~mijp1/teaching/2nd_year_Comp_Lab/guides/grep_awk_sed.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstand grep, awk and sed\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ferd.ca/awk-in-20-minutes.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwk in 20 minutes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://earthly.dev/blog/awk-examples/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstandin Awk\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://robotmoon.com/ssh-tunnels/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisual guide to SSH Tunnels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cockpit-project.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb based interface for Servers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"structured-data-tools\"\u003eStructured data tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/dbohdan/structured-text-tools\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStructured data tools\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"hardware\"\u003eHardware\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://lotoftech.com/10-best-lightweight-operating-system-for-old-computers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 Best Lightweight Operating System for old Laptop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://solar.lowtechmagazine.com/2020/12/how-and-why-i-stopped-buying-new-laptops.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow and why I stopped buying new laptops\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"useful-spreadsheet-formulas\"\u003eUseful spreadsheet formulas\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://bou.ke/blog/formulas/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFormulas for Personal finance\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"search-tools\"\u003eSearch tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://grep.app/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGrep app- Search across Git Repos\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"blogging-platforms-rss-etc\"\u003eBlogging platforms, RSS etc\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/writefreely/writefreely\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWritefreely\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nkanaev/yarr\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYarr - Yet another feed aggregator\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"book-of-secret-knowledge\"\u003eBook of secret knowledge\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/trimstray/the-book-of-secret-knowledge\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBook of Secret Knowledge\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"guidance-and-templates-for-resume-building\"\u003eGuidance and Templates for Resume Building\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://hwpi.harvard.edu/files/ocs/files/undergrad_resumes_and_cover_letters.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHarward Uni. guidance on Resume building\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/xitanggg/open-resume\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpenResume - Professional, Free resume builder \u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Tools"},{"content":"Background Recently, i got involved in assignment where in an application was facing issues with throughput. Expectation is to support more than 500 transactions per second while load testing results were indicating system was experiencing high latency beyond 100+ transactions per second.\nThis application is developed in .NET Framework + .NET Core and primarily uses Relational Database for persistence and has point to point integration (mainly over HTTP) with internal \u0026amp; external application(s).\nApproach The high level approach decided to perform diagnostics and subsequent corrective action(s) were,\nBenchmark code that involves Database and take corrective action Identify tasks in hot code path that could potentially be decoupled or done in fire-n-forget mode. For point 2 from above, some of the tasks identified were,\nSending Email/SMS on myriad of events Integration with External Applications over HTTP Next task was to arrive at approach on how to perform them effectively outside of hot code path without incurring need of any additional resources (hardware or software)as far as possible. Accordingly, we had two options,\nPolling - Periodically polling database to check for occurance of event and then performing the action. Event Driven - Using Event notification feature of database (e.g. Listen/Notify in PostgreSQL or Change Notification/Advanced Queuing in Oracle). We decided to go with Event driven as,\nCleaner approach that doesn\u0026rsquo;t require perodically checking for events thus consuming a database connection and more code. We may have to have more than one such daemons to cater to different events in application. Post finalizing on event driven approach for gathering events, next task was to determine how to effectively send email/sms or any other HTTP requests considering that rate of arrival of events will not be matching rate of processing them. Also these\nSo what are the options available in .NET Ecosystem, Below are the ones i am aware of,\nChannels - High performance implementation of In-memory producer/consumer pattern. TPL Dataflow - Super set of Channels Library. Aimed at use cases where blocks of logic are to be linked together to same or different consumers and so on. Also all these features come with additional overheads. For the task at hand, functionality offered by Channels is sufficient to implement in-memory producer consumer pattern.\nSo we wrapped above event processing in a Windows service implemented as .NET Core Worker Service\nGeneric Implementation is as follows,\nEvent Generator - In practice, this class will be responsible for wiring up to receive events from database\nEvent Consumer which uses channels to process events in parallel\nRefer Gist here\nAdditionally, one may want to process requests out of order or asynchronously without using message queues. One such use case could be service to send Notifications where this service is exposed as Web API and it uses external service to dispatch notifications. For such scenarios, one can use back ground job in conjunction with Channels to process requests.\nBelow code shows a Web API that handles HTTP Requests and delegates actual task to background worker which is deployed as hosted service.\nRefer Gist here\nHowever, note that there are trade-offs vis-a-vis message queues with this approach. Notably, in case of Web server crash, the pending jobs in queue will be lost.\nSummary Other languages (notably Channels in Go) have been providing out of the box implementation for in-memory producer with concurrent, parallel consumers. With Channels, .NET Ecosystem finally has construct that can be effectively put to use for high performance, concurrent use cases.\nUseful References, Event Pattern in C# Gist on using Channels Happy Coding !!\n","permalink":"http://localhost:1313/posts/channelsforproducerconsumer/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eRecently, i got involved in assignment where in  an application was facing issues with throughput. Expectation is to support more than 500 transactions per second while load testing results were indicating system was experiencing high latency beyond 100+ transactions per second.\u003c/p\u003e\n\u003cp\u003eThis application is developed in .NET Framework + .NET Core and primarily uses Relational Database for persistence and has point to point integration (mainly over HTTP) with internal \u0026amp; external application(s).\u003c/p\u003e","title":"Using Channels for High performance Producer consumer implementation"},{"content":"Oracle Database Performance, Best Practices Connection Strategies for Database Applications Using High-Speed Data Loading and Rolling Window Operations with Partitioning Designing Applications for Oracle Real-World Performance Best Practices for Extreme Performance with Oracle Data Warehousing Blog on Oracle Performance troubleshooting Using PL/SQL Bulk processing features Auditing tables using Oracle Flashback data archive instead of triggers Flashback Data Archive to record changes to Table Bulk processing with PL/SQL Bulk Processing with BULK COLLECT and FORALL Primer on Oracle Partitioning Database Core performance principles - Deck Database insert \u0026amp;amp; referential integrity - Performance On Connection Pools, Cursor Differentiation, and Optimal Ordering Analytical Functions Overview About Materialized Views How to find Slow SQL Using External Tables and Table Clusters in Oracle Oracle DBA - Application Tuning Replacing Kafka use cases with Oracle Advanced queues in modern applications SQL Tips you can’t do without Change Data Capture Nice writeup on options to do CDC in Oracle Database Integrating Oracle and Kafka Videos Real world performance video series Oracle LiveLabs How to:Analyze AWR Report 5 Minutes Demo: Using Liquibase in SQLcl to version Oracle Database Analytic SQL for Developers - Free course Connection Pooling and SmartDB Oracle Database for Developers - Training How to Create an Execution plan? Machine learning in Autonomous Database Utilities, Tools OraTOTP, Free tool to enable 2 factor authentication Audit table Generator for Oracle Tables Swingbench, free load generator (and benchmarks) designed to stress test an Oracle database (12c, 18c, 19c). Create Excel file PL/SQL ","permalink":"http://localhost:1313/links/oracle/","summary":"\u003ch2 id=\"oracle-database\"\u003eOracle Database\u003c/h2\u003e\n\u003ch3 id=\"performance-best-practices\"\u003ePerformance, Best Practices\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://docs.oracle.com/en/database/oracle/oracle-database/12.2/adfns/connection_strategies.html##GUID-25F85237-702B-4609-ACE2-1454EBC8284B\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection Strategies for Database Applications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.oracle.com/webfolder/technetwork/tutorials/obe/db/11g/r2/prod/bidw/etl/etl.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing High-Speed Data Loading and Rolling Window Operations with Partitioning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.oracle.com/en/database/oracle/oracle-database/12.2/adfns/rwp.html##GUID-754328E1-2203-4B03-A21B-A91C3E548233\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesigning Applications for Oracle Real-World Performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.oracle.com/technetwork/database/bi-datawarehousing/pres-best-practices-for-extreme-per-130805.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Practices for Extreme Performance with Oracle Data Warehousing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://savvinov.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBlog on Oracle Performance troubleshooting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/solving-the-row-by-row-problem\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing PL/SQL Bulk processing features\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/a-fresh-look-at-auditing-row-changes\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAuditing tables using Oracle Flashback data archive instead of triggers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;FpRAc-FEWbE\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFlashback Data Archive to record changes to Table\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://livesql.oracle.com/apex/livesql/file/tutorial_IEHP37S6LTWIIDQIR436SJ59L.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBulk processing with PL/SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/bulk-processing-with-bulk-collect-and-forall\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBulk Processing with BULK COLLECT and FORALL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://asktom.oracle.com/partitioning-for-developers.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrimer on Oracle Partitioning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/koppelaars/database-core-performance-principles\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase Core performance principles - Deck\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dev.to/gvenzl/comment/12137\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase insert \u0026amp;amp; referential integrity - Performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/on-connection-pools-cursor-differentiation-and-optimal-ordering\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOn Connection Pools, Cursor Differentiation, and Optimal Ordering\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/oraclemagazine/a-window-into-the-world-of-analytic-functions\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAnalytical Functions Overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://livesql.oracle.com/apex/livesql/file/tutorial_JN0Y98523UQ6VVZRREWOVZUT9.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Materialized Views\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://livesql.oracle.com/apex/livesql/file/tutorial_JN0XQTKBU5D2JMNDVMTRQCFIE.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to find Slow SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/sql/how-to-create-alter-and-drop-tables-in-sql#create-external\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing External Tables and Table Clusters in Oracle\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://videohub.oracle.com/media/1_57pd28lv?elq_mid\u0026#61;174954\u0026amp;sh\u0026#61;082624191813080613161522312216341235\u0026amp;cmid\u0026#61;WWMK200518P00173\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle DBA - Application Tuning \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;kFQqS9Ry-jI\u0026amp;list\u0026#61;WL\u0026amp;index\u0026#61;9\u0026amp;ab_channel\u0026#61;OracleMania\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReplacing Kafka use cases with Oracle Advanced queues in modern applications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://speakerdeck.com/sqlmaria/sql-tuning-tips-you-cant-do-withou\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Tips you can’t do without\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"change-data-capture\"\u003eChange Data Capture\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://rmoff.net/2018/12/12/streaming-data-from-oracle-into-kafka/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNice writeup on options to do CDC in Oracle Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://talks.rmoff.net/ixPL5r/integrating-oracle-and-kafka\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIntegrating Oracle and Kafka\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"videos\"\u003eVideos\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/playlist?list\u0026#61;PLKCk3OyNwIzvwEXdaubc6PQXwnQOAE9h2\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReal world performance video series\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://apexapps.oracle.com/pls/apex/dbpm/r/livelabs/livelabs-workshop-cards?p100_focus_area\u0026#61;141\u0026amp;me\u0026#61;110\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle LiveLabs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;xSXQ3EwU8t0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to:Analyze AWR Report\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.thatjeffsmith.com/archive/2020/02/5-minutes-demo-using-liquibase-in-sqlcl-to-version-oracle-database/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e5 Minutes Demo: Using Liquibase in SQLcl to version Oracle Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devgym.oracle.com/pls/apex/dg/class/analytic-sql-for-developers.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAnalytic SQL for Developers - Free course\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;eiydITTdDAQ\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection Pooling and SmartDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://asktom.oracle.com/databases-for-developers.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle Database for Developers - Training\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/sql/how-to-create-an-execution-plan\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to Create an Execution plan?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/SandeshRao4/machine-learning-in-autonomous-data-warehouse\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMachine learning in Autonomous Database\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"utilities-tools\"\u003eUtilities, Tools\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.dbarj.com.br/en/oratotp-oracle-time-based-one-time-password/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOraTOTP, Free tool to enable 2 factor authentication\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/connormcd/audit_utility\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAudit table Generator for Oracle Tables\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://www.dominicgiles.com/swingbench.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSwingbench,  free load generator (and benchmarks) designed to stress test an Oracle database (12c, 18c, 19c).\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://technology.amis.nl/languages/oracle-plsql/create-an-excel-file-with-plsql/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCreate Excel file PL/SQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Oracle"},{"content":"NOSQL Databases MongoDB FerretDB - MongoDB Interface with underlying PostgreSQL as database engine Amazon DynamoDB Data Modelling in DynamoDB Must follow Twitter handle of Rick Houlihan Best Practices for Secondary Indexes with DynamoDB Apache Cassandra 7 mistakes when using Apache Cassandra Apache Geode How Mastercard fights fraud with Apache Geode Apache Pinot Pinot- Enabling Real-time Analytics @ linkedin Redis About Redis DragonflyDB - Alternative to Redis Redis High Availability Redis Cluster KeyDB is a high performance fork of Redis with a focus on multithreading, memory efficiency, and high throughput. In addition to multithreading RediSQL, fastest, simplest, in-memory SQL Redisearch - Redis powered Search Engine JuiceFS - POSIX File System with Redis or S3 as backend SSDB - A fast NoSQL database, an alternative to Redis Comparing REDIS and Memcached Oracle Coherence Oracle Coherence Community Edition Full text Search Engines Deep Dive into Querying Elasticsearch. Filter vs Query. Full-text search Engine for Low-latency Computation over large data sets Open source Full text Search Engine Sonic - Fast, lightweight \u0026amp;amp; schema-less search backend ","permalink":"http://localhost:1313/links/nosql/","summary":"\u003ch1 id=\"nosql-databases\"\u003eNOSQL Databases\u003c/h1\u003e\n\u003ch2 id=\"mongodb\"\u003eMongoDB\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/FerretDB/FerretDB\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFerretDB - MongoDB Interface with underlying PostgreSQL as database engine\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"amazon-dynamodb\"\u003eAmazon DynamoDB\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;6yqfmXiZTlM\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Modelling in DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://twitter.com/houlihan_rick?lang\u0026#61;en\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMust follow Twitter handle of Rick Houlihan\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.trek10.com/blog/best-practices-for-secondary-indexes-with-dynamodb/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Practices for Secondary Indexes with DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"apache-cassandra\"\u003eApache Cassandra\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://blog.softwaremill.com/7-mistakes-when-using-apache-cassandra-51d2cf6df519\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e7 mistakes when using Apache Cassandra\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"apache-geode\"\u003eApache Geode\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://content.pivotal.io/blog/how-mastercard-fights-fraud-with-apache-geode\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Mastercard fights fraud with Apache Geode\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"apache-pinot\"\u003eApache Pinot\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/seunghyunlee1460/pinot-enabling-realtime-analytics-applications-linkedins-scale\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePinot- Enabling Real-time Analytics @ linkedin\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"redis\"\u003eRedis\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://architecturenotes.co/redis/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Redis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dragonflydb.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDragonflyDB - Alternative to Redis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alex.dzyoba.com/blog/redis-ha/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedis High Availability\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alex.dzyoba.com/blog/redis-cluster/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedis Cluster\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://keydb.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eKeyDB is a high performance fork of Redis with a focus on multithreading, memory efficiency, and high throughput. In addition to multithreading\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://redisql.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRediSQL, fastest, simplest, in-memory SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://oss.redislabs.com/redisearch/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedisearch - Redis powered Search Engine\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/juicedata/juicefs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJuiceFS - POSIX File System with Redis or S3 as backend\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ssdb.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSSDB - A fast NoSQL database, an alternative to Redis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.kablamo.com.au/posts/2021/memcached-vs-redis-whats-the-difference\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComparing REDIS and Memcached\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"oracle-coherence\"\u003eOracle Coherence\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/oracle/coherence\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle Coherence Community Edition\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"full-text-search-engines\"\u003eFull text Search Engines\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/deep-dive-into-querying-elasticsearch-filter-vs-query-full-text-search-b861b06bd4c0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDeep Dive into Querying Elasticsearch. Filter vs Query. Full-text search\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/vespa-engine/vespa\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEngine for Low-latency Computation over large data sets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.meilisearch.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source Full text Search Engine\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/valeriansaliou/sonic\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSonic -  Fast, lightweight \u0026amp;amp; schema-less search backend\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"NOSQL"},{"content":"MySQL Links Query analytics for the day-to-day developer with MySQL 8.0 Schema Change Management for MySQL Temporal Data tables in MariaDB MySQL 8.0 Indexes, Histograms, and Other Ways to Speed Up Your Queries Maxwell - MySQL to Kafka change data capture LetsEncrypt setup for MariaDB How LetsEncrypt has built Next Gen Database Servers 18 things you can do to remove mysql Bottlenecks due to High traffic MySQL from Developer’s perspective Replication in MySQL Interesting libraries, extensions Distributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres Orchestrator - Replication topology and high availability Vitess,a Distributed MySQL Massively scaling MySQL database How Slack uses Vitess ","permalink":"http://localhost:1313/links/mysql/","summary":"\u003ch1 id=\"mysql\"\u003eMySQL\u003c/h1\u003e\n\u003ch2 id=\"links\"\u003eLinks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/gabidavila/query-analytics-for-the-day-today-developer-with-my-sql-80\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuery analytics for the day-to-day developer with MySQL 8.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/skeema/skeema\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSchema Change Management for MySQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mariadb.com/kb/en/temporal-data-tables/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTemporal Data tables in MariaDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/davestokes/mysql-80-indexes-histograms-and-other-ways-to-speed-up-your-queries\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMySQL 8.0 Indexes, Histograms, and Other Ways to Speed Up Your Queries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/zendesk/maxwell\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMaxwell - MySQL to Kafka change data capture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/letsencrypt/openzfs-nvme-databases\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLetsEncrypt setup for MariaDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://letsencrypt.org/2021/01/21/next-gen-database-servers.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow LetsEncrypt has built Next Gen Database Servers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2020/04/03/18-things-you-can-do-to-remove-mysql-bottlenecks-caused-by-high-traffic-part-one/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e18 things you can do to remove mysql Bottlenecks due to High traffic\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.koehntopp.info/2020/09/07/mysql-from-a-developers-perspective.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMySQL from Developer’s perspective\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/JeanFranoisGagn/mysql-scalability-and-reliability-for-replicated-environment\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReplication in MySQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"interesting-libraries-extensions\"\u003eInteresting libraries, extensions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/knadh/sql-jobber\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/openark/orchestrator\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOrchestrator - Replication topology and high availability\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"vitessa-distributed-mysql\"\u003eVitess,a Distributed MySQL\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.infoq.com/presentations/vitess\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMassively scaling MySQL database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://slack.engineering/scaling-datastores-at-slack-with-vitess/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Slack uses Vitess\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"MySQL"},{"content":"Database Knowledge base around general database related topics.\nGeneral Links Which Data Architecture to choose Prisma’s Data Guide - A growing library of articles focused on making databases more approachable. Query optimization guide Database performance for Developers Heimdall data -Database scale-out without Application changes Database of databases Modern SQL in databases Eventual consistency by Werner Vogels Amazon Aurora ascendant: How we designed a cloud-native relational database - All Things Distributed Options for scaling from 1 to 100,000 tenants Amazon Aurora: design considerations for high throughput cloud-native relational databases | the morning paper NOSQL - Key Points Criteria for Choosing Data store Building Real Time Analytics APIs at Scale Streaming Database Changes with Debezium Why you should pick strong consistency, whenever possible Change Data Capture, Outbox and Event Sourcing Debezium Engine - setup without Apache Kafka Debezium without kafka connect Using Streamsets for CDC From Oracle to Other destinations Transactions in Google Spanner Things I Wished More Developers Knew About Databases Interactive Book about SQL SQL Interview Questions Hadoop or Laptop The lightweight, distributed relational database built on SQLite Optimizing SQL Queries, Regardless of Platform How to do Data Modelling the right way Primer on Database Replication Connection pool sizing for databases Some SQL tricks from Application DBA Best Practices while writing SQL Using checksums to verify syncing 100M database records How to populate a table with 1 million records using single query How databases optimize Sub-queries Approaches to database migration Tigetbeetle - Fast financial accounting database Opinionated thoughts on SQL Databases Tools Collection DBMS Tools OctoSQL - Query, Join CSV with Postgresql/mysql from Command line TSBS - tool to benchmark bulk load performance and query execution performance. Goose - Database schema migrations HammerDB - Benchmarking Suite for databases Sysbench - Scriptable database and system performance benchmark Soda core - Data schema checks, for Quality, as code Readyset - MySQL and Postgres wire-compatible caching layer that sits in front of existing databases to speed up queries and horizontally scale read throughput. Data Analytics Understanding avro, parquet and ORC Guidance on Data Visualizations Simple data pipeline Powertools Cube.dev - Open source Headless BI platform Evidence.dev - BI as Code - SQL \u0026#43; Markdown to generate Reports Apache spark defined Getting started with Spark in Python About Data Mesh Architecture Data mesh vs. Data Fabric Emerging Architectures for Modern Data Infrastructure Data Visualization/Exploration platforms Comparion Matrix Supercharging Apache Superset Snowplow - Cloud Native Behavioral data engine (e.g. User Analytics) Redash - Collaboration, dashboards Why data culture matters Designing a data transformation that delivers value right from the beginning List of Computational Data Analysis Workflow Systems Data Visualization framework for Python Analytics Academy by Segment Analytics Whitepapers by Sisense SQL Analytics Training A Beginner’s Guide to Data Engineering - 3-part series Chart types and its usage Rudder - Open source Customer Data Infrastructure Catalog of Widgets for Data Visualization Open source OLAP Database Modern Data stack guide by Castor Data Stack of 1mg A Unified Data Infrastructure Architecture Data and AI Product Landscape Transformations for DWH using DBT Awesome list of Business Intelligence Tools Article Series on Open source Data Analytics Stack (Postgres,Meltano, Airflow, dbt and Superset) Posthog - open source product analytics platform Typical Analytics Stack Flat Data - Scheduled Data Download on GitHub Actions in Repository and visualization Nocodb - Turn *MySQL/PostgreSQL data in smart Spreadsheet Real time data analysis with Apache Pinot and kafka UUIds are bad for performance Noria - Caching and updating Relational query results Differential Datalog - Language for incremental computation Using NanoIDs (not longer UUID) for public APis In-memory Databases Dragonfly - Compatible with REDIS Duck DB DuckDB - Embeddable OLAP DBMS SQL Workbench - run Duckdb on WASM DuckDB - Connect and join on external databases Using duckdb and postgres together ETL,ELT, Database-as-a-queue, Evolutionary Practices All about ETL Airbyte-Open source ELT Database CI/CD practices using Redshift Awesome Apache Airflow A Python library for building data applications: ETL, ML, Data Pipelines, and more. A modern data workflow platform Databus - Change Data capture System from Linkedin Dolt - Git for Data GridDB - next generation database for IoT \u0026amp;amp; big data with both NoSQL interface \u0026amp;amp; SQL Interface. Compressing data with Parquet Lance - alternate columnar, compressed format for ML Mara pipelines - Opinionated ETL framework Enso - Interactive Data Workflow builder with no coding Database for Event Sourcing What are Data Contracts Centrifuge - Database as a Queue Database scaling Database Hardware Selection Scaling TIDB to 1 million QPS Sharding a database MySQL Sharding at Quora CUID-Collision-resistant ids optimized for horizontal scaling and performance. Data Discovery OpenMetadata - Data Discovery, Lineage, Data Quality Evaluation of Data Discovery Platforms Data Discovery at Shopify Great Expectations - Data Documentation and Profiling tool Database Migration Practices Zero downtime database migrations Stripe - Database Online migration at scale using dual writes How big companies migrate from one database to another without losing data i.e database independent? Efficiently diff rows across two different databases. Metadata Management Growing importance of Metadata Management Systems SQLite Query against multiple SQLite databases using ATTACH Command Online SQLite Fiddle Why you should be using SQLITE(2023) Performance tuning settings Pocketbase - SQlite database with Go-based Wrapper to expose API Scaling SQLITE to 4M QPS on Single Server Streaming S3 Replication for SQLite lightweight, distributed relational database built on SQLite Interesting use cases for SQLITE Hosting SQLite databases on Github Pages Joining CSV and JSON data with an in-memory SQLite database Baked Data Architecture Pattern -DB side by side Web App Cron based backups for SQLITE Data Security, GDPR Tool for Sensitive Data Detection from Capital one Data bunker - Secure storage for personal records built to comply with GDPR Search Google Code Search using Inverted Index Open source Google Code Search tool in Go Manticore Search - easy to use open source fast database for search ZincSearch - lightweight alternative to ElasticSearch Why OpenSearch, fork of ElasticSearch Peer to peer web search and Intranet Search Appliance Get Started with Opensearch Capacity Planning About Oracle Capacity Planning Guidelines for SQL Server Capacity Planning Database Documentation [Schema spy - ER Diagram, Metadata Reports][https://github.com/schemaspy/schemaspy] Data Engineering Concepts Choosing a Data Catalog Awesome Data Catalog Create a Serverless Data Lake on AWS and Migrate your On-Prem Data to it Data Engineering How tos- List of Curated Articles/Videos Guide to Data lake, Data lake house Data Lake - Solution Patterns What is delta lake house? Poor man’s Data lake with Duckdb Data Model for Managing Collaborative Editing of Data Data platform playbook Dictionary of databases Database of Databases ","permalink":"http://localhost:1313/links/databases/","summary":"\u003ch1 id=\"database\"\u003eDatabase\u003c/h1\u003e\n\u003cp\u003eKnowledge base around general database related topics.\u003c/p\u003e\n\u003ch2 id=\"general-links\"\u003eGeneral Links\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://medium.com/academy-team/which-data-architecture-should-i-choose-for-my-workplace-a-data-engineers-approach-f913b71d8ee6\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhich Data Architecture to choose\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/prisma/dataguide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrisma’s Data Guide - A growing library of articles focused on making databases more approachable. \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aiven.co/developers/sql-query-optimization-guide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuery optimization guide\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.crunchydata.com/blog/demystifying-database-performance-for-developers\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase performance for Developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.heimdalldata.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHeimdall data -Database scale-out without Application changes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dbdb.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase of databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://use-the-index-luke.com/blog/2015-02/modern-sql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModern SQL in databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://use-the-index-luke.com/blog/2015-02/modern-sql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEventual consistency by Werner Vogels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.allthingsdistributed.com/2019/03/Amazon-Aurora-design-cloud-native-relational-database.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAmazon Aurora ascendant: How we designed a cloud-native relational database - All Things Distributed\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.citusdata.com/blog/2018/06/28/scaling-from-one-to-one-hundred-thousand-tenants/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOptions for scaling from 1 to 100,000 tenants\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.acolyer.org/2019/03/25/amazon-aurora-design-considerations-for-high-throughput-cloud-native-relational-databases/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAmazon Aurora: design considerations for high throughput cloud-native relational databases | the morning paper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://martinfowler.com/articles/nosqlKeyPoints.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNOSQL - Key Points\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/data-store-comparison\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCriteria for Choosing Data store\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.algolia.com/building-real-time-analytics-apis/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBuilding Real Time Analytics APIs at Scale\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;Qvrhh0sHCrc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStreaming Database Changes with Debezium\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cloud.google.com/blog/products/gcp/why-you-should-pick-strong-consistency-whenever-possible\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy you should pick strong consistency, whenever possible\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://debezium.io/blog/2020/02/10/event-sourcing-vs-cdc/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChange Data Capture, Outbox and Event Sourcing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://debezium.io/documentation/reference/stable/development/engine.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDebezium Engine - setup without Apache Kafka\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@kestra-io/debezium-change-data-capture-without-kafka-connect-18f43cf095d2\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDebezium without kafka connect\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://streamsets.com/blog/replicating-oracle-to-mysql-and-json/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Streamsets for CDC From Oracle to Other destinations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://spanner.fyi/transactions/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTransactions in Google Spanner\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThings I Wished More Developers Knew About Databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://selectstarsql.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteractive Book about SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://quip.com/2gwZArKuWk7W\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Interview Questions\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://veekaybee.github.io/2017/03/20/hadoop-or-laptop/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHadoop or Laptop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=www.rqlite.com\n    \n    \n\u003eThe lightweight, distributed relational database built on SQLite\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/learning-sql-201-optimizing-queries-regardless-of-platform-918a3af9c8b1#635a\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOptimizing SQL Queries, Regardless of Platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://erwin.com/blog/how-to-do-data-modeling-the-right-way/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to do Data Modelling the right way\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.brianstorti.com/replication/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrimer on Database Replication\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConnection pool sizing for databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://hakibenita.com/sql-tricks-application-dba\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSome SQL tricks from Application DBA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.metabase.com/learn/building-analytics/sql-templates/sql-best-practices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest Practices while writing SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sirupsen.com/napkin/problem-14-using-checksums-to-verify/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing checksums to verify syncing 100M database records\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://antonz.org/random-table/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to populate a  table with 1 million records using single query\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://scattered-thoughts.net/writing/materialize-decorrelation\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow databases optimize Sub-queries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.wix.engineering/post/wix-inbox-journey-3-approaches-for-zero-downtime-database-migration\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproaches to database migration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tigerbeetle.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTigetbeetle - Fast financial accounting database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.nelhage.com/post/some-opinionated-sql-takes/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpinionated thoughts on SQL Databases\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"tools-collection\"\u003eTools Collection\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://dbmstools.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDBMS Tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/cube2222/octosql\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOctoSQL - Query, Join CSV with Postgresql/mysql from Command line\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/timescale/tsbs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTSBS - tool to benchmark bulk load performance and query execution performance.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pressly.github.io/goose/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoose - Database schema migrations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hammerdb.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHammerDB - Benchmarking Suite for databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/akopytov/sysbench\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSysbench - Scriptable database and system performance benchmark\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.soda.io/core\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSoda core - Data schema checks, for Quality, as code\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/readysettech/readyset\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReadyset -  MySQL and Postgres wire-compatible caching layer that sits in front of existing databases to speed up queries and horizontally scale read throughput.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-analytics\"\u003eData Analytics\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.vladsiv.com/big-data-file-formats/?ref\u0026#61;davidgomes.com#final-words\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstanding avro, parquet and ORC\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/cxli233/FriendsDontLetFriends\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuidance on Data Visualizations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://csvbase.com/blog/5\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSimple data pipeline Powertools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cube.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCube.dev - Open source Headless BI platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://evidence.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvidence.dev - BI as Code - SQL \u0026#43; Markdown to generate Reports\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.infoworld.com/article/3236869/what-is-apache-spark-the-big-data-platform-that-crushed-hadoop.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApache spark defined\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGetting started with Spark in Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.datamesh-architecture.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Data Mesh Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.datanami.com/2021/10/25/data-mesh-vs-data-fabric-understanding-the-differences/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData mesh vs. Data Fabric\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://future.a16z.com/emerging-architectures-modern-data-infrastructure/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEmerging Architectures for Modern Data Infrastructure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dropbox.tech/application/why-we-chose-apache-superset-as-our-data-exploration-platform\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Visualization/Exploration platforms Comparion Matrix\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSupercharging Apache Superset\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/snowplow/snowplow\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSnowplow - Cloud Native Behavioral data engine (e.g. User Analytics)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://redash.io/help/open-source/setup#other\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRedash - Collaboration, dashboards\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/why-data-culture-matters#\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy data culture matters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.mckinsey.com/industries/financial-services/our-insights/designing-a-data-transformation-that-delivers-value-right-from-the-start#\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesigning a data transformation that delivers value right from the beginning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/common-workflow-language/common-workflow-language/wiki/Existing-Workflow-systems\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Computational Data Analysis Workflow Systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dash.plotly.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Visualization framework for Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://segment.com/academy/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAnalytics Academy by Segment\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.sisense.com/whitepapers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAnalytics Whitepapers by Sisense\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mode.com/sql-tutorial/sql-business-analytics-training/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Analytics Training\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Beginner’s Guide to Data Engineering - 3-part series\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://looker.com/blog/different-types-graphs-charts-uses\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChart types and its usage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rudderstack.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRudder - Open source Customer Data Infrastructure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://datavizcatalogue.com/search/time.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCatalog of Widgets for Data Visualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://clickhouse.tech/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source OLAP Database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://notion.castordoc.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModern Data stack guide by Castor\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rudderstack.com/blog/1mgs-data-stack-explained-how-they-harness-and-activate-unlimited-real-time-data/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Stack of 1mg\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://7a9z42689xx35658r1hutm8n-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/Data-Report-Martin-Inline-Graphics-R7.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Unified Data Infrastructure Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://mattturck.com/wp-content/uploads/2020/09/2020-Data-and-AI-Landscape-Matt-Turck-at-FirstMark-v1.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData and AI Product Landscape\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/fishtown-analytics/dbt\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTransformations for DWH using DBT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/thenaturalist/awesome-business-intelligence\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome list of Business Intelligence Tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://towardsdatascience.com/data-stacks-for-fun-nonprofit-part-iii-dcfd46da9f9f\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArticle Series on Open source Data Analytics Stack (Postgres,Meltano, Airflow, dbt and Superset) \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://posthog.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePosthog - open source product analytics platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://technically.dev/posts/what-your-data-team-is-using\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTypical Analytics Stack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://octo.github.com/projects/flat-data\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFlat Data - Scheduled Data Download on GitHub Actions in Repository and visualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nocodb/nocodb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNocodb - Turn *MySQL/PostgreSQL data in smart Spreadsheet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.confluent.io/blog/real-time-analytics-with-kafka-and-pinot/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReal time data analysis with Apache Pinot and kafka\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.percona.com/blog/2019/11/22/uuids-are-popular-but-bad-for-performance-lets-discuss/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUUIds are bad for performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mit-pdos/noria\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNoria - Caching and updating Relational query results\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/vmware/differential-datalog\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDifferential Datalog - Language for incremental computation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://planetscale.com/blog/why-we-chose-nanoids-for-planetscales-api\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing NanoIDs (not longer UUID) for public APis\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"in-memory-databases\"\u003eIn-memory Databases\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/dragonflydb/dragonfly\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDragonfly - Compatible with REDIS\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"duck-db\"\u003eDuck DB\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://duckdb.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDuckDB - Embeddable OLAP DBMS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sql-workbench.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSQL Workbench - run Duckdb on WASM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDuckDB - Connect and join on external databases\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://motherduck.com/blog/postgres-duckdb-options\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing duckdb and postgres together\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"etlelt-database-as-a-queue-evolutionary-practices\"\u003eETL,ELT, Database-as-a-queue, Evolutionary Practices\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.sas.com/en_us/insights/data-management/what-is-etl.html#:~:text\u0026#61;ETL%20is%20a%20type%20of,to%20build%20a%20data%20warehouse.\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAll about ETL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/airbytehq/airbyte\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAirbyte-Open source ELT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/big-data-engineering/redshift-cicd-how-we-did-it-and-why-you-should-do-it-to-e46ecf734eab\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase CI/CD practices using Redshift\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jghoman/awesome-apache-airflow\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Apache Airflow\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dagster-io/dagster\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Python library for building data applications: ETL, ML, Data Pipelines, and more. \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/prefecthq/prefect\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA modern data workflow platform \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/linkedin/databus\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabus - Change Data capture System from Linkedin\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/liquidata-inc/dolt\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDolt - Git for Data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://griddb.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGridDB - next generation database for IoT \u0026amp;amp; big data with both NoSQL interface \u0026amp;amp; SQL Interface.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dev.l1x.be/posts/2021/03/08/compressing-data-with-parquet/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCompressing data with Parquet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/lancedb/lance\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLance - alternate columnar, compressed format for ML\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mara/mara-pipelines\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMara pipelines - Opinionated ETL framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/enso-org/enso\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEnso - Interactive Data Workflow builder with no coding\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.eventstore.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase for Event Sourcing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mlops.community/an-engineers-guide-to-data-contracts-pt-1/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat are Data Contracts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://segment.com/blog/introducing-centrifuge/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCentrifuge - Database as a Queue\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"database-scaling\"\u003eDatabase scaling\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://momjian.us/main/writings/pgsql/hw_selection.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase Hardware Selection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.flipkart.tech/scaling-tidb-to-1-million-qps-d556aa6a16ef\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling TIDB to 1 million QPS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stackoverflow.blog/2022/03/14/how-sharding-a-database-can-make-it-faster/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSharding a database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.quora.com/q/quoraengineering/MySQL-sharding-at-Quora?share\u0026#61;1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMySQL Sharding at Quora\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ericelliott/cuid\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCUID-Collision-resistant ids optimized for horizontal scaling and performance.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-discovery\"\u003eData Discovery\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://open-metadata.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpenMetadata - Data Discovery, Lineage, Data Quality\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eugeneyan.com/writing/data-discovery-platforms/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvaluation of Data Discovery Platforms\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.shopify.com/blogs/engineering/solving-data-discovery-challenges-shopify\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Discovery at Shopify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/great-expectations/great_expectations\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGreat Expectations - Data Documentation and Profiling tool\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"database-migration-practices\"\u003eDatabase Migration Practices\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.rainforestqa.com/blog/2014-06-27-zero-downtime-database-migrations\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZero downtime database migrations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stripe.com/blog/online-migrations\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStripe - Database Online migration at scale using dual writes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.quora.com/How-big-companies-migrate-from-one-database-to-another-without-losing-data-i-e-database-independent/answer/Siddharth-Anand\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow big companies migrate from one database to another without losing data i.e database independent?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/datafold/data-diff\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEfficiently diff rows across two different databases.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"metadata-management\"\u003eMetadata Management\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://gradientflow.com/the-growing-importance-of-metadata-management-systems/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGrowing importance of Metadata Management Systems\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"sqlite\"\u003eSQLite\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://simonwillison.net/2021/Feb/21/cross-database-queries/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuery against multiple SQLite databases using ATTACH Command\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sqlite.org/fiddle/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOnline SQLite Fiddle\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.epicweb.dev/why-you-should-probably-be-using-sqlite\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy you should be using SQLITE(2023)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://phiresky.github.io/blog/2020/sqlite-performance-tuning\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePerformance tuning settings\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pocketbase.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePocketbase - SQlite database with Go-based Wrapper to expose API\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.expensify.com/2018/01/08/scaling-sqlite-to-4m-qps-on-a-single-server/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling SQLITE to 4M QPS on Single Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://litestream.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStreaming S3 Replication for SQLite\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rqlite/rqlite\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003elightweight, distributed relational database built on SQLite\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://antonz.org/sqlite-is-not-a-toy-database/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteresting use cases for SQLITE\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://phiresky.github.io/blog/2021/hosting-sqlite-databases-on-github-pages/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHosting SQLite databases on Github Pages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://simonwillison.net/2021/Jun/19/sqlite-utils-memory/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJoining CSV and JSON data with an in-memory SQLite database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://simonwillison.net/2021/Jul/28/baked-data/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBaked Data Architecture Pattern -DB side by side Web App\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://litestream.io/alternatives/cron/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCron based backups for SQLITE\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-security-gdpr\"\u003eData Security, GDPR\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://capitalone.github.io/DataProfiler/docs/0.4.5/html/index.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTool for Sensitive Data Detection from Capital one\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://databunker.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData bunker - Secure storage for personal records built to comply with GDPR\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"search\"\u003eSearch\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://swtch.com/~rsc/regexp/regexp4.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoogle Code Search using Inverted Index\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/google/codesearch\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source Google Code Search tool in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/manticoresoftware/manticoresearch/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eManticore Search -  easy to use open source fast database for search\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://zincsearch.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZincSearch - lightweight alternative to ElasticSearch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://logz.io/learn/opensearch-faq-what-is-opensearch/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy OpenSearch, fork of ElasticSearch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/yacy/yacy_search_server\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePeer to peer web search and Intranet Search Appliance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://amulyasharma.medium.com/opensearch-up-and-running-in-10-mins-49e05689087e\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGet Started with Opensearch\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"capacity-planning\"\u003eCapacity Planning\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=http://www.dba-oracle.com/concepts/database_administration.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Oracle Capacity Planning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/sharepoint/administration/storage-and-sql-server-capacity-planning-and-configuration\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuidelines for SQL Server Capacity Planning\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"database-documentation\"\u003eDatabase Documentation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e[Schema spy - ER Diagram, Metadata Reports][https://github.com/schemaspy/schemaspy]\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"data-engineering\"\u003eData Engineering\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://glossary.airbyte.com/term/data-engineering-concepts/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConcepts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sarahsnewsletter.substack.com/p/choosing-a-data-catalog\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChoosing a Data Catalog\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/opendatadiscovery/awesome-data-catalogs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Data Catalog\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@budilov/create-a-serverless-data-lake-on-aws-and-migrate-your-on-prem-data-to-it-80dad09e23cb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCreate a Serverless Data Lake on AWS and Migrate your On-Prem Data to it\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/adilkhash/Data-Engineering-HowTo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Engineering How tos- List of Curated Articles/Videos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuide to Data lake, Data lake house\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogs.oracle.com/bigdata/data-lake-solution-patterns-use-cases\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Lake - Solution Patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat is delta lake house?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dagster.io/blog/duckdb-data-lake\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePoor man’s Data lake with Duckdb\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hytradboi.com/2022/viewing-collaborative-editing-through-a-databases-lens\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Model for Managing Collaborative Editing of Data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://playbook.hackney.gov.uk/Data-Platform-Playbook/architecture-decisions\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData platform playbook\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dictionary-of-databases\"\u003eDictionary of databases\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://dbdb.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDatabase of Databases\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Databases"},{"content":"Below are some of my project(s),\nTracfee, One stop for Tutors to manage students, track fees. Developed as SPA in VueJS + Quasar using API in Golang, Oracle Database and hosted on Netlify.\nRSS APP RSS Reader app, to be used in lieu of Google Reader. Developed in Python with MongoDB as database.\n","permalink":"http://localhost:1313/projects/","summary":"\u003cp\u003eBelow are some of my project(s),\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=https://tracfee.netlify.app\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTracfee\u003c/a\u003e, One stop for Tutors to manage students, track fees. Developed as SPA in VueJS + Quasar using API in \u003ca href=https://golang.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGolang\u003c/a\u003e, Oracle Database and hosted on \u003ca href=https://netlify.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNetlify\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=https://github.com/sachinsu/rssapp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRSS APP\u003c/a\u003e RSS Reader app, to be used in lieu of Google Reader. Developed in Python with MongoDB as database.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"About"},{"content":"I am a software architect with more than 2 decades of experience, currently working at @worldlineglobal. This is my personal site where i share helpful content (gathered or authored) on Technology (and other topics).\nI appreciate any ideas/suggestions you have on how I can improve this site.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a software architect with more than 2 decades of experience, currently working at \u003ca href=https://twitter.com/WorldlineGlobal\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e@worldlineglobal\u003c/a\u003e. This is my personal site where i share helpful content (gathered or authored) on Technology (and other topics).\u003c/p\u003e\n\u003cp\u003eI appreciate any \u003ca href=https://github.com/sachinsu/sachinsu.github.io/issues/new\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eideas/suggestions you have\u003c/a\u003e on how I can improve this site.\u003c/p\u003e","title":"About"},{"content":"Microsoft .NET Platform where i have spent most time till now.\nGeneral Links What is .NET? by Scott Hanselman Async in Depth Using Async/Await in WCF or ASMX with AsyncEx Comparing Async/Await with GoRoutines .NET Presentations - Events in a Box Building Microservices in .NET Materialized View Pattern for Cross Service Queries Oracle DB and .NET - Optimizing Real-World Performance with Static Connection Pools Clean Code concepts and tools adapted for .NET Multiple ways how to limit parallel tasks processing Parallel programming in .NET Clean Architecture in .NET You’re (probably still) using HttpClient wrong and it is destabilizing your software Async/Await - Guidance \u0026amp;amp; Best Practices in Asynchronous Programming Async/Await - Deep dive for Windows based Async I/O One more look at why Async/Await, what happens underneath Implement a producer-consumer dataflow pattern Use Arrays of Blocking Collections in a Pipeline Performance related Web forms, Asynchronous operations and its performance impact List of Awesome Resources Using System.Diagnostics.StopWatch.GetTimeStamp for accurate duration C# Job Queues with TPL Dataflow and Failure Handling Know about Threadpool, types of Threads in CLR and changing them to improve performance Work flow of diagnosing memory performance issues ***Contention, poor performance, and deadlocks when you make calls to Web services from an ASP.NET application .NET GC - Memory fundamentals Debug high CPU usage in .NET Core Measure performance of High frequency events in .NET Core App .NET Core debug memory leak, High CPU Usaege, Deadlock TCP Connection Pool and how it works in .NET Framework/.NET Core Using max number of worker threads using Semaphore Performance tuning for .NET Core API A light-weight REST API development framework for ASP.NET 6 and newer. Starter kit .NET Core Starter kit ASP.NET Web forms What not to do in ASP.NET, and what to do instead Use Task.Run at the invocation, not in the implementation Take Advantage of ASP.NET Built-in Features to Fend Off Web Attacks Blazor for Web Form Developers Windows Forms Task.run vs. BackgroundWorker Tools, Libraries Coravel - In-memory Task Scheduling , Queueing Library Generate PDF using Scriban and Playwright .NET Playground RestSharp - REST HTTP Client Ocelot - API Gateway AsyncAwaitBestPractices Flurl Distributed transaction solution in micro-service base on eventually consistency, also an eventbus with Outbox pattern Simple Swiss Army knife for http/https troubleshooting and profiling Event sourcing using variety of stores like AMQP, database Feature Management library for ASP.NET Core General Checklist for Projects Open Source ing tool for .NET Core/.NET Framework that helps your application generate document-like reports Open source database, Optimized for Event sourcing bflat - No-frills, standalone compiler for .net Hashids.NET - Generate Youtube-like hashes (short codes) from one or more numbers Rate Limiting Library from Microsoft Task Queue/Scheduling tools Hangfire Tempus Background tasks with hosted services in ASP.NET Core Rebus - Smart end-points, dumb pipes service bus for .net Rules, workflow Workflow-core-Lightweight workflow engine for .NET Standard Rules Engine - A Json based Rules Engine with extensive Dynamic expression support from Microsoft .NET Core Approach for Incremental Migration from ASP.NET to ASP.NET Core .NET Portability Analyzer ASP.NET Core Architecture Overview ASP.NET Core Performance Best Practices Diagnosing Issues Under Load Of WebAPI App Migrated To ASP.NET Core On Linux Model binding in ASP.NET core HttpClient Connection Pooling in .NET Core An Introduction to System.Threading.Channels Working with Channels With Stephen Toub BackgroundService Gotcha: Application Lifetime AWS Porting Assistant for .NET Sample of Micro services in .NET Core CoreWCF (SOAP,TCP, WS-HTTP support) on .NET Core ASP.NET Web API Versioning Samples of ASP.NET Core you can use Step by Step OpenTelemetry in .NET Core Techempower performance benchmarks Security OWASP - Top Ten Vulnerabilities Microsoft RESTler-Security testing using Automated Fuzzing Security Code Scan in .NET Networking .NET 5 Networking Improvements Understanding WebRequest Problems and Exceptions Twitter Handles Scott Hanselman General .NET Conf 2021 Videos, Slides etc. Nuke - Alternate (to MSBUILD) Build system for .NET Design patterns implementations in C# ","permalink":"http://localhost:1313/links/dotnet/","summary":"\u003ch1 id=\"microsoft-net\"\u003eMicrosoft .NET\u003c/h1\u003e\n\u003cp\u003ePlatform where i have spent most time till now.\u003c/p\u003e\n\u003ch2 id=\"general-links\"\u003eGeneral Links\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?time_continue\u0026#61;1\u0026amp;v\u0026#61;bEfBfBQq7EE\u0026amp;feature\u0026#61;emb_logo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat is .NET? by Scott Hanselman\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/async-in-depth\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsync in Depth\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.stephencleary.com/2012/08/async-wcf-today-and-tomorrow.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing Async/Await in WCF or ASMX with AsyncEx\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alexyakunin.medium.com/go-vs-c-part-1-goroutines-vs-async-await-ac909c651c11\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eComparing Async/Await with GoRoutines\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://presentations.dotnetfoundation.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Presentations - Events in a Box\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://altkomsoftware.pl/en/blog/building-microservices-on-net-core-1/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBuilding Microservices in .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/architecture/patterns/materialized-view\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMaterialized View Pattern for Cross Service Queries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.oracle.com/en/database/oracle/oracle-database/12.2/jjucp/optimizing-real-world-performance.html#GUID-BC09F045-5D80-4AF5-93F5-FEF0531E0E1D\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOracle DB and .NET - Optimizing Real-World Performance with Static Connection Pools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/thangchung/clean-code-dotnet\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eClean Code concepts and tools adapted for .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/archive/blogs/fkaduk/multiple-ways-how-to-limit-parallel-tasks-processing\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMultiple ways how to limit parallel tasks processing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eParallel programming in .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ardalis/CleanArchitecture\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eClean Architecture in .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://josefottosson.se/you-are-probably-still-using-httpclient-wrong-and-it-is-destabilizing-your-software/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou’re (probably still) using HttpClient wrong and it is destabilizing your software\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/davidfowl/AspNetCoreDiagnosticScenarios/blob/master/AsyncGuidance.md#asynchronous-programming\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsync/Await - Guidance \u0026amp;amp; Best Practices in Asynchronous Programming\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tooslowexception.com/net-asyncawait-in-a-single-picture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsync/Await - Deep dive for Windows based Async I/O\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.scooletz.com/2018/05/14/task-async-await-valuetask-ivaluetasksource-and-how-to-keep-your-sanity-in-modern-net-world/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOne more look at why Async/Await, what happens underneath\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/how-to-implement-a-producer-consumer-dataflow-pattern\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eImplement a producer-consumer dataflow pattern\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/standard/collections/thread-safe/how-to-use-arrays-of-blockingcollections\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse Arrays of Blocking Collections in a Pipeline\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"performance-related\"\u003ePerformance related\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/web-forms/overview/performance-and-caching/using-asynchronous-methods-in-aspnet-45\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb forms, Asynchronous operations and its performance impact\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/adamsitnik/awesome-dot-net-performance\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Awesome Resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.stopwatch.gettimestamp?view\u0026#61;net-5.0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing System.Diagnostics.StopWatch.GetTimeStamp for accurate duration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://michaelscodingspot.com/c-job-queues-part-3-with-tpl-dataflow-and-failure-handling/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eC# Job Queues with TPL Dataflow and Failure Handling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gist.github.com/JonCole/e65411214030f0d823cb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eKnow about Threadpool, types of Threads in CLR and changing them to improve performance\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/work-flow-of-diagnosing-memory-performance-issues-part-0/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWork flow of diagnosing memory performance issues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://support.microsoft.com/en-us/help/821268/contention-poor-performance-and-deadlocks-when-you-make-calls-to-web-s\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e***Contention, poor performance, and deadlocks when you make calls to Web services from an ASP.NET application\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Maoni0/mem-doc/blob/master/doc/.NETMemoryPerformanceAnalysis.md#Memory-Fundamentals\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET GC - Memory fundamentals\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/core/diagnostics/debug-highcpu?WT.mc_id\u0026#61;-blog-scottha\u0026amp;tabs\u0026#61;windows\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDebug high CPU usage in .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/core/diagnostics/event-counter-perf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMeasure performance of High frequency events in .NET Core App\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/core/diagnostics/debug-highcpu?tabs\u0026#61;windows\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Core debug memory leak, High CPU Usaege, Deadlock\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/azure-sdk/net-framework-connection-pool-limits/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTCP Connection Pool and how it works in .NET Framework/.NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.codeproject.com/Articles/859108/Writing-a-Web-Server-from-Scratch\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing max number of worker threads using Semaphore\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://reubenbond.github.io/posts/dotnet-perf-tuning\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePerformance tuning for .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"api\"\u003eAPI\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/FastEndpoints/FastEndpoints\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA light-weight REST API development framework for ASP.NET 6 and newer. \u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"starter-kit\"\u003eStarter kit\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/fullstackhero/dotnet-starter-kit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Core Starter kit\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"aspnet-web-forms\"\u003eASP.NET Web forms\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/aspnet/overview/web-development-best-practices/what-not-to-do-in-aspnet-and-what-to-do-instead#standards\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhat not to do in ASP.NET, and what to do instead\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.stephencleary.com/2013/11/taskrun-etiquette-examples-dont-use.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse Task.Run at the invocation, not in the implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/previous-versions/dotnet/articles/ms972969%28v\u0026#61;msdn.10%29?redirectedfrom\u0026#61;MSDN\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTake Advantage of ASP.NET Built-in Features to Fend Off Web Attacks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dotnet.microsoft.com/en-us/learn/aspnet/architecture#ebook-blazor-for-web-forms-devs-swimlane\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBlazor for Web Form Developers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"windows-forms\"\u003eWindows Forms\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://blog.stephencleary.com/2013/09/taskrun-vs-backgroundworker-conclusion.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTask.run vs. BackgroundWorker\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"tools-libraries\"\u003eTools, Libraries\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/jamesmh/coravel\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCoravel - In-memory Task Scheduling , Queueing Library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.meziantou.net/generate-pdf-files-using-an-html-template-and-playwright.htm\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGenerate PDF using Scriban and Playwright\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sharplab.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Playground\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/restsharp/RestSharp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRestSharp - REST HTTP Client\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ocelot.readthedocs.io/en/latest/features/configuration.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOcelot - API Gateway\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/brminnick/AsyncAwaitBestPractices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsyncAwaitBestPractices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://flurl.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFlurl\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://cap.dotnetcore.xyz/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed transaction solution in micro-service base on eventually consistency, also an eventbus with Outbox pattern\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/trimstray/htrace.sh\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSimple Swiss Army knife for http/https troubleshooting and profiling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/eventflow/EventFlow\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvent sourcing using variety of stores like AMQP, database\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Unleash/unleash\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/FeatureManagement-Dotnet\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFeature Management library for ASP.NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/StephenCleary/Docs/blob/master/libraries/README.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGeneral Checklist for Projects\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.fast-report.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen Source ing tool for .NET Core/.NET Framework that helps your application generate document-like reports\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/eventstore/eventstore\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen source database, Optimized for Event sourcing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/MichalStrehovsky/bflat\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ebflat - No-frills, standalone compiler for .net\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ullmark/hashids.net\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHashids.NET - Generate Youtube-like hashes (short codes) from one or more numbers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/announcing-rate-limiting-for-dotnet/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRate Limiting Library from Microsoft\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"task-queuescheduling-tools\"\u003eTask Queue/Scheduling tools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.hangfire.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHangfire\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Workshell/tempus\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTempus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view\u0026#61;aspnetcore-5.0\u0026amp;tabs\u0026#61;visual-studio\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBackground tasks with hosted services in ASP.NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rebus-org/Rebus/wiki\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRebus - Smart end-points, dumb pipes service bus for .net\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"rules-workflow\"\u003eRules, workflow\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/danielgerlag/workflow-core\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWorkflow-core-Lightweight workflow engine for .NET Standard\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/RulesEngine\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRules Engine - A Json based Rules Engine with extensive Dynamic expression support from Microsoft\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"net-core\"\u003e.NET Core\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/incremental-asp-net-to-asp-net-core-migration/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproach for Incremental Migration from ASP.NET to ASP.NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/microsoft/dotnet-apiport/blob/dev/docs/Console/README.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Portability Analyzer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://speakerdeck.com/davidfowl/asp-dot-net-core-architecture-overview\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eASP.NET Core Architecture Overview\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/core/performance/performance-best-practices?WT.mc_id\u0026#61;ondotnet-channel9-cephilli\u0026amp;view\u0026#61;aspnetcore-2.2\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eASP.NET Core Performance Best Practices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hanselman.com/blog/CustomerNotesDiagnosingIssuesUnderLoadOfWebAPIAppMigratedToASPNETCoreOnLinux.aspx\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDiagnosing Issues Under Load Of WebAPI App Migrated To ASP.NET Core On Linux\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/aspnet/core/mvc/models/model-binding?view\u0026#61;aspnetcore-3.1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModel binding in ASP.NET core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.stevejgordon.co.uk/httpclient-connection-pooling-in-dotnet-core\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHttpClient Connection Pooling in .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/an-introduction-to-system-threading-channels/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAn Introduction to System.Threading.Channels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://channel9.msdn.com/Shows/On-NET/Working-with-Channels-in-NET?WT.mc_id\u0026#61;ondotnet-c9-cephilli\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWorking with Channels With Stephen Toub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.stephencleary.com/2020/06/backgroundservice-gotcha-application-lifetime.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBackgroundService Gotcha: Application Lifetime\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://aws.amazon.com/blogs/aws/announcing-the-porting-assistant-for-net/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAWS Porting Assistant for .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/madslundt/NetCoreMicroservicesSample\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSample of Micro services in .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://corewcf.github.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCoreWCF (SOAP,TCP, WS-HTTP support) on .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dotnet/aspnet-api-versioning\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eASP.NET Web API Versioning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dodyg/practical-aspnetcore\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSamples of ASP.NET Core you can use\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://logz.io/blog/csharp-dotnet-opentelemetry-instrumentation/#conc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStep by Step OpenTelemetry in .NET Core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.techempower.com/benchmarks/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTechempower performance benchmarks\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"security\"\u003eSecurity\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://owasp.org/www-project-top-ten/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOWASP - Top Ten Vulnerabilities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.microsoft.com/en-us/research/blog/restler-finds-security-and-reliability-bugs-through-automated-fuzzing/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicrosoft RESTler-Security testing using Automated Fuzzing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://security-code-scan.github.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSecurity Code Scan in .NET\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"networking\"\u003eNetworking\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://devblogs.microsoft.com/dotnet/net-5-new-networking-improvements/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET 5 Networking Improvements\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/dotnet/framework/network-programming/understanding-webrequest-problems-and-exceptions\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnderstanding WebRequest Problems and Exceptions\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"twitter-handles\"\u003eTwitter Handles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://twitter.com/shanselman\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScott Hanselman\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"general\"\u003eGeneral\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/dotnet-presentations/dotNETConf/tree/master/2021/MainEvent/Technical\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e.NET Conf 2021 Videos, Slides etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://nuke.build/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNuke - Alternate (to MSBUILD) Build system for .NET\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/skimedic/presentations/tree/main/Patterns\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesign patterns implementations in C#\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages - .NET"},{"content":"Go Language My current Favorite Language\nArticles, E-books About Go - Compiler, packaging etc. When (and when not to) to use Generics in Go Ver. 1.8 High performance GO Workshop Learnings from Production usage of Go Thoughts on Go performance optimization Effective Go Handling 1M websockets connections in Go Notes on Go language Standard Go Project Layout 10 things you (probably) don’t know about Go Useful patterns in Go Interesting ways of using Go channels How i writer web services in Go Embed static file(s) in Go Executable and expose over HTTP Using go:embed in Go 1.16 Go Useful patterns by Roberto Clapis Strategies for Working with Message Queues Continuous build \u0026amp;amp; Testing using Go Convey Why American Express chose Go Thoughts on Performance Optimizations in Go by Damian Gryski Quick list of performance improvement targets in Go 10 things you probably don’t know about Go Learn Go with test-driven development Cancellable Pipelines in Go Running Go binary in Docker Go for Cloud - Tips and Techniques Why and what to instrument in Go Web Apps Continuous Profiling of Go programs How I write HTTP services in 2024 Go Concurrency - Singleflight, Bounded concurrency, Weighted bounded concurrency Why you should be using errgroup withcontext in Golang WebAssembly in Go gRPC in Go Go: Discovery of the Trace Package Tracing in production for Latency Rust for Go Developers Rust vs Go - When to use which Example of how to let only one Goroutine do the task while letting others wait for it useful in case of reading data from DB to be cached How to leverage AWS Lambda timeouts with Go context cancellation Design philosophy TLS and Go Effectively using Systemd for setting up HTTP Server Useful Code patterns Streams onboarding plan for using Go in 10 weeks Libraries, Tools HTMX \u0026#43; Go in single binary Staticcheck - The advaned Go linter Scripting with Go Right way to check weather Generate Go Code for Database / SQL for Mysql and PostgreSQL Why SQLc is better approach than ORM Golang style guide by Uber ORM to Model and Traversal of Data as a Graph structure Gops-A tool to list and diagnose Go processes currently running on your system Pocketbase - SQlite database with Go-based Wrapper to expose API Wails - Electron like environment in Go Visualize call graph of a Go program using dot (Graphviz) Semgrep - Lightweight static code analysis focussed on Security Draw Application diagrams using Go A Go metrics interface with fast buffered metrics and third party reporters Hey - HTTP load generator, ApacheBench (ab) replacement Go-metrics - library for exporting performance and runtime metrics to external metrics systems (i.e. statsite, statsd) Progressive Web App (PWA) with WebAssembly in Go GoPlus - The Go\u0026#43; language for data science Notes on Profiling in Go Go-Micro - Web and RPC Framework for Microservices in Go Approach on project Structure in Go Zero Allocation JSON logger Use Makefile with Go Review of HTTP Routers Library over Financial Markets i.e. Yahoo Finance etc. Excelsize - pure Go library providing a set of functions that allow you to write to and read from XLSX / XLSM / XLTM / XLTX files Benthos - Simplified stream processing with built-in connectors Service weaver - Write Modular Monolith Apps Xo - Tool to Generate DB Specific Go Code Learning Learn go with tests Task queues Queueing with Update..skip locked Machinery - Asynchronous task queue/job queue Bleve - Full text Search Engine Event Sourcing, pub/sub using AMQP/SQL/Channels Hydra - OAuth 2.0 Server Temporal - Scalable orchestration platform Distributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres. Tunny - Library to manage pool of goroutines to limit incoming work Scheduler library for Go Web scraping, downloader Elegant Scraper and Crawler Framework for Golang Fast, simple and clean video downloader Videos, Talks Best practices for Industrial Programming - by Peter Bourgon Profiling \u0026amp;amp; Optimizing in Go Rethinking classical Concurrency patterns Justforfunc: Programming in Go A Channel Compendium Visualize Concurrency in Go Real-world systems in Go Host Free Go Web app on Netlify Zen of Go - Ten engineering values for writing simple, readable, maintainable Go code [Ultimate Go Study Guide](https://githu b.com/hoanhan101/ultimate-go) Code snippets Web Service in Go - Code with Best practices Remote service with Retries Curated list of design patterns implemented in Go Gophercises - Exercises for Go Developers Practical concurrency guide in Go, communication by channels, patterns Sample DDD Project with Code Podcasts Go Time Performance Analysis Example of Performance analysis of Go Program using benchmarks ","permalink":"http://localhost:1313/links/go/","summary":"\u003ch2 id=\"go-language\"\u003eGo Language\u003c/h2\u003e\n\u003cp\u003eMy current Favorite Language\u003c/p\u003e\n\u003ch3 id=\"articles-e-books\"\u003eArticles, E-books\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://christine.website/blog/we-have-go-2\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Go - Compiler, packaging etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://planetscale.com/blog/generics-can-make-your-go-code-slower\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhen (and when not to) to use Generics in Go Ver. 1.8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dave.cheney.net/high-performance-go-workshop/gophercon-2019.html#welcome\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHigh performance GO Workshop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rytisbiel.com/2021/03/06/darker-corners-of-go/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearnings from Production usage of Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dgryski/go-perfbook\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThoughts on Go performance optimization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://golang.org/doc/effective_go.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEffective Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/eranyanay/1m-go-websockets\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHandling 1M websockets connections in Go \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://notes.shichao.io/gopl/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNotes on Go language\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/golang-standards/project-layout\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStandard Go Project Layout\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://talks.golang.org/2012/10things.slide#1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 things you (probably) don’t know about Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogtitle.github.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUseful patterns in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/nomad-software/go-channel-compendium\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eInteresting ways of using Go channels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;rWBSMsLG8po\u0026amp;feature\u0026#61;emb_logo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow i writer web services in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rakyll/statik\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEmbed static file(s) in Go Executable and expose over HTTP\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.carlmjohnson.net/post/2021/how-to-use-go-embed/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUsing go:embed in Go 1.16\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blogtitle.github.io/some-useful-patterns/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo Useful patterns by Roberto Clapis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://www.doxsey.net/blog/strategies-for-working-with-message-queues\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStrategies for Working with Message Queues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://goconvey.co/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContinuous build \u0026amp;amp; Testing using Go Convey\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://americanexpress.io/choosing-go/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy American Express chose Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dgryski/go-perfbook\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThoughts on Performance Optimizations in Go by Damian Gryski\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stephen.sh/posts/quick-go-performance-improvements\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQuick list of performance improvement targets in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://talks.golang.org/2012/10things.slide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e10 things you probably don’t know about Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/quii/learn-go-with-tests\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearn Go with test-driven development\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.golang.org/pipelines\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCancellable Pipelines in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://jpetazzo.github.io/2016/09/09/go-docker/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRunning Go binary in Docker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://rakyll.org/go-cloud/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo for Cloud - Tips and Techniques\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alex.dzyoba.com/blog/go-prometheus-service/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy and what to instrument in Go Web Apps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/google-cloud/continuous-profiling-of-go-programs-96d4416af77b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContinuous Profiling of Go programs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://grafana.com/blog/2024/02/09/how-i-write-http-services-in-go-after-13-years/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow I write HTTP services in 2024\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://encore.dev/blog/advanced-go-concurrency\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo Concurrency - Singleflight, Bounded concurrency, Weighted bounded concurrency\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://bionic.fullstory.com/why-you-should-be-using-errgroup-withcontext-in-golang-server-handlers/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy you should be using errgroup withcontext in Golang\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dstoiko.github.io/posts/go-pong-wasm/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWebAssembly in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://talks.golang.org/2015/gotham-grpc.slide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003egRPC in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/a-journey-with-go/go-discovery-of-the-trace-package-e5a821743c3c\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo: Discovery of the Trace Package\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://speakerdeck.com/rakyll/tracing-for-granularity\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTracing in production for Latency\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://christine.website/blog/TLDR-rust-2020-09-19\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRust for Go Developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://thenewstack.io/rust-vs-go-why-theyre-better-together/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRust vs Go - When to use which\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lakefs.io/2020/09/23/in-process-caching-in-go-scaling-lakefs-to-100k-requests-second/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExample of how to let only one Goroutine do the task while letting others wait for it useful in case of reading data from DB to be cached\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@filiplubniewski/how-to-leverage-aws-lambda-timeouts-with-go-context-cancellation-7dacde656540\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to leverage AWS Lambda timeouts with Go context cancellation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ardanlabs/gotraining/blob/master/topics/go/README.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDesign philosophy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eli.thegreenplace.net/2021/go-https-servers-with-tls/#id8\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTLS and Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mgdm.net/weblog/systemd/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEffectively using Systemd for setting up HTTP Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://betterprogramming.pub/7-code-patterns-in-go-i-cant-live-without-f46f72f58c4b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUseful Code patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stream-wiki.notion.site/Stream-Go-10-Week-Backend-Eng-Onboarding-625363c8c3684753b7f2b7d829bcd67a\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStreams onboarding plan for using Go in 10 weeks\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"libraries-tools\"\u003eLibraries, Tools\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/maddalax/htmgo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHTMX \u0026#43; Go in single binary\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/dominikh/go-tools\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStaticcheck - The advaned Go linter\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://bitfieldconsulting.com/golang/scripting\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScripting with Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/chubin/wttr.in\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRight way to check weather\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://sqlc.dev\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGenerate Go Code for Database / SQL for Mysql and PostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://brandur.org/sqlc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy SQLc is better approach than ORM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/uber-go/guide/blob/master/style.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGolang style guide by Uber\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://entgo.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eORM to Model and Traversal of Data as a Graph structure\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/google/gops\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGops-A tool to list and diagnose Go processes currently running on your system\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pocketbase.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePocketbase - SQlite database with Go-based Wrapper to expose API\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/wailsapp/wails\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWails - Electron like environment in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ofabry.github.io/go-callvis/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisualize call graph of a Go program using dot (Graphviz)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://semgrep.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSemgrep - Lightweight static code analysis focussed on Security\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/blushft/go-diagrams\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDraw Application diagrams using Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/uber-go/tally\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Go metrics interface with fast buffered metrics and third party reporters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rakyll/hey\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHey - HTTP load generator, ApacheBench (ab) replacement\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/armon/go-metrics\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo-metrics - library for exporting performance and runtime metrics to external metrics systems (i.e. statsite, statsd)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://go-app.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProgressive Web App (PWA) with WebAssembly in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://goplus.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoPlus - The Go\u0026#43; language for data science\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/DataDog/go-profiler-notes\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eNotes on Profiling in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://go-micro.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo-Micro - Web and RPC Framework for Microservices in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/benbjohnson/wtf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eApproach on project Structure in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rs/zerolog\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZero Allocation JSON logger\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://earthly.dev/blog/golang-makefile/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUse Makefile with Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.alexedwards.net/blog/which-go-router-should-i-use\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReview of HTTP Routers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/piquette/finance-go\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLibrary over Financial Markets i.e. Yahoo Finance etc.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/qax-os/excelize\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExcelsize - pure Go library providing a set of functions that allow you to write to and read from XLSX / XLSM / XLTM / XLTX files\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Jeffail/benthos\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBenthos - Simplified stream processing with built-in connectors\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ServiceWeaver/weaver\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eService weaver - Write Modular Monolith Apps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/xo/xo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eXo - Tool to Generate DB Specific Go Code\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"learning\"\u003eLearning\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/quii/learn-go-with-tests\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearn go with tests\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"task-queues\"\u003eTask queues\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://ente.io/blog/tech/postgres-queue/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eQueueing with Update..skip locked\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/RichardKnop/machinery\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMachinery - Asynchronous task queue/job queue\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://blevesearch.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBleve - Full text Search Engine\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ThreeDotsLabs/watermill\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvent Sourcing, pub/sub using AMQP/SQL/Channels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ory.sh/hydra\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHydra - OAuth 2.0 Server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://temporal.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTemporal - Scalable orchestration platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/knadh/sql-jobber\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed job-queue built specifically for queuing and executing heavy SQL read jobs asynchronously. Supports MySQL and Postgres.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Jeffail/tunny\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTunny - Library to manage pool of goroutines to limit incoming work\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/reugn/go-quartz\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScheduler library for Go\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"web-scraping-downloader\"\u003eWeb scraping, downloader\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/gocolly/colly\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eElegant Scraper and Crawler Framework for Golang\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/iawia002/annie\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFast, simple and clean video downloader \u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"videos-talks\"\u003eVideos, Talks\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;PTE4VJIdHPg\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBest practices for Industrial Programming - by Peter Bourgon\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/bradfitz/talk-yapc-asia-2015/blob/master/talk.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProfiling \u0026amp;amp; Optimizing in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;5zXAHh5tJqQ\u0026amp;feature\u0026#61;emb_logo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRethinking classical Concurrency patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/channel/UC_BzFbxG2za3bp5NRRRXJSw\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eJustforfunc: Programming in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;SmoM1InWXr0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA Channel Compendium\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://divan.dev/posts/go_concurrency_visualize/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVisualize Concurrency in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;_YK0viplIl4\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReal-world systems in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.carlmjohnson.net/post/2020/how-to-host-golang-on-netlify-for-free/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHost Free Go Web app on Netlify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://the-zen-of-go.netlify.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eZen of Go - Ten engineering values for writing simple, readable, maintainable Go code\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e[Ultimate Go Study Guide](https://githu\nb.com/hoanhan101/ultimate-go)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"code-snippets\"\u003eCode snippets\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/ardanlabs/service/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb Service in Go - Code with Best practices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://play.golang.org/p/3mNhCTl01bX\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRemote service with Retries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tmrts/go-patterns\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCurated list of design patterns implemented in Go\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gophercises.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGophercises - Exercises for Go Developers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/luk4z7/go-concurrency-guide\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePractical concurrency guide in Go, communication by channels, patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ThreeDotsLabs/wild-workouts-go-ddd-example\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSample DDD Project with Code\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"podcasts\"\u003ePodcasts\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://changelog.com/gotime\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGo Time\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"performance-analysis\"\u003ePerformance Analysis\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://f4t.dev/software/go-performance-memory/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eExample of Performance analysis of Go Program using benchmarks\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages - Go"},{"content":"Testing Links Testing in 2021 How different software companies do testing HTTP(S) benchmark tools, testing/debugging, \u0026amp;amp; restAPI (RESTful) Toxiproxy - A TCP proxy to simulate network and system conditions for chaos and resiliency testing Papercut SMTP - Test Email delivery during development Malabi -Trace based testing in JavaScript AB Testing 101 API Test Client Bruno Load Testing K6 - Load testing tool Vegeta - HTTP load testing tool and library. Bombardier - Fast cross-platform HTTP benchmarking tool written in Go Plow - A high-performance HTTP benchmarking tool with real-time web UI Hey - HTTP load generator, ApacheBench (ab) replacement Collection of HTTP(S) benchmark tools, testing/debugging, \u0026amp;amp; restAPI (RESTful) Light weight cross-platform test automation ","permalink":"http://localhost:1313/links/testing/","summary":"\u003ch1 id=\"testing\"\u003eTesting\u003c/h1\u003e\n\u003ch2 id=\"links\"\u003eLinks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.tbray.org/ongoing/When/202x/2021/05/15/Testing-in-2021\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTesting in 2021\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/abhivaikar/howtheytest\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow different software companies do testing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/denji/awesome-http-benchmark\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHTTP(S) benchmark tools, testing/debugging, \u0026amp;amp; restAPI (RESTful)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://toxiproxy.io\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eToxiproxy - A TCP proxy to simulate network and system conditions for chaos and resiliency testing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/ChangemakerStudios/Papercut-SMTP\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePapercut SMTP - Test Email delivery during development\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/aspecto-io/malabi\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMalabi -Trace based testing in JavaScript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/jonathans-musings/ab-testing-101-5576de6466b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAB Testing 101\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"api-test-client\"\u003eAPI Test Client\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/usebruno/bruno\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBruno\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"load-testing\"\u003eLoad Testing\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://k6.io/open-source/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eK6 - Load testing tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/tsenart/vegeta\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVegeta - HTTP load testing tool and library.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/codesenberg/bombardier\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBombardier - Fast cross-platform HTTP benchmarking tool written in Go \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/six-ddc/plow\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePlow - A high-performance HTTP benchmarking tool with real-time web UI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/rakyll/hey\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHey - HTTP load generator, ApacheBench (ab) replacement\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/denji/awesome-http-benchmark\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of HTTP(S) benchmark tools, testing/debugging, \u0026amp;amp; restAPI (RESTful) \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gauge.org\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLight weight cross-platform test automation\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming - Testing"},{"content":"Programming Languages Links Hello world in every Programming Language General You are not Google Production Launch Checklist Things I Learnt The Hard Way in 30 Years of Software Development A collection of (mostly) technical things every software developer should know Startup idea Checklist System Design Primer Developer Roadmaps Why our team cancelled our move to microservices How Does HTTPS Work? RSA Encryption Explained How do you cut a monolith in half? Containers Awesome Collection of Docker Compose Recipes Podman Desktop - Alternative to Docker Desktop ","permalink":"http://localhost:1313/links/planguages/","summary":"\u003ch1 id=\"programming-languages\"\u003eProgramming Languages\u003c/h1\u003e\n\u003ch2 id=\"links\"\u003eLinks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/leachim6/hello-world\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHello world in every Programming Language\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"general\"\u003eGeneral\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://blog.bradfieldcs.com/you-are-not-google-84912cf44afb\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou are not Google\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://devchecklists.com/production-launch-checklist/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProduction Launch Checklist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.juliobiason.me/thoughts/things-i-learnt-the-hard-way/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThings I Learnt The Hard Way in 30 Years of Software Development\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mtdvio/every-programmer-should-know\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA collection of (mostly) technical things every software developer should know \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.defmacro.org/2019/03/26/startup-checklist.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eStartup idea Checklist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/donnemartin/system-design-primer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSystem Design Primer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://roadmap.sh/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDeveloper Roadmaps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@steven.lemon182/why-our-team-cancelled-our-move-to-microservices-8fd87898d952\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy our team cancelled our move to microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tiptopsecurity.com/how-does-https-work-rsa-encryption-explained/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow Does HTTPS Work? RSA Encryption Explained\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://programmingisterrible.com/post/162346490883/how-do-you-cut-a-monolith-in-half\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow do you cut a monolith in half?\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"containers\"\u003eContainers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/docker/awesome-compose\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome Collection of Docker Compose Recipes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/containers/podman-desktop\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePodman Desktop - Alternative to Docker Desktop\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Programming Languages"},{"content":"System Design, Architecture Links covering concepts and approaches around Distributed Systems, DevOps, Observability etc.\nArchitectural Case studies Temenos Serverless banking at Scale @ AWS using CQRS leveraging RDS and DynamoDB Temenos @ AWS Architecture Diagrams Architecture for Generations Ubers Domain-Oriented Microservice Architecture Books on Architecture,Design Software Architecture Patterns by Mark Richards A comprehensive list of books on Software Architecture. Introduction to architecting systems for scale. Strategies/Approaches Serving a billion web requests with boring code Professional programming resources Rob Pikes 5 Rules of Programming Modules, monoliths, and microservices The macro problem with Microservices Break Monolith into Microservices Steps to migrate from Monolith to Microservices Distributed architecture concepts I learned while building a large payments system Video: Developing Asynchronous Microservices • Chris Richardson Collection of Software development Videos Slides Managing Data Consistency in Microservices Architecture Reliable Microservices Data Exchange With the Outbox Pattern Scaling to 100k Users Monolith - Modular Approach You dont need Microservices Event Modelling - Approach Ready for changes with Hexagonal Architecture How to fix Overloaded Web server How gov.uk reliably sends SMS messages using multiple providers Rule of thumbs for Architecture Scalability About Structure of Design document Important Aspects about Circuit breaker from Shopify CRDTs for Synchronization Asynchronous transaction processing @ Facebook Evolutionary Database Design Scaling with Common Sense by Zerodha Guidelines for Command line interface Azure Well-Architected Framework Change Data Capture, Strangler fig and Saga Patterns Gateway pattern to encapsulate integration with external systems Why refactoring? OpenFeature - Standardizing Feature Flagging for Everyone featbit: Enterprise-level feature flag platform that you can self-host. Get started - free. Unleash - Open-source feature management platform API Development, Security, Cryptography The Web API Checklist** Mockoon - Run Mock APIs locally Bruno - Opensource IDE For Exploring and Testing Api’s REST API Guidelines from Microsoft Open Source Vulnerability Management Equinors API Strategy and Guidelines Checklist of Web APIs Guidelines for designing better APIs API Security Checklist Googles API Design Guidelines API Design for Serverless Apps OWASP - Top Ten Vulnerabilities API Security Checklist libsodium - Easy to use cryptography Schannel in Windows for Strong Ciphers/Cryptography Training Teach yourself Computer Science Collection of Video Courses on Computer Science Learn by doing - You dont need another MOOC Distributed Systems Build your own (insert technology here) Kubernetes for Everyone The Service Mesh: What Every Software Engineer Needs to Know about the Worlds Most Over-Hyped Technology Very Brief intro to Container Orchestrators E-book kubernetes Up \u0026amp;amp; Running Class materials for a distributed systems lecture series Containers - Training resources Distributed Systems Cheat Sheet Microservices — architecture nihilism in minimalisms clothes Microservices, pl. dont Disasters from Microservices world Saga: How to implement complex business transactions without two phase commit. Sagas by clement Vasters Ref. implementation of cloud design patterns Automation Microsoft Power Automate Desktop - Free Windows 10 Desktop Automation Automate the Boring Stuff with Python Four bad ways to use RPA Data Science at the Command line RobotFramework - Open source Test Automation and RPA WASP - Windows Automation Snapin for PowerShell Web API rate limiting Tools, Libraries (\nCollection of TILs (Today I learned) Miller - awk, sed, cut, join, and sort for name-indexed data such as CSV, TSV, and tabular JSON Digital services offerings from within European union Six things I wish we had known about scaling Awesome Design tools Regex Repository SpiderFoot, the most complete OSINT collection and reconnaissance tool Analyze TCP Connections by proxy TCP/IP -Why your websites should be 14KB in size Cloud Architecture Diagrams Free Online Cloud Architecture Diagram Tool Online Flowcharts, UML diagrams Embeddable charts using DataWrapper Figma - Design and prototype builder Open source Voice chat Zulip - Open source alternative to Slack Open source Video Conferencing Open network for secure, decentralized communication Alternatives for Local Kubernetes development Jami - tool for Encrypted Audio/Video calls Keycloak - Open source Identity and Access Management Ory - Next Gen Identity Management Diagram as Code (Python) Virtual whiteboard for sketching hand-drawn like diagrams with Collaboration*** Syncthing - Free, OSS, File synchronization across devices Library for Code Scanning Across GO, C#, Java etc. Open source Project Management Software Blueboat - Serverless infrastructure for On-premise deployment Text to Timeline (Gantt) chart Open source Pipelining, workflows Pipelines/workflow frameworks Workflow Engines List of ETL frameworks Streaming frameworks Extendable Workflow Automation tool in NodeJS Nodered - Low code event driven pipelines Security Definitive guide to key management7 A deep dive in CyberSecurity OWASP ZAP- Free Security Testing for Web Application Web Application Security Testing Understanding OAuth and OpenID Connect OWASP Cheat Sheet Series Microsoft App Inspector Open Policy Agent - General purpose Policy Engine Teler - Tool for Real time HTTP Intrusion detection Joern - platform for analyzing source code, bytecode, and binary executables Syft - Software Bill of Materials (SBOM) generator for vulnerability scanning Devops/Monitoring Open source Alerts Management Trivy - Scanner for vulnerabilities in container images, file systems, and Git repositories, as well as for configuration issues and hard-coded secrets Impact of Architecture on DevOps Run CI/CD pipeline locally with Dagger List of how organizations do SRE (Publicly available) Open source API Designer with CI/CD Workflow Microsoft Azure - DevOps Checklist Hashicorp Waypoint - easy way to build, deploy and release applications Zabbix, Time Series Data and TimescaleDB – Zabbix Blog PromScale - Observability backend powered by Timescaledb \u0026amp;amp; PostgreSQL How to Create and Manage CRON Jobs lazydocker - Docker mgmt tool for linux What’s in a CI pipeline Repository of DevOps Questions n Answers Google Incident Response Framework Dockerfile Best Practices Github Workflow - Test them locally using Act Code coverage best practices from Google A terminal UI for tshark, inspired by Wireshark Developer playbook approach by Hackney council Nice content on Ansible Performance profiling using Open source Pyroscope Server Act - Run Github Actions locally Approach to Uptime Guarantees Observability OpenObserve - Elasticsearch/Splunk/Datadog alternative for logs, metrics, traces Ntfy - OSS Server \u0026#43; Android App to send \u0026amp;amp; receive notification on Desktop/Android App Tips for Analyzing logs Decision guide on Tooling Prometheus and Cardinality of Metric All about Log Aggregation Observability in 2022 Observability @ Cloudflare What to Monitor and Metrics to collect for Web App with Background Jobs What was observability again? Dashboard design best practices Infrastructure Monitoring with Postgres Tracing, Fast and Slow – roguelynn OpenTelemetry in 2023 Course on using Opentelemetry Opentelemetry Overview Techniques for Monitoring Web services OpenTelemetry, Distributed Tracing, W3c Trace Context Tracing at Slack using Kafka Distributed tracing covering Client (Mobile App) tracing at slack Metrics, tracing, and logging Open source infrastructure and application Monitoring Opstrace - OSS alternative to Datadog,SignalFX Monitoring your own infrastructure using Grafana, InfluxDB, and CollectD Tool to extract whitebox monitoring data from application logs for collection in a timeseries database Percona Monitoring \u0026amp;amp; Mgmt - Open Source Software for MySQL/MongoDB/PostgreSQL Monitoring Monitoring and Observability With USE and RED Horizontally scalable storage for Prometheus Thanos - Highly available Prometheus setup with long term storage capabilities. Monitoring with VictoriaMetrics Healthchecks.io -Simple and Effective Cron Job Monitoring Decks on Prometheus deep dive, OpenMetrics Improving Observability with AWS App Mesh Metrics to track for your API Details about Cortex vs Thanos, Grafana Loki and Tempo Get started with Prometheus, Grafana and loki How to build a scalable prometheus architecture Introduction to FluentBit - Logs n Metrics Processor Distributed tracing vs. Logging Identifying disk i/o bottlenecks in Linux Signoz - Open Source Opentelemetry based Observability platform Centralized logging with Signoz What is eBPF \u0026amp;amp; its application in Observability Database Reliability Engineering(ebook) Distributed tracing using Tempo, OpenTelemetry and Grafana Cloud Skywalking - Open source Application Performance Monitoring tool HTTP Toolkit - Freemium HTTP Interceptor toolkit Comparing Open source log collectors Fluentd, Logstash, Fluentbit Observing Network Traffic with Open source tools Distributed messaging, Streams Iggy-persistent message streaming platform written in Rust, supporting QUIC, TCP and HTTP transport protocols, capable of processing millions of messages per second. SmoothMQ - Drop-in replacement for SQS With SQlite backend Comparison - BlazingMQ, RabbitMQ and Kafka Redpanda - Alternative to Kafka, Streaming Platform VerneMQ - A distributed MQTT message broker based on Erlang/OTP Kafka - Capacity Planning Why Kafka Is so Fast RabbitMQ vs Kafka - architec tural perspsective RabbitMQ vs Kafka A comparison between RabbitMQ and Apache Kafka Comparing RabbitMQ and Kafka Strategies for Working with Message Queues All about Queues Benefits of Message Queues Reasons to use Message Queues NSQ - a realtime distributed messaging platform designed to operate at scale Kafka Without Zookeeper - A Sneak peak Oracle Advanced Queues Instrumenting distributed systems for operational visibility Microservices Antipattern - Queue Explosion Trying out durable, replicated quorum queues in RabbitMQ ZeroMQ - Universal Messaging Library Comparing Techniques for Communicating Between HTTP Services Coding Style Guide Google Code Style Guide Rust Getting started with Rust A half-hour to learn Rust Tour of Rust PHP PHP: The Right way Email Server Setup Email server using Docker mailserver Networking All about Load Balancers Nerdy Videos Contalks Real world Architectures Deployment @ Wikimedia Interview Questions System Design 101 through Diagrams 10 API Product Manager Interview Questions API REST API Best practices Comparing API Architectural Styles Eventcatalog - Open source tool to document event driven Architectures Interesting free services Grist spreadsheets - alternative to Airtable Penpot - prototyping tool C, C++ Learnings from C Lang ","permalink":"http://localhost:1313/links/programming/","summary":"\u003ch1 id=\"system-design-architecture\"\u003eSystem Design, Architecture\u003c/h1\u003e\n\u003cp\u003eLinks covering concepts and approaches around Distributed Systems, DevOps, Observability etc.\u003c/p\u003e\n\u003ch2 id=\"architectural-case-studies\"\u003eArchitectural Case studies\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;mtZvA7ARepM\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTemenos Serverless banking at Scale @ AWS using CQRS leveraging RDS and DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://d1.awsstatic.com/architecture-diagrams/ArchitectureDiagrams/Temenos-on-aws.pdf?did\u0026#61;wp_card\u0026amp;trk\u0026#61;wp_card\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTemenos @ AWS Architecture Diagrams\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://increment.com/software-architecture/architecture-for-generations/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eArchitecture for Generations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eng.uber.com/microservice-architecture/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUbers Domain-Oriented Microservice Architecture\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"books-on-architecturedesign\"\u003eBooks on Architecture,Design\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://www.oreilly.com/content/software-architecture-patterns/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSoftware Architecture Patterns by Mark Richards\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mhadidg/software-architecture-books\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA comprehensive list of books on Software Architecture.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eIntroduction to architecting systems for scale.\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"strategiesapproaches\"\u003eStrategies/Approaches\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://notes.billmill.org/blog/2024/06/Serving_a_billion_web_requests_with_boring_code.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eServing a billion web requests with boring code\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/charlax/professional-programming\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eProfessional programming resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://users.ece.utexas.edu/~adnan/pike.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRob Pikes 5 Rules of Programming\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://tailscale.com/blog/modules-monoliths-and-microservices/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModules, monoliths, and microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://stackoverflow.blog/2020/11/23/the-macro-problem-with-microservices/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe macro problem with Microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://programmingisterrible.com/post/162346490883/how-do-you-cut-a-monolith-in-half\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBreak Monolith into Microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://semaphoreci.com/blog/monolith-microservices#modularize\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSteps to migrate from Monolith to Microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.pragmaticengineer.com/distributed-architecture-concepts-i-have-learned-while-building-payments-systems/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed architecture concepts I learned while building a large payments system\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.youtube.com/watch?v\u0026#61;kyNL7yCvQQc\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVideo: Developing Asynchronous Microservices • Chris Richardson\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://dev.tube/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of Software development Videos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/chris.e.richardson/saturn-2018-managing-data-consistency-in-a-microservice-architecture-using-sagas\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSlides Managing Data Consistency in Microservices Architecture \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReliable Microservices Data Exchange With the Outbox Pattern\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://alexpareto.com/scalability/systems/2020/02/03/scaling-100k.html#fnref:1\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling to 100k Users\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://speakerd.s3.amazonaws.com/presentations/7590b86ae80649c19cbbbb27ad89d798/2018-02-22_Microservices_Meetup_Munich_-_Monoliths.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMonolith - Modular Approach\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/swlh/stop-you-dont-need-microservices-dc732d70b3e0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eYou dont need Microservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eventmodeling.org/posts/what-is-event-modeling/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvent Modelling - Approach\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eReady for changes with Hexagonal Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://web.dev/overloaded-server/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to fix Overloaded Web server\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gds.blog.gov.uk/2020/04/03/how-gov-uk-notify-reliably-sends-text-messages-to-users/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow gov.uk reliably sends SMS messages using multiple providers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://medium.com/@i.gorton/six-rules-of-thumb-for-scaling-software-architectures-a831960414f9\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRule of thumbs for Architecture Scalability\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.industrialempathy.com/posts/design-docs-at-google/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAbout Structure of Design document\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.shopify.com/blogs/engineering/circuit-breaker-misconfigured\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eImportant Aspects about Circuit breaker from Shopify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jlongster/crdt-example-app\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCRDTs for Synchronization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://engineering.fb.com/production-engineering/async/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAsynchronous transaction processing @ Facebook\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.martinfowler.com/articles/evodb.html#AllDatabaseArtifactsAreVersionControlledWithApplicationCode\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEvolutionary Database Design\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://zerodha.tech/blog/scaling-with-common-sense/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eScaling with Common Sense by Zerodha\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://clig.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuidelines for Command line interface\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.microsoft.com/en-us/azure/architecture/framework/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAzure Well-Architected Framework\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.slideshare.net/slideshow/embed_code/key/d5w2hZIBJeFfu0\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChange Data Capture, Strangler fig and Saga Patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://martinfowler.com/articles/refactoring-external-service.html#SeparatingTheRemoteCallIntoAConnectionObject\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGateway pattern to encapsulate integration with external systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://xp123.com/articles/refactoring-whole-team-guide/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWhy refactoring?\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://openfeature.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpenFeature - Standardizing Feature Flagging for Everyone\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/featbit\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003efeatbit: Enterprise-level feature flag platform that you can self-host. Get started - free.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://gUnleash/unleash\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUnleash - Open-source feature management platform\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"api-development-security-cryptography\"\u003eAPI Development, Security, Cryptography\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://mathieu.fenniak.net/the-api-checklist/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Web API Checklist**\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mockoon/mockoon\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMockoon - Run Mock APIs locally\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/usebruno/bruno\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBruno - Opensource IDE For Exploring and Testing Api’s \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Microsoft/api-guidelines/blob/master/Guidelines.md#12-versioning\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eREST API Guidelines from Microsoft\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://fossa.com/product/open-source-vulnerability-management?ref\u0026#61;unzip.dev\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen Source Vulnerability Management\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/equinor/api-strategy/blob/master/docs/strategy.md\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eEquinors API Strategy and Guidelines\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://mathieu.fenniak.net/the-api-checklist/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eChecklist of Web APIs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://r.bluethl.net/how-to-design-better-apis\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGuidelines for designing better APIs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/shieldfy/API-Security-Checklist\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAPI Security Checklist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://google.aip.dev/100\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGoogles API Design Guidelines\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.readysetcloud.io/blog/allen.helton/the-importance-of-proper-serverless-api-design/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAPI Design for Serverless Apps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://owasp.org/www-project-top-ten/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOWASP - Top Ten Vulnerabilities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://curity.medium.com/api-security-checklist-a-guide-to-protecting-your-apis-c8fb5d385605\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAPI Security Checklist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/jedisct1/libsodium\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003elibsodium - Easy to use cryptography\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://techcommunity.microsoft.com/t5/core-infrastructure-and-security/demystifying-schannel/ba-p/259233\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSchannel in Windows for Strong Ciphers/Cryptography\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"training\"\u003eTraining\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://teachyourselfcs.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eTeach yourself Computer Science\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Developer-Y/cs-video-courses\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCollection of Video Courses on Computer Science\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://eugeneyan.com/writing/you-dont-need-another-mooc/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLearn by doing - You dont need another MOOC\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"distributed-systems\"\u003eDistributed Systems\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/danistefanovic/build-your-own-x#build-your-own-network-stack\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBuild your own (insert technology here)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://docs.google.com/document/d/1p4ZYQYM2VrMCR8K3T68JOMzWHlV-C8Jogrl9Ces77OA/edit?utm_sq\u0026#61;gjkgbut0r7\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eKubernetes for Everyone\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://servicemesh.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eThe Service Mesh: What Every Software Engineer Needs to Know about the Worlds Most Over-Hyped Technology\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lwn.net/SubscriberLink/905164/e1f4d4c1ce35f8b9/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eVery Brief intro to Container Orchestrators\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://azure.microsoft.com/en-us/resources/kubernetes-up-and-running/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eE-book kubernetes Up \u0026amp;amp; Running\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/aphyr/distsys-class\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eClass materials for a distributed systems lecture series\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://container.training/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eContainers - Training resources\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=http://dimafeng.com/2016/12/04/distributed-systems/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDistributed Systems Cheat Sheet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://vlfig.me/posts/microservices\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicroservices — architecture nihilism in minimalisms clothes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://riak.com/posts/technical/microservices-please-dont/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicroservices, pl. dont\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://world.hey.com/joaoqalves/disasters-i-ve-seen-in-a-microservices-world-a9137a51\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eDisasters from Microservices world\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.bernd-ruecker.com/saga-how-to-implement-complex-business-transactions-without-two-phase-commit-e00aa41a1b1b\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSaga: How to implement complex business transactions without two phase commit.\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://vasters.com/archive/Sagas.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eSagas by clement Vasters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mspnp/cloud-design-patterns\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRef. implementation of cloud design patterns\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"automation\"\u003eAutomation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://flow.microsoft.com/en-us/blog/automate-tasks-with-power-automate-desktop-for-windows-10-no-additional-cost/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMicrosoft Power Automate Desktop - Free Windows 10 Desktop Automation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://automatetheboringstuff.com/2e/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAutomate the Boring Stuff with Python\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.thoughtworks.com/insights/articles/four-bad-ways-use-rpa?utm_campaign\u0026#61;ping-jun19\u0026amp;utm_medium\u0026#61;email\u0026amp;utm_source\u0026#61;marketo\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eFour bad ways to use RPA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.datascienceatthecommandline.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eData Science at the Command line\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://robotframework.org/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eRobotFramework - Open source Test Automation and RPA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/mavaddat/wasp\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWASP - Windows Automation Snapin for PowerShell\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/stefanprodan/WebApiThrottle\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eWeb API rate limiting\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"tools-libraries\"\u003eTools, Libraries\u003c/h2\u003e\n\u003cp\u003e(\u003c/p\u003e","title":"Programming"},{"content":"Below is list of curated links for various technical topics, Awesome - de-facto repository covering wide range of technical topics. Awesome list of self hosted software List of Open source Alternatives to SASS Online Learning Perspectives Distributed Systems Design, Architecture Testing UI/UX Languages Go .NET/C# Python Databases MySQL Oracle PostgreSQL NoSQL Cloud Tech AI/Machine Learning Generative AI General Purpose tools Must follow Community Sites Hacker news Lobsters A list of SaaS, PaaS and IaaS offerings that have free tiers of interest to devops and infradev Miscellaneous OSS alternatives to Popular tools/Systems Open Source alternative tools Attention is all Manager need - Techniques and processes Gokey - Derived random passwords based on Master password Useful tools for Windows by Scott Hanselman Library of Free music Ergonomic Home office setup Consider upgrading a few PC/laptop Components like SSD How to use Google like a pro Pick Parts.Build Your PC.Compare And Share Privacy - Nice Overview and content Privacy tools for everyday user Hackers Diet Beam - Blog for a Project or Organization List of Greatest Novels of all time Cryptonomics by Tyler Cowen All About Public key Infrastructure(PKI) Most data work seems fundamentally Worthless 100 tips for Better Life ","permalink":"http://localhost:1313/links/home/","summary":"\u003ch4 id=\"below-is-list-of-curated-links-for-various-technical-topics\"\u003eBelow is list of curated links for various technical topics,\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=http://awesome.re/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome\u003c/a\u003e - de-facto repository covering wide range of technical topics.\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/awesome-selfhosted/awesome-selfhosted\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAwesome list of self hosted software\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/Runacapital/awesome-oss-alternatives\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Open source Alternatives to SASS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/onlearn/\n    \n    \n\u003eOnline Learning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/perspectives/\n    \n    \n\u003ePerspectives\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/programming/\n    \n    \n\u003eDistributed Systems Design, Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/testing/\n    \n    \n\u003eTesting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/uiux\n    \n    \n\u003eUI/UX\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/planguages/\n    \n    \n\u003eLanguages\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=/links/go/\n    \n    \n\u003eGo\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/dotnet/\n    \n    \n\u003e.NET/C#\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/python\n    \n    \n\u003ePython\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/databases/\n    \n    \n\u003eDatabases\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=/links/mysql/\n    \n    \n\u003eMySQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/oracle/\n    \n    \n\u003eOracle\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/postgresql/\n    \n    \n\u003ePostgreSQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/nosql/\n    \n    \n\u003eNoSQL\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/cloud/\n    \n    \n\u003eCloud Tech\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eAI/Machine Learning\n\u003cul\u003e\n\u003cli\u003e\u003ca href=/links/aiml/\n    \n    \n\u003eGenerative AI\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=/links/tools/\n    \n    \n\u003eGeneral Purpose tools\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"must-follow-community-sites\"\u003eMust follow Community Sites\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://news.ycombinator.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHacker news\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://lobste.rs\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLobsters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://free-for.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eA list of SaaS, PaaS and IaaS offerings that have free tiers of interest to devops and infradev\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"miscellaneous\"\u003eMiscellaneous\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=https://github.com/Runacapital/awesome-oss-alternatives\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOSS alternatives to Popular tools/Systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://degoogle.jmoore.dev/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eOpen Source alternative tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://philcalcado.com/2023/07/21/attention_is_all_a_manager_needs.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAttention is all Manager need  - Techniques and processes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/cloudflare/gokey\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eGokey - Derived random passwords based on Master password\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hanselman.com/blog/scott-hanselmans-2021-ultimate-developer-and-power-users-tool-list-for-windows\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eUseful tools for Windows by Scott Hanselman\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://cchound.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eLibrary of Free music\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://blog.amirathi.com/2019/08/18/ergonomic-office-setup/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eErgonomic Home office setup\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.hanselman.com/blog/consider-upgrading-a-few-pc-components-a-good-ssd-is-so-fast-its-not-even-funny\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eConsider upgrading a few PC/laptop Components like SSD\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://markodenic.com/use-google-like-a-pro/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHow to use Google like a pro\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://pcpartpicker.com/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePick Parts.Build Your PC.Compare And Share\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.eff.org/pages/tools\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrivacy - Nice Overview and content\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.privacytools.io/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003ePrivacy tools for everyday user\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.fourmilab.ch/hackdiet/www/tableofcontents1_6.html\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eHackers Diet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://github.com/planetscale/beam\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eBeam - Blog for a Project or Organization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://editoreric.com\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eList of Greatest Novels of all time\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://marginalrevolution.com/wp-content/uploads/2022/05/Cryptoeconomics-Modern-Principles.pdf\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eCryptonomics by Tyler Cowen\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://smallstep.com/blog/everything-pki/\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eAll About Public key Infrastructure(PKI)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://ludic.mataroa.blog/blog/most-data-work-seems-fundamentally-worthless\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eMost data work seems fundamentally Worthless\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=https://www.lesswrong.com/posts/7hFeMWC6Y5eaSixbD/100-tips-for-a-better-life\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003e100 tips for Better Life\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Useful Links"},{"content":"Background One of the key project(s) at my current organization is developed on .NET 4.6.1. It is developed as Modular Monolith. As part of it\u0026rsquo;s functionality, it supports different channels like Mobiles, Terminals and Web. For the Web channel, there was need to develop a Web application with,\nHigh availability Lightweight, High throughput (Need to support few thousand(s) active users) Accordingly, we have been exploring developing this Web Application in .NET core 3.1. However, it also means that we will have to use class libraries, targeted at .NET framework 4.6.1, in .NET core and vice-versa. How can this be done?\n.NET Standard to the rescue !!\n.Net Standard is a standard that enabled development of portable libraries usable across .NET versions.\nBelow is approach adopted to create usable libraries across .NET framework \u0026amp; .NET Core.\n.NET \u0026amp; IDE versions used are,\n.Net Framework 4.6.1 .Net core 3.1 Visual Studio 2015 - for .NET Framework 4.6.1 development Visual Studio Code - For .NET core development Step 1 -\nCreate a library that targets .NET Standard. Refer to Table on Implementation Support to decide on version that can be targetted at. In my case, it was 2.0 (Remember that higher the version, more APIs will be available to use). Do check .NET API browser, which lists API available with each version.\nUsing .NET core, use below command, dotnet new classlib \u0026lt;name\u0026gt;\nNote that, by default csproj file generated targets .NET Standard, but do confirm by checking in \u0026lt;name\u0026gt;.csproj file, It should have entry like,\n\u0026lt;PropertyGroup\u0026gt; \u0026lt;TargetFramework\u0026gt;netstandard2.0\u0026lt;/TargetFramework\u0026gt; \u0026lt;/PropertyGroup\u0026gt; Change the version of .NET Standard if required.\nAdd necessary code to the library and build it using, dotnet build\nCreate a Nuget Package using, dotnet pack This will generate \u0026lt;name\u0026gt;1.0.0.nupkg package in bin\\debug folder (assuming that you are using Debug mode)\nStep 2 -\nLets consume this library from console Application, using .NET Framework 4.6.1, in Visual Studio 2015.\nCreate New Console Application and ensure that it is targeted at .NET Framework 4.6.1 or Higher.\nBefore consuming .NET standard library, few steps are needed since VS 2015 only has legacy support for consuming .NET core artifacts also it does not have latest version of Nuget, so lets do below,\nInstall NuGet 3.6.0 or higher for VS 2015 from NuGet’s download site Install the \u0026ldquo;.NET Standard Support for Visual Studio 2015\u0026rdquo; from here Open the csproj file in Text Editor and add \u0026lt;ImplicitlyExpandDesignTimeFacades\u0026gt; tag as shown in below example, \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;Project ToolsVersion=\u0026#34;12.0\u0026#34; DefaultTargets=\u0026#34;Build\u0026#34; xmlns=\u0026#34;http://schemas.microsoft.com/developer/msbuild/2003\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;Configuration Condition=\u0026#34; \u0026#39;$(Configuration)\u0026#39; == \u0026#39;\u0026#39; \u0026#34;\u0026gt;Debug\u0026lt;/Configuration\u0026gt; \u0026lt;Platform Condition=\u0026#34; \u0026#39;$(Platform)\u0026#39; == \u0026#39;\u0026#39; \u0026#34;\u0026gt;AnyCPU\u0026lt;/Platform\u0026gt; \u0026lt;ProjectGuid\u0026gt;{75678902-8224-4222-BB33-756784B2FA29}\u0026lt;/ProjectGuid\u0026gt; \u0026lt;OutputType\u0026gt;Library\u0026lt;/OutputType\u0026gt; \u0026lt;RootNamespace\u0026gt;FooBar\u0026lt;/RootNamespace\u0026gt; \u0026lt;AssemblyName\u0026gt;FooBar\u0026lt;/AssemblyName\u0026gt; \u0026lt;TargetFrameworkVersion\u0026gt;v4.6.1\u0026lt;/TargetFrameworkVersion\u0026gt; ... \u0026lt;ImplicitlyExpandDesignTimeFacades\u0026gt;false\u0026lt;/ImplicitlyExpandDesignTimeFacades\u0026gt; \u0026lt;/PropertyGroup\u0026gt; Post update to file, VS 2015 will prompt to reload the project.\nNow we are set to consume .NET standard library, authored in .NET Core, in this project.\nStep 3 -\nWithin VS 2015, Goto Nuget Console and install the package created earlier. This link has steps to consume local nuget package(s). Happy Coding !!\n","permalink":"http://localhost:1313/posts/dotnetstandard/","summary":"\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003eOne of the key project(s) at my current organization is developed on .NET 4.6.1. It is developed as \u003ca href=https://www.youtube.com/watch?v\u0026#61;5OjqD-ow8GE\n    \n    target=_blank rel=\"noopener noreferrer\"\n\u003eModular Monolith\u003c/a\u003e. As part of it\u0026rsquo;s functionality, it supports different channels like Mobiles, Terminals and Web. For the \u003cem\u003eWeb\u003c/em\u003e channel, there was need to develop a Web application with,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHigh availability\u003c/li\u003e\n\u003cli\u003eLightweight, High throughput (Need to support few thousand(s) active users)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAccordingly, we have been exploring developing this Web Application in .NET core 3.1. However, it also means that we will have to use class libraries, targeted at .NET framework 4.6.1, in .NET core and vice-versa. How can this be done?\u003c/p\u003e","title":"Using .NET standard Assembly in .NET core and .NET Framework"},{"content":"Even Eric Evans explicitly states that DDD isn\u0026rsquo;t suitable for problems when there\u0026rsquo;s substantial technical complexity, but little business domain complexity. Using DDD is most beneficial when the complexity of the domain makes it challenging for the domain experts to communicate their needs to the software developers. By investing your time and effort into modeling the domain and coming up with a set of terminology that\u0026rsquo;s understood for each subdomain, the process of understanding and solving the problem becomes much simpler and smoother\nModeling is an intense examination of the problem space. Key to this is working together with the subject matter experts to identify the core domain and other subdomains that you\u0026rsquo;ll be tackling. Another important aspect of modeling is identifying what\u0026rsquo;s called bounded contexts. And within each of these bounded contexts, you focus on modeling a particular subdomain. As a result of modeling a bounded context, you\u0026rsquo;ll identify entities, value objects, aggregates, domain events, repositories, and more and how they interact with each other.\nthe ubiquitous language. A simple definition of a ubiquitous language is to come up with terms that\u0026rsquo;ll be commonly used when discussing a particular subdomain. And they will most likely be terms that come from the problem space, not the software world, but they have to be agreed upon so that as discussions move forward, there is no confusion or misunderstanding created by the terminology used by various members of the team\nProjects,\nFrontdesk.core - contains domain model Frontdesk.infrastructure - integration with database and rabbitmq Frontdesk.API - API Endpoints bounded contexts maintain their separation by giving each context its own team, codebase, and database schema.\nsubdomain is a view on the problem space, how you\u0026rsquo;ve chosen to break down the business or domain activity, whereas a bounded context represents the solution space, how the software and the development of that software has been organized. Quite often, these will match up perfectly, but not always.\nSame Entity can appear in more than one bounded context\nThe Domain Layer is responsible for representing concepts of the business, information about the business situation, and business rules. State that reflects the business situation is controlled and used here, even though the technical details of storing it are delegated to the infrastructure. This layer of the domain is the heart of business software.\nValue object is an object that is used to measure, quantify, or describe something in your domain. Rather than having an identity key, its identity is based on the composition of the values of all of its properties. Because the property values define a value object, it should be immutable. In other words, you shouldn\u0026rsquo;t be able to change any of the properties once you\u0026rsquo;ve created one of these objects. Instead, you would simply create another instance with the new values. If you need to compare two value objects to determine if they are equal, you should do so by comparing all of the values. Value objects may have methods and behavior, but they should never have side effects. Any methods on the value objects should only compute things; they shouldn\u0026rsquo;t change the state of the value object, since it\u0026rsquo;s immutable, or the system. If a new value is needed, a new value object should be returned. In DDD, both entities and value objects are typically defined as classes. Classes have advantages over structs when it comes to encapsulation and support for inheritance‑based extension and reuse.Value objects typically don\u0026rsquo;t exist alone, they\u0026rsquo;re usually applied to an entity to describe something about it.\ndomain services give you a place to put logic and behavior that you can\u0026rsquo;t find a home for in the entities and value objects in your domain.domain services should generally only be used if you don\u0026rsquo;t have an entity or value object where the behavior makes sense.domain services should be stateless, though they may have side effects. What this means is we should always be able to simply create a new instance of a service to perform an operation, rather than having to rely on any previous history that might have occurred within a particular service instance. But of course, the result of calling a method on a service might result in changes to the state of the system itself. These rules apply specifically to domain services which belong in the core of our application.\nSide effects are changes that occur in your application or any kind of interaction with the outside world.\nAggregates consist of one or more entities and value objects that change together. We need to treat them as a unit for data changes, and we need to consider the entire aggregate\u0026rsquo;s consistency before we apply changes.an aggregate is a cluster of associated objects that we treat as a unit for the purpose of data changes.\nA bidirectional association means that both objects can be understood only together. When application requirements do not call for traversal in both directions, adding a traversal direction reduces interdependence and simplifies the design.\nAn aggregate is a group of related objects that work together in a transaction. The root becomes the entry point through which you do any work with the aggregate, and the root also is what\u0026rsquo;s in charge of making sure that all of the rules that apply to that graph of objects are met. ‑Each of the rules that describes the state that the system must be in in order to be valid is called an invariant. Within our aggregates, we have objects that are related to one another. In DDD, we refer to these relationships as associations. If you use an ORM, you may hear the term navigation properties, which refers to those properties that reference the related objects in the model. And we talked about the importance of defaulting to one‑way relationships, which we also refer to as unidirectional relationships. ‑In addition to these important terms, Steve and I shared a lot of guidance around creating aggregates and roots in your domain models. Nobody wants to work with a big ball of mud. We use aggregates to organize our model. An aggregate is a set of related objects that live in a single transaction while encapsulating the rules and enforcing invariance of that transaction, making sure that the system is in a consistent state. When designing how related objects work together, your job will be easier with one‑way relationships. Use those as a default, and only introduce bidirectional navigation if you really need to. ‑And most importantly, don\u0026rsquo;t resist updating your model as you and your team of domain experts learn more about the domain. Hopefully, most of this will happen early on, and then just once in a while you might have a big breakthrough, like we did when we realized that the schedule made more sense as an aggregate root than trying to have each appointment be its own aggregate.\nbe sure to provide repositories only for aggregate roots that require direct access. And next, keep the clients focused on the model, while delegating all of the object storage and access concerns to the repositories.\neach domain event should be its own class\nDomain events are a type of object that actually represents something that occurred within the domain that other parts of the system may find interesting and want to tie their behavior to.\nanti‑corruption layers, which use a variety of design patterns to insulate our model from the design choices of other applications or bounded contexts.\n","permalink":"http://localhost:1313/posts/dddnotes/","summary":"\u003cp\u003eEven Eric Evans explicitly states that DDD isn\u0026rsquo;t suitable for problems when there\u0026rsquo;s substantial technical complexity, but little business domain complexity. Using DDD is most beneficial when the complexity of the domain makes it challenging for the domain experts to communicate their needs to the software developers. By investing your time and effort into modeling the domain and coming up with a set of terminology that\u0026rsquo;s understood for each subdomain, the process of understanding and solving the problem becomes much simpler and smoother\u003c/p\u003e","title":""}]