<!doctype html><html class=no-js lang=en><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Validating urls from 'Useful Links' section using bash / command line tools - Learnings in IT</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="http://localhost:1313/posts/urlhealthchecks/"><meta property="og:site_name" content="Learnings in IT"><meta property="og:title" content="Validating urls from 'Useful Links' section using bash / command line tools"><meta property="og:description" content="Background I started this blog, https://sachinsu.github.io few months back .
In this relatively short period of time, Blog has sizeable number of useful links across various categories in addition to the detailed blog post like this one.
As an ongoing activity, I think that it is necessary to verify links mentioned on this blog."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-10-15T10:25:04+05:30"><meta property="article:modified_time" content="2020-10-15T10:25:04+05:30"><meta property="article:tag" content="Bash"><meta property="article:tag" content="Grep"><meta property="article:tag" content="Sed"><meta property="article:tag" content="Curl"><meta itemprop=name content="Validating urls from 'Useful Links' section using bash / command line tools"><meta itemprop=description content="Background I started this blog, https://sachinsu.github.io few months back .
In this relatively short period of time, Blog has sizeable number of useful links across various categories in addition to the detailed blog post like this one.
As an ongoing activity, I think that it is necessary to verify links mentioned on this blog."><meta itemprop=datePublished content="2020-10-15T10:25:04+05:30"><meta itemprop=dateModified content="2020-10-15T10:25:04+05:30"><meta itemprop=wordCount content="553"><meta itemprop=keywords content="Bash,Grep,Sed,Curl"><meta name=twitter:card content="summary"><meta name=twitter:title content="Validating urls from 'Useful Links' section using bash / command line tools"><meta name=twitter:description content="Background I started this blog, https://sachinsu.github.io few months back .
In this relatively short period of time, Blog has sizeable number of useful links across various categories in addition to the detailed blog post like this one.
As an ongoing activity, I think that it is necessary to verify links mentioned on this blog."><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Learnings in IT" rel=home><div class="logo__item logo__text"><div class=logo__title>Learnings in IT</div><div class=logo__tagline>A Simple Technical Blog</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/about/><span class=menu__text>About</span></a></li><li class=menu__item><a class=menu__link href=/posts/><span class=menu__text>Blog</span></a></li><li class=menu__item><a class=menu__link href=/projects/><span class=menu__text>Projects</span></a></li><li class=menu__item><a class=menu__link href=https://gist.github.com/sachinsu><span class=menu__text>Gists</span></a></li><li class=menu__item><a class=menu__link href=/links/home><span class=menu__text>Useful Links</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Validating urls from 'Useful Links' section using bash / command line tools</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0a14 14 0 110 28 1 1 0 010-28m0 3a3 3 0 100 22 3 3 0 000-22m1 4h-2v8.4l6.8 4.4L22 18l-6-3.8z"/></svg><time class=meta__text datetime=2020-10-15T10:25:04+05:30>Oct 15 2020</time></div></div></header><div class="post__toc toc"><div class=toc__title>Page content</div><div class=toc__menu><nav id=TableOfContents><ul><li><a href=#background>Background</a></li><li><a href=#approach>Approach</a><ul><li><a href=#hat-tip>Hat Tip</a></li></ul></li></ul></nav></div></div><div class="content post__content clearfix"><h2 id=background>Background</h2><p>I started this blog, <a href=https://sachinsu.github.io target=_blank rel="noopener noreferrer">https://sachinsu.github.io</a> few months back .</p><p>In this relatively short period of time, Blog has sizeable number of useful links across various categories in addition to the detailed blog post like this one.</p><p>As an ongoing activity, I think that it is necessary to verify links mentioned on this blog.</p><p>So how can it be done ? obviously one way is to do it manually by visiting each link and updating/removing those that are no longer available. but there is always of better way of doing things.</p><p>The requirement is to,</p><ul><li>Parse all the files to links (being in Markdown links will be enclosed in brackets)</li><li>Send request to each link and verify if its active using HTTP Status (say 200 or 302)</li></ul><h2 id=approach>Approach</h2><p>Enter Automation !!</p><p>It is possible to write a utility/tool (or it might be already available) or can good old command line utlities be used for this task?</p><p>I decided to go for dos / shell script way and surprisingly all the necessary tools are already available.</p><p>Below is single command line that fulfils the requirement,</p><p><code>grep -E -i -w "http|https" *.md | sed 's/](http/\nhttp/g' | sed 's/)/\n/g' | grep ^http | xargs curl -s -I -w 'URL:%{url_effective} - %{http_code}\n' | grep ^URL:</code></p><p>In above chain,</p><ul><li><p>I am using excellent <a href=https://cmder.net/ target=_blank rel="noopener noreferrer">Cmder</a> console emulator, which also makes above nice tools (grep, sed etc.) available on Windows.</p></li><li><p><a href=https://man7.org/linux/man-pages/man1/grep.1.html target=_blank rel="noopener noreferrer">grep</a> -E -i -w &ldquo;http|https&rdquo; *.md - this command extracts all the lines containing <code>http(s)</code> from all the markdown (.md) files</p></li><li><p><a href=https://en.wikipedia.org/wiki/Pipeline_%28Unix%29 target=_blank rel="noopener noreferrer">Pipe |</a> - Pipe command streams output of command to the next one.</p></li><li><p><a href=https://en.wikipedia.org/wiki/Sed target=_blank rel="noopener noreferrer">sed</a> &rsquo;s/](http/\nhttp/g&rsquo; - this sed (stream editor) command adds line break before <code>http</code> for better extraction.</p></li><li><p><a href=https://en.wikipedia.org/wiki/Sed target=_blank rel="noopener noreferrer">sed</a> &rsquo;s/)/\n/g&rsquo; - this sed (stream editor) command removes trailing <code>)</code> bracket.</p></li><li><p><a href=https://man7.org/linux/man-pages/man1/grep.1.html target=_blank rel="noopener noreferrer">grep</a> ^http - this command removes all lines not containing <code>http</code>.</p></li><li><p><a href=https://man7.org/linux/man-pages/man1/xargs.1.html target=_blank rel="noopener noreferrer">xargs</a> - xargs is a command on Unix and most Unix-like operating systems used to build and execute commands from standard input.</p></li><li><p><a href=https://curl.haxx.se/ target=_blank rel="noopener noreferrer">curl</a> -s -I -w &lsquo;URL:%{url_effective} &mdash;> %{http_code}&rsquo;&rsquo; - previously used <code>xargs</code> command feeds each line (url) to this command as last argument. This command sends tcp request to the URL and prints out http status code along with URL.</p></li><li><p><a href=https://man7.org/linux/man-pages/man1/grep.1.html target=_blank rel="noopener noreferrer">grep</a> ^URL: - For some reason, CURL outputs content even if <code>-s</code> (silent) parameter is passed. Hence, this grep command is used to ignore all lines not containing URL and HTTP Status.</p></li></ul><p>The output is as below,</p><figure><img src=/images/urloutput.png><figcaption><h4>List of URLs with HTTP Status code</h4></figcaption></figure><p>So, It is possible to quickly come up with this using built-in tools if writing a program is not an option or cumbersome for task at hand.</p><p>As a next step, Plan is to automatically run this script as part of Github Build and notify in case of any URL is failing so that appropriate action can be taken.</p><h3 id=hat-tip>Hat Tip</h3><p>Suppose the requirement is to extract a particular text by recursively searching through files(for e.g. extract Target .NET Framework version across each of the project in a folder) then grep can be used as below,</p><p><code>grep -r --include "*.csproj" -oP "&lt;TargetFrameworkVersion(?:\s[^>]*)?>\K.*?(?=&lt;/TargetFrameworkVersion>)" .</code></p><p>This command will recursively search through all folders and print names of all those <code>.csproj</code> files containg <code>&lt;TargetFrameworkVersion></code> tag.</p><p>Let me know (in comments) if you are aware of any alternate better way of achieving this.</p><p>Happy Coding !!</p><hr><script src=https://utteranc.es/client.js repo=sachinsu/sachinsu.github.io issue-term=title label=blogcomment theme=github-light crossorigin=anonymous async></script></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M4 0h8s2 0 4 2l15 15s2 2 0 4L21 31s-2 2-4 0L2 16s-2-2-2-4V3s0-3 4-3m3 10a3 3 0 000-6 3 3 0 000 6"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/bash/ rel=tag>bash</a></li><li class=tags__item><a class="tags__link btn" href=/tags/grep/ rel=tag>grep</a></li><li class=tags__item><a class="tags__link btn" href=/tags/sed/ rel=tag>sed</a></li><li class=tags__item><a class="tags__link btn" href=/tags/curl/ rel=tag>curl</a></li></ul></div></footer></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/posts/connectiontimeouts/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Trobleshooting TCP Connection request time outs</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/posts/ninjabuildsystem/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Ninja - Using lightweight build system for Go projects</p></a></div></nav></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2024 Sachin Sunkle.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>